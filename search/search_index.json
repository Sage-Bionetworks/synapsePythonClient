{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Synapse Python/Command Line Client Documentation","text":""},{"location":"#notice-for-the-upcoming-v50-release","title":"Notice for the upcoming v5.0 release:","text":"<ul> <li>The upcoming v5.0 release will include a number of breaking changes. Take a look at this pubpub article detailing some of the changes.</li> <li>A release date has not been set. A number of these changes will be available within the 4.x.x versions hidden behind optional feature flags or different import paths. Any breaking changes will not be included until v5.0.</li> </ul> <p>The <code>synapseclient</code> package provides an interface to Synapse, a collaborative, open-source research platform that allows teams to share data, track analyses, and collaborate, providing support for:</p> <ul> <li>integrated presentation of data, code and text</li> <li>fine grained access control</li> <li>provenance tracking</li> </ul> <p>The <code>synapseclient</code> package lets you communicate with the cloud-hosted Synapse service to access data and create shared data analysis projects from within Python scripts or at the interactive Python console. Other Synapse clients exist for R, Java, and the web. The Python client can also be used from the command line.</p> <p>Installing this package will install <code>synapseclient</code>, <code>synapseutils</code> and the command line client. <code>synapseutils</code> contains beta features and the behavior of these features are subject to change.</p>"},{"location":"#whats-on-this-docs-site-for-you","title":"What\u2019s on this docs site for you?","text":"<ul> <li>Installation, Authentication, and Configuration of the <code>synapseclient</code></li> <li>Tutorials to get you and your team sharing, organizing, and discussing your scientific research</li> <li>How-To Guides showcasing the full power and functionality available to you</li> <li>API Reference of the programatic interfaces</li> <li>Further Reading to gain a deeper understanding of best practices and advanced use cases</li> <li>Our release notes</li> </ul>"},{"location":"#additional-background","title":"Additional Background","text":"<ul> <li>Read about Synapse\u2014how it got started and how it fits into the bigger data-sharing picture</li> <li>Gain a better understanding of Sage Bionetworks (that\u2019s us\u2014the nonprofit organization that created Synapse) and our other platforms that coincide with Synapse (such as portals)</li> <li>Learn about Synapse governance and how it protects data privacy</li> <li>Look up an unfamiliar term or acronym in our glossary</li> <li>See our help section for further assistance via the FAQ page, discussion forum, or contact information to get in touch</li> </ul>"},{"location":"news/","title":"Release Notes","text":""},{"location":"news/#notice-for-the-upcoming-v50-release","title":"Notice for the upcoming v5.0 release:","text":"<ul> <li>The upcoming v5.0 release will include a number of breaking changes. Take a look at this pubpub article detailing some of the changes.</li> <li>A release date has not been set. A number of these changes will be available within the 4.x.x versions hidden behind optional feature flags or different import paths. Any breaking changes will not be included until v5.0.</li> </ul>"},{"location":"news/#440-2024-07-05","title":"4.4.0 (2024-07-05)","text":""},{"location":"news/#highlights","title":"Highlights","text":"<ul> <li>Downloading files stability improvements:<ul> <li>The download algorithm has been re-written to focus on stability, reliability, and performance.</li> <li>Checkout the results of our benchmarking. Compared to v4.3.0 we are seeing a 10-50% decrease in overall transfer time for most test cases.</li> </ul> </li> <li>New Docker containers every release:</li> <li>Every production, release candidate, and develop release will create a new docker     image available here</li> <li>Credentials passed by command line argument will now be evaluated before credentials stored in the <code>~/.synapseConfig</code> file.</li> </ul>"},{"location":"news/#bug-fixes","title":"Bug Fixes","text":"<ul> <li>[SYNPY-1447] - <code>FutureWarning</code> received with latest pandas version when reading in a Synapse table as a data frame</li> </ul>"},{"location":"news/#stories","title":"Stories","text":"<ul> <li>[SYNPY-1457] - Resolve github build warnings for out-of-date dependencies</li> <li>[SYNPY-1476] - Improve stability of Synapse downloads</li> <li>[SYNPY-1479] - Create GHCR image for pre-release</li> <li>[SYNPY-1482] - Update annotations to use async/await instead of executor</li> <li>[SYNPY-1483] - Update credential chain to use user args first</li> <li>[SYNPY-1485] - Include isort with pre-commit</li> <li>[SYNPY-1487] - Fix missing coverage.xml bug</li> </ul>"},{"location":"news/#430-2024-05-30","title":"4.3.0 (2024-05-30)","text":""},{"location":"news/#highlights_1","title":"Highlights","text":"<ul> <li>New tutorial:<ul> <li>Uploading data in bulk is our newest tutorial. It covers the basics of working with manifest files to manage synapse projects.</li> </ul> </li> <li>Updates to syncToSynapse:<ul> <li>The <code>syncToSynapse</code> function has been refactored to improve performance and reliability.</li> <li>Minor behavior change: File entities will no longer have their version incremented during no-op changes. Only when file content, or fields on the file has been updated will a version number be incremented.</li> <li>Optional booleans <code>merge_existing_annotations</code> and <code>associate_activity_to_new_version</code> have been added. Both are used to give more fine tuned control when working with this interface.</li> <li>Check out the changes in the reference docs.</li> </ul> </li> </ul>"},{"location":"news/#bug-fixes_1","title":"Bug Fixes","text":"<ul> <li>[SYNPY-1456] - Flaky Integration tests due to duplicate entity names</li> <li>[SYNPY-1466] - user-agent not being set properly for synapse command line client</li> <li>[SYNPY-1474] - Order of credentials being used does not match docstring</li> </ul>"},{"location":"news/#stories_1","title":"Stories","text":"<ul> <li>[SYNPY-1356] - Refactor <code>syncToSynapse</code></li> <li>[SYNPY-1384] - Uploading data in bulk</li> <li>[SYNPY-1427] - Upgrade Pytest to v7 or later</li> <li>[SYNPY-1470] - Make sure that sonarcloud executes even when tests fail</li> </ul>"},{"location":"news/#420-2024-04-17","title":"4.2.0 (2024-04-17)","text":""},{"location":"news/#highlights_2","title":"Highlights","text":"<ul> <li>Continued Async Support:<ul> <li>Multi-threaded Uploads Are Now Async: This change optimizes the upload process to handle multiple tasks simultaneously: uploading file parts concurrently, performing MD5 checksum calculations in separate processes, and making HTTP calls asynchronously. Further, memory management techniques were implemented to prevent crashes on low-resource EC2 instances. Benchmark results can be found here.</li> <li>HTTPX Support &amp; Async Client Instances: In this update, support for the HTTPX library has been introduced, enhancing the functionality of Synapse with two new async client instances for seamless interaction with Synapse and Storage Providers. Additionally, the retry and back-off mechanisms have been revamped to improve reliability and performance, ensuring smoother operation even under challenging network conditions.</li> </ul> </li> </ul>"},{"location":"news/#bug-fixes_2","title":"Bug Fixes","text":"<ul> <li>[SYNPY-1453] - Cache bug: AttributeError: 'dict' object has no attribute 'endswith'</li> </ul>"},{"location":"news/#stories_2","title":"Stories","text":"<ul> <li>[SYNPY-1417] - Finish 'Annotation' OOP model</li> <li>[SYNPY-1419] - Add HTTPX dependency and an async client instance</li> <li>[SYNPY-1420] - Migrate multi-threaded uploads to Async</li> <li>[SYNPY-1465] - Adding Annotations to docs</li> </ul>"},{"location":"news/#411-2024-02-28","title":"4.1.1 (2024-02-28)","text":""},{"location":"news/#highlights_3","title":"Highlights","text":"<ul> <li>New Downloading Data in Bulk Tutorial<ul> <li>See Downloading data in bulk tutorial for more details on downloading data in bulk from Synapse.</li> </ul> </li> <li>Downloading Files Troubleshooting Improvement<ul> <li>Improved error logging for when users are downloading files using commands like <code>get-download-list</code> from Synapse.</li> </ul> </li> </ul>"},{"location":"news/#bug-fixes_3","title":"Bug Fixes","text":"<ul> <li>[SYNPY-1443] - Storing container without retrieving it before setting files/folder breaks</li> <li>[SYNPY-1445] - Improve error handling when unable to download file</li> </ul>"},{"location":"news/#stories_3","title":"Stories","text":"<ul> <li>[SYNPY-1383] - Downloading data in bulk documentation</li> <li>[SYNPY-1442] - Log exception when <code>get_download_list</code> fails</li> </ul>"},{"location":"news/#410-2024-02-21","title":"4.1.0 (2024-02-21)","text":""},{"location":"news/#highlights_4","title":"Highlights","text":"<ul> <li> <p>New Interfaces:</p> <ul> <li>Combines data and behavior into a single class, simplifying the understanding and usage of the system's models. Review the available synchronous and asynchronous models.</li> <li>New Interface: Introduced a revamped interface in the Synapse Python Client, shifting from a functional programming approach to an object-oriented one.</li> <li>Enhanced Developer Experience: This change highlights much needed quality of life updates for developers. Improved autocomplete, hoverdocs, and examples in docstrings provide a significantly better coding experience.</li> <li>Asyncio Support: Introduced support for asyncio, enabling more efficient use of system resources and enhancing performance for IO-bound tasks.</li> <li>Extensibility: Laying the foundation for an extensible platform, facilitating easier addition of new features, and improvements to the Synapse Python Client.</li> </ul> </li> <li> <p>synapseutils.walk Improvement:</p> <ul> <li>Improved performance for synapseutils.walk.</li> </ul> </li> <li> <p>Pandas Range Expansion:</p> <ul> <li>Expanded pandas range to <code>&gt;=1.5, &lt;3.0</code>.</li> </ul> </li> <li> <p>Version Notation Support:</p> <ul> <li>Using <code>syn123.version</code> notation is now supported with syn.get, synapseutils.syncFromSynapse, and syn.setProvenance. This enhances consistency in version management across various activities.</li> </ul> </li> </ul>"},{"location":"news/#bug-fixes_4","title":"Bug Fixes","text":"<ul> <li>[SYNPY-448] - synapseutils.changeFileMetaData should allow changing Synapse name (like web client) for consistency</li> <li>[SYNPY-1253] - syn.store(forceVersion=False) created new versions of the same file</li> <li>[SYNPY-1398] - syncToSynapse doesn't recognize a \"valid\" provenance synapse id</li> <li>[SYNPY-1412] - Issue importing synapseutils in notebook</li> </ul>"},{"location":"news/#stories_4","title":"Stories","text":"<ul> <li>[SYNPY-1326] - Update pandas dependency to support pandas 2.1</li> <li>[SYNPY-1344] - Implement 'Activity' model into OOP</li> <li>[SYNPY-1347] - Implement 'Team' model into OOP</li> <li>[SYNPY-1348] - Implement 'UserProfile' model into OOP</li> <li>[SYNPY-1401] - Avoid repeatedly calling syn.get in <code>_helpWalk</code></li> <li>[SYNPY-1414] - Finish 'Project' OOP model</li> <li>[SYNPY-1415] - Finish 'Folder' OOP model</li> <li>[SYNPY-1416] - Finish 'File' OOP model</li> <li>[SYNPY-1434] - Release python client 4.1</li> </ul>"},{"location":"news/#400-2024-01-12","title":"4.0.0 (2024-01-12)","text":""},{"location":"news/#highlights_5","title":"Highlights","text":"<ul> <li>Only authentication through Personal Access Token (aka: Authentication bearer token) is supported. Review the     Authentication document     for information on setting up your usage of a Personal Access Token to authenticate     with Synapse.</li> <li>Date type Annotations on Synapse entities are now timezone aware. Review our     reference documentation for Annotations.     The <code>pytz</code> package is recommended if you regularly     work with data across time zones.<ul> <li>If you do not set the <code>tzinfo</code> field on a date or datetime instance we will use the     timezone of the machine where the code is executing.</li> <li>If you are using the     Manifest TSV     for bulk actions on your projects you'll now see that     synapseutils.sync.syncFromSynapse will store dates as <code>YYYY-MM-DDTHH:MM:SSZ</code>.     Review our documentation for an     example manifest file.     Additionally, if you'd like to upload an annotation in a specific timezone please     make sure that it is in ISO 8601 format.     If you do not specify a timezone it is assumed to use the timezone of the machine     where the code is executing.</li> </ul> </li> <li>Support for annotations with multiple values through the Manifest TSV     with the usage of a comma delimited bracket wrapped list. Any manifest files wishing     to take advantage of multi-value annotations need to match this format. Examples:<ul> <li><code>[\"Annotation, with a comma\", another annotation]</code></li> <li><code>[1,2,3]</code></li> <li><code>[2023-12-04T07:00:00Z,2000-01-01T07:00:00Z]</code></li> </ul> </li> <li>Migration and expansion of the docs site! You'll see that the look, feel, and flow     of all of the information on this site has been touched. As we move forward we hope     that you'll     provide the Data Processing and Engineering team feedback on areas we can improve.</li> <li>Expansion of the available Python Tutorials can be found     starting here.</li> </ul>"},{"location":"news/#bug-fixes_5","title":"Bug Fixes","text":"<ul> <li>[SYNPY-1357] - Manifest does not support annotations with multiple values</li> <li>[SYNPY-1358] - Date and datetime annotations do not account for timezone</li> <li>[SYNPY-1387] - Update High level best practices for project structure document</li> </ul>"},{"location":"news/#stories_5","title":"Stories","text":"<ul> <li>[SYNPY-955] - Remove the ability to login using session token</li> <li>[SYNPY-1182] - Remove ability to manage API keys and to use API keys for auth' in R/Py/CLI</li> <li>[SYNPY-1225] - Remove the use of all authentication methods except authToken in the python client for security</li> <li>[SYNPY-1302] - Deprecate getPermissions and create get_permissions</li> <li>[SYNPY-1321] - Benchmark download speeds</li> <li>[SYNPY-1334] - Review and revamp the getting started documentation for the client</li> <li>[SYNPY-1365] - Finish migration of docstrings from sphinx to google style</li> <li>[SYNPY-1392] - Remove all older functions that have been labeled to be deprecated</li> <li>[SYNPY-1394] - Python client release 4.0.0</li> </ul>"},{"location":"news/#320-2023-11-27","title":"3.2.0 (2023-11-27)","text":""},{"location":"news/#highlights_6","title":"Highlights","text":"<ul> <li>Introduction of OpenTelemetry within the client. See information in     the README for further details.</li> <li>Added 2 new functions <code>get_user_profile_by_username</code> and     <code>get_user_profile_by_id</code> to handle for use cases when a     username is a number.</li> <li>Updated the local .cacheMap that is used to track local files     downloaded from Synapse to include the MD5 of the file when there is     a cache miss. This is used to determine if the file has changed     since we cannot fully rely on the file's modified date only.</li> <li>Include a progress indicator when downloading files via FTP.</li> <li>Benchmarking of upload speeds to allow us to make data driven     decisions and comparisons.</li> </ul>"},{"location":"news/#bug-fixes_6","title":"Bug Fixes","text":"<ul> <li>[SYNPY-1186]     When a username is a number, getUserProfile cannot retrieve the     user.</li> <li>[SYNPY-1316]     Calling <code>syn.get</code> with     <code>ifcollision='overwrite.local</code> does not always     overwrite previous file</li> <li>[SYNPY-1319]     Unstable test: test_download_file_false</li> <li>[SYNPY-1333]     synapse get on a file in a ftp server doesn't seem to be     downloading</li> </ul>"},{"location":"news/#stories_6","title":"Stories","text":"<ul> <li>[SYNPY-816]     Unstable test: integration.test_evaluations.test_teams</li> <li>[SYNPY-1274]     Set up pre-commit in github actions</li> <li>[SYNPY-1305]     Collect trace data for integration tests</li> <li>[SYNPY-1304]     Introduction of OpenTelemetry</li> <li>[SYNPY-1320]     Benchmark upload speeds</li> </ul>"},{"location":"news/#311-2023-10-30","title":"3.1.1 (2023-10-30)","text":""},{"location":"news/#highlights_7","title":"Highlights","text":"<ul> <li>A fix to dowloads when file names match but content does not when     <code>ifcollision=overwrite.local</code></li> </ul>"},{"location":"news/#bug-fixes_7","title":"Bug Fixes","text":"<ul> <li>[SYNPY-1316]     Calling <code>syn.get</code> with     <code>ifcollision='overwrite.local</code> does not always     overwrite previous file</li> <li>[SYNPY-1298]     Resolve unstable integration tests</li> </ul>"},{"location":"news/#310-2023-10-20","title":"3.1.0 (2023-10-20)","text":""},{"location":"news/#highlights_8","title":"Highlights","text":"<ul> <li>A fix to authentication when using a Personal Access token or API     Key. <code>synapse login</code> and <code>synapse config</code>     correctly work as a result.</li> <li>Replacement of custom <code>@memoize</code> decorator with     <code>@functools.lru_cache</code> decorator.</li> <li>Introduction of pipfile for easy creation of a virtual environment     for development.</li> </ul>"},{"location":"news/#bug-fixes_8","title":"Bug Fixes","text":"<ul> <li>[SYNPY-1283]     Fix dead link in docs</li> <li>[SYNPY-1296]     Unable to log into synapse only with auth token</li> </ul>"},{"location":"news/#stories_7","title":"Stories","text":"<ul> <li>[SYNPY-49]     py: getPermissions and permissions via group membership</li> <li>[SYNPY-967]     Replace @memoize annotation in python client with     @functools.lru_cache</li> <li>[SYNPY-1282]     Add type hints to 5 functions in client.py</li> <li>[SYNPY-1285]     Create pipenv lock file for synapsePythonClient</li> <li>[SYNPY-1293]     Address Dependabot security vulnerabilities</li> <li>[SYNPY-1295]     Doc: Add config command to authentication section in Synapse doc</li> </ul>"},{"location":"news/#300-2023-09-09","title":"3.0.0 (2023-09-09)","text":""},{"location":"news/#highlights_9","title":"Highlights","text":"<ul> <li>Removed all camel case or non-standard single dash long command line     interface (cli) parameters. Example: command line arguments like     <code>-parent</code> will become <code>--parent</code>. Commands     that support camel case like <code>--parentId</code> will be     changed to <code>--parent-id</code>.</li> <li>Remove support for Python 3.7 due to its end of life and support     Python 3.11</li> <li>Support Synapse JSON schema services</li> </ul>"},{"location":"news/#bug-fixes_9","title":"Bug Fixes","text":"<ul> <li>[SYNPY-570]     warning messages when downloading if files in the cache already</li> <li>[SYNPY-622]     Constructor for SubmissionStatus is not correctly implemented</li> <li>[SYNPY-1242]     _loggedIn() function doesn't work</li> <li>[SYNPY-1269]     Integration test failures against release-456</li> <li>[SYNPY-1271]     Integration test failure against release-458</li> </ul>"},{"location":"news/#stories_8","title":"Stories","text":"<ul> <li>[SYNPY-737]     deprecate single dash, multi-letter named params in command line     client</li> <li>[SYNPY-1012]     Synapse Command Line documentation is not distinct from Synapse     Python Client documentations</li> <li>[SYNPY-1213]     Add \\\"public\\\" and \\\"registered users\\\" group to setPermissions doc</li> <li>[SYNPY-1245]     Fix old links to synapse docs</li> <li>[SYNPY-1246]     Support Python 3.11</li> <li>[SYNPY-1122]     JSON Schema support</li> <li>[SYNPY-1255]     Support pandas 2.0 in python client</li> <li>[SYNPY-1270]     Deprecate the use of <code>date_parser</code> and     <code>parse_date</code> in [pd.read_csv` in table     module</li> <li>[SYNPY-716]     Deprecate and remove asInteger()</li> <li>[SYNPY-1227]     Run <code>black</code> the Python auto formatter on the files</li> </ul>"},{"location":"news/#272-2023-06-02","title":"2.7.2 (2023-06-02)","text":""},{"location":"news/#highlights_10","title":"Highlights","text":"<ul> <li>[SYNPY-1267]     -Lock down urllib3</li> <li>[SYNPY-1268]     -Add deprecation warning for non-support login arguments</li> <li>Next major release (3.0.0)...<ul> <li>Support only pandas <code>\\&gt;=</code> 1.5</li> <li>Remove support for Python 3.7 due to its end of life.</li> <li>There will be major cosmetic changes to the cli such as removing     all camel case or non-standard single dash long command line     interface (cli) parameters. Example: command line arguments like     <code>-parent</code> will become [--parent<code>.     Commands that support camel case like</code>--parentId<code>will be changed to</code>--parent-id`.</li> </ul> </li> </ul>"},{"location":"news/#271-2023-04-11","title":"2.7.1 (2023-04-11)","text":""},{"location":"news/#highlights_11","title":"Highlights","text":"<ul> <li> <p>Locked down pandas version to only support pandas <code>\\&lt;</code>     1.5</p> </li> <li> <p>Next major release (3.0.0)...</p> <ul> <li>Support only pandas <code>\\&gt;=</code> 1.5</li> <li>Remove support for Python 3.7 due to its end of life.</li> <li>There will be major cosmetic changes to the cli such as     removing all camel case or non-standard single dash long     command line interface (cli) parameters. Example: command line     arguments like <code>-parent</code> will become     <code>\\--parent</code>. Commands that support camel case like     <code>\\--parentId</code> will be changed to     <code>\\--parent-id</code>.</li> </ul> </li> </ul>"},{"location":"news/#270-2022-09-16","title":"2.7.0 (2022-09-16)","text":""},{"location":"news/#highlights_12","title":"Highlights","text":"<ul> <li> <p>Added support for Datasets</p> <pre><code># from python\nimport synapseclient\nimport synapseutils\nsyn = synapseclient.login()\ndataset_items = [\n    {'entityId': \"syn000\", 'versionNumber': 1},\n    {...},\n]\ndataset = synapseclient.Dataset(\n    name=\"My Dataset\",\n    parent=project,\n    dataset_items=dataset_items\n)\ndataset = syn.store(dataset)\n# Add/remove specific Synapse IDs to/from the Dataset\ndataset.add_item({'entityId': \"syn111\", 'versionNumber': 1})\ndataset.remove_item(\"syn000\")\ndataset = syn.store(dataset)\n# Add a single Folder to the Dataset\n# this will recursively add all the files in the folder\ndataset.add_folder(\"syn123\")\n# Add a list of Folders, overwriting any existing files in the dataset\ndataset.add_folders([\"syn456\", \"syn789\"], force=True)\ndataset = syn.store(dataset)\n# Create snapshot version of dataset\nsyn.create_snapshot_version(\n    dataset.id,\n    label=\"v1.0\",\n    comment=\"This is version 1\"\n)\n</code></pre> </li> <li> <p>Added support for downloading from download cart. You can use this     feature by first adding items to your download cart on Synapse.</p> <pre><code># from python\nimport synapseclient\nimport synapseutils\nsyn = synapseclient.login()\nmanifest_path = syn.get_download_list()\n</code></pre> <pre><code># from command line\nsynapse get-download-list\n</code></pre> </li> <li> <p>Next major release (3.0.0) there will be major cosmetic changes to     the cli such as removing all camel case or non-standard single dash     long command line interface (cli) parameters. Example: command line     arguments like <code>-parent</code> will become     <code>\\--parent</code>. Commands that support camel case like     <code>\\--parentId</code> will be changed to     <code>\\--parent-id</code>.</p> </li> </ul>"},{"location":"news/#bug-fixes_10","title":"Bug Fixes","text":"<ul> <li>[SYNPY-226]     -isConsistent fails as parameter for table query</li> <li>[SYNPY-562]     -Make sure SQL functions, including \\\"year\\\", are quoted correctly</li> <li>[SYNPY-1031]     -File version increments with 400 client error</li> <li>[SYNPY-1219]     -Update Entity class to be compatible with the new Dataset entity</li> <li>[SYNPY-1224]     -Correct SynapseUnmetAccessRestrictions message</li> <li>[SYNPY-1237]     -as_table_columns function is mishandling mixed data types</li> </ul>"},{"location":"news/#stories_9","title":"Stories","text":"<ul> <li>[SYNPY-63]     -py: use metaclass to replace the _entity_type_to_class hack</li> <li>[SYNPY-992]     -synapseutils changeFileMetadata missing syn parameter docstring</li> <li>[SYNPY-1175]     -Programmatic Support for Download V2 via Py Client</li> <li>[SYNPY-1193]     -Support Datasets functionality</li> <li>[SYNPY-1221]     -Set up gh-action: black, the python auto formatter on the python     client</li> </ul>"},{"location":"news/#tasks","title":"Tasks","text":"<ul> <li>[SYNPY-566]     -Clarify expected list format for sync manifest</li> <li>[SYNPY-1053]     -Increase documentation of forceVersion in syncToSynapse</li> <li>[SYNPY-1145]     -Link to manifest format in CLI sync command usage help</li> <li>[SYNPY-1226]     -Leverage <code>ViewBase</code> for Datasets instead of     <code>SchemaBase</code></li> <li>[SYNPY-1235]     -Create codeql scanning workflow</li> <li>[SYNPY-1207]     -Support syn.get() on a dataset</li> </ul>"},{"location":"news/#260-2022-04-19","title":"2.6.0 (2022-04-19)","text":""},{"location":"news/#highlights_13","title":"Highlights","text":"<ul> <li> <p>Next major release (3.0.0) there will be major cosmetic changes to     the cli such as removing all camel case or non-standard single dash     long command line interface (cli) parameters. Example: command line     arguments like <code>-parent</code> will become     <code>\\--parent</code>. Commands that support camel case like     <code>\\--parentId</code> will be changed to     <code>\\--parent-id</code>.</p> </li> <li> <p>Added support for materialized views</p> <pre><code># from python\nimport synapseclient\nimport synapseutils\nsyn = synapseclient.login()\nview = synapseclient.MaterializedViewSchema(\n    name=\"test-material-view\",\n    parent=\"syn34234\",\n    definingSQL=\"SELECT * FROM syn111 F JOIN syn2222 P on (F.PATIENT_ID = P.PATIENT_ID)\"\n)\nview_ent = syn.store(view)\n</code></pre> </li> <li> <p>Removed support for Python 3.6 and added support for Python 3.10</p> </li> <li> <p>Add function to create Synapse config file</p> <pre><code># from the command line\nsynapse config\n</code></pre> </li> </ul>"},{"location":"news/#bug-fixes_11","title":"Bug Fixes","text":"<ul> <li>[SYNPY-1204]     -Python 3.10 compatibility</li> </ul>"},{"location":"news/#stories_10","title":"Stories","text":"<ul> <li>[SYNPY-728]     -Improve error message when pandas is not available</li> <li>[SYNPY-974]     -Documentation for generateManifest</li> <li>[SYNPY-1209]     -Support for MaterializedViews in Py Client</li> </ul>"},{"location":"news/#tasks_1","title":"Tasks","text":"<ul> <li>[SYNPY-1174]     -Add function to create Synapse config file</li> <li>[SYNPY-1176]     -syncToSynapse aborted + silent failure of file upload</li> <li>[SYNPY-1184]     -Add <code>includeTypes</code> to <code>synapseutils.walk()</code></li> <li>[SYNPY-1189]     -Document \\\"maximumListLength\\\" parameter for Column</li> <li>[SYNPY-1196]     -Expose <code>forceVersion</code> on     <code>changeFileMetadata</code></li> <li>[SYNPY-1205]     -Python 3.6 EOL - Remove support for 3.6</li> <li>[SYNPY-1212]     -Include <code>dataset</code> as an entity type to return in     getChildren()</li> </ul>"},{"location":"news/#251-2021-12-02","title":"2.5.1 (2021-12-02)","text":""},{"location":"news/#highlights_14","title":"Highlights","text":"<ul> <li>Next major release (3.0.0) there will be major cosmetic changes to     the cli such as removing all camel case or non-standard single dash     long command line interface (cli) parameters. Example: command line     arguments like <code>-parent</code> will become     <code>\\--parent</code>. Commands that support camel case like     <code>\\--parentId</code> will be changed to     <code>\\--parent-id</code>.</li> </ul>"},{"location":"news/#bug-fixes_12","title":"Bug Fixes","text":"<ul> <li>[SYNPY-1197]     -Schema is a string and strings don't have columns_to_store     attributes</li> </ul>"},{"location":"news/#stories_11","title":"Stories","text":"<ul> <li>[SYNPY-772]     -update statement that appears on PyPi about Synapse to be     consistent</li> <li>[SYNPY-997]     -Typos in Views documentation</li> </ul>"},{"location":"news/#250-2021-10-05","title":"2.5.0 (2021-10-05)","text":""},{"location":"news/#highlights_15","title":"Highlights","text":"<ul> <li> <p>Added ability to generate a manifest file from your local directory     structure.</p> <pre><code># from the command line\n# write the manifest to manifest.tsv\nsynapse manifest --parent-id syn123 --manifest-file ./manifest.tsv /path/to/local/directory\n# stdout\nsynapse manifest --parent-id syn123 /path/to/local/directory\n</code></pre> </li> <li> <p>Added ability to pipe manifest stdout into sync function.</p> <pre><code># from the command line\nsynapse manifest --parent-id syn123 ./docs/ | synapse sync -\n</code></pre> </li> <li> <p>Added ability to return summary statistics of csv and tsv files     stored in Synapse.</p> <pre><code># from python\nimport synapseclient\nimport synapseutils\nsyn = synapseclient.login()\nstatistics = synapseutils.describe(syn=syn, entity=\"syn12345\")\nprint(statistics)\n{\n    \"column1\": {\n        \"dtype\": \"object\",\n        \"mode\": \"FOOBAR\"\n    },\n    \"column2\": {\n        \"dtype\": \"int64\",\n        \"mode\": 1,\n        \"min\": 1,\n        \"max\": 2,\n        \"mean\": 1.4\n    },\n    \"column3\": {\n        \"dtype\": \"bool\",\n        \"mode\": false,\n        \"min\": false,\n        \"max\": true,\n        \"mean\": 0.5\n    }\n}\n</code></pre> </li> <li> <p>Next major release (3.0.0) there will be major cosmetic changes to     the cli such as removing all camel case or non-standard single dash     long command line interface (cli) parameters. Example: command line     arguments like <code>-parent</code> will become     <code>\\--parent</code>. Commands that support camel case like     <code>\\--parentId</code> will be changed to     <code>\\--parent-id</code>.</p> </li> </ul>"},{"location":"news/#bug-fixes_13","title":"Bug Fixes","text":"<ul> <li>[SYNPY-669]     -Signing of Synapse authentication header does not correctly URL     encode the URL path</li> <li>[SYNPY-770]     -Files failing to upload using syncToSynapse</li> <li>[SYNPY-1123]     -All tables erroring when indexing</li> <li>[SYNPY-1146]     -Error writing Booleans from Python dataframes into Boolean columns     in a Synapse table</li> <li>[SYNPY-1156]     -datetimes in a Pandas dataframe are not properly stored to Synapse</li> </ul>"},{"location":"news/#stories_12","title":"Stories","text":"<ul> <li>[SYNPY-726]     -mirror local folder structure for bulk upload</li> <li>[SYNPY-1163]     -Expose synId with syn get -r</li> <li>[SYNPY-1165]     -Generate manifest template from local folder structure</li> <li>[SYNPY-1167]     -Support for Quick Summary Statistics on CSV and TSV files</li> </ul>"},{"location":"news/#tasks_2","title":"Tasks","text":"<ul> <li>[SYNPY-1169]     -Integration tests failures in develop branch against stack-371</li> <li>[SYNPY-1172]     -Passing a pandas dataframe with a column called \\\"read\\\" breaks the     type parsing in as_table_columns()</li> <li>[SYNPY-1173]     -Support DATE_LIST, ENTITYID_LIST, USERID_LIST table columns</li> <li>[SYNPY-1188]     -Support piping of <code>synapse manifest</code> stdout in <code>synapse sync</code> function</li> </ul>"},{"location":"news/#240-2021-07-08","title":"2.4.0 (2021-07-08)","text":""},{"location":"news/#highlights_16","title":"Highlights","text":"<ul> <li> <p>Added ability to authenticate from a <code>SYNAPSE_AUTH_TOKEN</code>     environment variable set with a valid personal access     token.</p> <pre><code># e.g. set environment variable prior to invoking a Synapse command or running a program that uses synapseclient\nSYNAPSE_AUTH_TOKEN='&lt;my_personal_access_token&gt;' synapse &lt;subcommand options&gt;\n</code></pre> <p>The environment variable will take priority over credentials in the user's <code>.synapseConfig</code> file or any credentials saved in a prior login using the remember me option.</p> <p>See here for more details on usage.</p> </li> <li> <p>Added ability to silence all console output.</p> <pre><code># from the command line, use the --silent option with any synapse subcommand, here it will suppress the download progress indicator\nsynapse --silent get &lt;synid&gt;\n</code></pre> <pre><code># from code using synapseclient, pass the silent option to the Synapse constructor\nimport synapseclient\n\nsyn = synapseclient.Synapse(silent=True)\nsyn.login()\nsyn.get(&lt;synid&gt;)\n</code></pre> </li> <li> <p>Improved robustness during downloads with unstable connections.     Specifically the client will automatically recover when encoutering     some types of network errors that previously would have caused a     download to start over as indicated by a reset progress bar.</p> </li> </ul>"},{"location":"news/#bug-fixes_14","title":"Bug Fixes","text":"<ul> <li>[SYNPY-198]     -get: Unmet access requirement should not raise error if entity not     downloadable</li> <li>[SYNPY-959]     -FileEntity 'path' property has wrong separator in Windows</li> <li>[SYNPY-1113]     -Confusing error when putting the positional FILE at the end of the     synapse store command with an optional n-arg</li> <li>[SYNPY-1128]     -failures downloading 14G vcf file</li> <li>[SYNPY-1130]     -Migration tool trying to move URL-linked data</li> <li>[SYNPY-1134]     -500 error during part copy to AWS presigned url</li> <li>[SYNPY-1135]     -Exceeding part limit during AD Migration</li> <li>[SYNPY-1136]     -Connection aborted to AWS part copy to presigned url during AD     Migration</li> <li>[SYNPY-1141]     -synapse get command line nargs usage/error</li> <li>[SYNPY-1150]     -Boolean-like string columns being reformatted (TRUE/FALSE to     True/False)</li> <li>[SYNPY-1158]     -race condition in test_caching.py#test_threaded_access</li> <li>[SYNPY-1159]     -logging in with an email address and an authToken gives spurious     error</li> <li>[SYNPY-1161]     -ChunkEncodingError encountered from external collaborator during a     synapseclient download</li> </ul>"},{"location":"news/#improvements","title":"Improvements","text":"<ul> <li>[SYNPY-638]     -add after date to cache purge</li> <li>[SYNPY-929]     -silent parameter for all functions which default to writing to     stdout</li> <li>[SYNPY-1068]     -Should show some progress indicator during upload md5 calculation</li> <li>[SYNPY-1125]     -Allow login with environment variables</li> <li>[SYNPY-1138]     -When using boto3 client to upload a file, also include ACL to give     bucket owner full access</li> </ul>"},{"location":"news/#tasks_3","title":"Tasks","text":"<ul> <li>[SYNPY-948]     -command line client set-annotations does not return proper error     code when there's a problem</li> <li>[SYNPY-1024]     -remove reference to deprecated 'status' field from Evaluation</li> <li>[SYNPY-1143]     -indicate in CLI doc's that select statement requires double quotes</li> </ul>"},{"location":"news/#231-2021-04-13","title":"2.3.1 (2021-04-13)","text":""},{"location":"news/#highlights_17","title":"Highlights","text":"<ul> <li> <p>Entities can be annotated with boolean datatypes, for example:</p> <pre><code>file = synapseclient.File('/path/to/file', parentId='syn123', synapse_is_great=True)\nsyn.store(file)\n</code></pre> </li> <li> <p>synapseclient is additionally packaged as a Python wheel.</p> </li> </ul>"},{"location":"news/#bug-fixes_15","title":"Bug Fixes","text":"<ul> <li>[SYNPY-829]     -syn.store always updates annotations</li> <li>[SYNPY-1033]     -If versionComment is left blank, previous version comment populates</li> </ul>"},{"location":"news/#improvements_1","title":"Improvements","text":"<ul> <li>[SYNPY-1120]     -Build wheel distributions</li> <li>[SYNPY-1129]     -Support boolean annotations in Python client</li> </ul>"},{"location":"news/#230-2021-03-03","title":"2.3.0 (2021-03-03)","text":""},{"location":"news/#highlights_18","title":"Highlights","text":"<ul> <li> <p>The     index_files_for_migration     and     migrate_indexed_files     functions are added to synapseutils to help migrate files in Synapse     projects and folders between AWS S3 buckets in the same region. More     details on using these utilities can be found     here.</p> </li> <li> <p>This version supports login programatically and from the command     line using personal access tokens that can be obtained from your     synapse.org Settings. Additional documentation on login and be found     here.</p> <pre><code># programmatic\nsyn = synapseclient.login(authToken=&lt;token&gt;)\n</code></pre> <pre><code># command line\nsynapse login -p &lt;token&gt;\n</code></pre> </li> <li> <p>The location where downloaded entities are cached can be customized     to a location other than the user's home directory. This is useful     in environments where writing to a home directory is not appropriate     (e.g. an AWS lambda).</p> <pre><code>syn = synapseclient.Synapse(cache_root_dir=&lt;directory path&gt;)\n</code></pre> </li> <li> <p>A helper method on     the Synapse object has been added to enable obtaining the Synapse     certification quiz status of a user.</p> <pre><code>passed = syn.is_certified(&lt;username or user_id&gt;)\n</code></pre> </li> <li> <p>This version has been tested with Python 3.9.</p> </li> </ul>"},{"location":"news/#bug-fixes_16","title":"Bug Fixes","text":"<ul> <li>[SYNPY-1039]     -tableQuery asDataFrame() results with TYPE_LIST columns should be     lists and not literal strings</li> <li>[SYNPY-1109]     -unparseable synapse cacheMap raises JSONDecodeError</li> <li>[SYNPY-1110]     -Cleanup on Windows console login</li> <li>[SYNPY-1112]     -Concurrent migration of entities sharing the same file handle can     result in an error</li> <li>[SYNPY-1114]     -Mitigate new Rust compiler dependency on Linux via transitive     cryptography dependency</li> <li>[SYNPY-1118]     -Migration tool erroring when it shouldn't</li> </ul>"},{"location":"news/#new-features","title":"New Features","text":"<ul> <li>[SYNPY-1058]     -Accept oauth access token for authentication to use Synapse REST     services</li> <li>[SYNPY-1103]     -Multipart copy integration</li> <li>[SYNPY-1111]     -Add function to get user certification status</li> </ul>"},{"location":"news/#improvements_2","title":"Improvements","text":"<ul> <li>[SYNPY-885]     -Public interface to customize CACHE_ROOT_DIR</li> <li>[SYNPY-1102]     -syncToSynapse adds empty annotation values</li> <li>[SYNPY-1104]     -Python 3.9 support</li> <li>[SYNPY-1119]     -Add source storage location option to storage migrate functions</li> </ul>"},{"location":"news/#222-2020-10-18","title":"2.2.2 (2020-10-18)","text":""},{"location":"news/#highlights_19","title":"Highlights","text":"<ul> <li>This version addresses an issue with downloads being retried     unsuccessfully after encountering certain types of errors.</li> <li>A     create_snapshot_version     function is added for making table and view snapshots.</li> </ul>"},{"location":"news/#bug-fixes_17","title":"Bug Fixes","text":"<ul> <li>[SYNPY-1096]     -Fix link to Synapse on PyPI</li> <li>[SYNPY-1097]     -downloaded files are reset when disk space exhausted</li> </ul>"},{"location":"news/#new-features_1","title":"New Features","text":"<ul> <li>[SYNPY-1041]     -Snapshot feature and programmatic clients</li> </ul>"},{"location":"news/#improvements_3","title":"Improvements","text":"<ul> <li>[SYNPY-1063]     -Consolidate builds to GitHub Actions</li> <li>[SYNPY-1099]     -Replace usage of deprecated PUT /entity/{id}/version endpoint</li> </ul>"},{"location":"news/#220-2020-08-31","title":"2.2.0 (2020-08-31)","text":""},{"location":"news/#highlights_20","title":"Highlights","text":"<ul> <li>Files that are part of     syncFromSynapse     and     syncToSynapse     operations (<code>synapse get -r</code> and <code>synapse sync</code> in the command line     client, respectively) are transferred in in parallel threads rather     than serially, substantially improving the performance of these     operations.</li> <li>Table metadata from [synapse get -q` is automatically     downloaded to a users working directory instead of to the Synapse     cache (a hidden folder).</li> <li>Users can now pass their API key to [synapse login` in     place of a password.</li> </ul>"},{"location":"news/#bug-fixes_18","title":"Bug Fixes","text":"<ul> <li>[SYNPY-1082]     -Downloading entity linked to URL fails: module 'urllib.parse' has     no attribute 'urlretrieve'</li> </ul>"},{"location":"news/#improvements_4","title":"Improvements","text":"<ul> <li>[SYNPY-1072]     -Improve throughput of multiple small file transfers</li> <li>[SYNPY-1073]     -Parellelize upload syncs</li> <li>[SYNPY-1074]     -Parallelize download syncs</li> <li>[SYNPY-1084]     -Allow anonymous usage for public APIs like GET /teamMembers/{id}</li> <li>[SYNPY-1088]     -Manifest is in cache with synapse get -q</li> <li>[SYNPY-1090]     -Command line client does not support apikey</li> </ul>"},{"location":"news/#tasks_4","title":"Tasks","text":"<ul> <li>[SYNPY-1080]     -Remove Versionable from SchemaBase</li> <li>[SYNPY-1085]     -Move to pytest testing framework</li> <li>[SYNPY-1087]     -Improve synapseclient installation instructions</li> </ul>"},{"location":"news/#211-2020-07-10","title":"2.1.1 (2020-07-10)","text":""},{"location":"news/#highlights_21","title":"Highlights","text":"<ul> <li> <p>This version includes a performance improvement for     syncFromSynapse     downloads of deep folder hierarchies to local filesystem locations     outside of the Synapse     cache.</p> </li> <li> <p>Support is added for SubmissionViews that can be used to query     and edit a set of submissions through table services.</p> <pre><code>from synapseclient import SubmissionViewSchema\n\nproject = syn.get(\"syn123\")\nevaluation_id = '9876543'\nview = syn.store(SubmissionViewSchema(name='My Submission View', parent=project, scopes=[evaluation_id]))\nview_table = syn.tableQuery(f\"select * from {view.id}\")\n</code></pre> </li> </ul>"},{"location":"news/#bug-fixes_19","title":"Bug Fixes","text":"<ul> <li>[SYNPY-1075]     -Error in Python test (submission annotations)</li> <li>[SYNPY-1076]     -Upgrade/fix Pandas dependency</li> </ul>"},{"location":"news/#improvements_5","title":"Improvements","text":"<ul> <li>[SYNPY-1070]     -Add support for submission views</li> <li>[SYNPY-1078]     -Improve syncFromSynapse performance for large folder structures     synced to external paths</li> </ul>"},{"location":"news/#210-2020-06-16","title":"2.1.0 (2020-06-16)","text":""},{"location":"news/#highlights_22","title":"Highlights","text":"<ul> <li> <p>A <code>max_threads</code> property of the Synapse object has been added to     customize the number of concurrent threads that will be used during     file transfers.</p> <pre><code>import synapseclient\nsyn = synapseclient.login()\nsyn.max_threads = 20\n</code></pre> <p>If not customized the default value is (CPU count + 4). Adjusting this value higher may speed up file transfers if the local system resources can take advantage of the higher setting. Currently this value applies only to files whose underlying storage is AWS S3.</p> <p>Alternately, a value can be stored in the synapseConfig configuration file that will automatically apply as the default if a value is not explicitly set.</p> <pre><code>[transfer]\nmax_threads=16\n</code></pre> </li> <li> <p>This release includes support for directly accessing S3 storage     locations using AWS Security Token Service credentials. This allows     use of external AWS clients and libraries with Synapse storage, and     can be used to accelerate file transfers under certain conditions.     To create an STS enabled folder and set-up direct access to S3     storage, see <code>here &lt;sts_storage_locations&gt;</code>{.interpreted-text     role=\"ref\"}.</p> </li> <li> <p>The <code>getAnnotations</code> and <code>setAnnotations</code> methods of the Synapse     object have been deprecated in favor of newer <code>get_annotations</code>     and <code>set_annotations</code> methods, respectively. The newer versions are     parameterized with a typed <code>Annotations</code> dictionary rather than a     plain Python dictionary to prevent existing annotations from being     accidentally overwritten. The expected usage for setting annotations     is to first retrieve the existing <code>Annotations</code> for an entity before     saving changes by passing back a modified value.</p> <pre><code>annos = syn.get_annotations('syn123')\n\n# set key 'foo' to have value of 'bar' and 'baz'\nannos['foo'] = ['bar', 'baz']\n# single values will automatically be wrapped in a list once stored\nannos['qwerty'] = 'asdf'\n\nannos = syn.set_annotations(annos)\n</code></pre> <p>The deprecated annotations methods may be removed in a future release.</p> </li> </ul> <p>A full list of issues addressed in this release are below.</p>"},{"location":"news/#bug-fixes_20","title":"Bug Fixes","text":"<ul> <li>[SYNPY-913]     -Travis Build badge for develop branch is pointing to pull request</li> <li>[SYNPY-960]     -AppVeyor build badge appears to be failed while the builds are     passed</li> <li>[SYNPY-1036]     -different users storing same file to same folder results in 403</li> <li>[SYNPY-1056]     -syn.getSubmissions fails due to new Annotation class in v2.1.0-rc</li> </ul>"},{"location":"news/#improvements_6","title":"Improvements","text":"<ul> <li>[SYNPY-1036]     -Make upload speeds comparable to those of the AWS S3 CLI</li> <li>[SYNPY-1049]     -Expose STS-related APIs</li> </ul>"},{"location":"news/#tasks_5","title":"Tasks","text":"<ul> <li>[SYNPY-1059]     -Use collections.abc instead of collections</li> </ul>"},{"location":"news/#200-2020-03-23","title":"2.0.0 (2020-03-23)","text":"<p>Python 2 is no longer supported as of this release. This release requires Python 3.6+.</p>"},{"location":"news/#highlights_23","title":"Highlights:","text":"<ul> <li> <p>Multi-threaded download of files from Synapse can be enabled by     setting <code>syn.multi_threaded</code> to <code>True</code> on a <code>synapseclient.Synapse</code>     object. This will become the default implementation in the future,     but to ensure stability for the first release of this feature, it     must be intentionally enabled.</p> <pre><code>import synapseclient\nsyn = synapseclient.login()\nsyn.multi_threaded = True\n# syn123 now will be downloaded via the multi-threaded implementation\nsyn.get(\"syn123\")\n</code></pre> <p>Currently, multi-threaded download only works with files stored in AWS S3, where most files on Synapse reside. This also includes custom storage locations that point to an AWS S3 bucket. Files not stored in S3 will fall back to single-threaded download even if <code>syn.multi_threaded==True</code>.</p> </li> </ul> <p>-</p> <pre><code>`synapseutils.copy()` now has limitations on what can be copied:\n\n:   -   A user must have download permissions on the entity they\n        want to copy.\n    -   Users cannot copy any entities that have [access\n        requirements](https://help.synapse.org/docs/Sharing-Settings,-Permissions,-and-Conditions-for-Use.2024276030.html).\n</code></pre> <ul> <li> <p><code>contentTypes</code> and <code>fileNames</code> are optional parameters in     <code>synapseutils.copyFileHandles()</code></p> </li> <li> <p>Synapse Docker Repository(<code>synapseclient.DockerRepository</code>) objects     can now be submitted to Synapse evaluation queues using the <code>entity</code>     argument in <code>synapseclient.Synapse.submit()</code>. An optional argument     <code>docker_tag=\"latest\"</code> has also been added to     <code>synapseclient.Synapse.submit()</code>\\\" to designate which tagged Docker     image to submit.</p> </li> </ul> <p>A full list of issues addressed in this release are below.</p>"},{"location":"news/#bugs-fixes","title":"Bugs Fixes","text":"<ul> <li>[SYNPY-271]     -cache.remove fails to return the file handles we removed</li> <li>[SYNPY-1032]<ul> <li>Support new columnTypes defined in backend</li> </ul> </li> </ul>"},{"location":"news/#tasks_6","title":"Tasks","text":"<ul> <li>[SYNPY-999]     -Remove unsafe copy functions from client</li> <li>[SYNPY-1027]     - Copy function should copy things when users are part of a Team     that has DOWNLOAD access</li> </ul>"},{"location":"news/#improvements_7","title":"Improvements","text":"<ul> <li>[SYNPY-389]     -submission of Docker repository</li> <li>[SYNPY-537]     -synapseutils.copyFileHandles requires fields that does not require     at rest</li> <li>[SYNPY-680]     -synapseutils.changeFileMetaData() needs description in     documentation</li> <li>[SYNPY-682]     -improve download speeds to be comparable to AWS</li> <li>[SYNPY-807]     -Drop support for Python 2</li> <li>[SYNPY-907]     -Replace `from \\&lt;module&gt; import ...` with `import \\&lt;module&gt;`</li> <li>[SYNPY-962]     -remove 'password' as an option in default synapse config file</li> <li>[SYNPY-972]     -Link on Synapse Python Client Documentation points back at itself</li> </ul>"},{"location":"news/#194-2019-06-28","title":"1.9.4 (2019-06-28)","text":""},{"location":"news/#bug-fixes_21","title":"Bug Fixes","text":"<ul> <li>[SYNPY-881]     -Synu.copy fails when copying a file with READ permissions</li> <li>[SYNPY-888]     -Docker repositories cannot be copied</li> <li>[SYNPY-927]     -trying to create a project with name that already exists hangs</li> <li>[SYNPY-1005]<ul> <li>cli docs missing sub-commands</li> </ul> </li> <li>[SYNPY-1018]<ul> <li>Synu.copy shouldn't copy any files with access restrictions</li> </ul> </li> </ul>"},{"location":"news/#new-features_2","title":"New Features","text":"<ul> <li>[SYNPY-851]     -invite user or list of users to a team</li> </ul>"},{"location":"news/#improvements_8","title":"Improvements","text":"<ul> <li>[SYNPY-608]     -Add how to contribute md to github project</li> <li>[SYNPY-735]     -command line for building a table</li> <li>[SYNPY-864]     -docstring for the command line client doesn't have complete list     of sub-commands available</li> <li>[SYNPY-926]     -allow forceVersion false for command line client</li> <li>[SYNPY-1013]<ul> <li>Documentation of \\\"store\\\" command for Synapse command line     client</li> </ul> </li> <li>[SYNPY-1021]<ul> <li>change email contact for code of conduct</li> </ul> </li> </ul>"},{"location":"news/#193-2019-06-28","title":"1.9.3 (2019-06-28)","text":""},{"location":"news/#bug-fixes_22","title":"Bug Fixes","text":"<ul> <li>[SYNPY-993]     -Fix [sendMessage` function</li> <li>[SYNPY-989]     -Fix unstable test</li> </ul>"},{"location":"news/#192-2019-02-15","title":"1.9.2 (2019-02-15)","text":"<p>In version 1.9.2, we improved Views' usability by exposing [set_entity_types()` function to change the entity types that will show up in a View:</p> <pre><code>import synapseclient\nfrom synapseclient.table import EntityViewType\n\nsyn = synapseclient.login()\nview = syn.get(\"syn12345\")\nview.set_entity_types([EntityViewType.FILE, EntityViewType.FOLDER])\nview = syn.store(view)\n</code></pre>"},{"location":"news/#features","title":"Features","text":"<ul> <li>[SYNPY-919]     -Expose a way to update entity types in a view using EntityViewType</li> </ul>"},{"location":"news/#bug-fixes_23","title":"Bug Fixes","text":"<ul> <li>[SYNPY-855]     -Single thread uploading fails in Lambda python3.6 environment</li> <li>[SYNPY-910]     -Store Wiki shows deprecation warning</li> <li>[SYNPY-920]     -Project View turned into File View after using syndccutils template</li> </ul>"},{"location":"news/#tasks_7","title":"Tasks","text":"<ul> <li>[SYNPY-790]     -Pin to a fixed version of the request package</li> <li>[SYNPY-866]     -Update Synapse logo in Python docs :)</li> </ul>"},{"location":"news/#improvements_9","title":"Improvements","text":"<ul> <li>[SYNPY-783]     -typos in comments and in stdout</li> <li>[SYNPY-916]     -Wonky display on parameters</li> <li>[SYNPY-917]     -Add instructions on how to login with API key</li> <li>[SYNPY-909]     -Missing columnTypes in Column docstring</li> </ul>"},{"location":"news/#191-2019-01-20","title":"1.9.1 (2019-01-20)","text":"<p>In version 1.9.1, we fix various bugs and added two new features:</p> <ul> <li>Python 3.7 is supported.</li> <li>Deprecation warnings are visible by default.</li> </ul>"},{"location":"news/#features_1","title":"Features","text":"<ul> <li>[SYNPY-802]     -Support Python 3.7</li> <li>[SYNPY-849]     -Add deprecation warning that isn't filtered by Python</li> </ul>"},{"location":"news/#bug-fixes_24","title":"Bug Fixes","text":"<ul> <li>[SYNPY-454]     -Some integration tests do not clean up after themselves</li> <li>[SYNPY-456]     -Problems with updated query system</li> <li>[SYNPY-515]     -sphinx documentation not showing for some new classes</li> <li>[SYNPY-526]     -deprecate downloadTableFile()</li> <li>[SYNPY-578]     -switch away from POST /entity/#/table/deleterows</li> <li>[SYNPY-594]     -Getting error from dev branch in integration test against staging</li> <li>[SYNPY-796]     -fix or remove PyPI downloads badge in readme</li> <li>[SYNPY-799]     -Unstable test: Test PartialRow updates to entity views from rowset     queries</li> <li>[SYNPY-846]     -error if password stored in config file contains a '%'</li> </ul>"},{"location":"news/#tasks_8","title":"Tasks","text":"<ul> <li>[SYNPY-491]     -Figure out custom release note fitlers</li> <li>[SYNPY-840]     -Install not working on latest python</li> <li>[SYNPY-847]     -uploadFileHandle should not be deprecated nor removed</li> <li>[SYNPY-852]     -Check and update help.synapse.org to reflect the change in the     Python client</li> <li>[SYNPY-860]     -vignette for how to upload a new version of a file directly to a     synapse entity</li> <li>[SYNPY-863]     -Update public documentation to move away from the query services</li> <li>[SYNPY-866]     -Update Synapse logo in Python docs :)</li> <li>[SYNPY-873]     -consolidate integration testing to platform dev account</li> </ul>"},{"location":"news/#improvements_10","title":"Improvements","text":"<ul> <li>[SYNPY-473]     -Change syn.list to no longer use deprecated function chunkedQuery</li> <li>[SYNPY-573]     -synapse list command line shouldn't list the parent container</li> <li>[SYNPY-581]     -\\&lt;entity&gt;.annotations return object is inconsistent with     getAnnotations()</li> <li>[SYNPY-612]     -Rename view_type to viewType in EntityViewSchema for consistency</li> <li>[SYNPY-777]     -Python client _list still uses chunckedQuery and result seem out     of date</li> <li>[SYNPY-804]     -Update styling in the python docs to more closely match the Docs     site styling</li> <li>[SYNPY-815]     -Update the build to use test user instead of migrationAdmin</li> <li>[SYNPY-848]     -remove outdated link to confluence for command line query</li> <li>[SYNPY-856]     -build_table example in the docs does not look right</li> <li>[SYNPY-858]     -Write file view documentation in python client that is similar to     synapser</li> <li>[SYNPY-870]     -Submitting to an evaluation queue can't accept team as int</li> </ul>"},{"location":"news/#190-2018-09-28","title":"1.9.0 (2018-09-28)","text":"<p>In version 1.9.0, we deprecated and removed <code>query()</code> and <code>chunkedQuery()</code>. These functions used the old query services which does not perform well. To query for entities filter by annotations, please use <code>EntityViewSchema</code>.</p> <p>We also deprecated the following functions and will remove them in Synapse Python client version 2.0. In the <code>Activity</code> object:</p> <ul> <li><code>usedEntity()</code></li> <li><code>usedURL()</code></li> </ul> <p>In the <code>Synapse</code> object:</p> <ul> <li><code>getEntity()</code></li> <li><code>loadEntity()</code></li> <li><code>createEntity()</code></li> <li><code>updateEntity()</code></li> <li><code>deleteEntity()</code></li> <li><code>downloadEntity()</code></li> <li><code>uploadFile()</code></li> <li><code>uploadFileHandle()</code></li> <li><code>uploadSynapseManagedFileHandle()</code></li> <li><code>downloadTableFile()</code></li> </ul> <p>Please see our documentation for more details on how to migrate your code away from these functions.</p>"},{"location":"news/#features_2","title":"Features","text":"<ul> <li>SYNPY-806 -     Support Folders and Tables in View</li> </ul>"},{"location":"news/#bug-fixes_25","title":"Bug Fixes","text":"<ul> <li>SYNPY-195 -     Dangerous exception handling</li> <li>SYNPY-261 -     error downloading data from synapse (python client)</li> <li>SYNPY-694 -     Uninformative error in <code>copyWiki</code> function</li> <li>SYNPY-805 -     Uninformative error when getting View that does not exist</li> <li>SYNPY-819 -     command-line clients need to be updated to replace the EntityView     'viewType' with 'viewTypeMask'</li> </ul>"},{"location":"news/#tasks_9","title":"Tasks","text":"<ul> <li>SYNPY-759 -     Look for all functions that are documented as \\\"Deprecated\\\" and     apply the deprecation syntax</li> <li>SYNPY-812 - Add     Github issue template</li> <li>SYNPY-824 -     Remove the deprecated function query() and chunkedQuery()</li> </ul>"},{"location":"news/#improvements_11","title":"Improvements","text":"<ul> <li>SYNPY-583 -     Better error message for create Link object</li> <li>SYNPY-810 -     simplify docs for deleting rows</li> <li>SYNPY-814 - fix     docs links in python client __init__.py</li> <li>SYNPY-822 -     Switch to use news.rst instead of multiple release notes files</li> <li>SYNPY-823 - Pin     keyring to version 12.0.2 to use SecretStorage 2.x</li> </ul>"},{"location":"news/#182-2018-08-17","title":"1.8.2 (2018-08-17)","text":"<p>In this release, we have been performed some house-keeping on the code base. The two major changes are:</p> <ul> <li> <p>making <code>syn.move()</code> available to move an entity to a     new parent in Synapse. For example:</p> <pre><code>import synapseclient\nfrom synapseclient import Folder\n\nsyn = synapseclient.login()\n\nfile = syn.get(\"syn123\")\nfolder = Folder(\"new folder\", parent=\"syn456\")\nfolder = syn.store(folder)\n\n# moving file to the newly created folder\nsyn.move(file, folder)\n</code></pre> </li> <li> <p>exposing the ability to use the Synapse Python client with single     threaded. This feature is useful when running Python script in an     environment that does not support multi-threading. However, this     will negatively impact upload speed. To use single threaded:</p> <pre><code>import synapseclient\nsynapseclient.config.single_threaded = True\n</code></pre> </li> </ul>"},{"location":"news/#bug-fixes_26","title":"Bug Fixes","text":"<ul> <li>SYNPY-535 -     Synapse Table update: Connection Reset</li> <li>SYNPY-603 -     Python client and synapser cannot handle table column type LINK</li> <li>SYNPY-688 -     Recursive get (sync) broken for empty folders.</li> <li>SYNPY-744 -     KeyError when trying to download using Synapse Client 1.8.1</li> <li>SYNPY-750 -     Error in downloadTableColumns for file view</li> <li>SYNPY-758 -     docs in Sphinx don't show for synapseclient.table.RowSet</li> <li>SYNPY-760 -     Keyring related error on Linux</li> <li>SYNPY-766 -     as_table_columns() returns a list of columns out of order for python     3.5 and 2.7</li> <li>SYNPY-776 -     Cannot log in to Synapse - error(54, 'Connection reset by peer')</li> <li>SYNPY-795 - Not     recognizable column in query result</li> </ul>"},{"location":"news/#features_3","title":"Features","text":"<ul> <li>SYNPY-582 -     move file or folder in the client</li> <li>SYNPY-788 - Add     option to use syn.store() without exercising multithreads</li> </ul>"},{"location":"news/#tasks_10","title":"Tasks","text":"<ul> <li>SYNPY-729 -     Deprecate query() and chunkedQuery()</li> <li>SYNPY-797 -     Check Python client code base on using PLFM object model</li> <li>SYNPY-798 -     Using github.io to host documentation</li> </ul>"},{"location":"news/#improvements_12","title":"Improvements","text":"<ul> <li>SYNPY-646 -     Error output of synGet is non-informative</li> <li>SYNPY-743 -     lint the entire python client code base</li> </ul>"},{"location":"news/#181-2018-05-17","title":"1.8.1 (2018-05-17)","text":"<p>This release is a hotfix for a bug. Please refer to 1.8.0 release notes for information about additional changes.</p>"},{"location":"news/#bug-fixes_27","title":"Bug Fixes","text":"<ul> <li>SYNPY-706 -     syn.username can cause attribute not found if user not logged in</li> </ul>"},{"location":"news/#180-2018-05-07","title":"1.8.0 (2018-05-07)","text":"<p>This release has 2 major changes:</p> <ul> <li>The client will no longer store your saved credentials in your     synapse cache (<code>\\~/synapseCache/.session</code>). The python     client now relies on keyring to     handle credential storage of your Synapse credentials.</li> <li>The client also now uses connection pooling, which means that all     method calls that connect to Synapse should now be faster.</li> </ul> <p>The remaining changes are bug fixes and cleanup of test code.</p> <p>Below are the full list of issues addressed by this release:</p>"},{"location":"news/#bug-fixes_28","title":"Bug Fixes","text":"<ul> <li>SYNPY-654 -     syn.getColumns does not terminate</li> <li>SYNPY-658 -     Security vunerability on clusters</li> <li>SYNPY-689 -     Wiki's attachments cannot be None</li> <li>SYNPY-692 -     synapseutils.sync.generateManifest() sets contentType incorrectly</li> <li>SYNPY-693 -     synapseutils.sync.generateManifest() UnicodeEncodingError in python     2</li> </ul>"},{"location":"news/#tasks_11","title":"Tasks","text":"<ul> <li>SYNPY-617 -     Remove use of deprecated service to delete table rows</li> <li>SYNPY-673 - Fix     Integration Tests being run on Appveyor</li> <li>SYNPY-683 -     Clean up print()s used in unit/integration tests</li> </ul>"},{"location":"news/#improvements_13","title":"Improvements","text":"<ul> <li>SYNPY-408 - Add     bettter error messages when /filehandle/batch fails.</li> <li>SYNPY-647 - Use     connection pooling for Python client's requests</li> </ul>"},{"location":"news/#175-2018-01-31","title":"1.7.5 (2018-01-31)","text":"<p>v1.7.4 release was broken for new users that installed from pip. v1.7.5 has the same changes as v1.7.4 but fixes the pip installation.</p>"},{"location":"news/#174-2018-01-29","title":"1.7.4 (2018-01-29)","text":"<p>This release mostly includes bugfixes and improvements for various Table classes:</p> <p>:   -   Fixed bug where you couldn't store a table converted to a         <code>pandas.Dataframe</code> if it had a INTEGER column with         some missing values.     -   <code>EntityViewSchema</code> can now automatically add all         annotations within your defined <code>scopes</code> as columns.         Just set the view's <code>addAnnotationColumns=True</code>         before calling <code>syn.store()</code>. This attribute         defaults to <code>True</code> for all newly created         <code>EntityViewSchemas</code>. Setting         <code>addAnnotationColumns=True</code> on existing tables will         only add annotation columns that are not already a part of your         schema.     -   You can now use <code>synapseutils.notifyMe</code> as a         decorator to notify you by email when your function has         completed. You will also be notified of any Errors if they are         thrown while your function runs.</p> <p>We also added some new features:</p> <p>:   -   <code>syn.findEntityId()</code> function that allows you to         find an Entity by its name and parentId, set parentId to         <code>None</code> to search for Projects by name.     -   The bulk upload functionality of         <code>synapseutils.syncToSynapse</code> is available from the         command line using: <code>synapse sync</code>.</p> <p>Below are the full list of issues addressed by this release:</p>"},{"location":"news/#features_4","title":"Features","text":"<ul> <li>SYNPY-506 -     need convenience function for /entity/child</li> <li>SYNPY-517 -     sync command line</li> </ul>"},{"location":"news/#improvements_14","title":"Improvements","text":"<ul> <li>SYNPY-267 -     Update Synapse tables for integer types</li> <li>SYNPY-304 -     Table objects should implement len()</li> <li>SYNPY-416 -     warning message for recursive get when a non-Project of Folder     entity is passed</li> <li>SYNPY-482 -     Create a sample synapseConfig if none is present</li> <li>SYNPY-489 - Add     a boolean parameter in EntityViewSchema that will indicate whether     the client should create columns based on annotations in the     specified scopes</li> <li>SYNPY-494 -     Link should be able to take an entity object as the parameter and     derive its id</li> <li>SYNPY-511 -     improve exception handling</li> <li>SYNPY-512 -     Remove the use of PaginatedResult's totalNumberOfResult</li> <li>SYNPY-539 -     When creating table Schemas, enforce a limit on the number of     columns that can be created.</li> </ul>"},{"location":"news/#bug-fixes_29","title":"Bug Fixes","text":"<ul> <li>SYNPY-235 -     can't print Row objects with dates in them</li> <li>SYNPY-272 - bug     syn.storing rowsets containing Python datetime objects</li> <li>SYNPY-297 -     as_table_columns shouldn't give fractional max size</li> <li>SYNPY-404 -     when we get a SynapseMd5MismatchError we should delete the     downloaded file</li> <li>SYNPY-425 -     onweb doesn't work for tables</li> <li>SYNPY-438 -     Need to change 'submit' not to use     evaluation/id/accessRequirementUnfulfilled</li> <li>SYNPY-496 -     monitor.NotifyMe can not be used as an annotation decorator</li> <li>SYNPY-521 -     inconsistent error message when username/password is wrong on login</li> <li>SYNPY-536 -     pre-signed upload URL expired warnings using Python client sync     function</li> <li>SYNPY-555 -     EntityViewSchema is missing from sphinx documentation</li> <li>SYNPY-558 -     synapseutils.sync.syncFromSynapse throws error when syncing a Table     object</li> <li>SYNPY-595 - Get     recursive folders filled with Links fails</li> <li>SYNPY-605 -     Update documentation for getUserProfile to include information about     refreshing and memoization</li> </ul>"},{"location":"news/#tasks_12","title":"Tasks","text":"<ul> <li>SYNPY-451 - Add     limit and offset for accessApproval and accessRequirement API calls     and remove 0x400 flag default when calling GET /entity/{id}/bundle</li> <li>SYNPY-546 -     Change warning message when user does not DOWNLOAD permissions.</li> </ul>"},{"location":"news/#173-2017-12-08","title":"1.7.3 (2017-12-08)","text":"<p>Release 1.7.3 introduces fixes and quality of life changes to Tables and synapseutils:</p> <ul> <li> <p>Changes to Tables:</p> <ul> <li>You no longer have to include the <code>etag</code> column in     your SQL query when using a <code>tableQuery()</code> to     update File/Project Views. just <code>SELECT</code> the     relevant columns and etags will be resolved automatically.</li> <li>The new <code>PartialRowSet</code> class allows you to only     have to upload changes to individual cells of a table instead     of every row that had a value changed. It is recommended to     use the <code>PartialRowSet.from_mapping()</code> classmethod     instead of the <code>PartialRowSet</code> constructor.</li> </ul> </li> <li> <p>Changes to synapseutils:</p> <ul> <li>Improved documentation</li> <li>You can now use <code>\\~</code> to refer to your home     directory in your manifest.tsv</li> </ul> </li> </ul> <p>We also added improved debug logging and use Python's builtin <code>logging</code> module instead of printing directly to <code>sys.stderr</code></p> <p>Below are the full list of issues addressed by this release:</p>"},{"location":"news/#bug-fixes_30","title":"Bug Fixes","text":"<ul> <li>SYNPY-419 -     support object store from client</li> <li>SYNPY-499 -     metadata manifest file name spelled wrong</li> <li>SYNPY-504 -     downloadTableFile changed return type with no change in     documentation or mention in release notes</li> <li>SYNPY-508 -     syncToSynapse does not work if \\\"the file path in \\\"used\\\" or     \\\"executed\\\" of the manifest.tsv uses home directory shortcut \\\"\\~\\\"</li> <li>SYNPY-516 -     synapse sync file does not work if file is a URL</li> <li>SYNPY-525 -     Download CSV file of Synapse Table - 416 error</li> <li>SYNPY-572 -     Users should only be prompted for updates if the first or second     part of the version number is changed.</li> </ul>"},{"location":"news/#features_5","title":"Features","text":"<ul> <li>SYNPY-450 -     Create convenience functions for synapse project settings</li> <li>SYNPY-517 -     sync command line</li> <li>SYNPY-519 -     Clean up doc string for Sync</li> <li>SYNPY-545 - no     module botocore</li> <li>SYNPY-577 -     Expose new view etags in command line clients</li> </ul>"},{"location":"news/#tasks_13","title":"Tasks","text":"<ul> <li>SYNPY-569 -     'includeEntityEtag' should be True for Async table csv query     downloads</li> </ul>"},{"location":"news/#improvements_15","title":"Improvements","text":"<ul> <li>SYNPY-304 -     Table objects should implement len()</li> <li>SYNPY-511 -     improve exception handling</li> <li>SYNPY-518 -     Clean up sync interface</li> <li>SYNPY-590 -     Need better logging of errors that occur in the Python client.</li> <li>SYNPY-597 - Add     ability to create PartialRowset updates</li> </ul>"},{"location":"news/#171-2017-11-17","title":"1.7.1 (2017-11-17)","text":"<p>Release 1.7 is a large bugfix release with several new features. The main ones include:</p> <ul> <li> <p>We have expanded the synapseutils     packages     to add the ability to:</p> <ul> <li>Bulk upload files to synapse (synapseutils.syncToSynapse).</li> <li>Notify you via email on the progress of a function (useful for     jobs like large file uploads that may take a long time to     complete).</li> <li>The syncFromSynapse function now creates a \\\"manifest\\\" which     contains the metadata of downloaded files. (These can also be     used to update metadata with the bulk upload function.</li> </ul> </li> <li> <p>File View tables can now be created from the python client using     EntityViewSchema. See fileviews     documentation.</p> </li> <li> <p>The python client is now able to upload to user owned S3 Buckets.     Click here for instructions on linking your S3 bucket to     synapse.</p> </li> </ul> <p>We've also made various improvements to existing features:</p> <ul> <li>The LARGETEXT type is now supported in Tables allowing for strings     up to 2Mb.</li> <li>The <code>\\--description</code> argument when creating/updating     entities from the command line client will now create a     <code>Wiki</code> for that entity. You can also use     <code>\\--descriptionFile</code> to write the contents of a markdown     file as the entity's <code>Wiki</code></li> <li>Two member variables of the File object,     <code>file_entity.cacheDir</code> and     <code>file_entity.files</code> is being DEPRECATED in favor of     <code>file_entity.path</code> for finding the location of a     downloaded <code>File</code></li> <li><code>pandas</code> <code>dataframe\\</code>s containing     `datetime` values can now be properly converted into     csv and uploaded to Synapse.</li> </ul> <p>We also added a optional <code>convert_to_datetime</code> parameter to <code>CsvFileTable.asDataFrame()</code> that will automatically convert Synapse DATE columns into <code>datetime</code> objects instead of leaving them as <code>long</code> unix timestamps</p> <p>Below are the full list of bugs and issues addressed by this release:</p>"},{"location":"news/#features_6","title":"Features","text":"<ul> <li>SYNPY-53 -     support syn.get of external FTP links in py client</li> <li>SYNPY-179 -     Upload to user owned S3 bucket</li> <li>SYNPY-412 -     allow query-based download based on view tables from command line     client</li> <li>SYNPY-487 - Add     remote monitoring of long running processes</li> <li>SYNPY-415 - Add     Docker and TableViews into Entity.py</li> <li>SYNPY-89 -     Python client: Bulk upload client/command</li> <li>SYNPY-413 -     Update table views via python client</li> <li>SYNPY-301 -     change actual file name from python client</li> <li>SYNPY-442 - set     config file path on command line</li> </ul>"},{"location":"news/#improvements_16","title":"Improvements","text":"<ul> <li>SYNPY-407 -     support LARGETEXT in tables</li> <li>SYNPY-360 -     Duplicate file handles are removed from BulkFileDownloadRequest</li> <li>SYNPY-187 -     Move --description in command line client to create wikis</li> <li>SYNPY-224 -     When uploading to a managed external file handle (e.g. SFTP), fill     in storageLocationId</li> <li>SYNPY-315 -     Default behavior for files in cache dir should be replace</li> <li>SYNPY-381 -     Remove references to \\\"files\\\" and \\\"cacheDir\\\".</li> <li>SYNPY-396 -     Create filehandle copies in synapseutils.copy instead of downloading</li> <li>SYNPY-403 - Use     single endpoint for all downloads</li> <li>SYNPY-435 -     Convenience function for new service to get entity's children</li> <li>SYNPY-471 -     docs aren't generated for synapseutils</li> <li>SYNPY-472 -     References to wrong doc site</li> <li>SYNPY-347 -     Missing dtypes in table.DTYPE_2_TABLETYPE</li> <li>SYNPY-463 -     When copying filehandles we should add the files to the cache if we     already donwloaded them</li> <li>SYNPY-475 -     Store Tables timeout error</li> </ul>"},{"location":"news/#bug-fixes_31","title":"Bug Fixes","text":"<ul> <li>SYNPY-190 -     syn.login('asdfasdfasdf') should fail</li> <li>SYNPY-344 -     weird cache directories</li> <li>SYNPY-346 -     ValueError: cannot insert ROW_ID, already exists in CsvTableFile     constructor</li> <li>SYNPY-351 -     Versioning broken for sftp files</li> <li>SYNPY-366 -     file URLs leads to wrong path</li> <li>SYNPY-393 - New     cacheDir causes cache to be ignored(?)</li> <li>SYNPY-409 -     Python client cannot depend on parsing Amazon pre-signed URLs</li> <li>SYNPY-418 -     Integration test failure against 167</li> <li>SYNPY-421 -     syn.getWikiHeaders has a return limit of 50 (Need to return all     headers)</li> <li>SYNPY-423 -     upload rate is off or incorrect</li> <li>SYNPY-424 -     File entities don't handle local_state correctly for setting     datafilehandleid</li> <li>SYNPY-426 -     multiple tests failing because of filenameOveride</li> <li>SYNPY-427 -     test dependent on config file</li> <li>SYNPY-428 -     sync function error</li> <li>SYNPY-431 -     download ending early and not restarting from previous spot</li> <li>SYNPY-443 -     tests/integration/integration_test_Entity.py:test_get_with_downloadLocation_and_ifcollision     AssertionError</li> <li>SYNPY-461 - On     Windows, command line client login credential prompt fails (python     2.7)</li> <li>SYNPY-465 -     Update tests that set permissions to also include 'DOWNLOAD'     permission and tests that test functions using queries</li> <li>SYNPY-468 -     Command line client incompatible with cache changes</li> <li>SYNPY-470 -     default should be read, download for setPermissions</li> <li>SYNPY-483 -     integration test fails for most users</li> <li>SYNPY-484 - URL     expires after retries</li> <li>SYNPY-486 -     Error in integration tests</li> <li>SYNPY-488 -     sync tests for command line client puts file in working directory</li> <li>SYNPY-142 - PY:     Error in login with rememberMe=True</li> <li>SYNPY-464 -     synapse get syn4988808 KeyError: u'preSignedURL'</li> </ul>"},{"location":"news/#tasks_14","title":"Tasks","text":"<ul> <li>SYNPY-422 -     reduce default page size for GET     /evaluation/{evalId}/submission/bundle/all</li> <li>SYNPY-437 -     Remove tests for access restrictions on evaluations</li> <li>SYNPY-402 - Add     release notes to Github release tag</li> </ul>"},{"location":"news/#161-2016-11-02","title":"1.6.1 (2016-11-02)","text":""},{"location":"news/#what-is-new","title":"What is New","text":"<p>In version 1.6 we introduce a new sub-module _synapseutils that provide convenience functions for more complicated operations in Synapse such as copying of files wikis and folders. In addition we have introduced several improvements in downloading content from Synapse. As with uploads we are now able to recover from an interrupted download and will retry on network failures.</p> <ul> <li>SYNPY-48 -     Automate build and test of Python client on Python 3.x</li> <li>SYNPY-180 -     Pass upload destination in chunked file upload</li> <li>SYNPY-349 -     Link Class</li> <li>SYNPY-350 -     Copy Function</li> <li>SYNPY-370 -     Building to new doc site for Synapse</li> <li>SYNPY-371 -     Support paths in syn.onweb</li> </ul>"},{"location":"news/#improvements_17","title":"Improvements","text":"<p>We have improved download robustness and error checking, along with extensive recovery on failed operations. This includes the ability for the client to pause operation when Synapse is updated.</p> <ul> <li>SYNPY-270 -     Synapse READ ONLY mode should cause pause in execution</li> <li>SYNPY-308 - Add     md5 checking after downloading a new file handle</li> <li>SYNPY-309 - Add     download recovery by using the 'Range': 'bytes=xxx-xxx' header</li> <li>SYNPY-353 -     Speed up downloads of fast connections</li> <li>SYNPY-356 - Add     support for version flag in synapse cat command line</li> <li>SYNPY-357 -     Remove failure message on retry in multipart_upload</li> <li>SYNPY-380 - Add     speed meter to downloads/uploads</li> <li>SYNPY-387 - Do     exponential backoff on 429 status and print explanatory error     message from server</li> <li>SYNPY-390 -     Move recursive download to Python client utils</li> </ul>"},{"location":"news/#bug-fixes_32","title":"Bug Fixes","text":"<ul> <li>SYNPY-154 - 500     Server Error when storing new version of file from command line</li> <li>SYNPY-168 -     Failure on login gives an ugly error message</li> <li>SYNPY-253 -     Error messages on upload retry inconsistent with behavior</li> <li>SYNPY-261 -     error downloading data from synapse (python client)</li> <li>SYNPY-274 -     Trying to use the client without logging in needs to give a     reasonable error</li> <li>SYNPY-331 -     test_command_get_recursive_and_query occasionally fails</li> <li>SYNPY-337 -     Download error on 10 Gb file.</li> <li>SYNPY-343 -     Login failure</li> <li>SYNPY-351 -     Versioning broken for sftp files</li> <li>SYNPY-352 -     file upload max retries exceeded messages</li> <li>SYNPY-358 -     upload failure from python client (threading)</li> <li>SYNPY-361 -     file download fails midway without warning/error</li> <li>SYNPY-362 -     setAnnotations bug when given synapse ID</li> <li>SYNPY-363 -     problems using provenance during upload</li> <li>SYNPY-382 -     Python client is truncating the entity id in download csv from table</li> <li>SYNPY-383 -     Travis failing with paramiko.ssh_exception.SSHException: No hostkey</li> <li>SYNPY-384 -     resuming a download after a ChunkedEncodingError created new file     with correct size</li> <li>SYNPY-388 -     Asynchronous creation of Team causes sporadic test failure</li> <li>SYNPY-391 -     downloadTableColumns() function doesn't work when resultsAs=rowset     is set for for syn.tableQuery()</li> <li>SYNPY-397 -     Error in syncFromSynapse() integration test on Windows</li> <li>SYNPY-399 -     python client not compatible with newly released Pandas 0.19</li> </ul>"},{"location":"explanations/access_control/","title":"Access Control","text":"<p>By default, data sets in Synapse are private to your user account, but they can easily be shared with specific users, groups, or the public.</p> <p>See:</p> <ul> <li>synapseclient.Synapse.getPermissions</li> <li>synapseclient.Synapse.setPermissions</li> </ul>"},{"location":"explanations/benchmarking/","title":"Benchmarking","text":"<p>Periodically we will be publishing results of benchmarking the Synapse Python Client compared to directly working with AWS S3. The purpose of these benchmarks is to make data driven decisions on where to spend time optimizing the client. Additionally, it will give us a way to measure the impact of changes to the client.</p>"},{"location":"explanations/benchmarking/#results","title":"Results","text":""},{"location":"explanations/benchmarking/#07022024-downloading-files-from-synapse","title":"07/02/2024: Downloading files from Synapse","text":"<p>These benchmarking results were collected due to the following changes:</p> <ul> <li>The download algorithm for the client was re-written to focus on error handling and handling of multi-threaded downloads orchestrated by AsyncIO.</li> <li>The <code>synapseutils.syncFromSynapse()</code> function was refactored to use this new logic</li> </ul> <p>The results were created on a <code>t3a.micro</code> EC2 instance with a 200GB disk size running in us-east-1. The script that was run can be found in <code>docs/scripts/downloadBenchmark.py</code>.</p> <p>Average transfer time result:</p> <ul> <li>&lt;= 100 MiB per file: <p>8% Decrease</p></li> <li>&gt;= 1 GiB per file: <p>31% Decrease</p></li> </ul> Test Total Transfer Size v4.4.0 .syncFromSynapse() v4.3.0 .syncFromSynapse() v4.4.0 .Get() v4.3.0 .Get() 10 File/10GiB ea 100GiB 1910s <p>39% Decrease</p> 3155s 2186s <p>26% Decrease</p> 2958s 1 File/10GiB ea 10GiB 229s <p>21% Decrease</p> 289s 214s <p>31% Decrease</p> 308s 10 File/1GiB ea 10GiB 174s <p>47% Decrease</p> 330s 224s <p>24% Decrease</p> 295s 100 File/100 MiB ea 10GiB 161s <p>3% Increase</p> 156s 228s <p>13% Decrease</p> 262s 10 File/100 MiB ea 1GiB 15s <p>12% Decrease</p> 17s 24s <p>11% Decrease</p> 27s 100 File/10 MiB ea 1GiB 24s <p>14% Decrease</p> 28s 69s <p>9% Decrease</p> 76s 1000 File/1 MiB ea 1GiB 98s <p>8% Decrease</p> 106s 309s <p>1% Decrease</p> 312s <ul> <li>.syncFromSynapse() documentation</li> <li>.Get() documentation</li> </ul>"},{"location":"explanations/benchmarking/#05102024-uploading-files-to-synapse","title":"05/10/2024: Uploading files to Synapse","text":"<p>These benchmarking results were collected due to the following changes:</p> <ul> <li>The upload algorithm for the Synapseutils <code>syncToSynapse</code> being re-written to take advantage of the new AsyncIO upload algorithm for individual files.</li> <li>An updated limit on concurrent file transfers to match <code>max_threads * 2</code></li> </ul> Test Total Transfer Size Synapseutils OOP Models Interface syn.Store() S3 Sync CLI 10 File/10GiB ea 100GiB 1656.64s 1656.77s 1674.63s 1519.75s 1 File/10GiB ea 10GiB 166.83s 166.41s 167.21 149.55s 10 File/1GiB ea 10GiB 168.74s 167.15s 184.78s 166.39s 100 File/100 MiB ea 10GiB 158.98 125.98s 293.07s 162.57s 10 File/100 MiB ea 1GiB 16.55s 14.37s 29.23s 19.18s 100 File/10 MiB ea 1GiB 15.92s 15.49s 129.90s 18.66s 1000 File/1 MiB ea 1GiB 135.77s 137.15s 1021.32s 26.03s"},{"location":"explanations/benchmarking/#a-high-level-overview-of-the-differences-between-each-of-the-upload-methods","title":"A high level overview of the differences between each of the upload methods:","text":"<ul> <li>OOP Models Interface: Uploads all files and 8MB chunks of each file in parallel using a new upload algorithm</li> <li>Synapseutils: Uploads all files and 8MB chunks of each file in parallel using a new upload algorithm</li> <li>syn.Store(): Uploads files sequentally, but 8MB chunks in parallel using a new upload algorithm</li> <li>S3 Sync CLI: Executing the <code>aws s3 sync</code> command through Python <code>subprocess.run()</code></li> </ul>"},{"location":"explanations/benchmarking/#04012024-uploading-files-to-synapse","title":"04/01/2024: Uploading files to Synapse","text":"<p>These benchmarking results bring together some important updates to the Upload logic. It has been re-written to bring a focus to concurrent file uploads and more effecient use of available threads. As a result of this change it is not reccommended to increase <code>max_threads</code> manually. Based on the available CPU cores this python package will use <code>multiprocessing.cpu_count() + 4</code>. For this testing the default thread size for the machine testing took place on was <code>6</code>.</p> <p>The results were created on a <code>t3a.micro</code> EC2 instance with a 200GB disk size running in us-east-1. The script that was run can be found in <code>docs/scripts/uploadBenchmark.py</code>.</p>"},{"location":"explanations/benchmarking/#some-insights","title":"Some insights:","text":"<ul> <li>The use of the Object-Orientated interfaces/Models Interface results in the best performance out of the box and will scale based on the hardware it's run on.</li> <li>Increasing the number of threads did increase performance for the previous upload logic and Synapseutils functionality. It may also increase performance for new uploads, however, it was not tested again. Increasing the number of threads in use also has inconsistent stability as found in previous benchmarks.</li> <li>The new upload algorithm follows a similar pattern to the S3 client upload times.</li> </ul> Test Total Transfer Size OOP Models Interface syn.Store(), New Upload S3 Sync CLI syn.Store(), Old Upload Synapseutils Synapseutils (25 Threads) syn.Store(), Old Upload (25 Threads) 10 File/10GiB ea 100GiB 1652.61s 1680.27s 1515.31s 2174.65s 2909.62s 1658.34s 1687.17s 1 File/10GiB ea 10GiB 168.39s 167s 152.35s 223s 255.99s 169s 166s 10 File/1GiB ea 10GiB 168.78s 172.48s 155.52s 224.59s 291.72s 167.9s 175.99s 100 File/100 MiB ea 10GiB 124.14s 248.57s 150.46s 320.50s 227.75s 170.82s 294.69s 10 File/100 MiB ea 1GiB 15.13s 28.38s 18.14s 33.74s 26.64s 17.69s 32.80s 100 File/10 MiB ea 1GiB 19.24s 141.23s 19.59s 139.31s 48.50s 18.34s 138.14s 1000 File/1 MiB ea 1GiB 152.65s 1044.42s 25.03s 1101.90s 340.07s 100.94s 1106.40s"},{"location":"explanations/benchmarking/#a-high-level-overview-of-the-differences-between-each-of-the-upload-methods_1","title":"A high level overview of the differences between each of the upload methods:","text":"<ul> <li>OOP Models Interface: Uploads all files and 8MB chunks of each file in parallel using a new upload algorithm</li> <li>Synapseutils: Uploads all files in parallel and 8MB chunks of each file in parallel using the old upload algorithm</li> <li>syn.Store(), New Upload: Uploads files sequentally, but 8MB chunks in parallel using a new upload algorithm</li> <li>syn.Store(), Old Upload: Uploads files sequentally, but 8MB chunks in parallel using the old upload algorithm</li> </ul>"},{"location":"explanations/benchmarking/#12122023-downloading-files-from-synapse","title":"12/12/2023: Downloading files from Synapse","text":"<p>The results were created on a <code>t3a.micro</code> EC2 instance with a 200GB disk size running in us-east-1. The script that was run can be found in <code>docs/scripts/downloadBenchmark.py</code> and <code>docs/scripts/uploadTestFiles.py</code>.</p> <p>During this download test I tried various thread counts to see what performance looked like at different levels. What I found was that going over the default count of threads during download of large files (10GB and over) led to signficantly unstable performance. The client would often crash or hang during execution. As a result the general reccomendation is as follows:</p> <ul> <li>For files over 1GB use the default number of threads: <code>multiprocessing.cpu_count() + 4</code></li> <li>For a large number of files 1GB and under 40-50 threads worked best</li> </ul> Test Thread Count Synapseutils Sync syn.getChildren + syn.get S3 Sync Per file size 25 Files 1MB total size 40 1.30s 5.48s 1.49s 40KB 775 Files 10MB total size 40 19.17s 161.46s 12.02s 12.9KB 10 Files 1GB total size 40 14.74s 21.91s 11.72s 100MB 10 Files 100GB total size 6 3859.66s 2006.53s 1023.57s 10GB 10 Files 100GB total size 40 Wouldn't complete Wouldn't complete N/A 10GB"},{"location":"explanations/benchmarking/#12062023-uploading-files-to-synapse-varying-thread-count-5-annotations-per-file","title":"12/06/2023: Uploading files to Synapse, Varying thread count, 5 annotations per file","text":"<p>The results were created on a <code>t3a.micro</code> EC2 instance with a 200GB disk size running in us-east-1. The script that was run can be found in <code>docs/scripts</code>. The time to create the files on disk is not included.</p> <p>This test includes adding 5 annotations to each file, a Text, Integer, Floating Point, Boolean, and Date.</p> <p>S3 was not benchmarked again.</p> <p>As a result of these tests the sweet spot for thread count is around 50 threads. It is not recommended to go over 50 threads as it resulted in signficant instability in the client.</p> Test Thread Count Synapseutils Sync os.walk + syn.store Per file size 25 Files 1MB total size 6 10.75s 10.96s 40KB 25 Files 1MB total size 25 6.79s 11.31s 40KB 25 Files 1MB total size 50 6.05s 10.90s 40KB 25 Files 1MB total size 100 6.14s 10.89s 40KB 775 Files 10MB total size 6 268.33s 298.12s 12.9KB 775 Files 10MB total size 25 162.63s 305.93s 12.9KB 775 Files 10MB total size 50 86.46s 304.40s 12.9KB 775 Files 10MB total size 100 85.55s 304.71s 12.9KB 10 Files 1GB total size 6 27.17s 36.25s 100MB 10 Files 1GB total size 25 22.26s 12.77s 100MB 10 Files 1GB total size 50 22.24s 12.26s 100MB 10 Files 1GB total size 100 Wouldn't complete Wouldn't complete 100MB"},{"location":"explanations/benchmarking/#11142023-uploading-files-to-synapse-default-thread-count","title":"11/14/2023: Uploading files to Synapse, Default thread count","text":"<p>The results were created on a <code>t3a.micro</code> EC2 instance with a 200GB disk size running in us-east-1. The script that was run can be found in <code>docs/scripts</code>. The time to create the files on disk is not included.</p> <p>This test uses the default number of threads in the client: <code>multiprocessing.cpu_count() + 4</code></p> Test Synapseutils Sync os.walk + syn.store S3 Sync Per file size 25 Files 1MB total size 10.43s 8.99s 1.83s 40KB 775 Files 10MB total size 243.57s 257.27s 7.64s 12.9KB 10 Files 1GB total size 27.18s 33.73s 16.31s 100MB 10 Files 100GB total size 3211s 3047s 3245s 10GB"},{"location":"explanations/domain_models_of_synapse/","title":"Domain Model of Synapse","text":"<p>Here you'll find more information about how all of the models/concepts of Synapse work together and what their purpose is.</p>"},{"location":"explanations/domain_models_of_synapse/#entity","title":"Entity","text":"<p>Any distinct item in Synapse that has its own Synapse ID, including a project, folder, file, wiki, dataset, and view, among other items.</p> <p>Synapse entities are identified by a unique identifier called a Synapse ID, or synID. The synID is represented by the prefix \u201csyn\u201d followed by numbers (for example, syn12345678). This identifier can be used to refer to a specific entity on the web and through the programmatic clients.</p>"},{"location":"explanations/domain_models_of_synapse/#projects","title":"Projects","text":"<p>Projects\u00a0in Synapse are \u201ccontainers\u201d that group relevant content and people together. All data must be uploaded into a project. Projects can be private so only you can see the contents, they can be shared with your collaborators, or they can be made public so anyone on the web can view your research.</p> <p>Projects help you to:</p> <ul> <li> <p>Organize your work: With Synapse, you can organize the parts in your workflow (data, code, etc) into a hierarchy like a file system. With the tabs across the top of each project, you can easily navigate to your\u00a0wikis,\u00a0files and folders, SQL-based\u00a0tables, and even conduct conversations using\u00a0discussion forums.</p> </li> <li> <p>Store data, code, and results: You can upload your data, code, and results to Synapse, or store a reference to their location in your local computer system or on the web. Everything can be stored as files hosted by Synapse, in your own external cloud storage, or using\u00a0Docker containers.</p> </li> <li> <p>Control data access or release it publicly: You have complete control over how users and groups can interact with your work. Work privately, openly, or somewhere in between.</p> </li> <li> <p>Link and share content with others: Just as you can control the access to your work, projects can serve as a platform for linking and sharing your work with others.</p> </li> <li> <p>Custom, searchable annotations: Assign any key/value pair you want. Those values become searchable and available to those granted access.</p> </li> <li> <p>Attach figures and documents: Upload documents and images via the website or programmatically.</p> </li> </ul>"},{"location":"explanations/domain_models_of_synapse/#folders","title":"Folders","text":"<p>Similar to projects, folders are \u201ccontainers\u201d that offer an additional way to organize your data. Instead of uploading a bunch of single files into your project, you can create folders to separate your data in a systematic way.</p> <p>Folders in Synapse always have a \u201cparent\u201d, which could be a project or a folder. You can organize collections of folders and sub-folders, just as you would on your local computer.</p> <p>You can control who has access to folders that you upload in two ways. First, you can apply sharing settings, which control who can view, edit, download, or delete a file. Second, you can also apply conditions for use, which are additional requirements that Synapse users must meet before accessing your file. By default, files inherit the conditions for use of the Synapse folder where they are uploaded. You can also add additional conditions for use on specific folders within a folder.</p> <ul> <li>To read more about how to use sharing settings and conditions for use together, see the full article on Sharing Settings, Permissions, and Conditions for Use.</li> </ul>"},{"location":"explanations/domain_models_of_synapse/#files","title":"Files","text":"<p>Synapse files can be created by uploading content from your local computer or linking to digital files on the web. You can annotate files with custom metadata, embed files into Synapse wiki pages, or associate them with a DOI.</p> <p>Files in Synapse always have a \u201cparent\u201d, which could be a project or a folder. You can organize collections of files into folders and sub-folders, just as you would on your local computer.</p> <p>You can control who has access to files that you upload in two ways. First, you can apply sharing settings, which control who can view, edit, download, or delete a file. Second, you can also apply conditions for use, which are additional requirements that Synapse users must meet before accessing your file. By default, files inherit the conditions for use of the Synapse folder where they are uploaded. You can also add additional conditions for use on specific files within a folder.</p> <ul> <li>To read more about how to use sharing settings and conditions for use together, see the full article on Sharing Settings, Permissions, and Conditions for Use.</li> </ul>"},{"location":"explanations/domain_models_of_synapse/#annotations","title":"Annotations","text":"<p>Annotations help users search for and find data, and they are a powerful tool used to systematically group and/or describe things in Synapse.</p> <p>Annotations are stored as key-value pairs in Synapse, where the key defines a particular aspect of your data, for example (<code>species</code>, <code>assay</code>, <code>fileFormat</code>) and the value defines a variable that belongs to that category (<code>mouse</code>, <code>RNAseq</code>, <code>.bam</code>). You can use annotations to add additional information about a project, file, folder, table, or view. Annotations can be based on an existing ontology or controlled vocabulary, or can be created as needed and modified later as your metadata evolves.</p> <p>For example, if you have uploaded a collection of alignment files in the BAM file format from an RNA-sequencing experiment, each representing a sample and experimental replicate, you can use annotations to surface this information in a structured way. Sometimes, users encode this information in file names, e.g., sampleA_conditionB.bam, which makes it \u201chuman-readable\u201d but not searchable.</p> <p>In this case, you may want to add annotations that look like this:</p> <p></p>"},{"location":"explanations/domain_models_of_synapse/#activityprovenance","title":"Activity/Provenance","text":"<p>Reproducible research is a fundamental responsibility of scientists, but the best practices for achieving it are not established in computational biology. The Synapse provenance system is one of many solutions you can use to make your work reproducible by you and others.</p> <p>Provenance is a concept describing the origin of something. In Synapse, it is used to describe the connections between the workflow steps used to create a particular file or set of results. Data analysis often involves multiple steps to go from a raw data file to a finished analysis. Synapse\u2019s provenance tools allow users to keep track of each step involved in an analysis and share those steps with other users.</p> <p>The model Synapse uses for provenance is based on the W3C provenance spec where items are derived from an activity which has components that were used and components that were executed. Think of the used items as input files and executed items as software or code. Both used and executed items can reside in Synapse or in URLs such as a link to a GitHub commit or a link to a specific version of a software tool.</p> <p>Activity can be seen as an individual item, whereas Provenance can be seen as the relationship of multiple activities.</p>"},{"location":"explanations/home/","title":"Further Reading","text":"<p>Welcome!</p> <p>This is where you'll find information that gives you a deeper understanding of best practices and advanced use cases for interacting with Synapse.</p>"},{"location":"explanations/manifest_tsv/","title":"Manifest","text":"<p>The manifest is a tsv file with file locations and metadata to be pushed to Synapse. The purpose is to allow bulk actions through a TSV without the need to manually execute commands for every requested action.</p>"},{"location":"explanations/manifest_tsv/#manifest-file-format","title":"Manifest file format","text":"<p>The format of the manifest file is a tab delimited file with one row per file to upload and columns describing the file. The minimum required columns are path and parent where path is the local file path and parent is the Synapse Id of the project or folder where the file is uploaded to.</p> <p>In addition to these columns you can specify any of the parameters to the File constructor (name, synapseStore, contentType) as well as parameters to the syn.store command (used, executed, activityName, activityDescription, forceVersion).</p> <p>For only updating annotations without uploading new versions of unchanged files, the syn.store parameter forceVersion should be included in the manifest with the value set to False.</p> <p>Used and executed can be semi-colon (\";\") separated lists of Synapse ids, urls and/or local filepaths of files already stored in Synapse (or being stored in Synapse by the manifest). If you leave a space, like \"syn1234; syn2345\" the white space from \" syn2345\" will be stripped.</p> <p>Any additional columns will be added as annotations.</p>"},{"location":"explanations/manifest_tsv/#required-fields","title":"Required fields:","text":"Field Meaning Example path local file path or URL /path/to/local/file.txt parent synapse id syn1235"},{"location":"explanations/manifest_tsv/#common-fields","title":"Common fields:","text":"Field Meaning Example name name of file in Synapse Example_file forceVersion whether to update version False"},{"location":"explanations/manifest_tsv/#activityprovenance-fields","title":"Activity/Provenance fields:","text":"<p>Each of these are individual examples and is what you would find in a row in each of these columns. To clarify, \"syn1235;/path/to_local/file.txt\" below states that you would like both \"syn1234\" and \"/path/to_local/file.txt\" added as items used to generate a file. You can also specify one item by specifying \"syn1234\"</p> Field Meaning Example used List of items used to generate file \"syn1235;/path/to_local/file.txt\" executed List of items executed \"https://github.org/;/path/to_local/code.py\" activityName Name of activity in provenance \"Ran normalization\" activityDescription Text description on what was done \"Ran algorithm xyx with parameters...\" <p>See:</p> <ul> <li>Activity</li> </ul>"},{"location":"explanations/manifest_tsv/#annotations","title":"Annotations:","text":"<p>Any columns that are not in the reserved names described above will be interpreted as annotations of the file</p> <p>Adding 4 annotations to each row:</p> path parent annot1 annot2 annot3 annot4 annot5 /path/file1.txt syn1243 bar 3.1415 [aaaa, bbbb] [14,27,30] [\"Annotation, with a comma\", another annotation] /path/file2.txt syn12433 baz 2.71 [value_1,value_2] [1,2,3] [test 123, test 456] /path/file3.txt syn12455 zzz 3.52 [value_3,value_4] [42, 56, 77] [a single annotation]"},{"location":"explanations/manifest_tsv/#multiple-values-of-annotations-per-key","title":"Multiple values of annotations per key","text":"<p>Using multiple values for a single annotation should be used sparingly as it makes it more difficult for you to manage the data. However, it is supported.</p> <p>Annotations can be comma <code>,</code> separated lists surrounded by brackets <code>[]</code>.</p> <p>If you have a string that requires a <code>,</code> to be used in the formatting of the string and you want it to be a part of a multi-value annotation you will need to wrap it in double quotes.</p> <p>This is an annotation with 2 values:</p> path parent annot1 /path/file1.txt syn1243 [my first annotation, \"my, second, annotation\"] <p>This is an annotation with 4 value:</p> path parent annot1 /path/file1.txt syn1243 [my first annotation, my, second, annotation] <p>This is an annotation with 1 value:</p> path parent annot1 /path/file1.txt syn1243 my, sentence, with, commas <p>See:</p> <ul> <li>Annotations</li> </ul>"},{"location":"explanations/manifest_tsv/#other-optional-fields","title":"Other optional fields:","text":"Field Meaning Example synapseStore Boolean describing whether to upload files True contentType content type of file to overload defaults text/html"},{"location":"explanations/manifest_tsv/#example-manifest-file","title":"Example manifest file","text":"path parent annot1 annot2 collection_date used executed /path/file1.txt syn1243 \"bar\" 3.1415 2023-12-04 07:00:00+00:00 \"syn124;/path/file2.txt\" \"https://github.org/foo/bar\" /path/file2.txt syn12433 \"baz\" 2.71 2001-01-01 15:00:00+07:00 \"\" \"https://github.org/foo/baz\" /path/file3.txt syn12455 \"zzz\" 3.52 2023-12-04T07:00:00Z \"\" \"https://github.org/foo/zzz\""},{"location":"explanations/manifest_tsv/#dates-in-the-manifest-file","title":"Dates in the manifest file","text":"<p>Dates within the manifest file will always be written as ISO 8601 format in UTC without milliseconds. For example: <code>2023-12-20T16:55:08Z</code>.</p> <p>Dates can be written in other formats specified in ISO 8601 and it will be reconginzed, however, the synapseutils.syncFromSynapse will always write this in the UTC format specified above. For example you may want to specify a datetime at a specific timezone like: <code>2023-12-20 23:55:08-07:00</code> and this will be recognized as a valid datetime.</p>"},{"location":"explanations/manifest_tsv/#refernces","title":"Refernces:","text":"<ul> <li>synapseutils.syncFromSynapse</li> <li>synapseutils.syncToSynapse</li> <li>Managing custom metadata at scale</li> <li>synapseutils.sync.syncToSynapse</li> <li>synapseutils.sync.syncFromSynapse</li> </ul>"},{"location":"explanations/properties_vs_annotations/","title":"Properties and annotations, implementation details","text":"<p>In Synapse, entities have both properties and annotations. Properties are used by the system, whereas annotations are completely user defined. In the Python client, we try to present this situation as a normal object, with one set of properties.</p> <p>Printing an entity will show the division between properties and annotations.</p> <pre><code>print(entity)\n</code></pre> <p>Under the covers, an Entity object has two dictionaries, one for properties and one for annotations. These two namespaces are distinct, so there is a possibility of collisions. It is recommended to avoid defining annotations with names that collide with properties, but this is not enforced.</p> <pre><code>## don't do this!\nentity.properties['description'] = 'One thing'\nentity.annotations['description'] = 'A different thing'\n</code></pre> <p>In case of conflict, properties will take precedence.</p> <pre><code>print(entity.description)\n#&gt; One thing\n</code></pre> <p>Some additional ambiguity is entailed in the use of dot notation. Entity objects have their own internal properties which are not persisted to Synapse. As in all Python objects, these properties are held in object.dict. For example, this dictionary holds the keys 'properties' and 'annotations' whose values are both dictionaries themselves.</p> <p>The rule, for either getting or setting is: first look in the object then look in properties, then look in annotations. If the key is not found in any of these three, a get results in a <code>KeyError</code> and a set results in a new annotation being created. Thus, the following results in a new annotation that will be persisted in Synapse:</p> <pre><code>entity.foo = 'bar'\n</code></pre> <p>To create an object member variable, which will not be persisted in Synapse, this unfortunate notation is required:</p> <pre><code>entity.__dict__['foo'] = 'bar'\n</code></pre> <p>As mentioned previously, name collisions are entirely possible. Keys in the three namespaces can be referred to unambiguously like so:</p> <pre><code>entity.__dict__['key']\n\nentity.properties.key\nentity.properties['key']\n\nentity.annotations.key\nentity.annotations['key']\n</code></pre> <p>Most of the time, users should be able to ignore these distinctions and treat Entities like normal Python objects. End users should never need to manipulate items in dict.</p> <p>See also:</p> <ul> <li>synapseclient.annotations</li> </ul>"},{"location":"explanations/structuring_your_project/","title":"Structuring Your Synapse Project","text":"<p>Based on the experience on managing data coordination projects for 10+ years at Sage, the below are recommendations on how best to manage your Synapse project for data sharing and management.</p> <p>Note: This page is a work in progress and will contain code examples at a later date.</p>"},{"location":"explanations/structuring_your_project/#permissions-management","title":"Permissions Management","text":"<p>We recommend creating Synapse Teams for permission management on your Synapse project so that you manage users that are in these teams instead of granting individual users access to your project. These are the recommended teams to create:</p> <ul> <li> Admin - This team should have \"Administrator\" access to the project and is used to used to manage the project and grant access to other teams. <li> Users - This team is optional, but can be used to grant a curated set of users download access to the project, by grant \"Can Download\" permission to the team. If you want to grant all registered users on Synapse download access to your project, click the \"Make Public\" button in project's sharing settings instead of creating and managing this team. <p>Below are some key permission criteria to consider when setting up your project:</p> <ul> <li>Create a Synapse Team and Project per data contributor if there are (1) multiple data contributors and (2) the data contributors should not have access to each other's raw data. You would then create a central \"public\" project that will contain the harmonized data. You can technically leverage local share settings by creating private folders in one project but managing local share settings is more complicated and not recommended.</li> <li>Do not mix data that requires different permission models within a folder. For example, if you have a project that contains both public and private data, you should create two folders, one for public data and one for private data. You can then grant the appropriate permissions to each folder. You can use local share settings to manage each file's permission, but this is not recommended!</li> </ul>"},{"location":"explanations/structuring_your_project/#project-structure","title":"Project Structure","text":"<p>When organizing your data for upload we have a preferred organization (flattened data layout) and an alternate option (hierarchy data layout) if your project requires that. Synapse files are automatically versioned when you create a file with the same filename, so be sure to account for that when organizing your folders.</p> <p>NOTE: If you and your contributing site decide to use a hierarchical file structure within your cloud storage location, please remember that each top-level folder and all of its subfolders must contain data of the same type (see details below).</p>"},{"location":"explanations/structuring_your_project/#top-level-folder-names","title":"Top Level Folder Names","text":"<p>Top level folders correspond to the datasets being submitted. See the examples below. You can name your datasets in a way that is descriptive for your contributing site.</p> <p>You can use either the Hierarchy or Flattened data layout according to the examples below.</p>"},{"location":"explanations/structuring_your_project/#flattened-data-layout-example","title":"Flattened Data Layout Example","text":"<p>This is the preferred dataset organization option. Each dataset folder contains the same datatype, and there aren\u2019t nested folders containing datasets.</p> <pre><code>.\n\u251c\u2500\u2500 biospecimen_experiment_1\n    \u251c\u2500\u2500 manifest1.tsv\n\u251c\u2500\u2500 biospecimen_experiment_2\n    \u251c\u2500\u2500 manifestA.tsv\n\u251c\u2500\u2500 single_cell_RNAseq_batch_1\n    \u251c\u2500\u2500 manifestX.tsv\n    \u251c\u2500\u2500 fileA.txt\n    \u251c\u2500\u2500 fileB.txt\n    \u251c\u2500\u2500 fileC.txt\n    \u2514\u2500\u2500 fileD.txt\n\u2514\u2500\u2500 single_cell_RNAseq_batch_2\n    \u251c\u2500\u2500 manifestY.tsv\n    \u2514\u2500\u2500 file1.txt\n</code></pre>"},{"location":"explanations/structuring_your_project/#hierarchy-data-layout-example","title":"Hierarchy Data Layout Example","text":"<p>In this option, subfolders should be of the same data type and level as the root folder they are contained in. For example, you should not put a biospecimen and a clinical demographics subfolder within the same folder. Your files should be reasonably descriptive in stating the assay type and level and be consistently prefixed with the assay type.</p> <ul> <li>A dataset folder can\u2019t be inside another dataset folder. For example, a clinical demographics folder can't be inside the biospecimen folder.</li> <li>The dataset folders must have unique names.</li> <li>Folder hierarchy may contain non-dataset folders (e.g. storing reports or other kinds of entities).</li> </ul> <pre><code>.\n\u251c\u2500\u2500 clinical_diagnosis\n\u251c\u2500\u2500 clinical_demographics\n\u251c\u2500\u2500 biospecimen\n    \u251c\u2500\u2500 experiment_1\n        \u251c\u2500\u2500 manifest1.tsv\n    \u2514\u2500\u2500 experiment_2\n        \u251c\u2500\u2500 manifestA.tsv\n\u2514\u2500\u2500 single_cell\n    \u251c\u2500\u2500 batch_1\n        \u251c\u2500\u2500 manifestX.tsv\n        \u251c\u2500\u2500 fileA.txt\n        \u251c\u2500\u2500 fileB.txt\n        \u251c\u2500\u2500 fileC.txt\n        \u2514\u2500\u2500 fileD.txt\n    \u2514\u2500\u2500 batch_2\n        \u251c\u2500\u2500 manifestY.tsv\n        \u2514\u2500\u2500 file1.txt\n</code></pre>"},{"location":"explanations/structuring_your_project/#file-views","title":"File Views","text":"<p>A File View allows you to see groups of files, tables, projects, or submissions and any associated annotations about those items. Annotations are an essential component to building a view. Annotations are labels that you apply to your data, stored as key-value pairs in Synapse. You can use annotations to select specific subsets of your data across many projects or folders and group things together in one view.</p> <p>You can use a view to:</p> <ul> <li>Search and query many files, tables, projects, and submissions at once</li> <li>View and edit file or table annotations in bulk</li> <li>Group or link files, tables, projects, or submissions together by their annotations</li> </ul>"},{"location":"explanations/structuring_your_project/#creating-the-file-view","title":"Creating the File View","text":"<ul> <li>Create a File View with the project set to the scope of the File View</li> <li>Give every Team Download level access to this File View.</li> <li>Note: creating this File View will not be possible if files/folders don\u2019t yet exist in the data contributing site specific projects; Synapse will not allow you to create a File View with an empty scope.</li> <li>Make sure to add both file and folder entities to the scope of the File View.</li> <li>Make sure you leverage Synapse annotations per file and folder to allow for your files to be more easily discoverable via a File View.</li> </ul> <p>For more information, visit File Views.</p>"},{"location":"explanations/structuring_your_project/#uploading-annotations-with-manifests","title":"Uploading annotations with manifests","text":"<p>Manifests are crucial for the organization of your data in Synapse. In the hierarchical case, you would fill in one manifest and include all files in experiment/batches; in the flattened case, you would fill in one manifest for each top level folder. The manifest would contain Synapse annotations which can be used to query the data when a File View is created. Please read manifest_tsv for more information.</p>"},{"location":"explanations/structuring_your_project/#an-example-elite-portal","title":"An example: ELITE portal","text":"<p>Synapse Project: https://www.synapse.org/#!Synapse:syn27229419/wiki/623145</p> <p>This project powers the elite portal: https://eliteportal.synapse.org/. More information about the studies and the files can be found in this portal.</p>"},{"location":"guides/accessing_the_rest_api/","title":"Accessing the Rest API","text":"<p>These methods enable access to the Synapse REST(ish) API taking care of details like endpoints and authentication. See the REST API documentation.</p> <p>See:</p> <ul> <li>synapseclient.Synapse.restGET</li> <li>synapseclient.Synapse.restPOST</li> <li>synapseclient.Synapse.restPUT</li> <li>synapseclient.Synapse.restDELETE</li> </ul>"},{"location":"guides/data_storage/","title":"Data Storage","text":""},{"location":"guides/data_storage/#s3-storage-features","title":"S3 Storage Features","text":"<p>Synapse can use a variety of storage mechanisms to store content, however the most common storage solution is AWS S3. This article illustrates some special features that can be used with S3 storage and how they interact with the Python client. In particular it covers:</p> <ol> <li>Linking External storage locations to new/existing projects or folders</li> <li>Migration of existing projects or folders to new external storage locations</li> <li>Creating STS enabled storage locations</li> <li>Using SFTP</li> </ol>"},{"location":"guides/data_storage/#external-storage-locations","title":"External storage locations","text":"<p>Synapse projects or folders can be configured to use custom implementations for their underlying data storage. More information on this feature can be found here. The most common implementation of this is to configure a folder to store data in a user controlled AWS S3 bucket rather than Synapse's default internal S3 storage.</p>"},{"location":"guides/data_storage/#creating-a-new-folder-backed-by-a-user-specified-s3-bucket","title":"Creating a new folder backed by a user specified S3 bucket","text":"<p>The following illustrates creating a new folder backed by a user specified S3 bucket. Note: An existing folder also works.</p> <p>If you are changing the storage location of an existing folder to a user specified S3 bucket none of the files will be migrated. In order to migrate the files to the new storage location see the section Migrating programmatically. When you change the storage location for a folder only NEW files uploaded to the folder are uploaded to the user specific S3 bucket.</p> <ol> <li> <p>Ensure that the bucket is properly configured.</p> </li> <li> <p>Create a folder and configure it to use external S3 storage:</p> </li> </ol> <pre><code># create a new folder to use with external S3 storage\nfolder = syn.store(Folder(name=folder_name, parent=parent))\n# You may also use an existing folder like:\n# folder = syn.get(\"syn123\")\nfolder, storage_location, project_setting = syn.create_s3_storage_location(\n    folder=folder,\n    bucket_name='my-external-synapse-bucket',\n    base_key='path/within/bucket',\n )\n\n# if needed the unique storage location identifier can be obtained e.g.\nstorage_location_id = storage_location['storageLocationId']\n</code></pre>"},{"location":"guides/data_storage/#creating-a-new-project-backed-by-a-user-specified-s3-bucket","title":"Creating a new project backed by a user specified S3 bucket","text":"<p>The following illustrates creating a new project backed by a user specified S3 bucket. Note: An existing project also works.</p> <p>If you are changing the storage location of an existing project to a user specified S3 bucket none of the files will be migrated. In order to migrate the files to the new storage location see the documentation further down in this article labeled 'Migrating programmatically'. When you change the storage location for a project only NEW files uploaded to the project are uploaded to the user specific S3 bucket.</p> <ol> <li> <p>Ensure that the bucket is properly configured.</p> </li> <li> <p>Create a project and configure it to use external S3 storage:</p> </li> </ol> <pre><code># create a new, or retrieve an existing project to use with external S3 storage\nproject = syn.store(Project(name=\"my_project_name\"))\nproject_storage, storage_location, project_setting = syn.create_s3_storage_location(\n    # Despite the KW argument name, this can be a project or folder\n    folder=project,\n    bucket_name='my-external-synapse-bucket',\n    base_key='path/within/bucket',\n)\n\n# if needed the unique storage location identifier can be obtained e.g.\nstorage_location_id = storage_location['storageLocationId']\n</code></pre> <p>Once an external S3 storage folder exists, you can interact with it as you would any other folder using Synapse tools. If you wish to add an object that is stored within the bucket to Synapse you can do that by adding a file handle for that object using the Python client and then storing the file to that handle.</p> <pre><code>parent_synapse_folder_id = 'syn123'\nlocal_file_path = '/path/to/local/file'\nbucket = 'my-external-synapse-bucket'\ns3_key = 'path/within/bucket/file'\n\n# in this example we use boto to create a file independently of Synapse\ns3_client = boto3.client('s3')\ns3_client.upload_file(\n    Filename=local_file_path,\n    Bucket=bucket,\n    Key=s3_key\n)\n\n# now we add a file handle for that file and store the file to that handle\nfile_handle = syn.create_external_s3_file_handle(\n    bucket,\n    s3_key,\n    local_file_path,\n    parent=parent_synapse_folder_id,\n)\nfile = File(parentId=folder['id'], dataFileHandleId=file_handle['id'])\nfile_entity = syn.store(file)\n</code></pre>"},{"location":"guides/data_storage/#storage-location-migration","title":"Storage location migration","text":"<p>There are circumstances where it can be useful to move the files underlying Synapse entities from one storage location to another without impacting the structure or identifiers of the Synapse entities themselves. An example scenario is needing to use STS features with an existing Synapse Project that was not initially configured with an STS enabled custom storage location.</p> <p>The Synapse client has utilities for migrating entities to a new storage location without having to download the content locally and re-uploading it which can be slow, and may alter the meta data associated with the entities in undesirable ways.</p> <p>During the migration it is recommended that uploads and downloads are blocked to prevent possible conflicts or race conditions. This can be done by setting permissions to <code>Can view</code> for the project or folder being migrated. After the migration is complete set the permissions back to their original values.</p> <p>Expected time to migrate data is around 13 minutes per 100Gb as of 11/21/2023.</p>"},{"location":"guides/data_storage/#migrating-programmatically","title":"Migrating programmatically","text":"<p>Migrating a Synapse project or folder programmatically is a two step process.</p> <p>First ensure that you know the id of the storage location you want to migrate to. More info on storage locations can be found above and here.</p> <p>Once the storage location is known, the first step to migrate the project or folder is to create a migratable index of its contents using the index_files_for_migration function, e.g.</p> <p>When specifying the <code>.db</code> file for the migratable indexes you need to specify a <code>.db</code> file that does not already exist for another synapse project or folder on disk. It is the best practice to specify a unique name for the file by including the synapse id in the name of the file, or other unique identifier.</p> <pre><code>import synapseutils\n\nentity_id = 'syn123'  # a Synapse entity whose contents need to be migrated, e.g. a Project or Folder\ndest_storage_location_id = '12345'  # the id of the destination storage location being migrated to\n\n# a path on disk where this utility can create a sqlite database to store its index.\n# nothing needs to exist at this path, but it must be a valid path on a volume with sufficient\n# disk space to store a meta data listing of all the contents in the indexed entity.\n# a rough rule of thumb is 100kB per 1000 entities indexed.\ndb_path = '/tmp/foo/syn123_bar.db'\n\nresult = synapseutils.index_files_for_migration(\n    syn,\n    entity_id,\n    dest_storage_location_id,\n    db_path,\n\n    # optional args, see function documentation linked above for a description of these parameters\n    source_storage_location_ids=['54321', '98765'],\n    file_version_strategy='new',\n    include_table_files=False,\n    continue_on_error=True\n)\n</code></pre> <p>If called on a container (e.g. a Project or Folder) the index_files_for_migration function will recursively index all of the children of that container (including its subfolders). Once the entity has been indexed you can optionally programmatically inspect the the contents of the index or output its contents to a csv file in order to manually inspect it using the available methods on the returned result object.</p> <p>The next step to trigger the migration from the indexed files is using the migrate_indexed_files function, e.g.</p> <pre><code>result = synapseutils.migrate_indexed_files(\n    syn,\n    db_path,\n\n    # optional args, see function documentation linked above for a description of these parameters\n    create_table_snapshots=True,\n    continue_on_error=False,\n    force=True\n)\n</code></pre> <p>The result can be again be inspected as above to see the results of the migration.</p> <p>Note that above the force parameter is necessary if running from a non-interactive shell. Proceeding with a migration requires confirmation in the form of user prompt. If running programmatically this parameter instead confirms your intention to proceed with the migration.</p>"},{"location":"guides/data_storage/#putting-all-the-migration-pieces-together","title":"Putting all the migration pieces together","text":"<pre><code>import os\nimport synapseutils\nimport synapseclient\n\nmy_synapse_project_or_folder_to_migrate = \"syn123\"\n\nexternal_bucket_name = \"my-external-synapse-bucket\"\nexternal_bucket_base_key = \"path/within/bucket/\"\n\nmy_user_id = \"1234\"\n\n# a path on disk where this utility can create a sqlite database to store its index.\n# nothing needs to exist at this path, but it must be a valid path on a volume with sufficient\n# disk space to store a meta data listing of all the contents in the indexed entity.\n# a rough rule of thumb is 100kB per 1000 entities indexed.\ndb_path = os.path.expanduser(\n    f\"~/synapseMigration/{my_synapse_project_or_folder_to_migrate}_my.db\"\n)\n\nsyn = synapseclient.Synapse()\n\n# Log-in with ~.synapseConfig `authToken`\nsyn.login()\n\n# The project or folder I want to migrate everything to this S3 storage location\nproject_or_folder = syn.get(my_synapse_project_or_folder_to_migrate)\n\nproject_or_folder, storage_location, project_setting = syn.create_s3_storage_location(\n    # Despite the KW argument name, this can be a project or folder\n    folder=project_or_folder,\n    bucket_name=external_bucket_name,\n    base_key=external_bucket_base_key,\n)\n\n# The id of the destination storage location being migrated to\nstorage_location_id = storage_location[\"storageLocationId\"]\nprint(\n    f\"Indexing: {project_or_folder.id} for migration to storage_id: {storage_location_id} at: {db_path}\"\n)\n\ntry:\n    result = synapseutils.index_files_for_migration(\n        syn,\n        project_or_folder.id,\n        storage_location_id,\n        db_path,\n        file_version_strategy=\"all\",\n    )\n\n    print(f\"Indexing result: {result.get_counts_by_status()}\")\n\n    print(\"Migrating files...\")\n\n    result = synapseutils.migrate_indexed_files(\n        syn,\n        db_path,\n        force=True,\n    )\n\n    print(f\"Migration result: {result.get_counts_by_status()}\")\n    syn.sendMessage(\n        userIds=[my_user_id],\n        messageSubject=f\"Migration success for {project_or_folder.id}\",\n        messageBody=f\"Migration result: {result.get_counts_by_status()}\",\n    )\nexcept Exception as e:\n    syn.sendMessage(\n        userIds=[my_user_id],\n        messageSubject=f\"Migration failed for {project_or_folder.id}\",\n        messageBody=f\"Migration failed with error: {e}\",\n    )\n</code></pre> <p>The result of running this should look like</p> <pre><code>Indexing: syn123 for migration to storage_id: 11111 at: /home/user/synapseMigration/syn123_my.db\nIndexing result: {'INDEXED': 100, 'MIGRATED': 0, 'ALREADY_MIGRATED': 0, 'ERRORED': 0}\nMigrating files...\nMigration result: {'INDEXED': 0, 'MIGRATED': 100, 'ALREADY_MIGRATED': 0, 'ERRORED': 0}\n</code></pre>"},{"location":"guides/data_storage/#migrating-from-the-command-line","title":"Migrating from the command line","text":"<p>Synapse entities can also be migrated from the command line. The options are similar to above. Whereas migrating programatically involves two separate function calls, from the command line there is a single <code>migrate</code> command with the dryRun argument providing the option to generate the index only without proceeding onto the migration.</p> <p>Note that as above, confirmation is required before a migration starts. As above, this must either be in the form of confirming via a prompt if running the command from an interactive shell, or using the force command.</p> <p>The optional csv_log_path argument will output the results to a csv file for record keeping, and is recommended.</p> <pre><code>synapse migrate syn123 54321 /tmp/migrate.db --csv_log_path /tmp/migrate.csv\n</code></pre> <p>Sample output:</p> <pre><code>Indexing Project syn123\nIndexing file entity syn888\nIndexing file entity syn999\nIndexed 2 items, 2 needing migration, 0 already stored in destination storage location (54321). Encountered 0 errors.\n21 items for migration to 54321. Proceed? (y/n)? y\nCreating new version for file entity syn888\nCreating new version for file entity syn999\nCompleted migration of syn123. 2 files migrated. 0 errors encountered\nWriting csv log to /tmp/migrate.csv\n</code></pre>"},{"location":"guides/data_storage/#sts-storage-locations","title":"STS Storage Locations","text":"<p>Create an STS enabled folder to use AWS Security Token Service credentials with S3 storage locations. These credentials can be scoped to access individual Synapse files or folders and can be used with external S3 tools such as the awscli and the boto3 library separately from Synapse to read and write files to and from Synapse storage. At this time read and write capabilities are supported for external storage locations, while default Synapse storage is limited to read only. Please read the linked documentation for a complete understanding of the capabilities and restrictions of STS enabled folders.</p>"},{"location":"guides/data_storage/#creating-an-sts-enabled-folder","title":"Creating an STS enabled folder","text":"<p>Creating an STS enabled folder is similar to creating an external storage folder as described above, but this time passing an additional sts_enabled=True keyword parameter. The bucket_name and base_key parameters apply to external storage locations and can be omitted to use Synapse internal storage. Note also that STS can only be enabled on an empty folder.</p> <pre><code># create a new folder to use with STS and external S3 storage\nfolder = syn.store(Folder(name=folder_name, parent=parent))\nfolder, storage_location, project_setting = syn.create_s3_storage_location(\n    folder=folder,\n    bucket_name='my-external-synapse-bucket',\n    base_key='path/within/bucket',\n    sts_enabled=True,\n)\n</code></pre>"},{"location":"guides/data_storage/#using-credentials-with-the-awscli","title":"Using credentials with the awscli","text":"<p>This example illustrates obtaining STS credentials and using them with the awscli command line tool. The first command outputs the credentials as shell commands to execute which will then be picked up by subsequent aws cli commands. Note that the bucket-owner-full-control ACL is required when putting an object via STS credentials. This ensures that the object ownership will be transferred to the owner of the AWS bucket.</p> <pre><code>$ synapse get-sts-token -o shell syn123 read_write\n\nexport SYNAPSE_STS_S3_LOCATION=\"s3://my-external-synapse-bucket/path/within/bucket\"\nexport AWS_ACCESS_KEY_ID=\"&lt;access_key_id&gt;\"\nexport AWS_SECRET_ACCESS_KEY=\"&lt;secret_access_key&gt;\"\nexport AWS_SESSION_TOKEN=\"&lt;session_token&gt;\n\n# if the above are executed in the shell, the awscli will automatically apply them\n\n# e.g. copy a file directly to the bucket using the exported credentials\n$ aws s3 cp /path/to/local/file $SYNAPSE_STS_S3_LOCATION --acl bucket-owner-full-control\n</code></pre>"},{"location":"guides/data_storage/#using-credentials-with-boto3-in-python","title":"Using credentials with boto3 in python","text":"<p>This example illustrates retrieving STS credentials and using them with boto3 within python code, in this case to upload a file.  Note that the bucket-owner-full-control ACL is required when putting an object via STS credentials. This ensures that the object ownership will be transferred to the owner of the AWS bucket.</p> <pre><code># the boto output_format is compatible with the boto3 session api.\ncredentials = syn.get_sts_storage_token('syn123', 'read_write', output_format='boto')\n\ns3_client = boto3.client('s3', **credentials)\ns3_client.upload_file(\n    Filename='/path/to/local/file,\n    Bucket='my-external-synapse-bucket',\n    Key='path/within/bucket/file',\n    ExtraArgs={'ACL': 'bucket-owner-full-control'},\n)\n</code></pre>"},{"location":"guides/data_storage/#automatic-transfers-tofrom-sts-storage-locations-using-boto3-with-synapseclient","title":"Automatic transfers to/from STS storage locations using boto3 with synapseclient","text":"<p>The Python Synapse client can be configured to automatically use STS tokens to perform uploads and downloads to enabled storage locations using an installed boto3 library rather than through the traditional Synapse client APIs. This can improve performance in certain situations, particularly uploads of large files, as the data transfer itself can be conducted purely against the AWS S3 APIs, only invoking the Synapse APIs to retrieve the necessary token and to update Synapse metadata in the case of an upload. Once configured to do so, retrieval of STS tokens for supported operations occurs automatically without any change in synapseclient usage.</p> <p>To enable STS/boto3 transfers on all <code>get</code> and <code>store</code> operations, do the following:</p> <ol> <li>Ensure that boto3 is installed in the same Python installation as synapseclient.</li> </ol> <pre><code>pip install boto3\n</code></pre> <ol> <li>To enable automatic transfers on all uploads and downloads, update your Synapse client configuration file (typically \u201c.synapseConfig\u201d in your $HOME directory, unless otherwise configured) with the [transfer] section, if it is not already present. To leverage STS/boto3 transfers on a per Synapse client object basis, set the use_boto_sts_transfers property.</li> </ol> <pre><code># add to .synapseConfig to automatically apply as default for all synapse client instances\n[transfer]\nuse_boto_sts=true\n\n# alternatively set on a per instance basis within python code\nsyn.use_boto_sts_transfers = True\n</code></pre> <p>Note that if boto3 is not installed, then these settings will have no effect.</p>"},{"location":"guides/data_storage/#sftp","title":"SFTP","text":""},{"location":"guides/data_storage/#installation","title":"Installation","text":"<p>Installing the extra libraries that the Python client uses to communicate with SFTP servers may add a few steps to the installation process.</p> <p>The required libraries are:</p> <ul> <li>pysftp</li> <li>paramiko</li> <li>pycrypto</li> <li>ecdsa</li> </ul>"},{"location":"guides/data_storage/#installing-on-unix-variants","title":"Installing on Unix variants","text":"<p>Building these libraries on Unix OS's is straightforward, but you need the Python development headers and libraries. For example, in Debian or Ubuntu distributions:</p> <pre><code>sudo apt-get install python-dev\n</code></pre> <p>Once this requirement is met, <code>sudo pip install synapseclient</code> should be able to build pycrypto.</p>"},{"location":"guides/data_storage/#installing-on-windows","title":"Installing on Windows","text":"<p>Binary distributions of pycrypto built for Windows is available from Michael Foord at Voidspace. Install this before installing the Python client.</p> <p>After running the pycrypto installer, <code>sudo pip install synapseclient</code> should work.</p> <p>Another option is to build your own binary with either the free developer tools from Microsoft or the MinGW compiler.</p>"},{"location":"guides/data_storage/#configure-your-client","title":"Configure your client","text":"<p>Make sure you configure your ~/.synapseConfig file to connect to your SFTP server.</p>"},{"location":"guides/home/","title":"How-To Guides","text":"<p>Welcome!</p> <p>In this module you'll find extensive examples of all the things you can do with the Synapse Python/Command line client.</p>"},{"location":"guides/validate_annotations/","title":"Validate Annotations","text":"<p>Warning: This is a beta implementation and is subject to change.  Use at your own risk.</p> <p>Validate annotations on your Synapse entities by leveraging the JSON schema services. Here are the steps you must take to set up the JSON Schema service.</p>"},{"location":"guides/validate_annotations/#create-a-json-schema-organization","title":"Create a JSON Schema organization","text":"<p>Set up Synapse client and JSON Schema service:</p> <pre><code>import synapseclient\nsyn = synapseclient.login()\nsyn.get_available_services()  # Output: ['json_schema']\njs = syn.service(\"json_schema\")\n</code></pre> <p>Create, manage, and delete a JSON Schema organization:</p> <pre><code>my_org_name = &lt;your org name here&gt;\nmy_org = js.JsonSchemaOrganization(my_org_name)\nmy_org  # Output: JsonSchemaOrganization(name=my_org_name)\nmy_org.create()\nmy_org.get_acl()\nmy_org.set_acl([syn.getUserProfile().ownerId])\n# my_org.update_acl([syn.getUserProfile().ownerId])\nmy_org.delete()\n</code></pre> <p>Retrieve existing organization and associated JSON schemas:</p> <pre><code>orgs     = js.list_organizations()\nsage_org = js.JsonSchemaOrganization(\"sage.annotations\")\nschemas  = sage_org.list_json_schemas()\nschema1  = next(schemas)\nschema2  = sage_org.get_json_schema(schema1.name)\nassert schema1 is schema2  # True\nschema1  # Output: JsonSchema(org='sage.annotations', name='analysis.alignmentMethod')\n</code></pre> <p>Manage a specific version of a JSON schema:</p> <pre><code>versions  = schema1.list_versions()\nversion1  = next(versions)\nraw_body  = version1.body\nfull_body = version1.expand()\nversion1\n# Output: JsonSchemaVersion(org='sage.annotations', name='analysis.alignmentMethod', version='0.0.1')\n</code></pre> <p>Create a new JSON schema version for an existing organization:</p> <pre><code>from random import randint\nrint = randint(0, 100000)\nschema_name = \"my.schema\"\n\n# Method 1\nmy_org          = js.JsonSchemaOrganization(my_org_name)\nnew_version1    = my_org.create_json_schema(raw_body, schema_name, f\"0.{rint}.1\")\n\n# Method 2\nmy_schema    = js.JsonSchema(my_org, schema_name)\nnew_version2 = my_schema.create(raw_body, f\"0.{rint}.2\")\n\n# Method 3\nmy_version   = js.JsonSchemaVersion(my_org, schema_name, f\"0.{rint}.3\")\nnew_version3 = my_version.create(raw_body)\n</code></pre> <p>Test validation on a Synapse entity:</p> <pre><code>from time import sleep\nsynapse_id = \"syn25922647\"\njs.bind_json_schema(new_version1.uri, synapse_id)\njs.get_json_schema(synapse_id)\nsleep(3)\njs.validate(synapse_id)\njs.validate_children(synapse_id)\njs.validation_stats(synapse_id)\njs.unbind_json_schema(synapse_id)\n</code></pre> <p>Access to low-level API functions:</p> <pre><code>js.create_organization(organization_name)\njs.get_organization(organization_name)\njs.list_organizations()\njs.delete_organization(organization_id)\njs.get_organization_acl(organization_id)\njs.update_organization_acl(organization_id, resource_access, etag)\njs.list_json_schemas(organization_name)\njs.list_json_schema_versions(organization_name, json_schema_name)\njs.create_json_schema(json_schema_body, dry_run)\njs.get_json_schema_body(json_schema_uri)\njs.delete_json_schema(json_schema_uri)\njs.json_schema_validation(json_schema_uri)\njs.bind_json_schema_to_entity(synapse_id, json_schema_uri)\njs.get_json_schema_from_entity(synapse_id)\njs.delete_json_schema_from_entity(synapse_id)\njs.validate_entity_with_json_schema(synapse_id)\njs.get_json_schema_validation_statistics(synapse_id)\njs.get_invalid_json_schema_validation(synapse_id)\n</code></pre>"},{"location":"guides/views/","title":"Views","text":"<p>A view is a view of all entities (File, Folder, Project, Table, Docker Repository, View) within one or more Projects or Folders. Views can:</p> <ul> <li>Provide a way of isolating or linking data based on similarities</li> <li>Provide the ability to link entities together by their annotations</li> <li>Allow view/editing entities attributes in bulk</li> <li>Allow entities to be easily searched and queried</li> </ul> <p>Let's go over some examples to demonstrate how view works. First, create a new project and add some files:</p> <pre><code>import synapseclient\nfrom synapseclient import Project, File, Column, Table, EntityViewSchema, EntityViewType\nsyn = synapseclient.Synapse()\nsyn.login()\n\n# Create a new project\nproject = syn.store(Project(\"test view\"))\n\n# Create some files\nfile1 = syn.store(File(path=\"path/to/file1.txt\", parent=project))\nfile2 = syn.store(File(path=\"path/to/file2.txt\", parent=project))\n\n# add some annotations\nsyn.setAnnotations(file1, {\"contributor\":\"Sage\", \"class\":\"V\"})\nsyn.setAnnotations(file2, {\"contributor\":\"UW\", \"rank\":\"X\"})\n</code></pre>"},{"location":"guides/views/#creating-a-view","title":"Creating a View","text":"<p>To create a view, defines its name, columns, parent, scope, and the type of the view:</p> <pre><code>view = EntityViewSchema(name=\"my first file view\",\n                        columns=[\n                            Column(name=\"contributor\", columnType=\"STRING\"),\n                            Column(name=\"class\", columnType=\"STRING\"),\n                            Column(name=\"rank\", columnType=\"STRING\")),\n                        parent=project['id'],\n                        scopes=project['id'],\n                        includeEntityTypes=[EntityViewType.FILE, EntityViewType.FOLDER],\n                        addDefaultViewColumns=True)\nview = syn.store(view)\n</code></pre> <p>We support the following entity type in a View:</p> <pre><code>* EntityViewType.FILE\n* EntityViewType.PROJECT\n* EntityViewType.TABLE\n* EntityViewType.FOLDER\n* EntityViewType.VIEW\n* EntityViewType.DOCKER\n</code></pre> <p>To see the content of your newly created View, use syn.tableQuery():</p> <pre><code>query_results = syn.tableQuery(\"select * from %s\" % view['id'])\ndata = query_results.asDataFrame()\n</code></pre>"},{"location":"guides/views/#updating-annotations-using-view","title":"Updating Annotations using View","text":"<p>To update <code>class</code> annotation for <code>file2</code>, simply update the view:</p> <pre><code># Retrieve the view data using table query\nquery_results = syn.tableQuery(\"select * from %s\" % view['id'])\ndata = query_results.asDataFrame()\n\n# Modify the annotations by modifying the view data and store it\ndata[\"class\"] = [\"V\", \"VI\"]\nsyn.store(Table(view['id'], data))\n</code></pre> <p>The change in annotations reflect in synGetAnnotations():</p> <pre><code>syn.getAnnotations(file2['id'])\n</code></pre> <p>A View is a Table. Please visit Tables to see how to change schema, update content, and other operations that can be done on View.</p>"},{"location":"reference/activity/","title":"Activity/Provenance","text":""},{"location":"reference/activity/#synapseclient.activity","title":"<code>synapseclient.activity</code>","text":""},{"location":"reference/activity/#synapseclient.activity--provenance","title":"Provenance","text":"<p>The Activity object represents the source of a data set or the data processing steps used to produce it. Using W3C provenance ontology terms, a result is generated by a combination of data and code which are either used or executed.</p>"},{"location":"reference/activity/#synapseclient.activity--imports","title":"Imports","text":"<pre><code>from synapseclient import Activity\n</code></pre>"},{"location":"reference/activity/#synapseclient.activity--creating-an-activity-object","title":"Creating an activity object","text":"<pre><code>act = Activity(name='clustering',\n               description='whizzy clustering',\n               used=['syn1234','syn1235'],\n               executed='syn4567')\n</code></pre> <p>Here, syn1234 and syn1235 might be two types of measurements on a common set of samples. Some whizzy clustering code might be referred to by syn4567.  The used and executed can reference entities in Synapse or URLs.</p> <p>Alternatively, you can build an activity up piecemeal:</p> <pre><code>act = Activity(name='clustering', description='whizzy clustering')\nact.used(['syn12345', 'syn12346'])\nact.executed(\n    'https://raw.githubusercontent.com/Sage-Bionetworks/synapsePythonClient/develop/tests/unit/unit_test_client.py')\n</code></pre>"},{"location":"reference/activity/#synapseclient.activity--storing-entities-with-provenance","title":"Storing entities with provenance","text":"<p>The activity can be passed in when storing an Entity to set the Entity's provenance:</p> <pre><code>clustered_samples = syn.store(clustered_samples, activity=act)\n</code></pre> <p>We've now recorded that <code>clustered_samples</code> is the output of our whizzy clustering algorithm applied to the data stored in syn1234 and syn1235.</p>"},{"location":"reference/activity/#synapseclient.activity--recording-data-source","title":"Recording data source","text":"<p>The synapseclient.Synapse.store has shortcuts for specifying the used and executed lists directly. For example, when storing a data entity, it's a good idea to record its source:</p> <pre><code>excellent_data = syn.store(excellent_data,\n                           activityName='data-r-us'\n                           activityDescription='downloaded from data-r-us',\n                           used='http://data-r-us.com/excellent/data.xyz')\n</code></pre>"},{"location":"reference/activity/#synapseclient.activity-classes","title":"Classes","text":""},{"location":"reference/activity/#synapseclient.activity.Activity","title":"<code>Activity</code>","text":"<p>               Bases: <code>dict</code></p> <p>Represents the provenance of a Synapse Entity.</p> PARAMETER DESCRIPTION <code>name</code> <p>Name of the Activity</p> <p> DEFAULT: <code>None</code> </p> <code>description</code> <p>A short text description of the Activity</p> <p> DEFAULT: <code>None</code> </p> <code>used</code> <p>Either a list of:</p> <ul> <li>reference objects (e.g. [{'targetId':'syn123456', 'targetVersionNumber':1}])</li> <li>a list of Synapse Entities or Entity IDs</li> <li>a list of URL's</li> </ul> <p> DEFAULT: <code>None</code> </p> <code>executed</code> <p>A code resource that was executed to generate the Entity.</p> <p> DEFAULT: <code>None</code> </p> <code>data</code> <p>A dictionary representation of an Activity, with fields 'name', 'description' and 'used' (a list of reference objects)</p> <p> DEFAULT: <code>{}</code> </p> <p>See also: The W3C's provenance ontology</p> Source code in <code>synapseclient/activity.py</code> <pre><code>class Activity(dict):\n    \"\"\"\n    Represents the provenance of a Synapse Entity.\n\n    Parameters:\n        name: Name of the Activity\n        description: A short text description of the Activity\n        used: Either a list of:\n\n            - [reference objects](https://rest-docs.synapse.org/rest/org/sagebionetworks/repo/model/Reference.html) (e.g. [{'targetId':'syn123456', 'targetVersionNumber':1}])\n            - a list of Synapse Entities or Entity IDs\n            - a list of URL's\n        executed: A code resource that was executed to generate the Entity.\n        data: A dictionary representation of an Activity, with fields 'name', 'description' and 'used' (a list of reference objects)\n\n    See also: The [W3C's provenance ontology](http://www.w3.org/TR/prov-o/)\n    \"\"\"\n\n    # TODO: make constructors from JSON consistent across objects\n    def __init__(self, name=None, description=None, used=None, executed=None, data={}):\n        super(Activity, self).__init__(data)\n        if \"used\" not in self:\n            self[\"used\"] = []\n\n        if name is not None:\n            self[\"name\"] = name\n        if description is not None:\n            self[\"description\"] = description\n        if used is not None:\n            self.used(used)\n        if executed is not None:\n            self.executed(executed)\n\n    def used(\n        self, target=None, targetVersion=None, wasExecuted=None, url=None, name=None\n    ):\n        \"\"\"\n        Add a resource used by the activity.\n\n        This method tries to be as permissive as possible. It accepts a string which might be a synapse ID or a URL,\n        a synapse entity, a UsedEntity or UsedURL dictionary or a list containing any combination of these.\n\n        In addition, named parameters can be used to specify the fields of either a UsedEntity or a UsedURL.\n        If target and optionally targetVersion are specified, create a UsedEntity.\n        If url and optionally name are specified, create a UsedURL.\n\n        It is an error to specify both target/targetVersion parameters and url/name parameters in the same call.\n        To add multiple UsedEntities and UsedURLs, make a separate call for each or pass in a list.\n\n        In case of conflicting settings for wasExecuted both inside an object and with a parameter, the parameter wins.\n        For example, this UsedURL will have wasExecuted set to False:\n\n            activity.used({'url':'http://google.com', 'name':'Goog', 'wasExecuted':True}, wasExecuted=False)\n\n        Entity examples:\n\n            activity.used('syn12345')\n            activity.used(entity)\n            activity.used(target=entity, targetVersion=2)\n            activity.used(codeEntity, wasExecuted=True)\n            activity.used({'reference':{'target':'syn12345', 'targetVersion':1}, 'wasExecuted':False})\n\n        URL examples:\n\n            activity.used('http://mydomain.com/my/awesome/data.RData')\n            activity.used(url='http://mydomain.com/my/awesome/data.RData', name='Awesome Data')\n            activity.used(url='https://github.com/joe_hacker/code_repo', name='Gnarly hacks', wasExecuted=True)\n            activity.used({'url':'https://github.com/joe_hacker/code_repo', 'name':'Gnarly hacks'}, wasExecuted=True)\n\n        List example:\n\n            activity.used(['syn12345', 'syn23456', entity, \\\n                          {'reference':{'target':'syn100009', 'targetVersion':2}, 'wasExecuted':True}, \\\n                          'http://mydomain.com/my/awesome/data.RData'])\n        \"\"\"\n        # -- A list of targets\n        if isinstance(target, list):\n            badargs = _get_any_bad_args([\"targetVersion\", \"url\", \"name\"], locals())\n            _raise_incorrect_used_usage(badargs, \"list of used resources\")\n\n            for item in target:\n                self.used(item, wasExecuted=wasExecuted)\n            return\n\n        # -- UsedEntity\n        elif is_used_entity(target):\n            badargs = _get_any_bad_args([\"targetVersion\", \"url\", \"name\"], locals())\n            _raise_incorrect_used_usage(\n                badargs, \"dictionary representing a used resource\"\n            )\n\n            resource = target\n            if \"concreteType\" not in resource:\n                resource[\n                    \"concreteType\"\n                ] = \"org.sagebionetworks.repo.model.provenance.UsedEntity\"\n\n        # -- Used URL\n        elif is_used_url(target):\n            badargs = _get_any_bad_args([\"targetVersion\", \"url\", \"name\"], locals())\n            _raise_incorrect_used_usage(badargs, \"URL\")\n\n            resource = target\n            if \"concreteType\" not in resource:\n                resource[\n                    \"concreteType\"\n                ] = \"org.sagebionetworks.repo.model.provenance.UsedURL\"\n\n        # -- Synapse Entity\n        elif is_synapse_entity(target):\n            badargs = _get_any_bad_args([\"url\", \"name\"], locals())\n            _raise_incorrect_used_usage(badargs, \"Synapse entity\")\n\n            reference = {\"targetId\": target[\"id\"]}\n            if \"versionNumber\" in target:\n                reference[\"targetVersionNumber\"] = target[\"versionNumber\"]\n            if targetVersion:\n                reference[\"targetVersionNumber\"] = int(targetVersion)\n            resource = {\n                \"reference\": reference,\n                \"concreteType\": \"org.sagebionetworks.repo.model.provenance.UsedEntity\",\n            }\n        # -- URL parameter\n        elif url:\n            badargs = _get_any_bad_args([\"target\", \"targetVersion\"], locals())\n            _raise_incorrect_used_usage(badargs, \"URL\")\n\n            resource = {\n                \"url\": url,\n                \"name\": name if name else target,\n                \"concreteType\": \"org.sagebionetworks.repo.model.provenance.UsedURL\",\n            }\n\n        # -- URL as a string\n        elif is_url(target):\n            badargs = _get_any_bad_args([\"targetVersion\"], locals())\n            _raise_incorrect_used_usage(badargs, \"URL\")\n            resource = {\n                \"url\": target,\n                \"name\": name if name else target,\n                \"concreteType\": \"org.sagebionetworks.repo.model.provenance.UsedURL\",\n            }\n\n        # -- Synapse Entity ID (assuming the string is an ID)\n        elif isinstance(target, str):\n            badargs = _get_any_bad_args([\"url\", \"name\"], locals())\n            _raise_incorrect_used_usage(badargs, \"Synapse entity\")\n            if not is_synapse_id_str(target):\n                raise ValueError(\"%s is not a valid Synapse id\" % target)\n            synid, version = get_synid_and_version(\n                target\n            )  # Handle synapseIds of from syn234.4\n            if version:\n                if targetVersion and int(targetVersion) != int(version):\n                    raise ValueError(\n                        \"Two conflicting versions for %s were specified\" % target\n                    )\n                targetVersion = int(version)\n            reference = {\"targetId\": synid}\n            if targetVersion:\n                reference[\"targetVersionNumber\"] = int(targetVersion)\n            resource = {\n                \"reference\": reference,\n                \"concreteType\": \"org.sagebionetworks.repo.model.provenance.UsedEntity\",\n            }\n        else:\n            raise SynapseError(\"Unexpected parameters in call to Activity.used().\")\n\n        # Set wasExecuted\n        if wasExecuted is None:\n            # Default to False\n            if \"wasExecuted\" not in resource:\n                resource[\"wasExecuted\"] = False\n        else:\n            # wasExecuted parameter overrides setting in an object\n            resource[\"wasExecuted\"] = wasExecuted\n\n        # Add the used resource to the activity\n        self[\"used\"].append(resource)\n\n    def executed(self, target=None, targetVersion=None, url=None, name=None):\n        \"\"\"\n        Add a code resource that was executed during the activity.\n        See [synapseclient.activity.Activity.used][]\n        \"\"\"\n        self.used(\n            target=target,\n            targetVersion=targetVersion,\n            url=url,\n            name=name,\n            wasExecuted=True,\n        )\n\n    def _getStringList(self, wasExecuted=True):\n        usedList = []\n        for source in [\n            source\n            for source in self[\"used\"]\n            if source.get(\"wasExecuted\", False) == wasExecuted\n        ]:\n            if source[\"concreteType\"].endswith(\"UsedURL\"):\n                if source.get(\"name\"):\n                    usedList.append(source.get(\"name\"))\n                else:\n                    usedList.append(source.get(\"url\"))\n            else:  # It is an entity for now\n                tmpstr = source[\"reference\"][\"targetId\"]\n                if \"targetVersionNumber\" in source[\"reference\"]:\n                    tmpstr += \".%i\" % source[\"reference\"][\"targetVersionNumber\"]\n                usedList.append(tmpstr)\n        return usedList\n\n    def _getExecutedStringList(self):\n        return self._getStringList(wasExecuted=True)\n\n    def _getUsedStringList(self):\n        return self._getStringList(wasExecuted=False)\n\n    def __str__(self):\n        str = \"%s\\n  Executed:\\n\" % self.get(\"name\", \"\")\n        str += \"\\n\".join(self._getExecutedStringList())\n        str += \"  Used:\\n\"\n        str += \"\\n\".join(self._getUsedStringList())\n        return str\n</code></pre>"},{"location":"reference/activity/#synapseclient.activity.Activity-functions","title":"Functions","text":""},{"location":"reference/activity/#synapseclient.activity.Activity.used","title":"<code>used(target=None, targetVersion=None, wasExecuted=None, url=None, name=None)</code>","text":"<p>Add a resource used by the activity.</p> <p>This method tries to be as permissive as possible. It accepts a string which might be a synapse ID or a URL, a synapse entity, a UsedEntity or UsedURL dictionary or a list containing any combination of these.</p> <p>In addition, named parameters can be used to specify the fields of either a UsedEntity or a UsedURL. If target and optionally targetVersion are specified, create a UsedEntity. If url and optionally name are specified, create a UsedURL.</p> <p>It is an error to specify both target/targetVersion parameters and url/name parameters in the same call. To add multiple UsedEntities and UsedURLs, make a separate call for each or pass in a list.</p> <p>In case of conflicting settings for wasExecuted both inside an object and with a parameter, the parameter wins. For example, this UsedURL will have wasExecuted set to False:</p> <pre><code>activity.used({'url':'http://google.com', 'name':'Goog', 'wasExecuted':True}, wasExecuted=False)\n</code></pre> <p>Entity examples:</p> <pre><code>activity.used('syn12345')\nactivity.used(entity)\nactivity.used(target=entity, targetVersion=2)\nactivity.used(codeEntity, wasExecuted=True)\nactivity.used({'reference':{'target':'syn12345', 'targetVersion':1}, 'wasExecuted':False})\n</code></pre> <p>URL examples:</p> <pre><code>activity.used('http://mydomain.com/my/awesome/data.RData')\nactivity.used(url='http://mydomain.com/my/awesome/data.RData', name='Awesome Data')\nactivity.used(url='https://github.com/joe_hacker/code_repo', name='Gnarly hacks', wasExecuted=True)\nactivity.used({'url':'https://github.com/joe_hacker/code_repo', 'name':'Gnarly hacks'}, wasExecuted=True)\n</code></pre> <p>List example:</p> <pre><code>activity.used(['syn12345', 'syn23456', entity,                           {'reference':{'target':'syn100009', 'targetVersion':2}, 'wasExecuted':True},                           'http://mydomain.com/my/awesome/data.RData'])\n</code></pre> Source code in <code>synapseclient/activity.py</code> <pre><code>def used(\n    self, target=None, targetVersion=None, wasExecuted=None, url=None, name=None\n):\n    \"\"\"\n    Add a resource used by the activity.\n\n    This method tries to be as permissive as possible. It accepts a string which might be a synapse ID or a URL,\n    a synapse entity, a UsedEntity or UsedURL dictionary or a list containing any combination of these.\n\n    In addition, named parameters can be used to specify the fields of either a UsedEntity or a UsedURL.\n    If target and optionally targetVersion are specified, create a UsedEntity.\n    If url and optionally name are specified, create a UsedURL.\n\n    It is an error to specify both target/targetVersion parameters and url/name parameters in the same call.\n    To add multiple UsedEntities and UsedURLs, make a separate call for each or pass in a list.\n\n    In case of conflicting settings for wasExecuted both inside an object and with a parameter, the parameter wins.\n    For example, this UsedURL will have wasExecuted set to False:\n\n        activity.used({'url':'http://google.com', 'name':'Goog', 'wasExecuted':True}, wasExecuted=False)\n\n    Entity examples:\n\n        activity.used('syn12345')\n        activity.used(entity)\n        activity.used(target=entity, targetVersion=2)\n        activity.used(codeEntity, wasExecuted=True)\n        activity.used({'reference':{'target':'syn12345', 'targetVersion':1}, 'wasExecuted':False})\n\n    URL examples:\n\n        activity.used('http://mydomain.com/my/awesome/data.RData')\n        activity.used(url='http://mydomain.com/my/awesome/data.RData', name='Awesome Data')\n        activity.used(url='https://github.com/joe_hacker/code_repo', name='Gnarly hacks', wasExecuted=True)\n        activity.used({'url':'https://github.com/joe_hacker/code_repo', 'name':'Gnarly hacks'}, wasExecuted=True)\n\n    List example:\n\n        activity.used(['syn12345', 'syn23456', entity, \\\n                      {'reference':{'target':'syn100009', 'targetVersion':2}, 'wasExecuted':True}, \\\n                      'http://mydomain.com/my/awesome/data.RData'])\n    \"\"\"\n    # -- A list of targets\n    if isinstance(target, list):\n        badargs = _get_any_bad_args([\"targetVersion\", \"url\", \"name\"], locals())\n        _raise_incorrect_used_usage(badargs, \"list of used resources\")\n\n        for item in target:\n            self.used(item, wasExecuted=wasExecuted)\n        return\n\n    # -- UsedEntity\n    elif is_used_entity(target):\n        badargs = _get_any_bad_args([\"targetVersion\", \"url\", \"name\"], locals())\n        _raise_incorrect_used_usage(\n            badargs, \"dictionary representing a used resource\"\n        )\n\n        resource = target\n        if \"concreteType\" not in resource:\n            resource[\n                \"concreteType\"\n            ] = \"org.sagebionetworks.repo.model.provenance.UsedEntity\"\n\n    # -- Used URL\n    elif is_used_url(target):\n        badargs = _get_any_bad_args([\"targetVersion\", \"url\", \"name\"], locals())\n        _raise_incorrect_used_usage(badargs, \"URL\")\n\n        resource = target\n        if \"concreteType\" not in resource:\n            resource[\n                \"concreteType\"\n            ] = \"org.sagebionetworks.repo.model.provenance.UsedURL\"\n\n    # -- Synapse Entity\n    elif is_synapse_entity(target):\n        badargs = _get_any_bad_args([\"url\", \"name\"], locals())\n        _raise_incorrect_used_usage(badargs, \"Synapse entity\")\n\n        reference = {\"targetId\": target[\"id\"]}\n        if \"versionNumber\" in target:\n            reference[\"targetVersionNumber\"] = target[\"versionNumber\"]\n        if targetVersion:\n            reference[\"targetVersionNumber\"] = int(targetVersion)\n        resource = {\n            \"reference\": reference,\n            \"concreteType\": \"org.sagebionetworks.repo.model.provenance.UsedEntity\",\n        }\n    # -- URL parameter\n    elif url:\n        badargs = _get_any_bad_args([\"target\", \"targetVersion\"], locals())\n        _raise_incorrect_used_usage(badargs, \"URL\")\n\n        resource = {\n            \"url\": url,\n            \"name\": name if name else target,\n            \"concreteType\": \"org.sagebionetworks.repo.model.provenance.UsedURL\",\n        }\n\n    # -- URL as a string\n    elif is_url(target):\n        badargs = _get_any_bad_args([\"targetVersion\"], locals())\n        _raise_incorrect_used_usage(badargs, \"URL\")\n        resource = {\n            \"url\": target,\n            \"name\": name if name else target,\n            \"concreteType\": \"org.sagebionetworks.repo.model.provenance.UsedURL\",\n        }\n\n    # -- Synapse Entity ID (assuming the string is an ID)\n    elif isinstance(target, str):\n        badargs = _get_any_bad_args([\"url\", \"name\"], locals())\n        _raise_incorrect_used_usage(badargs, \"Synapse entity\")\n        if not is_synapse_id_str(target):\n            raise ValueError(\"%s is not a valid Synapse id\" % target)\n        synid, version = get_synid_and_version(\n            target\n        )  # Handle synapseIds of from syn234.4\n        if version:\n            if targetVersion and int(targetVersion) != int(version):\n                raise ValueError(\n                    \"Two conflicting versions for %s were specified\" % target\n                )\n            targetVersion = int(version)\n        reference = {\"targetId\": synid}\n        if targetVersion:\n            reference[\"targetVersionNumber\"] = int(targetVersion)\n        resource = {\n            \"reference\": reference,\n            \"concreteType\": \"org.sagebionetworks.repo.model.provenance.UsedEntity\",\n        }\n    else:\n        raise SynapseError(\"Unexpected parameters in call to Activity.used().\")\n\n    # Set wasExecuted\n    if wasExecuted is None:\n        # Default to False\n        if \"wasExecuted\" not in resource:\n            resource[\"wasExecuted\"] = False\n    else:\n        # wasExecuted parameter overrides setting in an object\n        resource[\"wasExecuted\"] = wasExecuted\n\n    # Add the used resource to the activity\n    self[\"used\"].append(resource)\n</code></pre>"},{"location":"reference/activity/#synapseclient.activity.Activity.executed","title":"<code>executed(target=None, targetVersion=None, url=None, name=None)</code>","text":"<p>Add a code resource that was executed during the activity. See synapseclient.activity.Activity.used</p> Source code in <code>synapseclient/activity.py</code> <pre><code>def executed(self, target=None, targetVersion=None, url=None, name=None):\n    \"\"\"\n    Add a code resource that was executed during the activity.\n    See [synapseclient.activity.Activity.used][]\n    \"\"\"\n    self.used(\n        target=target,\n        targetVersion=targetVersion,\n        url=url,\n        name=name,\n        wasExecuted=True,\n    )\n</code></pre>"},{"location":"reference/activity/#synapseclient.activity-functions","title":"Functions","text":""},{"location":"reference/activity/#synapseclient.activity.is_used_entity","title":"<code>is_used_entity(x)</code>","text":"RETURNS DESCRIPTION <code>bool</code> <p>True if the given object represents a UsedEntity.</p> Source code in <code>synapseclient/activity.py</code> <pre><code>def is_used_entity(x) -&gt; bool:\n    \"\"\"\n    Returns:\n        True if the given object represents a UsedEntity.\n    \"\"\"\n\n    # A UsedEntity must be a dictionary with a 'reference' field, with a 'targetId' field\n    if (\n        not isinstance(x, collections.abc.Mapping)\n        or \"reference\" not in x\n        or \"targetId\" not in x[\"reference\"]\n    ):\n        return False\n\n    # Must only have three keys\n    if not all(key in (\"reference\", \"wasExecuted\", \"concreteType\") for key in x.keys()):\n        return False\n\n    # 'reference' field can only have two keys\n    if not all(\n        key in (\"targetId\", \"targetVersionNumber\") for key in x[\"reference\"].keys()\n    ):\n        return False\n\n    return True\n</code></pre>"},{"location":"reference/activity/#synapseclient.activity.is_used_url","title":"<code>is_used_url(x)</code>","text":"RETURNS DESCRIPTION <code>bool</code> <p>True if the given object represents a UsedURL.</p> Source code in <code>synapseclient/activity.py</code> <pre><code>def is_used_url(x) -&gt; bool:\n    \"\"\"\n    Returns:\n        True if the given object represents a UsedURL.\n    \"\"\"\n\n    # A UsedURL must be a dictionary with a 'url' field\n    if not isinstance(x, collections.abc.Mapping) or \"url\" not in x:\n        return False\n\n    # Must only have four keys\n    if not all(\n        key in (\"url\", \"name\", \"wasExecuted\", \"concreteType\") for key in x.keys()\n    ):\n        return False\n\n    return True\n</code></pre>"},{"location":"reference/annotations/","title":"Annotations","text":""},{"location":"reference/annotations/#synapseclient.annotations","title":"<code>synapseclient.annotations</code>","text":""},{"location":"reference/annotations/#synapseclient.annotations--annotations","title":"Annotations","text":"<p>Annotations are arbitrary metadata attached to Synapse entities. They can be accessed like ordinary object properties or like dictionary keys:</p> <pre><code>entity.my_annotation = 'This is one way to do it'\nentity['other_annotation'] = 'This is another'\n</code></pre> <p>Annotations can be given in the constructor for Synapse Entities:</p> <pre><code>entity = File('data.xyz', parent=my_project, rating=9.1234)\n</code></pre> <p>Annotate the entity with location data:</p> <pre><code>entity.lat_long = [47.627477, -122.332154]\n</code></pre> <p>Record when we collected the data. This will use the current timezone of the machine running the code.</p> <pre><code>from datetime import datetime as Datetime\nentity.collection_date = Datetime.now()\n</code></pre> <p>Record when we collected the data in UTC:</p> <pre><code>from datetime import datetime as Datetime\nentity.collection_date = Datetime.utcnow()\n</code></pre> <p>You may also use a Timezone aware datetime object like the following example. Using the pytz library is recommended for this purpose.:</p> <pre><code>from datetime import datetime as Datetime, timezone as Timezone, timedelta as Timedelta\n\ndate = Datetime(2023, 12, 20, 8, 10, 0, tzinfo=Timezone(Timedelta(hours=-5)))\n</code></pre> <p>See:</p> <ul> <li>synapseclient.Synapse.get_annotations</li> <li>synapseclient.Synapse.set_annotations</li> </ul>"},{"location":"reference/annotations/#synapseclient.annotations--annotating-data-sources","title":"Annotating data sources","text":"<p>Data sources are best recorded using Synapse's Activity/Provenance tools.</p>"},{"location":"reference/annotations/#synapseclient.annotations--implementation-details","title":"Implementation details","text":"<p>In Synapse, entities have both properties and annotations. Properties are used by the system, whereas annotations are completely user defined. In the Python client, we try to present this situation as a normal object, with one set of properties.</p> <p>See also:</p> <ul> <li>Read more about Properties vs Annotations</li> <li>synapseclient.entity.Entity</li> </ul>"},{"location":"reference/annotations/#synapseclient.annotations-classes","title":"Classes","text":""},{"location":"reference/annotations/#synapseclient.annotations.Annotations","title":"<code>Annotations</code>","text":"<p>               Bases: <code>dict</code></p> <p>Represent Synapse Entity annotations as a flat dictionary with the system assigned properties id, etag as object attributes.</p> ATTRIBUTE DESCRIPTION <code>id</code> <p>Synapse ID of the Entity</p> <p> </p> <code>etag</code> <p>Synapse etag of the Entity</p> <p> </p> <code>values</code> <p>(Optional) dictionary of values to be copied into annotations</p> <p> </p> <code>**kwargs</code> <p>additional key-value pairs to be added as annotations</p> <p> </p> Creating a few instances <p>Creating and setting annotations</p> <pre><code>from synapseclient import Annotations\n\nexample1 = Annotations('syn123','40256475-6fb3-11ea-bb0a-9cb6d0d8d984', {'foo':'bar'})\nexample2 = Annotations('syn123','40256475-6fb3-11ea-bb0a-9cb6d0d8d984', foo='bar')\nexample3 = Annotations('syn123','40256475-6fb3-11ea-bb0a-9cb6d0d8d984')\nexample3['foo'] = 'bar'\n</code></pre> Source code in <code>synapseclient/annotations.py</code> <pre><code>class Annotations(dict):\n    \"\"\"\n    Represent Synapse Entity annotations as a flat dictionary with the system assigned properties id, etag\n    as object attributes.\n\n    Attributes:\n        id: Synapse ID of the Entity\n        etag: Synapse etag of the Entity\n        values: (Optional) dictionary of values to be copied into annotations\n        **kwargs: additional key-value pairs to be added as annotations\n\n    Example: Creating a few instances\n        Creating and setting annotations\n\n            from synapseclient import Annotations\n\n            example1 = Annotations('syn123','40256475-6fb3-11ea-bb0a-9cb6d0d8d984', {'foo':'bar'})\n            example2 = Annotations('syn123','40256475-6fb3-11ea-bb0a-9cb6d0d8d984', foo='bar')\n            example3 = Annotations('syn123','40256475-6fb3-11ea-bb0a-9cb6d0d8d984')\n            example3['foo'] = 'bar'\n    \"\"\"\n\n    id: str\n    etag: str\n\n    def __init__(\n        self,\n        id: typing.Union[str, int, Entity],\n        etag: str,\n        values: typing.Dict = None,\n        **kwargs,\n    ):\n        \"\"\"\n        Create an Annotations object taking key value pairs from a dictionary or from keyword arguments.\n        System properties id, etag, creationDate and uri become attributes of the object.\n\n        Attributes:\n            id:  A Synapse ID, a Synapse Entity object, a plain dictionary in which 'id' maps to a Synapse ID\n            etag: etag of the Synapse Entity\n            values: (Optional) dictionary of values to be copied into annotations\n            **kwargs: additional key-value pairs to be added as annotations\n\n        Example: Creating a few instances\n            Creating and setting annotations\n\n                from synapseclient import Annotations\n\n                example1 = Annotations('syn123','40256475-6fb3-11ea-bb0a-9cb6d0d8d984', {'foo':'bar'})\n                example2 = Annotations('syn123','40256475-6fb3-11ea-bb0a-9cb6d0d8d984', foo='bar')\n                example3 = Annotations('syn123','40256475-6fb3-11ea-bb0a-9cb6d0d8d984')\n                example3['foo'] = 'bar'\n\n        \"\"\"\n        super().__init__()\n\n        self.id = id\n        self.etag = etag\n\n        if values:\n            self.update(values)\n        if kwargs:\n            self.update(kwargs)\n\n    @property\n    def id(self):\n        return self._id\n\n    @id.setter\n    def id(self, value):\n        if value is None:\n            raise ValueError(\"id must not be None\")\n        self._id = id_of(value)\n\n    @property\n    def etag(self):\n        return self._etag\n\n    @etag.setter\n    def etag(self, value):\n        if value is None:\n            raise ValueError(\"etag must not be None\")\n        self._etag = str(value)\n</code></pre>"},{"location":"reference/annotations/#synapseclient.annotations-functions","title":"Functions","text":""},{"location":"reference/annotations/#synapseclient.annotations.is_synapse_annotations","title":"<code>is_synapse_annotations(annotations)</code>","text":"<p>Tests if the given object is a Synapse-style Annotations object.</p> PARAMETER DESCRIPTION <code>annotations</code> <p>A key-value mapping that may or may not be a Synapse-style</p> <p> TYPE: <code>Mapping</code> </p> RETURNS DESCRIPTION <code>bool</code> <p>True if the given object is a Synapse-style Annotations object, False</p> <code>bool</code> <p>otherwise.</p> Source code in <code>synapseclient/annotations.py</code> <pre><code>def is_synapse_annotations(annotations: typing.Mapping) -&gt; bool:\n    \"\"\"Tests if the given object is a Synapse-style Annotations object.\n\n    Arguments:\n        annotations: A key-value mapping that may or may not be a Synapse-style\n        Annotations object.\n\n    Returns:\n        True if the given object is a Synapse-style Annotations object, False\n        otherwise.\n    \"\"\"\n    if not isinstance(annotations, collections.abc.Mapping):\n        return False\n    return annotations.keys() &gt;= {\"id\", \"etag\", \"annotations\"}\n</code></pre>"},{"location":"reference/annotations/#synapseclient.annotations.is_submission_status_annotations","title":"<code>is_submission_status_annotations(annotations)</code>","text":"<p>Tests if the given dictionary is in the form of annotations to submission status.</p> PARAMETER DESCRIPTION <code>annotations</code> <p>A key-value mapping that may or may not be a submission status</p> <p> TYPE: <code>Mapping</code> </p> RETURNS DESCRIPTION <code>bool</code> <p>True if the given object is a submission status annotations object, False</p> <code>bool</code> <p>otherwise.</p> Source code in <code>synapseclient/annotations.py</code> <pre><code>def is_submission_status_annotations(annotations: collections.abc.Mapping) -&gt; bool:\n    \"\"\"Tests if the given dictionary is in the form of annotations to submission\n    status.\n\n    Arguments:\n        annotations: A key-value mapping that may or may not be a submission status\n        annotations object.\n\n    Returns:\n        True if the given object is a submission status annotations object, False\n        otherwise.\n    \"\"\"\n    keys = [\"objectId\", \"scopeId\", \"stringAnnos\", \"longAnnos\", \"doubleAnnos\"]\n    if not isinstance(annotations, collections.abc.Mapping):\n        return False\n    return all([key in keys for key in annotations.keys()])\n</code></pre>"},{"location":"reference/annotations/#synapseclient.annotations.to_submission_status_annotations","title":"<code>to_submission_status_annotations(annotations, is_private=True)</code>","text":"<p>Converts a normal dictionary to the format used to annotate submission statuses, which is different from the format used to annotate entities.</p> PARAMETER DESCRIPTION <code>annotations</code> <p>A normal Python dictionary whose values are strings, floats, ints or doubles.</p> <p> </p> <code>is_private</code> <p>Set privacy on all annotations at once. These can be set individually using         set_privacy.</p> <p> DEFAULT: <code>True</code> </p> Using this function <p>Adding and converting annotations</p> <pre><code>import synapseclient\nfrom synapseclient.annotations import to_submission_status_annotations\nfrom datetime import datetime as Datetime\n\n## Initialize a Synapse object &amp; authenticate\nsyn = synapseclient.Synapse()\nsyn.login()\n\n## create a submission and get its status\nsubmission = syn.submit(evaluation, 'syn11111111')\nsubmission_status = syn.getSubmissionStatus(submission)\n\n## add annotations\nsubmission_status.annotations = {'foo':'bar', 'shoe_size':12, 'IQ':12, 'timestamp':Datetime.now()}\n\n## convert annotations\nsubmission_status.annotations = to_submission_status_annotations(submission_status.annotations)\nsubmission_status = syn.store(submission_status)\n</code></pre> <p>Synapse categorizes these annotations by: stringAnnos, doubleAnnos, longAnnos.</p> Source code in <code>synapseclient/annotations.py</code> <pre><code>def to_submission_status_annotations(annotations, is_private=True):\n    \"\"\"\n    Converts a normal dictionary to the format used to annotate submission statuses, which is different from the format\n    used to annotate entities.\n\n    Arguments:\n        annotations: A normal Python dictionary whose values are strings, floats, ints or doubles.\n        is_private: Set privacy on all annotations at once. These can be set individually using\n                    [set_privacy][synapseclient.annotations.set_privacy].\n\n\n    Example: Using this function\n        Adding and converting annotations\n\n            import synapseclient\n            from synapseclient.annotations import to_submission_status_annotations\n            from datetime import datetime as Datetime\n\n            ## Initialize a Synapse object &amp; authenticate\n            syn = synapseclient.Synapse()\n            syn.login()\n\n            ## create a submission and get its status\n            submission = syn.submit(evaluation, 'syn11111111')\n            submission_status = syn.getSubmissionStatus(submission)\n\n            ## add annotations\n            submission_status.annotations = {'foo':'bar', 'shoe_size':12, 'IQ':12, 'timestamp':Datetime.now()}\n\n            ## convert annotations\n            submission_status.annotations = to_submission_status_annotations(submission_status.annotations)\n            submission_status = syn.store(submission_status)\n\n\n    Synapse categorizes these annotations by: stringAnnos, doubleAnnos, longAnnos.\n    \"\"\"\n    if is_submission_status_annotations(annotations):\n        return annotations\n    synapseAnnos = {}\n    for key, value in annotations.items():\n        if key in [\"objectId\", \"scopeId\", \"stringAnnos\", \"longAnnos\", \"doubleAnnos\"]:\n            synapseAnnos[key] = value\n        elif isinstance(value, bool):\n            synapseAnnos.setdefault(\"stringAnnos\", []).append(\n                {\"key\": key, \"value\": str(value).lower(), \"isPrivate\": is_private}\n            )\n        elif isinstance(value, int):\n            synapseAnnos.setdefault(\"longAnnos\", []).append(\n                {\"key\": key, \"value\": value, \"isPrivate\": is_private}\n            )\n        elif isinstance(value, float):\n            synapseAnnos.setdefault(\"doubleAnnos\", []).append(\n                {\"key\": key, \"value\": value, \"isPrivate\": is_private}\n            )\n        elif isinstance(value, str):\n            synapseAnnos.setdefault(\"stringAnnos\", []).append(\n                {\"key\": key, \"value\": value, \"isPrivate\": is_private}\n            )\n        elif is_date(value):\n            synapseAnnos.setdefault(\"longAnnos\", []).append(\n                {\n                    \"key\": key,\n                    \"value\": to_unix_epoch_time(value),\n                    \"isPrivate\": is_private,\n                }\n            )\n        else:\n            synapseAnnos.setdefault(\"stringAnnos\", []).append(\n                {\"key\": key, \"value\": str(value), \"isPrivate\": is_private}\n            )\n    return synapseAnnos\n</code></pre>"},{"location":"reference/annotations/#synapseclient.annotations.from_submission_status_annotations","title":"<code>from_submission_status_annotations(annotations)</code>","text":"<p>Convert back from submission status annotation format to a normal dictionary.</p> PARAMETER DESCRIPTION <code>annotations</code> <p>A dictionary in the format used to annotate submission statuses.</p> <p> </p> RETURNS DESCRIPTION <code>dict</code> <p>A normal Python dictionary.</p> Using this function <p>Converting from submission status annotations</p> <pre><code>from synapseclient.annotations import from_submission_status_annotations\n\nsubmission_status.annotations = from_submission_status_annotations(submission_status.annotations)\n</code></pre> Source code in <code>synapseclient/annotations.py</code> <pre><code>def from_submission_status_annotations(annotations) -&gt; dict:\n    \"\"\"\n    Convert back from submission status annotation format to a normal dictionary.\n\n    Arguments:\n        annotations: A dictionary in the format used to annotate submission statuses.\n\n    Returns:\n        A normal Python dictionary.\n\n    Example: Using this function\n        Converting from submission status annotations\n\n            from synapseclient.annotations import from_submission_status_annotations\n\n            submission_status.annotations = from_submission_status_annotations(submission_status.annotations)\n    \"\"\"\n    dictionary = {}\n    for key, value in annotations.items():\n        if key in [\"stringAnnos\", \"longAnnos\"]:\n            dictionary.update({kvp[\"key\"]: kvp[\"value\"] for kvp in value})\n        elif key == \"doubleAnnos\":\n            dictionary.update({kvp[\"key\"]: float(kvp[\"value\"]) for kvp in value})\n        else:\n            dictionary[key] = value\n    return dictionary\n</code></pre>"},{"location":"reference/annotations/#synapseclient.annotations.set_privacy","title":"<code>set_privacy(annotations, key, is_private=True, value_types=['longAnnos', 'doubleAnnos', 'stringAnnos'])</code>","text":"<p>Set privacy of individual annotations, where annotations are in the format used by Synapse SubmissionStatus objects. See the Annotations documentation.</p> PARAMETER DESCRIPTION <code>annotations</code> <p>Annotations that have already been converted to Synapse format using             to_submission_status_annotations.</p> <p> </p> <code>key</code> <p>The key of the annotation whose privacy we're setting.</p> <p> </p> <code>is_private</code> <p>If False, the annotation will be visible to users with READ permission on the evaluation.             If True, the it will be visible only to users with READ_PRIVATE_SUBMISSION on the evaluation.</p> <p> DEFAULT: <code>True</code> </p> <code>value_types</code> <p>A list of the value types in which to search for the key.</p> <p> DEFAULT: <code>['longAnnos', 'doubleAnnos', 'stringAnnos']</code> </p> Source code in <code>synapseclient/annotations.py</code> <pre><code>def set_privacy(\n    annotations,\n    key,\n    is_private=True,\n    value_types=[\"longAnnos\", \"doubleAnnos\", \"stringAnnos\"],\n):\n    \"\"\"\n    Set privacy of individual annotations, where annotations are in the format used by Synapse SubmissionStatus objects.\n    See the [Annotations documentation](https://rest-docs.synapse.org/rest/org/sagebionetworks/repo/model/annotation/Annotations.html).\n\n    Arguments:\n        annotations: Annotations that have already been converted to Synapse format using\n                        [to_submission_status_annotations][synapseclient.annotations.to_submission_status_annotations].\n        key:         The key of the annotation whose privacy we're setting.\n        is_private:  If False, the annotation will be visible to users with READ permission on the evaluation.\n                        If True, the it will be visible only to users with READ_PRIVATE_SUBMISSION on the evaluation.\n        value_types: A list of the value types in which to search for the key.\n\n    \"\"\"\n    for value_type in value_types:\n        kvps = annotations.get(value_type, None)\n        if kvps:\n            for kvp in kvps:\n                if kvp[\"key\"] == key:\n                    kvp[\"isPrivate\"] = is_private\n                    return kvp\n    raise KeyError('The key \"%s\" couldn\\'t be found in the annotations.' % key)\n</code></pre>"},{"location":"reference/annotations/#synapseclient.annotations.to_synapse_annotations","title":"<code>to_synapse_annotations(annotations)</code>","text":"<p>Transforms a simple flat dictionary to a Synapse-style Annotation object. See the Synapse API documentation for more information on Synapse-style Annotation objects.</p> PARAMETER DESCRIPTION <code>annotations</code> <p>A simple flat dictionary of annotations.</p> <p> TYPE: <code>Annotations</code> </p> RETURNS DESCRIPTION <code>Dict[str, Any]</code> <p>A Synapse-style Annotation dict.</p> Source code in <code>synapseclient/annotations.py</code> <pre><code>def to_synapse_annotations(annotations: Annotations) -&gt; typing.Dict[str, typing.Any]:\n    \"\"\"Transforms a simple flat dictionary to a Synapse-style Annotation object. See\n    the [Synapse API](https://rest-docs.synapse.org/rest/org/sagebionetworks/repo/model/annotation/v2/Annotations.html)\n    documentation for more information on Synapse-style Annotation objects.\n\n    Arguments:\n        annotations: A simple flat dictionary of annotations.\n\n    Returns:\n        A Synapse-style Annotation dict.\n    \"\"\"\n\n    if is_synapse_annotations(annotations):\n        return annotations\n    synapse_annos = {}\n\n    if not isinstance(annotations, Annotations):\n        raise TypeError(\n            \"annotations must be a synapseclient.Annotations object with 'id' and\"\n            \" 'etag' attributes\"\n        )\n\n    synapse_annos[\"id\"] = annotations.id\n    synapse_annos[\"etag\"] = annotations.etag\n\n    synapse_annos[\"annotations\"] = _convert_to_annotations_list(annotations)\n    return synapse_annos\n</code></pre>"},{"location":"reference/annotations/#synapseclient.annotations.from_synapse_annotations","title":"<code>from_synapse_annotations(raw_annotations)</code>","text":"<p>Transforms a Synapse-style Annotation object to a simple flat dictionary.</p> PARAMETER DESCRIPTION <code>raw_annotations</code> <p>A Synapse-style Annotation dict.</p> <p> TYPE: <code>Dict[str, Any]</code> </p> RETURNS DESCRIPTION <code>Annotations</code> <p>A simple flat dictionary of annotations.</p> Source code in <code>synapseclient/annotations.py</code> <pre><code>def from_synapse_annotations(\n    raw_annotations: typing.Dict[str, typing.Any]\n) -&gt; Annotations:\n    \"\"\"Transforms a Synapse-style Annotation object to a simple flat dictionary.\n\n    Arguments:\n        raw_annotations: A Synapse-style Annotation dict.\n\n    Returns:\n        A simple flat dictionary of annotations.\n    \"\"\"\n    if not is_synapse_annotations(raw_annotations):\n        raise ValueError(\n            'Unexpected format of annotations from Synapse. Must include keys: \"id\",'\n            ' \"etag\", and \"annotations\"'\n        )\n\n    annos = Annotations(raw_annotations[\"id\"], raw_annotations[\"etag\"])\n    for key, value_and_type in raw_annotations[\"annotations\"].items():\n        key: str\n        conversion_func = ANNO_TYPE_TO_FUNC[value_and_type[\"type\"]]\n        annos[key] = [conversion_func(v) for v in value_and_type[\"value\"]]\n\n    return annos\n</code></pre>"},{"location":"reference/annotations/#synapseclient.annotations.convert_old_annotation_json","title":"<code>convert_old_annotation_json(annotations)</code>","text":"<p>Transforms a parsed JSON dictionary of old style annotations into a new style consistent with the entity bundle v2 format.</p> <p>This is intended to support some models that were saved as serialized entity bundle JSON (Submissions). we don't need to support newer types here e.g. BOOLEAN because they did not exist at the time that annotation JSON was saved in this form.</p> PARAMETER DESCRIPTION <code>annotations</code> <p>A parsed JSON dictionary of old style annotations.</p> <p> </p> RETURNS DESCRIPTION <p>A v2 Annotation-style dictionary.</p> Source code in <code>synapseclient/annotations.py</code> <pre><code>def convert_old_annotation_json(annotations):\n    \"\"\"Transforms a parsed JSON dictionary of old style annotations\n    into a new style consistent with the entity bundle v2 format.\n\n    This is intended to support some models that were saved as serialized\n    entity bundle JSON (Submissions). we don't need to support newer\n    types here e.g. BOOLEAN because they did not exist at the time\n    that annotation JSON was saved in this form.\n\n    Arguments:\n        annotations: A parsed JSON dictionary of old style annotations.\n\n    Returns:\n        A v2 Annotation-style dictionary.\n    \"\"\"\n\n    meta_keys = (\"id\", \"etag\", \"creationDate\", \"uri\")\n\n    type_mapping = {\n        \"doubleAnnotations\": \"DOUBLE\",\n        \"stringAnnotations\": \"STRING\",\n        \"longAnnotations\": \"LONG\",\n        \"dateAnnotations\": \"TIMESTAMP_MS\",\n    }\n\n    annos_v1_keys = set(meta_keys) | set(type_mapping.keys())\n\n    # blobAnnotations appear to be little/unused and there is no mapping defined here but if they\n    # are present on the annos we should treat it as an old style annos dict\n    annos_v1_keys.add(\"blobAnnotations\")\n\n    # if any keys in the annos dict are not consistent with an old style annotations then we treat\n    # it as an annotations2 style dictionary that is not in need of any conversion\n    if any(k not in annos_v1_keys for k in annotations.keys()):\n        return annotations\n\n    converted = {k: v for k, v in annotations.items() if k in meta_keys}\n    converted_annos = converted[\"annotations\"] = {}\n\n    for old_type_key, converted_type in type_mapping.items():\n        values = annotations.get(old_type_key)\n        if values:\n            for k, vs in values.items():\n                converted_annos[k] = {\n                    \"type\": converted_type,\n                    \"value\": vs,\n                }\n\n    return converted\n</code></pre>"},{"location":"reference/cli/","title":"Command Line Client","text":"<p>The Synapse Python Client can be used from the command line via the synapse command.</p> <p>Note: The command line client is installed along with installation of the Synapse Python client.</p>"},{"location":"reference/cli/#usage","title":"Usage","text":"<p>For help, type:</p> <pre><code>synapse -h\n</code></pre>"},{"location":"reference/client/","title":"Client","text":""},{"location":"reference/client/#synapseclient.Synapse","title":"<code>synapseclient.Synapse</code>","text":"<p>               Bases: <code>object</code></p> <p>Constructs a Python client object for the Synapse repository service</p> ATTRIBUTE DESCRIPTION <code>repoEndpoint</code> <p>Location of Synapse repository</p> <p> </p> <code>authEndpoint</code> <p>Location of authentication service</p> <p> </p> <code>fileHandleEndpoint</code> <p>Location of file service</p> <p> </p> <code>portalEndpoint</code> <p>Location of the website</p> <p> </p> <code>serviceTimeoutSeconds</code> <p>Wait time before timeout (currently unused)</p> <p> </p> <code>debug</code> <p>Print debugging messages if True</p> <p> </p> <code>skip_checks</code> <p>Skip version and endpoint checks</p> <p> </p> <code>configPath</code> <p>Path to config File with setting for Synapse. Defaults to ~/.synapseConfig</p> <p> </p> <code>requests_session</code> <p>A custom requests.Session object that this Synapse instance will use                    when making http requests.</p> <p> </p> <code>cache_root_dir</code> <p>Root directory for storing cache data</p> <p> </p> <code>silent</code> <p>Defaults to False.</p> <p> </p> Getting started <p>Logging in to Synapse using an authToken</p> <pre><code>import synapseclient\nsyn = synapseclient.login(authToken=\"authtoken\")\n</code></pre> <p>Using environment variable or <code>.synapseConfig</code></p> <pre><code>import synapseclient\nsyn = synapseclient.login()\n</code></pre> Source code in <code>synapseclient/client.py</code> <pre><code>class Synapse(object):\n    \"\"\"\n    Constructs a Python client object for the Synapse repository service\n\n    Attributes:\n        repoEndpoint:          Location of Synapse repository\n        authEndpoint:          Location of authentication service\n        fileHandleEndpoint:    Location of file service\n        portalEndpoint:        Location of the website\n        serviceTimeoutSeconds: Wait time before timeout (currently unused)\n        debug:                 Print debugging messages if True\n        skip_checks:           Skip version and endpoint checks\n        configPath:            Path to config File with setting for Synapse. Defaults to ~/.synapseConfig\n        requests_session:      A custom [requests.Session object](https://requests.readthedocs.io/en/latest/user/advanced/) that this Synapse instance will use\n                               when making http requests.\n        cache_root_dir:        Root directory for storing cache data\n        silent:                Defaults to False.\n\n    Example: Getting started\n        Logging in to Synapse using an authToken\n\n            import synapseclient\n            syn = synapseclient.login(authToken=\"authtoken\")\n\n        Using environment variable or `.synapseConfig`\n\n            import synapseclient\n            syn = synapseclient.login()\n\n    \"\"\"\n\n    _synapse_client = None\n\n    # TODO: add additional boolean for write to disk?\n    def __init__(\n        self,\n        repoEndpoint: str = None,\n        authEndpoint: str = None,\n        fileHandleEndpoint: str = None,\n        portalEndpoint: str = None,\n        debug: bool = None,\n        skip_checks: bool = False,\n        configPath: str = CONFIG_FILE,\n        requests_session: requests.Session = None,\n        cache_root_dir: str = None,\n        silent: bool = None,\n        requests_session_async_synapse: httpx.AsyncClient = None,\n        requests_session_storage: httpx.Client = None,\n        asyncio_event_loop: asyncio.AbstractEventLoop = None,\n    ) -&gt; \"Synapse\":\n        \"\"\"\n        Initialize Synapse object\n\n        Arguments:\n            repoEndpoint:       Location of Synapse repository.\n            authEndpoint:       Location of authentication service.\n            fileHandleEndpoint: Location of file service.\n            portalEndpoint:     Location of the website.\n            debug:              Print debugging messages if True.\n            skip_checks:        Skip version and endpoint checks.\n            configPath:         Path to config File with setting for Synapse.\n            requests_session:   A custom [requests.Session object](https://requests.readthedocs.io/en/latest/user/advanced/) that this Synapse instance will use\n                                when making http requests.\n            cache_root_dir:     Root directory for storing cache data.\n            silent:             Suppresses message.\n            requests_session_async_synapse: The HTTPX Async client for interacting with\n                Synapse services.\n            requests_session_storage: The HTTPX client for interacting with\n                storage providers like AWS S3 and Google Cloud.\n            asyncio_event_loop: The event loop that is going to be used while executing\n                this code. This is optional and only used when you are manually\n                specifying an async HTTPX client.\n\n        Raises:\n            ValueError: Warn for non-boolean debug value.\n        \"\"\"\n        self._requests_session = requests_session or requests.Session()\n\n        # `requests_session_async_synapse` and the thread pools are being stored in\n        # a dict based on the current running event loop. This is to ensure that the\n        # connection pooling is maintained within the same event loop. This is to\n        # prevent the connection pooling from being shared across different event loops.\n        if requests_session_async_synapse and asyncio_event_loop:\n            self._requests_session_async_synapse = {\n                asyncio_event_loop: requests_session_async_synapse\n            }\n        else:\n            self._requests_session_async_synapse = {}\n\n        span_dict: Dict[httpx.Request, trace.Span] = {}\n\n        def log_request(request: httpx.Request) -&gt; None:\n            \"\"\"\n            Log the HTTPX request to an otel span.\n\n            Arguments:\n                request: The HTTPX request object.\n            \"\"\"\n            # Don't log the query string as it will contain tokens\n            url_without_query_string: httpx.URL = request.url.copy_with(query=None)\n            current_span = trace.get_current_span()\n            if current_span.is_recording():\n                span = tracer.start_span(\n                    f\"{request.method} {url_without_query_string}\", kind=SpanKind.CLIENT\n                )\n                span.set_attributes(\n                    {\n                        \"url\": str(url_without_query_string),\n                        \"http.method\": request.method,\n                    }\n                )\n                span_dict.update({request: span})\n\n        def log_response(response: httpx.Response) -&gt; None:\n            \"\"\"\n            Log the HTTPX response to an otel span.\n\n            Arguments:\n                response: The HTTPX response object.\n            \"\"\"\n            span = span_dict.pop(response.request, None)\n            if span and span.is_recording():\n                span.set_attribute(\"http.response.status_code\", response.status_code)\n                span.end()\n\n        event_hooks = {\"request\": [log_request], \"response\": [log_response]}\n        httpx_timeout = httpx.Timeout(70, pool=None)\n        self._requests_session_storage = requests_session_storage or httpx.Client(\n            timeout=httpx_timeout, event_hooks=event_hooks\n        )\n\n        cache_root_dir = (\n            cache.CACHE_ROOT_DIR if cache_root_dir is None else cache_root_dir\n        )\n\n        config_debug = None\n        # Check for a config file\n        self.configPath = configPath\n        if os.path.isfile(configPath):\n            config = get_config_file(configPath)\n            if config.has_option(\"cache\", \"location\"):\n                cache_root_dir = config.get(\"cache\", \"location\")\n            if config.has_section(\"debug\"):\n                config_debug = True\n\n        if debug is None:\n            debug = config_debug if config_debug is not None else DEBUG_DEFAULT\n\n        self.cache = cache.Cache(cache_root_dir)\n        self._sts_token_store = sts_transfer.StsTokenStore()\n\n        self.setEndpoints(\n            repoEndpoint, authEndpoint, fileHandleEndpoint, portalEndpoint, skip_checks\n        )\n\n        self.default_headers = {\n            \"content-type\": \"application/json; charset=UTF-8\",\n            \"Accept\": \"application/json; charset=UTF-8\",\n        }\n        self.credentials = None\n\n        if not isinstance(debug, bool):\n            raise ValueError(\"debug must be set to a bool (either True or False)\")\n        self.debug = debug\n\n        self.silent = silent\n        self._init_logger()  # initializes self.logger\n\n        self.skip_checks = skip_checks\n\n        self.table_query_sleep = 2\n        self.table_query_backoff = 1.1\n        self.table_query_max_sleep = 20\n        self.table_query_timeout = 600  # in seconds\n        self.multi_threaded = True  # if set to True, multi threaded download will be used for http and https URLs\n\n        transfer_config = get_transfer_config(config_path=self.configPath)\n        self.max_threads = transfer_config[\"max_threads\"]\n        self._thread_executor = {}\n        self._process_executor = {}\n        self._parallel_file_transfer_semaphore = {}\n        self._md5_semaphore = {}\n        self.use_boto_sts_transfers = transfer_config[\"use_boto_sts\"]\n        self._parts_transfered_counter = 0\n\n    def _get_requests_session_async_synapse(\n        self, asyncio_event_loop: asyncio.AbstractEventLoop\n    ) -&gt; httpx.AsyncClient:\n        \"\"\"\n        httpx.AsyncClient can only use connection pooling within the same event loop.\n        As a result an `atexit` handler is used to close the connection when the event\n        loop is closed. It will also delete the attribute from the object to prevent\n        it from being reused in the future.\n\n        Further documentation can be found here:\n        &lt;https://github.com/encode/httpx/discussions/2959&gt;\n\n\n        As a result of this issue: It is recommended to use the same event loop for all\n        requests. This means to enter into an event loop before making any requests.\n\n        This is expected to be called from within an AsyncIO loop.\n        \"\"\"\n        if (\n            hasattr(self, \"_requests_session_async_synapse\")\n            and asyncio_event_loop in self._requests_session_async_synapse\n            and self._requests_session_async_synapse[asyncio_event_loop] is not None\n        ):\n            return self._requests_session_async_synapse[asyncio_event_loop]\n\n        async def close_connection() -&gt; None:\n            \"\"\"Close connection when event loop exits\"\"\"\n            await self._requests_session_async_synapse[asyncio_event_loop].aclose()\n            del self._requests_session_async_synapse[asyncio_event_loop]\n\n        httpx_timeout = httpx.Timeout(70, pool=None)\n        span_dict: Dict[httpx.Request, trace.Span] = {}\n\n        async def log_request(request: httpx.Request) -&gt; None:\n            \"\"\"\n            Log the HTTPX request to an otel span.\n\n            Arguments:\n                request: The HTTPX request object.\n            \"\"\"\n            current_span = trace.get_current_span()\n            if current_span.is_recording():\n                span = tracer.start_span(\n                    f\"{request.method} {request.url}\", kind=SpanKind.CLIENT\n                )\n                span.set_attributes(\n                    {\"url\": str(request.url), \"http.method\": request.method}\n                )\n                self._attach_rest_data_to_otel(\n                    request.method, str(request.url), request.content, span\n                )\n                span_dict.update({request: span})\n\n        async def log_response(response: httpx.Response) -&gt; None:\n            \"\"\"\n            Log the HTTPX response to an otel span.\n\n            Arguments:\n                response: The HTTPX response object.\n            \"\"\"\n            span = span_dict.pop(response.request, None)\n            if span and span.is_recording():\n                span.set_attribute(\"http.response.status_code\", response.status_code)\n                span.end()\n\n        event_hooks = {\"request\": [log_request], \"response\": [log_response]}\n        self._requests_session_async_synapse.update(\n            {\n                asyncio_event_loop: httpx.AsyncClient(\n                    limits=httpx.Limits(max_connections=25),\n                    timeout=httpx_timeout,\n                    event_hooks=event_hooks,\n                )\n            }\n        )\n\n        asyncio_atexit.register(close_connection)\n        return self._requests_session_async_synapse[asyncio_event_loop]\n\n    def _get_thread_pool_executor(\n        self, asyncio_event_loop: asyncio.AbstractEventLoop\n    ) -&gt; ThreadPoolExecutor:\n        \"\"\"\n        Retrieve the thread pool executor for the Synapse client. Or create a new one if\n        it does not exist. This executor is used for concurrent uploads of data to\n        storage providers like AWS S3 and Google Cloud Storage.\n\n        This is expected to be called from within an AsyncIO loop.\n        \"\"\"\n        if (\n            hasattr(self, \"_thread_executor\")\n            and asyncio_event_loop in self._thread_executor\n            and self._thread_executor[asyncio_event_loop] is not None\n        ):\n            return self._thread_executor[asyncio_event_loop]\n\n        def close_pool() -&gt; None:\n            \"\"\"Close pool when event loop exits\"\"\"\n            self._thread_executor[asyncio_event_loop].shutdown(wait=True)\n            del self._thread_executor[asyncio_event_loop]\n\n        self._thread_executor.update(\n            {asyncio_event_loop: get_executor(thread_count=self.max_threads)}\n        )\n\n        asyncio_atexit.register(close_pool)\n        return self._thread_executor[asyncio_event_loop]\n\n    def _get_process_pool_executor(self, asyncio_event_loop: asyncio.AbstractEventLoop):\n        \"\"\"\n        Retrieve the process pool executor for the Synapse client. Or create a new one\n        if it does not exist. This executor is used for parallel processing of data.\n\n        This is expected to be called from within an AsyncIO loop.\n\n        Note: Within Windows a ProcessPoolExecutor requires that the initial entry point\n        into the code be within a `if __name__ == \"__main__\":` block. This is not\n        possible within the current codebase as it would require everyone using this\n        library to have this as their entry point. As a result, the ProcessPoolExecutor\n        will not work within Windows.\n\n        To get around this Windows limitation this is using this package:\n        https://github.com/joblib/loky\n        \"\"\"\n        if (\n            hasattr(self, \"_process_executor\")\n            and asyncio_event_loop in self._process_executor\n            and self._process_executor[asyncio_event_loop] is not None\n        ):\n            return self._process_executor[asyncio_event_loop]\n\n        self._process_executor.update({asyncio_event_loop: get_reusable_executor(1)})\n\n        return self._process_executor[asyncio_event_loop]\n\n    def _get_md5_semaphore(\n        self, asyncio_event_loop: asyncio.AbstractEventLoop\n    ) -&gt; asyncio.Semaphore:\n        \"\"\"\n        Retrieve the semaphore for the Synapse client. Or create a new one if it does not\n        exist. This semaphore is used to ensure that only one process is calculating the\n        MD5 hash at a time. This is to prevent the custom process pool executor from\n        thrashing or handling the waiting. We should let asyncio handle the waiting.\n\n        This is expected to be called from within an AsyncIO loop.\n        \"\"\"\n        if (\n            hasattr(self, \"_md5_semaphore\")\n            and asyncio_event_loop in self._md5_semaphore\n            and self._md5_semaphore[asyncio_event_loop] is not None\n        ):\n            return self._md5_semaphore[asyncio_event_loop]\n\n        self._md5_semaphore.update({asyncio_event_loop: asyncio.Semaphore(1)})\n\n        return self._md5_semaphore[asyncio_event_loop]\n\n    def _get_parallel_file_transfer_semaphore(\n        self, asyncio_event_loop: asyncio.AbstractEventLoop\n    ) -&gt; asyncio.Semaphore:\n        \"\"\"\n        Retrieve the semaphore for the Synapse client. Or create a new one if it does\n        not exist. This semaphore is used to limit the number of files that can actively\n        enter the uploading/downloading process.\n\n        This is expected to be called from within an AsyncIO loop.\n\n        By default the number of files that can enter the \"uploading\" state will be\n        limited to 2 * max_threads. This is to ensure that the files that are entering\n        into the \"uploading\" state will have priority to finish. Additionally, it means\n        that there should be a good spread of files getting up to the \"uploading\"\n        state, entering the \"uploading\" state, and finishing the \"uploading\" state.\n\n        If we break these states down into large components they would look like:\n        - Before \"uploading\" state: HTTP rest calls to retrieve what data Synapse has\n        - Entering \"uploading\" state: MD5 calculation and HTTP rest calls to determine\n          how/where to upload a file to.\n        - During \"uploading\" state: Uploading the file to a storage provider.\n        - After \"uploading\" state: HTTP rest calls to finalize the upload.\n\n        This has not yet been applied to parallel file downloads. That will take place\n        later on.\n        \"\"\"\n        if (\n            hasattr(self, \"_parallel_file_transfer_semaphore\")\n            and asyncio_event_loop in self._parallel_file_transfer_semaphore\n            and self._parallel_file_transfer_semaphore[asyncio_event_loop] is not None\n        ):\n            return self._parallel_file_transfer_semaphore[asyncio_event_loop]\n\n        self._parallel_file_transfer_semaphore.update(\n            {asyncio_event_loop: asyncio.Semaphore(max(self.max_threads * 2, 1))}\n        )\n\n        return self._parallel_file_transfer_semaphore[asyncio_event_loop]\n\n    # initialize logging\n    def _init_logger(self):\n        \"\"\"\n        Initialize logging\n        \"\"\"\n        logger_name = (\n            SILENT_LOGGER_NAME\n            if self.silent\n            else DEBUG_LOGGER_NAME\n            if self.debug\n            else DEFAULT_LOGGER_NAME\n        )\n        self.logger = logging.getLogger(logger_name)\n        logging.getLogger(\"py.warnings\").handlers = self.logger.handlers\n\n    @classmethod\n    def get_client(cls, synapse_client: typing.Union[None, \"Synapse\"]) -&gt; \"Synapse\":\n        \"\"\"\n        Convience function to get an instance of 'Synapse'. The latest instance created\n        by 'login()' or set via `set_client` will be returned.\n\n        When 'logout()' is called it will delete the instance.\n\n        Arguments:\n            synapse_client: An instance of 'Synapse' or None. This is used to simplify logical checks\n                    in cases where synapse is passed into them.\n\n        Returns:\n            An instance of 'Synapse'.\n\n        Raises:\n            SynapseError: No instance has been created - Please use login() first\n        \"\"\"\n        if synapse_client:\n            return synapse_client\n\n        if not cls._synapse_client:\n            raise SynapseError(\n                \"No instance has been created - Please use login() first\"\n            )\n        return cls._synapse_client\n\n    @classmethod\n    def set_client(cls, synapse_client) -&gt; None:\n        cls._synapse_client = synapse_client\n\n    @property\n    def max_threads(self) -&gt; int:\n        return self._max_threads\n\n    @max_threads.setter\n    def max_threads(self, value: int):\n        self._max_threads = min(max(value, 1), MAX_THREADS_CAP)\n\n    @property\n    def username(self) -&gt; Union[str, None]:\n        # for backwards compatability when username was a part of the Synapse object and not in credentials\n        return self.credentials.username if self.credentials is not None else None\n\n    @deprecated(\n        version=\"4.4.0\",\n        reason=\"To be removed in 5.0.0. \"\n        \"Moved to synapseclient/api/configuration_services.py::get_config_file\",\n    )\n    @functools.lru_cache()\n    def getConfigFile(self, configPath: str) -&gt; configparser.RawConfigParser:\n        \"\"\"\n        Retrieves the client configuration information.\n\n        Arguments:\n            configPath:  Path to configuration file on local file system\n\n        Returns:\n            A RawConfigParser populated with properties from the user's configuration file.\n        \"\"\"\n\n        try:\n            config = configparser.RawConfigParser()\n            config.read(configPath)  # Does not fail if the file does not exist\n            return config\n        except configparser.Error as ex:\n            raise ValueError(\n                \"Error parsing Synapse config file: {}\".format(configPath)\n            ) from ex\n\n    def setEndpoints(\n        self,\n        repoEndpoint: str = None,\n        authEndpoint: str = None,\n        fileHandleEndpoint: str = None,\n        portalEndpoint: str = None,\n        skip_checks: bool = False,\n    ) -&gt; None:\n        \"\"\"\n        Sets the locations for each of the Synapse services (mostly useful for testing).\n\n        Arguments:\n            repoEndpoint:          Location of synapse repository\n            authEndpoint:          Location of authentication service\n            fileHandleEndpoint:    Location of file service\n            portalEndpoint:        Location of the website\n            skip_checks:           Skip version and endpoint checks\n\n        Example: Switching endpoints\n            To switch between staging and production endpoints\n\n                syn.setEndpoints(**synapseclient.client.STAGING_ENDPOINTS)\n                syn.setEndpoints(**synapseclient.client.PRODUCTION_ENDPOINTS)\n\n        \"\"\"\n\n        endpoints = {\n            \"repoEndpoint\": repoEndpoint,\n            \"authEndpoint\": authEndpoint,\n            \"fileHandleEndpoint\": fileHandleEndpoint,\n            \"portalEndpoint\": portalEndpoint,\n        }\n\n        # For unspecified endpoints, first look in the config file\n        config = get_config_file(self.configPath)\n        for point in endpoints.keys():\n            if endpoints[point] is None and config.has_option(\"endpoints\", point):\n                endpoints[point] = config.get(\"endpoints\", point)\n\n        # Endpoints default to production\n        for point in endpoints.keys():\n            if endpoints[point] is None:\n                endpoints[point] = PRODUCTION_ENDPOINTS[point]\n\n            # Update endpoints if we get redirected\n            if not skip_checks:\n                response = self._requests_session.get(\n                    endpoints[point],\n                    allow_redirects=False,\n                    headers=synapseclient.USER_AGENT,\n                )\n                if response.status_code == 301:\n                    endpoints[point] = response.headers[\"location\"]\n\n        self.repoEndpoint = endpoints[\"repoEndpoint\"]\n        self.authEndpoint = endpoints[\"authEndpoint\"]\n        self.fileHandleEndpoint = endpoints[\"fileHandleEndpoint\"]\n        self.portalEndpoint = endpoints[\"portalEndpoint\"]\n\n    def login(\n        self,\n        email: str = None,\n        silent: bool = False,\n        authToken: str = None,\n        cache_client: bool = True,\n    ) -&gt; None:\n        \"\"\"\n        Valid combinations of login() arguments:\n\n        - authToken\n\n        If no login arguments are provided or only username is provided, login() will attempt to log in using\n         information from these sources (in order of preference):\n\n        1. .synapseConfig file (in user home folder unless configured otherwise)\n        2. User defined arguments during a CLI session\n        3. User's Personal Access Token (aka: Synapse Auth Token)\n            from the environment variable: SYNAPSE_AUTH_TOKEN\n        4. Retrieves user's authentication token from AWS SSM Parameter store (if configured)\n\n        Arguments:\n            email:        Synapse user name (or an email address associated with a Synapse account)\n            authToken:    A bearer authorization token, e.g. a\n                [personal access token](https://python-docs.synapse.org/tutorials/authentication/).\n            silent:       Defaults to False.  Suppresses the \"Welcome ...!\" message.\n            cache_client: Whether to cache the Synapse client object in the Synapse module. Defaults to True.\n                             When set to True anywhere a `Synapse` object is optional you do not need to pass an\n                             instance of `Synapse` to that function, method, or class.\n\n        Example: Logging in\n            Using an auth token:\n\n                syn.login(authToken=\"authtoken\")\n                &gt; Welcome, Me!\n\n            Using an auth token and username. The username is optional but verified\n            against the username in the auth token:\n\n                syn.login(email=\"my-username\", authToken=\"authtoken\")\n                &gt; Welcome, Me!\n\n        \"\"\"\n        # Note: the order of the logic below reflects the ordering in the docstring above.\n\n        # Check version before logging in\n        if not self.skip_checks:\n            version_check()\n\n        # Make sure to invalidate the existing session\n        self.logout()\n\n        credential_provider_chain = get_default_credential_chain()\n\n        self.credentials = credential_provider_chain.get_credentials(\n            syn=self,\n            user_login_args=UserLoginArgs(\n                email,\n                authToken,\n            ),\n        )\n\n        # Final check on login success\n        if not self.credentials:\n            raise SynapseNoCredentialsError(\"No credentials provided.\")\n\n        if not silent:\n            profile = self.getUserProfile()\n            display_name = (\n                profile[\"displayName\"]\n                if \"displayName\" in profile\n                else self.credentials.username\n            )\n            self.logger.info(f\"Welcome, {display_name}!\\n\")\n\n        if cache_client:\n            Synapse.set_client(self)\n\n    @deprecated(\n        version=\"4.4.0\",\n        reason=\"To be removed in 5.0.0. \"\n        \"Moved to synapseclient/api/configuration_services.py::get_config_section_dict\",\n    )\n    def _get_config_section_dict(self, section_name: str) -&gt; Dict[str, str]:\n        \"\"\"\n        Get a profile section in the configuration file with the section name.\n\n        Arguments:\n            section_name: The name of the profile section in the configuration file\n\n        Returns:\n            A dictionary containing the configuration profile section content\n        \"\"\"\n        config = get_config_file(self.configPath)\n        try:\n            return dict(config.items(section_name))\n        except configparser.NoSectionError:\n            # section not present\n            return {}\n\n    @deprecated(\n        version=\"4.4.0\",\n        reason=\"To be removed in 5.0.0. \"\n        \"Moved to synapseclient/api/configuration_services.py::get_config_authentication\",\n    )\n    def _get_config_authentication(self) -&gt; Dict[str, str]:\n        \"\"\"\n        Get the authentication section of the configuration file.\n\n        Returns:\n            The authentication section of the configuration file\n        \"\"\"\n        return get_config_section_dict(\n            section_name=config_file_constants.AUTHENTICATION_SECTION_NAME,\n            config_path=self.configPath,\n        )\n\n    @deprecated(\n        version=\"4.4.0\",\n        reason=\"To be removed in 5.0.0. \"\n        \"Moved to synapseclient/api/configuration_services.py::get_client_authenticated_s3_profile\",\n    )\n    def _get_client_authenticated_s3_profile(\n        self, endpoint: str, bucket: str\n    ) -&gt; Dict[str, str]:\n        \"\"\"\n        Get the authenticated S3 profile from the configuration file.\n\n        Arguments:\n            endpoint: The location of the target service\n            bucket:   AWS S3 bucket name\n\n        Returns:\n            The authenticated S3 profile\n        \"\"\"\n        config_section = endpoint + \"/\" + bucket\n        return get_config_section_dict(\n            section_name=config_section, config_path=self.configPath\n        ).get(\"profile_name\", \"default\")\n\n    @deprecated(\n        version=\"4.4.0\",\n        reason=\"To be removed in 5.0.0. \"\n        \"Moved to synapseclient/api/configuration_services.py::get_transfer_config\",\n    )\n    def _get_transfer_config(self) -&gt; Dict[str, str]:\n        \"\"\"\n        Get the transfer profile from the configuration file.\n\n        Raises:\n            ValueError: Invalid max_threads value. Should be equal or less than 16.\n            ValueError: Invalid use_boto_sts value. Should be true or false.\n\n        Returns:\n            The transfer profile\n        \"\"\"\n        # defaults\n        transfer_config = {\"max_threads\": DEFAULT_NUM_THREADS, \"use_boto_sts\": False}\n\n        for k, v in get_config_section_dict(\n            section_name=\"transfer\", config_path=self.configPath\n        ).items():\n            if v:\n                if k == \"max_threads\" and v:\n                    try:\n                        transfer_config[\"max_threads\"] = int(v)\n                    except ValueError as cause:\n                        raise ValueError(\n                            f\"Invalid transfer.max_threads config setting {v}\"\n                        ) from cause\n\n                elif k == \"use_boto_sts\":\n                    lower_v = v.lower()\n                    if lower_v not in (\"true\", \"false\"):\n                        raise ValueError(\n                            f\"Invalid transfer.use_boto_sts config setting {v}\"\n                        )\n\n                    transfer_config[\"use_boto_sts\"] = \"true\" == lower_v\n\n        return transfer_config\n\n    def _is_logged_in(self) -&gt; bool:\n        \"\"\"\n        Test whether the user is logged in to Synapse.\n\n        Returns:\n            Boolean value indicating current user's login status\n        \"\"\"\n        # This is a quick sanity check to see if credentials have been\n        # configured on the client\n        if self.credentials is None:\n            return False\n        # The public can query this command so there is no need to try catch.\n        user = self.restGET(\"/userProfile\")\n        if user.get(\"userName\") == \"anonymous\":\n            return False\n        return True\n\n    def logout(self) -&gt; None:\n        \"\"\"\n        Removes authentication information from the Synapse client.\n\n        Returns:\n            None\n        \"\"\"\n        self.credentials = None\n\n    @deprecated(\n        version=\"4.0.0\",\n        reason=\"deprecated with no replacement. The client does not support API keys for \"\n        \"authentication. Please use a personal access token instead. This method will \"\n        \"be removed in a future release.\",\n    )\n    def invalidateAPIKey(self):\n        \"\"\"\n        **Deprecated with no replacement.** The client does not support API keys for\n        authentication. Please use a\n        [personal access token](https://python-docs.synapse.org/tutorials/authentication/)\n        instead. This method will be removed in a future release.\n\n\n        Invalidates authentication across all clients.\n\n        Returns:\n            None\n        \"\"\"\n\n        # Logout globally\n        if self._is_logged_in():\n            self.restDELETE(\"/secretKey\", endpoint=self.authEndpoint)\n\n    @functools.lru_cache()\n    def get_user_profile_by_username(\n        self,\n        username: str = None,\n        sessionToken: str = None,\n    ) -&gt; UserProfile:\n        \"\"\"\n        Get the details about a Synapse user.\n        Retrieves information on the current user if 'id' is omitted or is empty string.\n\n        Arguments:\n            username:     The userName of a user\n            sessionToken: The session token to use to find the user profile\n\n        Returns:\n            The user profile for the user of interest.\n\n        Example: Using this function\n            Getting your own profile\n\n                my_profile = syn.get_user_profile_by_username()\n\n            Getting another user's profile\n\n                freds_profile = syn.get_user_profile_by_username('fredcommo')\n        \"\"\"\n        is_none = username is None\n        is_str = isinstance(username, str)\n        if not is_str and not is_none:\n            raise TypeError(\"username must be string or None\")\n        if is_str:\n            principals = self._findPrincipals(username)\n            for principal in principals:\n                if principal.get(\"userName\", None).lower() == username.lower():\n                    id = principal[\"ownerId\"]\n                    break\n            else:\n                raise ValueError(f\"Can't find user '{username}'\")\n        else:\n            id = \"\"\n        uri = f\"/userProfile/{id}\"\n        return UserProfile(\n            **self.restGET(\n                uri, headers={\"sessionToken\": sessionToken} if sessionToken else None\n            )\n        )\n\n    @functools.lru_cache()\n    def get_user_profile_by_id(\n        self,\n        id: int = None,\n        sessionToken: str = None,\n    ) -&gt; UserProfile:\n        \"\"\"\n        Get the details about a Synapse user.\n        Retrieves information on the current user if 'id' is omitted.\n\n        Arguments:\n            id:           The ownerId of a user\n            sessionToken: The session token to use to find the user profile\n\n        Returns:\n            The user profile for the user of interest.\n\n\n        Example: Using this function\n            Getting your own profile\n\n                my_profile = syn.get_user_profile_by_id()\n\n            Getting another user's profile\n\n                freds_profile = syn.get_user_profile_by_id(1234567)\n        \"\"\"\n        if id:\n            if not isinstance(id, int):\n                raise TypeError(\"id must be an 'ownerId' integer\")\n        else:\n            id = \"\"\n        uri = f\"/userProfile/{id}\"\n        return UserProfile(\n            **self.restGET(\n                uri, headers={\"sessionToken\": sessionToken} if sessionToken else None\n            )\n        )\n\n    @functools.lru_cache()\n    def getUserProfile(\n        self,\n        id: Union[str, int, UserProfile, TeamMember] = None,\n        sessionToken: str = None,\n    ) -&gt; UserProfile:\n        \"\"\"\n        Get the details about a Synapse user.\n        Retrieves information on the current user if 'id' is omitted.\n\n        Arguments:\n            id:           The 'userId' (aka 'ownerId') of a user or the userName\n            sessionToken: The session token to use to find the user profile\n\n        Returns:\n            The user profile for the user of interest.\n\n        Example: Using this function\n            Getting your own profile\n\n                my_profile = syn.getUserProfile()\n\n            Getting another user's profile\n\n                freds_profile = syn.getUserProfile('fredcommo')\n        \"\"\"\n        try:\n            # if id is unset or a userID, this will succeed\n            id = \"\" if id is None else int(id)\n        except (TypeError, ValueError):\n            if isinstance(id, collections.abc.Mapping) and \"ownerId\" in id:\n                id = id.ownerId\n            elif isinstance(id, TeamMember):\n                id = id.member.ownerId\n            else:\n                principals = self._findPrincipals(id)\n                if len(principals) == 1:\n                    id = principals[0][\"ownerId\"]\n                else:\n                    for principal in principals:\n                        if principal.get(\"userName\", None).lower() == id.lower():\n                            id = principal[\"ownerId\"]\n                            break\n                    else:  # no break\n                        raise ValueError('Can\\'t find user \"%s\": ' % id)\n        uri = \"/userProfile/%s\" % id\n        return UserProfile(\n            **self.restGET(\n                uri, headers={\"sessionToken\": sessionToken} if sessionToken else None\n            )\n        )\n\n    def _findPrincipals(self, query_string: str) -&gt; List[UserGroupHeader]:\n        \"\"\"\n        Find users or groups by name or email.\n\n        Returns:\n            A list of userGroupHeader objects with fields displayName, email, firstName, lastName, isIndividual, ownerId\n\n\n        Example: Using this function\n            Find userGroupHeader objects for test user\n\n                syn._findPrincipals('test')\n\n                [{u'displayName': u'Synapse Test',\n                u'email': u'syn...t@sagebase.org',\n                u'firstName': u'Synapse',\n                u'isIndividual': True,\n                u'lastName': u'Test',\n                u'ownerId': u'1560002'},\n                {u'displayName': ... }]\n        \"\"\"\n        uri = \"/userGroupHeaders?prefix=%s\" % urllib_urlparse.quote(query_string)\n        return [UserGroupHeader(**result) for result in self._GET_paginated(uri)]\n\n    def _get_certified_passing_record(\n        self, userid: int\n    ) -&gt; Dict[str, Union[str, int, bool, list]]:\n        \"\"\"\n        Retrieve the Passing Record on the User Certification test for the given user.\n\n        Arguments:\n            userid: Synapse user Id\n\n        Returns:\n            Synapse Passing Record. A record of whether a given user passed a given test.\n            &lt;https://rest-docs.synapse.org/rest/org/sagebionetworks/repo/model/quiz/PassingRecord.html&gt;\n        \"\"\"\n        response = self.restGET(f\"/user/{userid}/certifiedUserPassingRecord\")\n        return response\n\n    def _get_user_bundle(self, userid: int, mask: int) -&gt; Dict[str, Union[str, dict]]:\n        \"\"\"\n        Retrieve the user bundle for the given user.\n\n        Arguments:\n            userid: Synapse user Id\n            mask:   Bit field indicating which components to include in the bundle.\n\n        Returns:\n            [Synapse User Bundle](https://rest-docs.synapse.org/rest/org/sagebionetworks/repo/model/UserBundle.html)\n        \"\"\"\n        try:\n            response = self.restGET(f\"/user/{userid}/bundle?mask={mask}\")\n        except SynapseHTTPError as ex:\n            if ex.response.status_code == 404:\n                return None\n        return response\n\n    def is_certified(self, user: typing.Union[str, int]) -&gt; bool:\n        \"\"\"Determines whether a Synapse user is a certified user.\n\n        Arguments:\n            user: Synapse username or Id\n\n        Returns:\n            True if the Synapse user is certified\n        \"\"\"\n        # Check if userid or username exists\n        syn_user = self.getUserProfile(user)\n        # Get passing record\n\n        try:\n            certification_status = self._get_certified_passing_record(\n                syn_user[\"ownerId\"]\n            )\n            return certification_status[\"passed\"]\n        except SynapseHTTPError as ex:\n            if ex.response.status_code == 404:\n                # user hasn't taken the quiz\n                return False\n            raise\n\n    def is_synapse_id(self, syn_id: str) -&gt; bool:\n        \"\"\"Checks if given synID is valid (attached to actual entity?)\n\n        Arguments:\n            syn_id: A Synapse ID\n\n        Returns:\n            True if the Synapse ID is valid\n        \"\"\"\n        if isinstance(syn_id, str):\n            try:\n                self.get(syn_id, downloadFile=False)\n            except SynapseFileNotFoundError:\n                return False\n            except (\n                SynapseHTTPError,\n                SynapseAuthenticationError,\n            ) as err:\n                status = (\n                    err.__context__.response.status_code or err.response.status_code\n                )\n                if status in (400, 404):\n                    return False\n                # Valid ID but user lacks permission or is not logged in\n                elif status == 403:\n                    return True\n            return True\n        self.logger.warning(\"synID must be a string\")\n        return False\n\n    def onweb(self, entity, subpageId=None):\n        \"\"\"Opens up a browser window to the entity page or wiki-subpage.\n\n        Arguments:\n            entity:    Either an Entity or a Synapse ID\n            subpageId: (Optional) ID of one of the wiki's sub-pages\n\n        Returns:\n            None\n        \"\"\"\n        if isinstance(entity, str) and os.path.isfile(entity):\n            entity = self.get(entity, downloadFile=False)\n        synId = id_of(entity)\n        if subpageId is None:\n            webbrowser.open(\"%s#!Synapse:%s\" % (self.portalEndpoint, synId))\n        else:\n            webbrowser.open(\n                \"%s#!Wiki:%s/ENTITY/%s\" % (self.portalEndpoint, synId, subpageId)\n            )\n\n    def printEntity(self, entity, ensure_ascii=True) -&gt; None:\n        \"\"\"\n        Pretty prints an Entity.\n\n        Arguments:\n            entity: The entity to be printed.\n            ensure_ascii: If True, escapes all non-ASCII characters\n\n        Returns:\n            None\n        \"\"\"\n\n        if utils.is_synapse_id_str(entity):\n            synid, version = utils.get_synid_and_version(entity)\n            entity = self._getEntity(synid, version)\n        try:\n            self.logger.info(\n                json.dumps(entity, sort_keys=True, indent=2, ensure_ascii=ensure_ascii)\n            )\n        except TypeError:\n            self.logger.info(str(entity))\n\n    def _print_transfer_progress(self, *args, **kwargs) -&gt; None:\n        \"\"\"\n        Checking synapse if the mode is silent mode.\n        If self.silent is True, no need to print out transfer progress.\n        \"\"\"\n        if self.silent is not True:\n            cumulative_transfer_progress.printTransferProgress(*args, **kwargs)\n\n    ############################################################\n    #                      Service methods                     #\n    ############################################################\n\n    _services = {\n        \"json_schema\": \"JsonSchemaService\",\n    }\n\n    def get_available_services(self) -&gt; typing.List[str]:\n        \"\"\"Get available Synapse services\n        This is a beta feature and is subject to change\n\n        Returns:\n            List of available services\n        \"\"\"\n        services = self._services.keys()\n        return list(services)\n\n    def service(self, service_name: str):\n        \"\"\"Get available Synapse services\n        This is a beta feature and is subject to change\n\n        Arguments:\n            service_name: name of the service\n        \"\"\"\n        # This is to avoid circular imports\n        # TODO: revisit the import order and method https://stackoverflow.com/a/37126790\n        # To move this to the top\n        import synapseclient.services\n\n        assert isinstance(service_name, str)\n        service_name = service_name.lower().replace(\" \", \"_\")\n        assert service_name in self._services, (\n            f\"Unrecognized service ({service_name}). Run the 'get_available_\"\n            \"services()' method to get a list of available services.\"\n        )\n        service_attr = self._services[service_name]\n        service_cls = getattr(synapseclient.services, service_attr)\n        service = service_cls(self)\n        return service\n\n    ############################################################\n    #                   Get / Store methods                    #\n    ############################################################\n\n    def get(self, entity, **kwargs):\n        \"\"\"\n        Gets a Synapse entity from the repository service.\n\n        Arguments:\n            entity:           A Synapse ID (e.g. syn123 or syn123.1, with .1 denoting version), a Synapse Entity object,\n                              a plain dictionary in which 'id' maps to a Synapse ID or a local file that is stored in\n                              Synapse (found by the file MD5)\n            version:          The specific version to get.\n                                Defaults to the most recent version. If not denoted in the entity input.\n            downloadFile:     Whether associated files(s) should be downloaded.\n                                Defaults to True.\n            downloadLocation: Directory where to download the Synapse File Entity.\n                                Defaults to the local cache.\n            followLink:       Whether the link returns the target Entity.\n                                Defaults to False.\n            ifcollision:      Determines how to handle file collisions.\n                                May be \"overwrite.local\", \"keep.local\", or \"keep.both\".\n                                Defaults to \"keep.both\".\n            limitSearch:      A Synanpse ID used to limit the search in Synapse if entity is specified as a local\n                                file.  That is, if the file is stored in multiple locations in Synapse only the ones\n                                in the specified folder/project will be returned.\n            md5: The MD5 checksum for the file, if known. Otherwise if the file is a\n                local file, it will be calculated automatically.\n\n        Returns:\n            A new Synapse Entity object of the appropriate type.\n\n        Example: Using this function\n            Download file into cache\n\n                entity = syn.get('syn1906479')\n                print(entity.name)\n                print(entity.path)\n\n            Download file into current working directory\n\n                entity = syn.get('syn1906479', downloadLocation='.')\n                print(entity.name)\n                print(entity.path)\n\n            Determine the provenance of a locally stored file as indicated in Synapse\n\n                entity = syn.get('/path/to/file.txt', limitSearch='syn12312')\n                print(syn.getProvenance(entity))\n        \"\"\"\n        # If entity is a local file determine the corresponding synapse entity\n        if isinstance(entity, str) and os.path.isfile(entity):\n            bundle = self._getFromFile(\n                entity, kwargs.pop(\"limitSearch\", None), md5=kwargs.get(\"md5\", None)\n            )\n            kwargs[\"downloadFile\"] = False\n            kwargs[\"path\"] = entity\n\n        elif isinstance(entity, str) and not utils.is_synapse_id_str(entity):\n            raise SynapseFileNotFoundError(\n                (\n                    \"The parameter %s is neither a local file path \"\n                    \" or a valid entity id\" % entity\n                )\n            )\n        # have not been saved entities\n        elif isinstance(entity, Entity) and not entity.get(\"id\"):\n            raise ValueError(\n                \"Cannot retrieve entity that has not been saved.\"\n                \" Please use syn.store() to save your entity and try again.\"\n            )\n        else:\n            input_version = kwargs.get(\"version\", None)\n            synid_and_version = utils.get_synid_and_version(entity)\n            version = (\n                input_version if input_version is not None else synid_and_version[1]\n            )\n            # If ``version`` is None, the arg will be ignored\n            bundle = self._getEntityBundle(synid_and_version[0], version)\n\n        # Check and warn for unmet access requirements\n        self._check_entity_restrictions(\n            bundle, entity, kwargs.get(\"downloadFile\", True)\n        )\n\n        return_data = self._getWithEntityBundle(\n            entityBundle=bundle, entity=entity, **kwargs\n        )\n        trace.get_current_span().set_attributes(\n            {\n                \"synapse.id\": return_data.get(\"id\", \"\"),\n                \"synapse.concrete_type\": return_data.get(\"concreteType\", \"\"),\n            }\n        )\n        return return_data\n\n    def _check_entity_restrictions(\n        self, bundle: dict, entity: Union[str, Entity, dict], downloadFile: bool\n    ) -&gt; None:\n        \"\"\"\n        Check and warn for unmet access requirements.\n\n        Arguments:\n            bundle: A Synapse entityBundle\n            entity: A Synapse ID, a Synapse Entity object, a plain dictionary in which 'id' maps to a\n                    Synapse ID or a local file that is stored in Synapse (found by the file MD5)\n            downloadFile: Whether associated files(s) should be downloaded.\n\n        Raises:\n            SynapseUnmetAccessRestrictions: Warning for unmet access requirements.\n        \"\"\"\n        restrictionInformation = bundle[\"restrictionInformation\"]\n        if restrictionInformation[\"hasUnmetAccessRequirement\"]:\n            warning_message = (\n                \"\\nThis entity has access restrictions. Please visit the web page for this entity \"\n                f'(syn.onweb(\"{id_of(entity)}\")). Look for the \"Access\" label and the lock icon underneath '\n                'the file name. Click \"Request Access\", and then review and fulfill the file '\n                \"download requirement(s).\\n\"\n            )\n            if downloadFile and bundle.get(\"entityType\") not in (\"project\", \"folder\"):\n                raise SynapseUnmetAccessRestrictions(warning_message)\n            warnings.warn(warning_message)\n\n    def _getFromFile(\n        self, filepath: str, limitSearch: str = None, md5: str = None\n    ) -&gt; Dict[str, dict]:\n        \"\"\"\n        Gets a Synapse entityBundle based on the md5 of a local file.\n        See [get][synapseclient.Synapse.get].\n\n        Arguments:\n            filepath:    The path to local file\n            limitSearch: Limits the places in Synapse where the file is searched for.\n            md5: The MD5 checksum for the file, if known. Otherwise if the file is a\n                local file, it will be calculated automatically.\n\n\n        Raises:\n            SynapseFileNotFoundError: If the file is not in Synapse.\n\n        Returns:\n            A Synapse entityBundle\n        \"\"\"\n        results = self.restGET(\n            \"/entity/md5/%s\" % (md5 or utils.md5_for_file(filepath).hexdigest())\n        )[\"results\"]\n        if limitSearch is not None:\n            # Go through and find the path of every entity found\n            paths = [self.restGET(\"/entity/%s/path\" % ent[\"id\"]) for ent in results]\n            # Filter out all entities whose path does not contain limitSearch\n            results = [\n                ent\n                for ent, path in zip(results, paths)\n                if utils.is_in_path(limitSearch, path)\n            ]\n        if len(results) == 0:  # None found\n            raise SynapseFileNotFoundError(\"File %s not found in Synapse\" % (filepath,))\n        elif len(results) &gt; 1:\n            id_txts = \"\\n\".join(\n                [\"%s.%i\" % (r[\"id\"], r[\"versionNumber\"]) for r in results]\n            )\n            self.logger.warning(\n                \"\\nThe file %s is associated with many files in Synapse:\\n%s\\n\"\n                \"You can limit to files in specific project or folder by setting the limitSearch to the\"\n                \" synapse Id of the project or folder.\\n\"\n                \"Will use the first one returned: \\n\"\n                \"%s version %i\\n\"\n                % (filepath, id_txts, results[0][\"id\"], results[0][\"versionNumber\"])\n            )\n        entity = results[0]\n\n        bundle = self._getEntityBundle(entity, version=entity[\"versionNumber\"])\n        self.cache.add(bundle[\"entity\"][\"dataFileHandleId\"], filepath)\n\n        return bundle\n\n    def move(self, entity, new_parent):\n        \"\"\"\n        Move a Synapse entity to a new container.\n\n        Arguments:\n            entity:     A Synapse ID, a Synapse Entity object, or a local file that is stored in Synapse\n            new_parent: The new parent container (Folder or Project) to which the entity should be moved.\n\n        Returns:\n            The Synapse Entity object that has been moved.\n\n        Example: Using this function\n            Move a Synapse Entity object to a new parent container\n\n                entity = syn.move('syn456', 'syn123')\n        \"\"\"\n\n        entity = self.get(entity, downloadFile=False)\n        entity.parentId = id_of(new_parent)\n        entity = self.store(entity, forceVersion=False)\n        trace.get_current_span().set_attributes(\n            {\n                \"synapse.id\": entity.get(\"id\", \"\"),\n                \"synapse.parent_id\": entity.get(\"parentId\", \"\"),\n            }\n        )\n\n        return entity\n\n    def _getWithEntityBundle(\n        self, entityBundle: dict, entity: Entity = None, **kwargs\n    ) -&gt; Entity:\n        \"\"\"\n        Creates a [Entity][synapseclient.Entity] from an entity bundle returned by Synapse.\n        An existing Entity can be supplied in case we want to refresh a stale Entity.\n\n        Arguments:\n            entityBundle: Uses the given dictionary as the meta information of the Entity to get\n            entity:       Optional, entity whose local state will be copied into the returned entity\n            submission:   Optional, access associated files through a submission rather than through an entity.\n\n        Returns:\n            A new Synapse Entity\n\n        Also see:\n        - See [get][synapseclient.Synapse.get].\n        - See [_getEntityBundle][synapseclient.Synapse._getEntityBundle].\n        - See [Entity][synapseclient.Entity].\n        \"\"\"\n        # Note: This version overrides the version of 'entity' (if the object is Mappable)\n        kwargs.pop(\"version\", None)\n        downloadFile = kwargs.pop(\"downloadFile\", True)\n        downloadLocation = kwargs.pop(\"downloadLocation\", None)\n        ifcollision = kwargs.pop(\"ifcollision\", None)\n        submission = kwargs.pop(\"submission\", None)\n        followLink = kwargs.pop(\"followLink\", False)\n        path = kwargs.pop(\"path\", None)\n\n        # If Link, get target ID entity bundle\n        if (\n            entityBundle[\"entity\"][\"concreteType\"]\n            == \"org.sagebionetworks.repo.model.Link\"\n            and followLink\n        ):\n            targetId = entityBundle[\"entity\"][\"linksTo\"][\"targetId\"]\n            targetVersion = entityBundle[\"entity\"][\"linksTo\"].get(\"targetVersionNumber\")\n            entityBundle = self._getEntityBundle(targetId, targetVersion)\n\n        # TODO is it an error to specify both downloadFile=False and downloadLocation?\n        # TODO this matters if we want to return already cached files when downloadFile=False\n\n        # Make a fresh copy of the Entity\n        local_state = (\n            entity.local_state() if entity and isinstance(entity, Entity) else {}\n        )\n        if path is not None:\n            local_state[\"path\"] = path\n        properties = entityBundle[\"entity\"]\n        annotations = from_synapse_annotations(entityBundle[\"annotations\"])\n        entity = Entity.create(properties, annotations, local_state)\n\n        # Handle download of fileEntities\n        if isinstance(entity, File):\n            # update the entity with FileHandle metadata\n            file_handle = next(\n                (\n                    handle\n                    for handle in entityBundle[\"fileHandles\"]\n                    if handle[\"id\"] == entity.dataFileHandleId\n                ),\n                None,\n            )\n            entity._update_file_handle(file_handle)\n\n            if downloadFile:\n                if file_handle:\n                    wrap_async_to_sync(\n                        coroutine=download_file_entity(\n                            download_location=downloadLocation,\n                            entity=entity,\n                            if_collision=ifcollision,\n                            submission=submission,\n                            synapse_client=self,\n                        ),\n                        syn=self,\n                    )\n                else:  # no filehandle means that we do not have DOWNLOAD permission\n                    warning_message = (\n                        \"WARNING: You have READ permission on this file entity but not DOWNLOAD \"\n                        \"permission. The file has NOT been downloaded.\"\n                    )\n                    self.logger.warning(\n                        \"\\n\"\n                        + \"!\" * len(warning_message)\n                        + \"\\n\"\n                        + warning_message\n                        + \"\\n\"\n                        + \"!\" * len(warning_message)\n                        + \"\\n\"\n                    )\n        return entity\n\n    @deprecated(\n        version=\"4.4.0\",\n        reason=\"To be removed in 5.0.0. \"\n        \"Moved to synapseclient/core/download/download_functions.py::ensure_download_location_is_directory\",\n    )\n    def _ensure_download_location_is_directory(self, downloadLocation: str) -&gt; str:\n        \"\"\"\n        Check if the download location is a directory\n\n        Arguments:\n            downloadLocation: The download location\n\n        Raises:\n            ValueError: If the downloadLocation is not a directory\n\n        Returns:\n            The download location\n        \"\"\"\n        download_dir = os.path.expandvars(os.path.expanduser(downloadLocation))\n        if os.path.isfile(download_dir):\n            raise ValueError(\n                \"Parameter 'downloadLocation' should be a directory, not a file.\"\n            )\n        return download_dir\n\n    @deprecated(\n        version=\"4.4.0\",\n        reason=\"To be removed in 5.0.0. \"\n        \"Moved to synapseclient/core/download/download_functions.py::download_file_entity\",\n    )\n    def _download_file_entity(\n        self,\n        downloadLocation: str,\n        entity: Entity,\n        ifcollision: str,\n        submission: str,\n    ) -&gt; None:\n        \"\"\"\n        Download file entity\n\n        Arguments:\n            downloadLocation: The download location\n            entity:           The Synapse Entity object\n            ifcollision:      Determines how to handle file collisions.\n                              May be\n\n                - `overwrite.local`\n                - `keep.local`\n                - `keep.both`\n\n            submission:       Access associated files through a submission rather than through an entity.\n        \"\"\"\n        # set the initial local state\n        entity.path = None\n        entity.files = []\n        entity.cacheDir = None\n\n        # check to see if an UNMODIFIED version of the file (since it was last downloaded) already exists\n        # this location could be either in .synapseCache or a user specified location to which the user previously\n        # downloaded the file\n        cached_file_path = self.cache.get(entity.dataFileHandleId, downloadLocation)\n\n        # location in .synapseCache where the file would be corresponding to its FileHandleId\n        synapseCache_location = self.cache.get_cache_dir(entity.dataFileHandleId)\n\n        file_name = (\n            entity._file_handle.fileName\n            if cached_file_path is None\n            else os.path.basename(cached_file_path)\n        )\n\n        # Decide the best download location for the file\n        if downloadLocation is not None:\n            # Make sure the specified download location is a fully resolved directory\n            downloadLocation = self._ensure_download_location_is_directory(\n                downloadLocation\n            )\n        elif cached_file_path is not None:\n            # file already cached so use that as the download location\n            downloadLocation = os.path.dirname(cached_file_path)\n        else:\n            # file not cached and no user-specified location so default to .synapseCache\n            downloadLocation = synapseCache_location\n\n        # resolve file path collisions by either overwriting, renaming, or not downloading, depending on the\n        # ifcollision value\n        downloadPath = self._resolve_download_path_collisions(\n            downloadLocation,\n            file_name,\n            ifcollision,\n            synapseCache_location,\n            cached_file_path,\n        )\n        if downloadPath is None:\n            return\n\n        if cached_file_path is not None:  # copy from cache\n            if downloadPath != cached_file_path:\n                # create the foider if it does not exist already\n                if not os.path.exists(downloadLocation):\n                    os.makedirs(downloadLocation)\n                shutil.copy(cached_file_path, downloadPath)\n\n        else:  # download the file from URL (could be a local file)\n            objectType = \"FileEntity\" if submission is None else \"SubmissionAttachment\"\n            objectId = entity[\"id\"] if submission is None else submission\n\n            # reassign downloadPath because if url points to local file (e.g. file://~/someLocalFile.txt)\n            # it won't be \"downloaded\" and, instead, downloadPath will just point to '~/someLocalFile.txt'\n            # _downloadFileHandle may also return None to indicate that the download failed\n            downloadPath = self._downloadFileHandle(\n                entity.dataFileHandleId, objectId, objectType, downloadPath\n            )\n\n            if downloadPath is None or not os.path.exists(downloadPath):\n                return\n\n        # converts the path format from forward slashes back to backward slashes on Windows\n        entity.path = os.path.normpath(downloadPath)\n        entity.files = [os.path.basename(downloadPath)]\n        entity.cacheDir = os.path.dirname(downloadPath)\n\n    @deprecated(\n        version=\"4.4.0\",\n        reason=\"To be removed in 5.0.0. \"\n        \"Moved to synapseclient/core/download/download_functions.py::resolve_download_path_collisions\",\n    )\n    def _resolve_download_path_collisions(\n        self,\n        downloadLocation: str,\n        file_name: str,\n        ifcollision: str,\n        synapseCache_location: str,\n        cached_file_path: str,\n    ) -&gt; str:\n        \"\"\"\n        Resolve file path collisions\n\n        Arguments:\n            downloadLocation:      The download location\n            file_name:             The file name\n            ifcollision:           Determines how to handle file collisions.\n                                   May be \"overwrite.local\", \"keep.local\", or \"keep.both\".\n            synapseCache_location: The location in .synapseCache where the file would be\n                                   corresponding to its FileHandleId.\n            cached_file_path:      The file path of the cached copy\n\n        Raises:\n            ValueError: Invalid ifcollision. Should be \"overwrite.local\", \"keep.local\", or \"keep.both\".\n\n        Returns:\n            The download file path with collisions resolved\n        \"\"\"\n        # always overwrite if we are downloading to .synapseCache\n        if utils.normalize_path(downloadLocation) == synapseCache_location:\n            if ifcollision is not None and ifcollision != \"overwrite.local\":\n                self.logger.warning(\n                    \"\\n\"\n                    + \"!\" * 50\n                    + f\"\\nifcollision={ifcollision} \"\n                    + \"is being IGNORED because the download destination is synapse's cache.\"\n                    ' Instead, the behavior is \"overwrite.local\". \\n' + \"!\" * 50 + \"\\n\"\n                )\n            ifcollision = \"overwrite.local\"\n        # if ifcollision not specified, keep.local\n        ifcollision = ifcollision or \"keep.both\"\n\n        downloadPath = utils.normalize_path(os.path.join(downloadLocation, file_name))\n        # resolve collison\n        if os.path.exists(downloadPath):\n            if ifcollision == \"overwrite.local\":\n                pass\n            elif ifcollision == \"keep.local\":\n                # Don't want to overwrite the local file.\n                return None\n            elif ifcollision == \"keep.both\":\n                if downloadPath != cached_file_path:\n                    return utils.unique_filename(downloadPath)\n            else:\n                raise ValueError(\n                    'Invalid parameter: \"%s\" is not a valid value '\n                    'for \"ifcollision\"' % ifcollision\n                )\n        return downloadPath\n\n    def store(\n        self,\n        obj,\n        *,\n        createOrUpdate=True,\n        forceVersion=True,\n        versionLabel=None,\n        isRestricted=False,\n        activity=None,\n        used=None,\n        executed=None,\n        activityName=None,\n        activityDescription=None,\n        set_annotations=True,\n    ):\n        \"\"\"\n        Creates a new Entity or updates an existing Entity, uploading any files in the process.\n\n        Arguments:\n            obj: A Synapse Entity, Evaluation, or Wiki\n            used: The Entity, Synapse ID, or URL used to create the object (can also be a list of these)\n            executed: The Entity, Synapse ID, or URL representing code executed to create the object\n                        (can also be a list of these)\n            activity: Activity object specifying the user's provenance.\n            activityName: Activity name to be used in conjunction with *used* and *executed*.\n            activityDescription: Activity description to be used in conjunction with *used* and *executed*.\n            createOrUpdate: Indicates whether the method should automatically perform an update if the 'obj'\n                            conflicts with an existing Synapse object.\n            forceVersion: Indicates whether the method should increment the version of the object even if nothing\n                            has changed.\n            versionLabel: Arbitrary string used to label the version.\n            isRestricted: If set to true, an email will be sent to the Synapse access control team to start the\n                            process of adding terms-of-use or review board approval for this entity.\n                            You will be contacted with regards to the specific data being restricted and the\n                            requirements of access.\n            set_annotations: If True, set the annotations on the entity. If False, do not set the annotations.\n\n        Returns:\n            A Synapse Entity, Evaluation, or Wiki\n\n        Example: Using this function\n            Creating a new Project:\n\n                from synapseclient import Project\n\n                project = Project('My uniquely named project')\n                project = syn.store(project)\n\n            Adding files with [provenance (aka: Activity)][synapseclient.Activity]:\n\n                from synapseclient import File, Activity\n\n            A synapse entity *syn1906480* contains data and an entity *syn1917825* contains code\n\n                activity = Activity(\n                    'Fancy Processing',\n                    description='No seriously, really fancy processing',\n                    used=['syn1906480', 'http://data_r_us.com/fancy/data.txt'],\n                    executed='syn1917825')\n\n                test_entity = File('/path/to/data/file.xyz', description='Fancy new data', parent=project)\n                test_entity = syn.store(test_entity, activity=activity)\n\n        \"\"\"\n        trace.get_current_span().set_attributes({\"thread.id\": threading.get_ident()})\n        # SYNPY-1031: activity must be Activity object or code will fail later\n        if activity:\n            if not isinstance(activity, synapseclient.Activity):\n                raise ValueError(\"activity should be synapseclient.Activity object\")\n        # _before_store hook\n        # give objects a chance to do something before being stored\n        if hasattr(obj, \"_before_synapse_store\"):\n            obj._before_synapse_store(self)\n\n        # _synapse_store hook\n        # for objects that know how to store themselves\n        if hasattr(obj, \"_synapse_store\"):\n            return obj._synapse_store(self)\n\n        # Handle all non-Entity objects\n        if not (isinstance(obj, Entity) or type(obj) == dict):\n            if isinstance(obj, Wiki):\n                return self._storeWiki(obj, createOrUpdate)\n\n            if \"id\" in obj:  # If ID is present, update\n                trace.get_current_span().set_attributes({\"synapse.id\": obj[\"id\"]})\n                return type(obj)(**self.restPUT(obj.putURI(), obj.json()))\n\n            try:  # If no ID is present, attempt to POST the object\n                trace.get_current_span().set_attributes({\"synapse.id\": \"\"})\n                return type(obj)(**self.restPOST(obj.postURI(), obj.json()))\n\n            except SynapseHTTPError as err:\n                # If already present and we want to update attempt to get the object content\n                if createOrUpdate and err.response.status_code == 409:\n                    newObj = self.restGET(obj.getByNameURI(obj.name))\n                    newObj.update(obj)\n                    obj = type(obj)(**newObj)\n                    trace.get_current_span().set_attributes({\"synapse.id\": obj[\"id\"]})\n                    obj.update(self.restPUT(obj.putURI(), obj.json()))\n                    return obj\n                raise\n\n        # If the input object is an Entity or a dictionary\n        entity = obj\n        properties, annotations, local_state = split_entity_namespaces(entity)\n        bundle = None\n        # Explicitly set an empty versionComment property if none is supplied,\n        # otherwise an existing entity bundle's versionComment will be copied to the update.\n        properties[\"versionComment\"] = (\n            properties[\"versionComment\"] if \"versionComment\" in properties else None\n        )\n\n        # Anything with a path is treated as a cache-able item\n        # Only Files are expected in the following logic\n        if entity.get(\"path\", False) and not isinstance(obj, Folder):\n            local_file_md5_hex = None\n            if \"concreteType\" not in properties:\n                properties[\"concreteType\"] = File._synapse_entity_type\n            # Make sure the path is fully resolved\n            entity[\"path\"] = os.path.expanduser(entity[\"path\"])\n\n            # Check if the File already exists in Synapse by fetching metadata on it\n            bundle = self._getEntityBundle(entity)\n\n            if bundle:\n                if createOrUpdate:\n                    # update our properties from the existing bundle so that we have\n                    # enough to process this as an entity update.\n                    properties = {**bundle[\"entity\"], **properties}\n\n                # Check if the file should be uploaded\n                fileHandle = find_data_file_handle(bundle)\n                if (\n                    fileHandle\n                    and fileHandle[\"concreteType\"]\n                    == \"org.sagebionetworks.repo.model.file.ExternalFileHandle\"\n                ):\n                    # switching away from ExternalFileHandle or the url was updated\n                    needs_upload = entity[\"synapseStore\"] or (\n                        fileHandle[\"externalURL\"] != entity[\"externalURL\"]\n                    )\n                else:\n                    synapse_store_flag = entity[\"synapseStore\"] or local_state.get(\n                        \"synapseStore\"\n                    )\n                    # Check if we need to upload a new version of an existing\n                    # file. If the file referred to by entity['path'] has been\n                    # modified, we want to upload the new version.\n                    # If synapeStore is false then we must upload a ExternalFileHandle\n                    needs_upload = not synapse_store_flag or not self.cache.contains(\n                        bundle[\"entity\"][\"dataFileHandleId\"], entity[\"path\"]\n                    )\n\n                    md5_stored_in_synapse = local_state.get(\"_file_handle\", {}).get(\n                        \"contentMd5\", None\n                    ) or (fileHandle or {}).get(\"contentMd5\", None)\n\n                    # Check if we got an MD5 checksum from Synapse and compare it to the local file\n                    if (\n                        synapse_store_flag\n                        and needs_upload\n                        and os.path.isfile(entity[\"path\"])\n                        and md5_stored_in_synapse\n                        and md5_stored_in_synapse\n                        == (\n                            local_file_md5_hex := utils.md5_for_file(\n                                entity[\"path\"]\n                            ).hexdigest()\n                        )\n                    ):\n                        needs_upload = False\n            elif entity.get(\"dataFileHandleId\", None) is not None:\n                needs_upload = False\n            else:\n                needs_upload = True\n\n            if needs_upload:\n                local_state_fh = local_state.get(\"_file_handle\", {})\n                synapseStore = local_state.get(\"synapseStore\", True)\n\n                # parent_id_for_upload is allowing `store` to be called on files that have\n                # already been stored to Synapse, but did not specify a parentId in the\n                # FileEntity. This is useful as it prevents the need to specify the\n                # parentId every time a file is stored to Synapse when the ID is\n                # already known.\n                parent_id_for_upload = entity.get(\"parentId\", None)\n                if not parent_id_for_upload and bundle and bundle.get(\"entity\", None):\n                    parent_id_for_upload = bundle[\"entity\"][\"parentId\"]\n\n                if not parent_id_for_upload:\n                    raise SynapseMalformedEntityError(\n                        \"Entities of type File must have a parentId.\"\n                    )\n\n                fileHandle = wrap_async_to_sync(\n                    upload_file_handle_async(\n                        self,\n                        parent_id_for_upload,\n                        local_state[\"path\"]\n                        if (synapseStore or local_state_fh.get(\"externalURL\") is None)\n                        else local_state_fh.get(\"externalURL\"),\n                        synapse_store=synapseStore,\n                        md5=local_file_md5_hex or local_state_fh.get(\"contentMd5\"),\n                        file_size=local_state_fh.get(\"contentSize\"),\n                        mimetype=local_state_fh.get(\"contentType\"),\n                    ),\n                    self,\n                )\n                properties[\"dataFileHandleId\"] = fileHandle[\"id\"]\n                local_state[\"_file_handle\"] = fileHandle\n\n            elif \"dataFileHandleId\" not in properties:\n                # Handle the case where the Entity lacks an ID\n                # But becomes an update() due to conflict\n                properties[\"dataFileHandleId\"] = bundle[\"entity\"][\"dataFileHandleId\"]\n\n            # update the file_handle metadata if the FileEntity's FileHandle id has changed\n            local_state_fh_id = local_state.get(\"_file_handle\", {}).get(\"id\")\n            if (\n                local_state_fh_id\n                and properties[\"dataFileHandleId\"] != local_state_fh_id\n            ):\n                local_state[\"_file_handle\"] = find_data_file_handle(\n                    self._getEntityBundle(\n                        properties[\"id\"],\n                        requestedObjects={\n                            \"includeEntity\": True,\n                            \"includeFileHandles\": True,\n                        },\n                    )\n                )\n\n                # check if we already have the filehandleid cached somewhere\n                cached_path = self.cache.get(properties[\"dataFileHandleId\"])\n                if cached_path is None:\n                    local_state[\"path\"] = None\n                    local_state[\"cacheDir\"] = None\n                    local_state[\"files\"] = []\n                else:\n                    local_state[\"path\"] = cached_path\n                    local_state[\"cacheDir\"] = os.path.dirname(cached_path)\n                    local_state[\"files\"] = [os.path.basename(cached_path)]\n\n        # Create or update Entity in Synapse\n        if \"id\" in properties:\n            trace.get_current_span().set_attributes({\"synapse.id\": properties[\"id\"]})\n            properties = self._updateEntity(properties, forceVersion, versionLabel)\n        else:\n            # If Link, get the target name, version number and concrete type and store in link properties\n            if properties[\"concreteType\"] == \"org.sagebionetworks.repo.model.Link\":\n                target_properties = self._getEntity(\n                    properties[\"linksTo\"][\"targetId\"],\n                    version=properties[\"linksTo\"].get(\"targetVersionNumber\"),\n                )\n                if target_properties[\"parentId\"] == properties[\"parentId\"]:\n                    raise ValueError(\n                        \"Cannot create a Link to an entity under the same parent.\"\n                    )\n                properties[\"linksToClassName\"] = target_properties[\"concreteType\"]\n                if (\n                    target_properties.get(\"versionNumber\") is not None\n                    and properties[\"linksTo\"].get(\"targetVersionNumber\") is not None\n                ):\n                    properties[\"linksTo\"][\"targetVersionNumber\"] = target_properties[\n                        \"versionNumber\"\n                    ]\n                properties[\"name\"] = target_properties[\"name\"]\n            try:\n                properties = self._createEntity(properties)\n            except SynapseHTTPError as ex:\n                if createOrUpdate and ex.response.status_code == 409:\n                    # Get the existing Entity's ID via the name and parent\n                    existing_entity_id = self.findEntityId(\n                        properties[\"name\"], properties.get(\"parentId\", None)\n                    )\n                    if existing_entity_id is None:\n                        raise\n\n                    # get existing properties and annotations\n                    if not bundle:\n                        bundle = self._getEntityBundle(\n                            existing_entity_id,\n                            requestedObjects={\n                                \"includeEntity\": True,\n                                \"includeAnnotations\": True,\n                            },\n                        )\n\n                    properties = {**bundle[\"entity\"], **properties}\n\n                    # we additionally merge the annotations under the assumption that a missing annotation\n                    # from a resolved conflict represents an newer annotation that should be preserved\n                    # rather than an intentionally deleted annotation.\n                    annotations = {\n                        **from_synapse_annotations(bundle[\"annotations\"]),\n                        **annotations,\n                    }\n\n                    properties = self._updateEntity(\n                        properties, forceVersion, versionLabel\n                    )\n\n                else:\n                    raise\n\n        # Deal with access restrictions\n        if isRestricted:\n            self._createAccessRequirementIfNone(properties)\n\n        # Update annotations\n        if set_annotations and (\n            (not bundle and annotations)\n            or (\n                bundle and check_annotations_changed(bundle[\"annotations\"], annotations)\n            )\n        ):\n            annotations = self.set_annotations(\n                Annotations(properties[\"id\"], properties[\"etag\"], annotations)\n            )\n            properties[\"etag\"] = annotations.etag\n\n        # If the parameters 'used' or 'executed' are given, create an Activity object\n        if used or executed:\n            if activity is not None:\n                raise SynapseProvenanceError(\n                    \"Provenance can be specified as an Activity object or as used/executed\"\n                    \" item(s), but not both.\"\n                )\n            activity = Activity(\n                name=activityName,\n                description=activityDescription,\n                used=used,\n                executed=executed,\n            )\n\n        # If we have an Activity, set it as the Entity's provenance record\n        if activity:\n            self.setProvenance(properties, activity)\n\n            # 'etag' has changed, so get the new Entity\n            properties = self._getEntity(properties)\n\n        # Return the updated Entity object\n        entity = Entity.create(properties, annotations, local_state)\n        return_data = self.get(entity, downloadFile=False)\n\n        trace.get_current_span().set_attributes(\n            {\n                \"synapse.id\": return_data.get(\"id\", \"\"),\n                \"synapse.concrete_type\": entity.get(\"concreteType\", \"\"),\n            }\n        )\n        return return_data\n\n    def _createAccessRequirementIfNone(self, entity: Union[Entity, str]) -&gt; None:\n        \"\"\"\n        Checks to see if the given entity has access requirements. If not, then one is added\n\n        Arguments:\n            entity: A Synapse ID or a Synapse Entity object\n        \"\"\"\n        existingRestrictions = self.restGET(\n            \"/entity/%s/accessRequirement?offset=0&amp;limit=1\" % id_of(entity)\n        )\n        if len(existingRestrictions[\"results\"]) &lt;= 0:\n            self.restPOST(\"/entity/%s/lockAccessRequirement\" % id_of(entity), body=\"\")\n\n    def _getEntityBundle(\n        self,\n        entity: Union[Entity, str],\n        version: int = None,\n        requestedObjects: Dict[str, bool] = None,\n    ) -&gt; Dict[str, Union[dict, str, int, bool]]:\n        \"\"\"\n        Gets some information about the Entity.\n\n        Arguments:\n            entity:           A Synapse Entity or Synapse ID\n            version:          The entity's version. Defaults to None meaning most recent version.\n            requestedObjects: A dictionary indicating settings for what to include.\n\n        Default value for requestedObjects is:\n\n            requestedObjects = {'includeEntity': True,\n                                'includeAnnotations': True,\n                                'includeFileHandles': True,\n                                'includeRestrictionInformation': True}\n\n        Keys available for requestedObjects:\n\n            includeEntity\n            includeAnnotations\n            includePermissions\n            includeEntityPath\n            includeHasChildren\n            includeAccessControlList\n            includeFileHandles\n            includeTableBundle\n            includeRootWikiId\n            includeBenefactorACL\n            includeDOIAssociation\n            includeFileName\n            includeThreadCount\n            includeRestrictionInformation\n\n\n        Keys with values set to False may simply be omitted.\n        For example, we might ask for an entity bundle containing file handles, annotations, and properties:\n            requested_objects = {'includeEntity':True\n                                 'includeAnnotations':True,\n                                 'includeFileHandles':True}\n            bundle = syn._getEntityBundle('syn111111', )\n\n        Returns:\n            An EntityBundle with the requested fields or by default Entity header, annotations, unmet access\n            requirements, and file handles\n        \"\"\"\n        # If 'entity' is given without an ID, try to find it by 'parentId' and 'name'.\n        # Use case:\n        #     If the user forgets to catch the return value of a syn.store(e)\n        #     this allows them to recover by doing: e = syn.get(e)\n        if requestedObjects is None:\n            requestedObjects = {\n                \"includeEntity\": True,\n                \"includeAnnotations\": True,\n                \"includeFileHandles\": True,\n                \"includeRestrictionInformation\": True,\n            }\n        if (\n            isinstance(entity, collections.abc.Mapping)\n            and \"id\" not in entity\n            and \"name\" in entity\n        ):\n            entity = self.findEntityId(entity[\"name\"], entity.get(\"parentId\", None))\n\n        # Avoid an exception from finding an ID from a NoneType\n        try:\n            id_of(entity)\n        except ValueError:\n            return None\n\n        if version is not None:\n            uri = f\"/entity/{id_of(entity)}/version/{int(version):d}/bundle2\"\n        else:\n            uri = f\"/entity/{id_of(entity)}/bundle2\"\n        bundle = self.restPOST(uri, body=json.dumps(requestedObjects))\n\n        return bundle\n\n    def delete(\n        self,\n        obj,\n        version=None,\n    ):\n        \"\"\"\n        Removes an object from Synapse.\n\n        Arguments:\n            obj: An existing object stored on Synapse such as Evaluation, File, Project, or Wiki\n            version: For entities, specify a particular version to delete.\n        \"\"\"\n        # Handle all strings as the Entity ID for backward compatibility\n        if isinstance(obj, str):\n            entity_id = id_of(obj)\n            trace.get_current_span().set_attributes({\"synapse.id\": entity_id})\n            if version:\n                self.restDELETE(uri=f\"/entity/{entity_id}/version/{version}\")\n            else:\n                self.restDELETE(uri=f\"/entity/{entity_id}\")\n        elif hasattr(obj, \"_synapse_delete\"):\n            return obj._synapse_delete(self)\n        else:\n            try:\n                if isinstance(obj, Versionable):\n                    self.restDELETE(obj.deleteURI(versionNumber=version))\n                else:\n                    self.restDELETE(obj.deleteURI())\n            except AttributeError:\n                raise SynapseError(\n                    f\"Can't delete a {type(obj)}. Please specify a Synapse object or id\"\n                )\n\n    _user_name_cache = {}\n\n    def _get_user_name(self, user_id: str) -&gt; str:\n        \"\"\"\n        Get username with ownerId\n\n        Arguments:\n            user_id: The ownerId of a user\n\n        Returns:\n            A username\n        \"\"\"\n        if user_id not in self._user_name_cache:\n            self._user_name_cache[user_id] = utils.extract_user_name(\n                self.getUserProfile(user_id)\n            )\n        return self._user_name_cache[user_id]\n\n    def _list(\n        self,\n        parent: str,\n        recursive: bool = False,\n        long_format: bool = False,\n        show_modified: bool = False,\n        indent: float = 0,\n        out=sys.stdout,\n    ) -&gt; None:\n        \"\"\"\n        List child objects of the given parent, recursively if requested.\n\n        Arguments:\n            parent:        A Synapse ID for folder or project that you want to list child objects for\n            recursive:     Whether to show subfolder\n            long_format:   Whether to show createdOn, createdBy and version\n            show_modified: Whether to show modifiedOn and modifiedBy\n            indent:        The left padding of the file tree structure\n            out:           The location to write the output.\n        \"\"\"\n        fields = [\"id\", \"name\", \"nodeType\"]\n        if long_format:\n            fields.extend([\"createdByPrincipalId\", \"createdOn\", \"versionNumber\"])\n        if show_modified:\n            fields.extend([\"modifiedByPrincipalId\", \"modifiedOn\"])\n        results = self.getChildren(parent)\n\n        results_found = False\n        for result in results:\n            results_found = True\n\n            fmt_fields = {\n                \"name\": result[\"name\"],\n                \"id\": result[\"id\"],\n                \"padding\": \" \" * indent,\n                \"slash_or_not\": \"/\" if is_container(result) else \"\",\n            }\n            fmt_string = \"{id}\"\n\n            if long_format:\n                fmt_fields[\"createdOn\"] = utils.iso_to_datetime(\n                    result[\"createdOn\"]\n                ).strftime(\"%Y-%m-%d %H:%M\")\n                fmt_fields[\"createdBy\"] = self._get_user_name(result[\"createdBy\"])[:18]\n                fmt_fields[\"version\"] = result[\"versionNumber\"]\n                fmt_string += \" {version:3}  {createdBy:&gt;18} {createdOn}\"\n            if show_modified:\n                fmt_fields[\"modifiedOn\"] = utils.iso_to_datetime(\n                    result[\"modifiedOn\"]\n                ).strftime(\"%Y-%m-%d %H:%M\")\n                fmt_fields[\"modifiedBy\"] = self._get_user_name(result[\"modifiedBy\"])[\n                    :18\n                ]\n                fmt_string += \"  {modifiedBy:&gt;18} {modifiedOn}\"\n\n            fmt_string += \"  {padding}{name}{slash_or_not}\\n\"\n            out.write(fmt_string.format(**fmt_fields))\n\n            if (indent == 0 or recursive) and is_container(result):\n                self._list(\n                    result[\"id\"],\n                    recursive=recursive,\n                    long_format=long_format,\n                    show_modified=show_modified,\n                    indent=indent + 2,\n                    out=out,\n                )\n\n        if indent == 0 and not results_found:\n            out.write(\n                \"No results visible to {username} found for id {id}\\n\".format(\n                    username=self.credentials.username, id=id_of(parent)\n                )\n            )\n\n    def uploadFileHandle(\n        self, path, parent, synapseStore=True, mimetype=None, md5=None, file_size=None\n    ):\n        \"\"\"Uploads the file in the provided path (if necessary) to a storage location based on project settings.\n        Returns a new FileHandle as a dict to represent the stored file.\n\n        Arguments:\n            parent: Parent of the entity to which we upload.\n            path:   File path to the file being uploaded\n            synapseStore: If False, will not upload the file, but instead create an ExternalFileHandle that references\n                            the file on the local machine.\n                            If True, will upload the file based on StorageLocation determined by the entity_parent_id\n            mimetype: The MIME type metadata for the uploaded file\n            md5: The MD5 checksum for the file, if known. Otherwise if the file is a local file, it will be calculated\n                    automatically.\n            file_size: The size the file, if known. Otherwise if the file is a local file, it will be calculated\n                        automatically.\n            file_type: The MIME type the file, if known. Otherwise if the file is a local file, it will be calculated\n                        automatically.\n\n        Returns:\n            A dict of a new FileHandle as a dict that represents the uploaded file\n        \"\"\"\n        return wrap_async_to_sync(\n            upload_file_handle_async(\n                self, parent, path, synapseStore, md5, file_size, mimetype\n            ),\n            self,\n        )\n\n    ############################################################\n    #                  Download List                           #\n    ############################################################\n    def clear_download_list(self):\n        \"\"\"Clear all files from download list\"\"\"\n        self.restDELETE(\"/download/list\")\n\n    def remove_from_download_list(self, list_of_files: typing.List[typing.Dict]) -&gt; int:\n        \"\"\"Remove a batch of files from download list\n\n        Arguments:\n            list_of_files: Array of files in the format of a mapping {fileEntityId: synid, versionNumber: version}\n\n        Returns:\n            Number of files removed from download list\n        \"\"\"\n        request_body = {\"batchToRemove\": list_of_files}\n        num_files_removed = self.restPOST(\n            \"/download/list/remove\", body=json.dumps(request_body)\n        )\n        return num_files_removed\n\n    def _generate_manifest_from_download_list(\n        self,\n        quoteCharacter: str = '\"',\n        escapeCharacter: str = \"\\\\\",\n        lineEnd: str = os.linesep,\n        separator: str = \",\",\n        header: bool = True,\n    ):\n        \"\"\"\n        Creates a download list manifest generation request\n\n        Arguments:\n            quoteCharacter:  The character to be used for quoted elements in the resulting file.\n            escapeCharacter: The escape character to be used for escaping a separator or quote in the resulting file.\n            lineEnd:         The line feed terminator to be used for the resulting file.\n            separator:       The delimiter to be used for separating entries in the resulting file.\n            header:          Is the first line a header?\n\n        Returns:\n            Filehandle of download list manifest\n        \"\"\"\n        request_body = {\n            \"concreteType\": \"org.sagebionetworks.repo.model.download.DownloadListManifestRequest\",\n            \"csvTableDescriptor\": {\n                \"separator\": separator,\n                \"quoteCharacter\": quoteCharacter,\n                \"escapeCharacter\": escapeCharacter,\n                \"lineEnd\": lineEnd,\n                \"isFirstLineHeader\": header,\n            },\n        }\n        return self._waitForAsync(\n            uri=\"/download/list/manifest/async\", request=request_body\n        )\n\n    def get_download_list_manifest(self):\n        \"\"\"Get the path of the download list manifest file\n\n        Returns:\n            Path of download list manifest file\n        \"\"\"\n        manifest = self._generate_manifest_from_download_list()\n        # Get file handle download link\n        file_result = get_file_handle_for_download(\n            file_handle_id=manifest[\"resultFileHandleId\"],\n            synapse_id=manifest[\"resultFileHandleId\"],\n            entity_type=\"FileEntity\",\n            synapse_client=self,\n        )\n        # Download the manifest\n        downloaded_path = self._download_from_URL(\n            url=file_result[\"preSignedURL\"],\n            destination=\"./\",\n            fileHandleId=file_result[\"fileHandleId\"],\n            expected_md5=file_result[\"fileHandle\"].get(\"contentMd5\"),\n        )\n        trace.get_current_span().set_attributes(\n            {\"synapse.file_handle_id\": file_result[\"fileHandleId\"]}\n        )\n        return downloaded_path\n\n    def get_download_list(self, downloadLocation: str = None) -&gt; str:\n        \"\"\"Download all files from your Synapse download list\n\n        Arguments:\n            downloadLocation: Directory to download files to.\n\n        Returns:\n            Manifest file with file paths\n        \"\"\"\n        dl_list_path = self.get_download_list_manifest()\n        downloaded_files = []\n        new_manifest_path = f\"manifest_{time.time_ns()}.csv\"\n        with open(dl_list_path) as manifest_f, open(\n            new_manifest_path, \"w\"\n        ) as write_obj:\n            reader = csv.DictReader(manifest_f)\n            columns = reader.fieldnames\n            columns.extend([\"path\", \"error\"])\n            # Write the downloaded paths to a new manifest file\n            writer = csv.DictWriter(write_obj, fieldnames=columns)\n            writer.writeheader()\n\n            for row in reader:\n                # You can add things to the download list that you don't have access to\n                # So there must be a try catch here\n                try:\n                    entity = self.get(row[\"ID\"], downloadLocation=downloadLocation)\n                    # Must include version number because you can have multiple versions of a\n                    # file in the download list\n                    downloaded_files.append(\n                        {\n                            \"fileEntityId\": row[\"ID\"],\n                            \"versionNumber\": row[\"versionNumber\"],\n                        }\n                    )\n                    row[\"path\"] = entity.path\n                    row[\"error\"] = \"\"\n                except Exception:\n                    row[\"path\"] = \"\"\n                    row[\"error\"] = \"DOWNLOAD FAILED\"\n                    self.logger.exception(\"Unable to download file\")\n                writer.writerow(row)\n\n        # Don't want to clear all the download list because you can add things\n        # to the download list after initiating this command.\n        # Files that failed to download should not be removed from download list\n        # Remove all files from download list after the entire download is complete.\n        # This is because if download fails midway, we want to return the full manifest\n        if downloaded_files:\n            # Only want to invoke this if there is a list of files to remove\n            # or the API call will error\n            self.remove_from_download_list(list_of_files=downloaded_files)\n        else:\n            self.logger.warning(\"A manifest was created, but no files were downloaded\")\n\n        # Always remove original manifest file\n        os.remove(dl_list_path)\n\n        return new_manifest_path\n\n    ############################################################\n    #                  Get / Set Annotations                   #\n    ############################################################\n\n    def _getRawAnnotations(\n        self, entity: Union[Entity, str], version: int = None\n    ) -&gt; Dict[str, Union[str, dict]]:\n        \"\"\"\n        Retrieve annotations for an Entity returning them in the native Synapse format.\n\n        Arguments:\n            entity:  A Synapse Entity or Synapse ID\n            version: The entity's version. Defaults to None meaning most recent version.\n\n        Returns:\n            An annotation dictionary\n        \"\"\"\n        # Note: Specifying the version results in a zero-ed out etag,\n        # even if the version is the most recent.\n        # See [PLFM-1874](https://sagebionetworks.jira.com/browse/PLFM-1874) for more details.\n        if version:\n            uri = f\"/entity/{id_of(entity)}/version/{str(version)}/annotations2\"\n        else:\n            uri = f\"/entity/{id_of(entity)}/annotations2\"\n        return self.restGET(uri)\n\n    def get_annotations(\n        self, entity: typing.Union[str, Entity], version: typing.Union[str, int] = None\n    ) -&gt; Annotations:\n        \"\"\"\n        Retrieve annotations for an Entity from the Synapse Repository as a Python dict.\n\n        Note that collapsing annotations from the native Synapse format to a Python dict may involve some loss of\n        information. See `_getRawAnnotations` to get annotations in the native format.\n\n        Arguments:\n            entity: An Entity or Synapse ID to lookup\n            version: The version of the Entity to retrieve.\n\n        Returns:\n            A [synapseclient.annotations.Annotations][] object, a dict that also has id and etag attributes\n        \"\"\"\n        return from_synapse_annotations(self._getRawAnnotations(entity, version))\n\n    def set_annotations(self, annotations: Annotations):\n        \"\"\"\n        Store annotations for an Entity in the Synapse Repository.\n\n        Arguments:\n            annotations: A [synapseclient.annotations.Annotations][] of annotation names and values,\n                            with the id and etag attribute set\n\n        Returns:\n            The updated [synapseclient.annotations.Annotations][] for the entity\n\n        Example: Using this function\n            Getting annotations, adding a new annotation, and updating the annotations:\n\n                annos = syn.get_annotations('syn123')\n\n            `annos` will contain the id and etag associated with the entity upon retrieval\n\n                print(annos.id)\n                &gt; syn123\n                print(annos.etag)\n                &gt; 7bdb83e9-a50a-46e4-987a-4962559f090f   (Usually some UUID in the form of a string)\n\n            Returned `annos` object from `get_annotations()` can be used as if it were a dict.\n            Set key 'foo' to have value of 'bar' and 'baz'\n\n                annos['foo'] = ['bar', 'baz']\n\n            Single values will automatically be wrapped in a list once stored\n\n                annos['qwerty'] = 'asdf'\n\n            Store the annotations\n\n                annos = syn.set_annotations(annos)\n\n                print(annos)\n                &gt; {'foo':['bar','baz], 'qwerty':['asdf']}\n        \"\"\"\n\n        if not isinstance(annotations, Annotations):\n            raise TypeError(\"Expected a synapseclient.Annotations object\")\n\n        synapseAnnos = to_synapse_annotations(annotations)\n\n        entity_id = id_of(annotations)\n        trace.get_current_span().set_attributes({\"synapse.id\": entity_id})\n\n        return from_synapse_annotations(\n            self.restPUT(\n                f\"/entity/{entity_id}/annotations2\",\n                body=json.dumps(synapseAnnos),\n            )\n        )\n\n    ############################################################\n    #                         Querying                         #\n    ############################################################\n\n    def getChildren(\n        self,\n        parent,\n        includeTypes=[\n            \"folder\",\n            \"file\",\n            \"table\",\n            \"link\",\n            \"entityview\",\n            \"dockerrepo\",\n            \"submissionview\",\n            \"dataset\",\n            \"materializedview\",\n        ],\n        sortBy=\"NAME\",\n        sortDirection=\"ASC\",\n    ):\n        \"\"\"\n        Retrieves all of the entities stored within a parent such as folder or project.\n\n        Arguments:\n            parent: An id or an object of a Synapse container or None to retrieve all projects\n            includeTypes: Must be a list of entity types (ie. [\"folder\",\"file\"]) which can be found [here](http://docs.synapse.org/rest/org/sagebionetworks/repo/model/EntityType.html)\n            sortBy: How results should be sorted. Can be NAME, or CREATED_ON\n            sortDirection: The direction of the result sort. Can be ASC, or DESC\n\n        Yields:\n            An iterator that shows all the children of the container.\n\n        Also see:\n\n        - [synapseutils.walk][]\n        \"\"\"\n        parentId = id_of(parent) if parent is not None else None\n\n        trace.get_current_span().set_attributes({\"synapse.parent_id\": parentId})\n        entityChildrenRequest = {\n            \"parentId\": parentId,\n            \"includeTypes\": includeTypes,\n            \"sortBy\": sortBy,\n            \"sortDirection\": sortDirection,\n            \"nextPageToken\": None,\n        }\n        entityChildrenResponse = {\"nextPageToken\": \"first\"}\n        while entityChildrenResponse.get(\"nextPageToken\") is not None:\n            entityChildrenResponse = self.restPOST(\n                \"/entity/children\", body=json.dumps(entityChildrenRequest)\n            )\n            for child in entityChildrenResponse[\"page\"]:\n                yield child\n            if entityChildrenResponse.get(\"nextPageToken\") is not None:\n                entityChildrenRequest[\"nextPageToken\"] = entityChildrenResponse[\n                    \"nextPageToken\"\n                ]\n\n    def md5Query(self, md5):\n        \"\"\"\n        Find the Entities which have attached file(s) which have the given MD5 hash.\n\n        Arguments:\n            md5: The MD5 to query for (hexadecimal string)\n\n        Returns:\n            A list of Entity headers\n        \"\"\"\n\n        return self.restGET(\"/entity/md5/%s\" % md5)[\"results\"]\n\n    ############################################################\n    #                     ACL manipulation                     #\n    ############################################################\n\n    def _getBenefactor(\n        self, entity: Union[Entity, str]\n    ) -&gt; Dict[str, Union[str, int, bool]]:\n        \"\"\"\n        Get an Entity's benefactor.\n        An Entity gets its ACL from its benefactor.\n\n        Arguments:\n            entity: A Synapse Entity or Synapse ID\n\n        Returns:\n            A dictionary of the Entity's benefactor\n\n        \"\"\"\n        if utils.is_synapse_id_str(entity) or is_synapse_entity(entity):\n            synid, _ = utils.get_synid_and_version(entity)\n            return self.restGET(\"/entity/%s/benefactor\" % synid)\n\n        return entity\n\n    def _getACL(self, entity: Union[Entity, str]) -&gt; Dict[str, Union[str, list]]:\n        \"\"\"\n        Get the effective Access Control Lists (ACL) for a Synapse Entity.\n\n        Arguments:\n            entity: A Synapse Entity or Synapse ID\n\n        Returns:\n            A dictionary of the Entity's ACL\n        \"\"\"\n        if hasattr(entity, \"getACLURI\"):\n            uri = entity.getACLURI()\n        else:\n            # Get the ACL from the benefactor (which may be the entity itself)\n            benefactor = self._getBenefactor(entity)\n            trace.get_current_span().set_attributes({\"synapse.id\": benefactor[\"id\"]})\n            uri = \"/entity/%s/acl\" % (benefactor[\"id\"])\n        return self.restGET(uri)\n\n    def _storeACL(\n        self, entity: Union[Entity, str], acl: Dict[str, Union[str, list]]\n    ) -&gt; Dict[str, Union[str, list]]:\n        \"\"\"\n        Create or update the ACL for a Synapse Entity.\n\n        Arguments:\n            entity:  A Synapse Entity or Synapse ID\n            acl:     An ACl as a dictionary\n\n        The format of acl:\n\n            {'resourceAccess': [\n                {'accessType': ['READ'],\n                 'principalId': 222222}\n            ]}\n\n        Returns:\n            The new or updated ACL\n        \"\"\"\n        if hasattr(entity, \"putACLURI\"):\n            return self.restPUT(entity.putACLURI(), json.dumps(acl))\n        else:\n            # Get benefactor. (An entity gets its ACL from its benefactor.)\n            entity_id = id_of(entity)\n            uri = \"/entity/%s/benefactor\" % entity_id\n            benefactor = self.restGET(uri)\n\n            # Update or create new ACL\n            uri = \"/entity/%s/acl\" % entity_id\n            if benefactor[\"id\"] == entity_id:\n                return self.restPUT(uri, json.dumps(acl))\n            else:\n                return self.restPOST(uri, json.dumps(acl))\n\n    def _getUserbyPrincipalIdOrName(self, principalId: str = None) -&gt; int:\n        \"\"\"\n        Given either a string, int or None finds the corresponding user where None implies PUBLIC\n\n        Arguments:\n            principalId: Identifier of a user or group\n\n        Raises:\n            SynapseError: Warn for unknown user principalId\n\n        Returns:\n            The integer ID of the user\n        \"\"\"\n        if principalId is None or principalId == \"PUBLIC\":\n            return PUBLIC\n        try:\n            return int(principalId)\n\n        # If principalId is not a number assume it is a name or email\n        except ValueError:\n            userProfiles = self.restGET(\"/userGroupHeaders?prefix=%s\" % principalId)\n            totalResults = len(userProfiles[\"children\"])\n            if totalResults == 1:\n                return int(userProfiles[\"children\"][0][\"ownerId\"])\n            elif totalResults &gt; 1:\n                for profile in userProfiles[\"children\"]:\n                    if profile[\"userName\"] == principalId:\n                        return int(profile[\"ownerId\"])\n\n            supplementalMessage = (\n                \"Please be more specific\" if totalResults &gt; 1 else \"No matches\"\n            )\n            raise SynapseError(\n                \"Unknown Synapse user (%s).  %s.\" % (principalId, supplementalMessage)\n            )\n\n    def get_acl(\n        self,\n        entity: Union[Entity, Evaluation, str, collections.abc.Mapping],\n        principal_id: str = None,\n    ) -&gt; typing.List[str]:\n        \"\"\"\n        Get the [ACL](https://rest-docs.synapse.org/rest/org/\n        sagebionetworks/repo/model/ACCESS_TYPE.html)\n        that a user or group has on an Entity.\n\n        Arguments:\n            entity:      An Entity or Synapse ID to lookup\n            principal_id: Identifier of a user or group (defaults to PUBLIC users)\n\n        Returns:\n            An array containing some combination of\n                ['READ', 'UPDATE', 'CREATE', 'DELETE', 'DOWNLOAD', 'MODERATE',\n                'CHANGE_PERMISSIONS', 'CHANGE_SETTINGS']\n                or an empty array\n        \"\"\"\n\n        principal_id = self._getUserbyPrincipalIdOrName(principal_id)\n\n        trace.get_current_span().set_attributes(\n            {\"synapse.id\": id_of(entity), \"synapse.principal_id\": principal_id}\n        )\n\n        acl = self._getACL(entity)\n\n        team_list = self._find_teams_for_principal(principal_id)\n        team_ids = [int(team.id) for team in team_list]\n        effective_permission_set = set()\n\n        # This user_profile_bundle is being used to verify that the principal_id\n        #  is a registered user of the system\n        user_profile_bundle = self._get_user_bundle(principal_id, 1)\n\n        # Loop over all permissions in the returned ACL and add it to the effective_permission_set\n        # if the principalId in the ACL matches\n        # 1) the one we are looking for,\n        # 2) a team the entity is a member of,\n        # 3) PUBLIC\n        # 4) A user_profile_bundle exists for the principal_id\n        for permissions in acl[\"resourceAccess\"]:\n            if \"principalId\" in permissions and (\n                permissions[\"principalId\"] == principal_id\n                or permissions[\"principalId\"] in team_ids\n                or permissions[\"principalId\"] == PUBLIC\n                or (\n                    permissions[\"principalId\"] == AUTHENTICATED_USERS\n                    and user_profile_bundle is not None\n                )\n            ):\n                effective_permission_set = effective_permission_set.union(\n                    permissions[\"accessType\"]\n                )\n        return list(effective_permission_set)\n\n    @deprecated(\n        version=\"4.0.0\",\n        reason=\"deprecated and replaced with synapseclient.Synapse.get_acl\",\n    )\n    def getPermissions(\n        self,\n        entity: Union[Entity, Evaluation, str, collections.abc.Mapping],\n        principal_id: str = None,\n    ) -&gt; typing.List[str]:\n        \"\"\"\n        **Deprecated** and replaced with [get_acl][synapseclient.Synapse.get_acl].\n\n\n        Get the permissions that a user or group has on an Entity.\n\n        Arguments:\n            entity:      An Entity or Synapse ID to lookup\n            principal_id: Identifier of a user or group (defaults to PUBLIC users)\n\n        Returns:\n            An array containing some combination of\n                ['READ', 'UPDATE', 'CREATE', 'DELETE', 'DOWNLOAD', 'MODERATE',\n                'CHANGE_PERMISSIONS', 'CHANGE_SETTINGS']\n                or an empty array\n        \"\"\"\n\n        return self.get_acl(entity=entity, principal_id=principal_id)\n\n    def get_permissions(\n        self, entity: Union[Entity, Evaluation, str, collections.abc.Mapping]\n    ) -&gt; Permissions:\n        \"\"\"\n        Get the [permissions](https://rest-docs.synapse.org/rest/org/\n        sagebionetworks/repo/model/auth/UserEntityPermissions.html)\n        that the caller has on an Entity.\n\n        Arguments:\n            entity: An Entity or Synapse ID to lookup\n\n        Returns:\n            An Permissions object\n\n\n        Example: Using this function:\n            Getting permissions for a Synapse Entity\n\n                permissions = syn.get_permissions(Entity)\n\n            Getting permissions for a Synapse ID\n\n                permissions = syn.get_permissions(\"syn12345\")\n\n            Getting access types list from the Permissions object\n\n                permissions.access_types\n        \"\"\"\n\n        entity_id = id_of(entity)\n\n        trace.get_current_span().set_attributes({\"synapse.id\": entity_id})\n\n        url = f\"/entity/{entity_id}/permissions\"\n        data = self.restGET(url)\n        return Permissions.from_dict(data)\n\n    def setPermissions(\n        self,\n        entity,\n        principalId=None,\n        accessType=[\"READ\", \"DOWNLOAD\"],\n        modify_benefactor=False,\n        warn_if_inherits=True,\n        overwrite=True,\n    ):\n        \"\"\"\n        Sets permission that a user or group has on an Entity.\n        An Entity may have its own ACL or inherit its ACL from a benefactor.\n\n        Arguments:\n            entity: An Entity or Synapse ID to modify\n            principalId: Identifier of a user or group. '273948' is for all registered Synapse users\n                            and '273949' is for public access. None implies public access.\n            accessType: Type of permission to be granted. One or more of CREATE, READ, DOWNLOAD, UPDATE,\n                            DELETE, CHANGE_PERMISSIONS\n            modify_benefactor: Set as True when modifying a benefactor's ACL\n            warn_if_inherits: Set as False, when creating a new ACL.\n                                Trying to modify the ACL of an Entity that inherits its ACL will result in a warning\n            overwrite: By default this function overwrites existing permissions for the specified user.\n                        Set this flag to False to add new permissions non-destructively.\n\n        Returns:\n            An Access Control List object\n\n        Example: Setting permissions\n            Grant all registered users download access\n\n                syn.setPermissions('syn1234','273948',['READ','DOWNLOAD'])\n\n            Grant the public view access\n\n                syn.setPermissions('syn1234','273949',['READ'])\n        \"\"\"\n        entity_id = id_of(entity)\n        trace.get_current_span().set_attributes({\"synapse.id\": entity_id})\n\n        benefactor = self._getBenefactor(entity)\n        if benefactor[\"id\"] != entity_id:\n            if modify_benefactor:\n                entity = benefactor\n            elif warn_if_inherits:\n                self.logger.warning(\n                    \"Creating an ACL for entity %s, which formerly inherited access control from a\"\n                    ' benefactor entity, \"%s\" (%s).\\n'\n                    % (entity_id, benefactor[\"name\"], benefactor[\"id\"])\n                )\n\n        acl = self._getACL(entity)\n\n        principalId = self._getUserbyPrincipalIdOrName(principalId)\n\n        # Find existing permissions\n        permissions_to_update = None\n        for permissions in acl[\"resourceAccess\"]:\n            if (\n                \"principalId\" in permissions\n                and permissions[\"principalId\"] == principalId\n            ):\n                permissions_to_update = permissions\n                break\n\n        if accessType is None or accessType == []:\n            # remove permissions\n            if permissions_to_update and overwrite:\n                acl[\"resourceAccess\"].remove(permissions_to_update)\n        else:\n            # add a 'resourceAccess' entry, if necessary\n            if not permissions_to_update:\n                permissions_to_update = {\"accessType\": [], \"principalId\": principalId}\n                acl[\"resourceAccess\"].append(permissions_to_update)\n            if overwrite:\n                permissions_to_update[\"accessType\"] = accessType\n            else:\n                permissions_to_update[\"accessType\"] = list(\n                    set(permissions_to_update[\"accessType\"]) | set(accessType)\n                )\n        return self._storeACL(entity, acl)\n\n    ############################################################\n    #                        Provenance                        #\n    ############################################################\n\n    # TODO: rename these to Activity\n    def getProvenance(\n        self,\n        entity: typing.Union[str, collections.abc.Mapping, numbers.Number],\n        version: int = None,\n    ) -&gt; Activity:\n        \"\"\"\n        Retrieve provenance information for a Synapse Entity.\n\n        Arguments:\n            entity:  An Entity or Synapse ID to lookup\n            version: The version of the Entity to retrieve. Gets the most recent version if omitted\n\n        Returns:\n            An Activity object or raises exception if no provenance record exists\n\n        Raises:\n            SynapseHTTPError: if no provenance record exists\n        \"\"\"\n        # Get versionNumber from Entity\n        if version is None and \"versionNumber\" in entity:\n            version = entity[\"versionNumber\"]\n        entity_id = id_of(entity)\n        if version:\n            uri = \"/entity/%s/version/%d/generatedBy\" % (entity_id, version)\n        else:\n            uri = \"/entity/%s/generatedBy\" % entity_id\n\n        trace.get_current_span().set_attributes({\"synapse.id\": entity_id})\n        return Activity(data=self.restGET(uri))\n\n    def setProvenance(\n        self,\n        entity: typing.Union[str, collections.abc.Mapping, numbers.Number],\n        activity: Activity,\n    ) -&gt; Activity:\n        \"\"\"\n        Stores a record of the code and data used to derive a Synapse entity.\n\n        Arguments:\n            entity:   An Entity or Synapse ID to modify\n            activity: A [synapseclient.activity.Activity][]\n\n        Returns:\n            An updated [synapseclient.activity.Activity][] object\n        \"\"\"\n        # Assert that the entity was generated by a given Activity.\n        activity = self._saveActivity(activity)\n\n        entity_id = id_of(entity)\n        # assert that an entity is generated by an activity\n        uri = \"/entity/%s/generatedBy?generatedBy=%s\" % (entity_id, activity[\"id\"])\n        activity = Activity(data=self.restPUT(uri))\n\n        trace.get_current_span().set_attributes({\"synapse.id\": entity_id})\n        return activity\n\n    def deleteProvenance(\n        self,\n        entity: typing.Union[str, collections.abc.Mapping, numbers.Number],\n    ) -&gt; None:\n        \"\"\"\n        Removes provenance information from an Entity and deletes the associated Activity.\n\n        Arguments:\n            entity: An Entity or Synapse ID to modify\n        \"\"\"\n        activity = self.getProvenance(entity)\n        if not activity:\n            return\n        entity_id = id_of(entity)\n        trace.get_current_span().set_attributes({\"synapse.id\": entity_id})\n\n        uri = \"/entity/%s/generatedBy\" % entity_id\n        self.restDELETE(uri)\n\n        # If the activity is shared by more than one entity you recieve an HTTP 400 error:\n        # \"If you wish to delete this activity, please first delete all Entities generated by this Activity.\"\"\n        uri = \"/activity/%s\" % activity[\"id\"]\n        self.restDELETE(uri)\n\n    def _saveActivity(self, activity: Activity) -&gt; Activity:\n        \"\"\"\n        Save the Activity\n\n        Arguments:\n            activity: The Activity to be saved\n\n        Returns:\n            An Activity object\n        \"\"\"\n        if \"id\" in activity:\n            # We're updating provenance\n            uri = \"/activity/%s\" % activity[\"id\"]\n            activity = Activity(data=self.restPUT(uri, json.dumps(activity)))\n        else:\n            activity = self.restPOST(\"/activity\", body=json.dumps(activity))\n        return activity\n\n    def updateActivity(self, activity) -&gt; Activity:\n        \"\"\"\n        Modifies an existing Activity.\n\n        Arguments:\n            activity: The Activity to be updated.\n\n        Returns:\n            An updated Activity object\n        \"\"\"\n        if \"id\" not in activity:\n            raise ValueError(\"The activity you want to update must exist on Synapse\")\n        trace.get_current_span().set_attributes({\"synapse.id\": activity[\"id\"]})\n        return self._saveActivity(activity)\n\n    def _convertProvenanceList(self, usedList: list, limitSearch: str = None) -&gt; list:\n        \"\"\"\n        Convert a list of Synapse IDs, URLs and local files by replacing local files with Synapse IDs\n\n        Arguments:\n            usedList:    A list of Synapse IDs, URLs and local files\n            limitSearch: Limits the places in Synapse where the file is searched for.\n\n        Returns:\n            A converted list with local files being replaced with Synapse IDs\n        \"\"\"\n        if usedList is None:\n            return None\n        usedList = [\n            self.get(target, limitSearch=limitSearch)\n            if (os.path.isfile(target) if isinstance(target, str) else False)\n            else target\n            for target in usedList\n        ]\n        return usedList\n\n    ############################################################\n    #                File handle service calls                 #\n    ############################################################\n\n    @deprecated(\n        version=\"4.4.0\",\n        reason=\"To be removed in 5.0.0. \"\n        \"Moved to synapseclient/api/file_services.py::get_file_handle_for_download\",\n    )\n    def _getFileHandleDownload(\n        self, fileHandleId: str, objectId: str, objectType: str = None\n    ) -&gt; Dict[str, str]:\n        \"\"\"\n        Gets the URL and the metadata as filehandle object for a filehandle or fileHandleId\n\n        Arguments:\n            fileHandleId:   ID of fileHandle to download\n            objectId:       The ID of the object associated with the file e.g. syn234\n            objectType:     Type of object associated with a file e.g. FileEntity, TableEntity\n\n        Raises:\n            SynapseFileNotFoundError: If the fileHandleId is not found in Synapse.\n            SynapseError:             If the user does not have the permission to access the fileHandleId.\n\n        Returns:\n            A dictionary with keys: fileHandle, fileHandleId and preSignedURL\n        \"\"\"\n        body = {\n            \"includeFileHandles\": True,\n            \"includePreSignedURLs\": True,\n            \"requestedFiles\": [\n                {\n                    \"fileHandleId\": fileHandleId,\n                    \"associateObjectId\": objectId,\n                    \"associateObjectType\": objectType or \"FileEntity\",\n                }\n            ],\n        }\n        response = self.restPOST(\n            \"/fileHandle/batch\", body=json.dumps(body), endpoint=self.fileHandleEndpoint\n        )\n        result = response[\"requestedFiles\"][0]\n        failure = result.get(\"failureCode\")\n        if failure == \"NOT_FOUND\":\n            raise SynapseFileNotFoundError(\n                \"The fileHandleId %s could not be found\" % fileHandleId\n            )\n        elif failure == \"UNAUTHORIZED\":\n            raise SynapseError(\n                \"You are not authorized to access fileHandleId %s associated with the Synapse\"\n                \" %s: %s\" % (fileHandleId, objectType, objectId)\n            )\n        return result\n\n    @staticmethod\n    @deprecated(\n        version=\"4.4.0\",\n        reason=\"To be removed in 5.0.0. \"\n        \"Moved to synapseclient/core/download/download_functions.py::is_retryable_download_error\",\n    )\n    def _is_retryable_download_error(ex: Exception) -&gt; bool:\n        \"\"\"\n        Check if the download error is retryable\n\n        Arguments:\n            ex: An exception\n\n        Returns:\n            Boolean value indicating whether the download error is retryable\n        \"\"\"\n        # some exceptions caught during download indicate non-recoverable situations that\n        # will not be remedied by a repeated download attempt.\n        return not (\n            (isinstance(ex, OSError) and ex.errno == errno.ENOSPC)\n            or isinstance(ex, SynapseMd5MismatchError)  # out of disk space\n        )\n\n    @deprecated(\n        version=\"4.4.0\",\n        reason=\"To be removed in 5.0.0. \"\n        \"Moved to synapseclient/core/download/download_functions.py::download_by_file_handle\",\n    )\n    def _downloadFileHandle(\n        self,\n        fileHandleId: str,\n        objectId: str,\n        objectType: str,\n        destination: str,\n        retries: int = 5,\n    ) -&gt; str:\n        \"\"\"\n        Download a file from the given URL to the local file system.\n\n        Arguments:\n            fileHandleId: The id of the FileHandle to download\n            objectId:     The id of the Synapse object that uses the FileHandle e.g. \"syn123\"\n            objectType:   The type of the Synapse object that uses the FileHandle e.g. \"FileEntity\"\n            destination:  The destination on local file system\n            retries:      The Number of download retries attempted before throwing an exception.\n\n        Returns:\n            The path to downloaded file\n        \"\"\"\n        os.makedirs(os.path.dirname(destination), exist_ok=True)\n\n        while retries &gt; 0:\n            try:\n                fileResult = self._getFileHandleDownload(\n                    fileHandleId, objectId, objectType\n                )\n                fileHandle = fileResult[\"fileHandle\"]\n                concreteType = fileHandle[\"concreteType\"]\n                storageLocationId = fileHandle.get(\"storageLocationId\")\n\n                if concreteType == concrete_types.EXTERNAL_OBJECT_STORE_FILE_HANDLE:\n                    profile = get_client_authenticated_s3_profile(\n                        endpoint=fileHandle[\"endpointUrl\"],\n                        bucket=fileHandle[\"bucket\"],\n                        config_path=self.configPath,\n                    )\n                    downloaded_path = S3ClientWrapper.download_file(\n                        fileHandle[\"bucket\"],\n                        fileHandle[\"endpointUrl\"],\n                        fileHandle[\"fileKey\"],\n                        destination,\n                        profile_name=profile,\n                        show_progress=not self.silent,\n                    )\n\n                elif (\n                    sts_transfer.is_boto_sts_transfer_enabled(self)\n                    and sts_transfer.is_storage_location_sts_enabled(\n                        self, objectId, storageLocationId\n                    )\n                    and concreteType == concrete_types.S3_FILE_HANDLE\n                ):\n\n                    def download_fn(credentials):\n                        return S3ClientWrapper.download_file(\n                            fileHandle[\"bucketName\"],\n                            None,\n                            fileHandle[\"key\"],\n                            destination,\n                            credentials=credentials,\n                            show_progress=not self.silent,\n                            # pass through our synapse threading config to boto s3\n                            transfer_config_kwargs={\n                                \"max_concurrency\": self.max_threads\n                            },\n                        )\n\n                    downloaded_path = sts_transfer.with_boto_sts_credentials(\n                        download_fn,\n                        self,\n                        objectId,\n                        \"read_only\",\n                    )\n\n                elif (\n                    self.multi_threaded\n                    and concreteType == concrete_types.S3_FILE_HANDLE\n                    and fileHandle.get(\"contentSize\", 0)\n                    &gt; multithread_download.SYNAPSE_DEFAULT_DOWNLOAD_PART_SIZE\n                ):\n                    # run the download multi threaded if the file supports it, we're configured to do so,\n                    # and the file is large enough that it would be broken into parts to take advantage of\n                    # multiple downloading threads. otherwise it's more efficient to run the download as a simple\n                    # single threaded URL download.\n                    downloaded_path = self._download_from_url_multi_threaded(\n                        fileHandleId,\n                        objectId,\n                        objectType,\n                        destination,\n                        expected_md5=fileHandle.get(\"contentMd5\"),\n                    )\n\n                else:\n                    downloaded_path = self._download_from_URL(\n                        fileResult[\"preSignedURL\"],\n                        destination,\n                        fileHandle[\"id\"],\n                        expected_md5=fileHandle.get(\"contentMd5\"),\n                    )\n                self.cache.add(fileHandle[\"id\"], downloaded_path)\n                return downloaded_path\n\n            except Exception as ex:\n                if not self._is_retryable_download_error(ex):\n                    raise\n\n                exc_info = sys.exc_info()\n                ex.progress = 0 if not hasattr(ex, \"progress\") else ex.progress\n                self.logger.debug(\n                    \"\\nRetrying download on error: [%s] after progressing %i bytes\"\n                    % (exc_info[0], ex.progress),\n                    exc_info=True,\n                )  # this will include stack trace\n                if ex.progress == 0:  # No progress was made reduce remaining retries.\n                    retries -= 1\n                if retries &lt;= 0:\n                    # Re-raise exception\n                    raise\n\n        raise Exception(\"should not reach this line\")\n\n    @deprecated(\n        version=\"4.4.0\",\n        reason=\"To be removed in 5.0.0. \"\n        \"Moved to synapseclient/core/download/download_functions.py::download_from_url_multi_threaded\",\n    )\n    def _download_from_url_multi_threaded(\n        self,\n        file_handle_id: str,\n        object_id: str,\n        object_type: str,\n        destination: str,\n        *,\n        expected_md5: str = None,\n    ) -&gt; str:\n        \"\"\"\n        Download a file from the given URL using multiple threads.\n\n        Arguments:\n            file_handle_id: The id of the FileHandle to download\n            object_id:      The id of the Synapse object that uses the FileHandle e.g. \"syn123\"\n            object_type:    The type of the Synapse object that uses the FileHandle e.g. \"FileEntity\"\n            destination:    The destination on local file system\n            expected_md5:   The expected MD5\n        Raises:\n            SynapseMd5MismatchError: If the actual MD5 does not match expected MD5.\n\n        Returns:\n            The path to downloaded file\n        \"\"\"\n        destination = os.path.abspath(destination)\n        temp_destination = utils.temp_download_filename(destination, file_handle_id)\n\n        request = multithread_download.DownloadRequest(\n            file_handle_id=int(file_handle_id),\n            object_id=object_id,\n            object_type=object_type,\n            path=temp_destination,\n            debug=self.debug,\n        )\n\n        multithread_download.download_file(self, request)\n\n        if (\n            expected_md5\n        ):  # if md5 not set (should be the case for all except http download)\n            actual_md5 = utils.md5_for_file(temp_destination).hexdigest()\n            # check md5 if given\n            if actual_md5 != expected_md5:\n                try:\n                    os.remove(temp_destination)\n                except FileNotFoundError:\n                    # file already does not exist. nothing to do\n                    pass\n                raise SynapseMd5MismatchError(\n                    \"Downloaded file {filename}'s md5 {md5} does not match expected MD5 of\"\n                    \" {expected_md5}\".format(\n                        filename=temp_destination,\n                        md5=actual_md5,\n                        expected_md5=expected_md5,\n                    )\n                )\n        # once download completed, rename to desired destination\n        shutil.move(temp_destination, destination)\n\n        return destination\n\n    @deprecated(\n        version=\"4.4.0\",\n        reason=\"To be removed in 5.0.0. \"\n        \"Moved to synapseclient/core/download/download_functions.py::is_synapse_uri\",\n    )\n    def _is_synapse_uri(self, uri: str) -&gt; bool:\n        \"\"\"\n        Check whether the given uri is hosted at the configured Synapse repo endpoint\n\n        Arguments:\n            uri: A given uri\n\n        Returns:\n            A boolean value indicating whether the given uri is hosted at the configured Synapse repo endpoint\n        \"\"\"\n        uri_domain = urllib_urlparse.urlparse(uri).netloc\n        synapse_repo_domain = urllib_urlparse.urlparse(self.repoEndpoint).netloc\n        return uri_domain.lower() == synapse_repo_domain.lower()\n\n    @deprecated(\n        version=\"4.4.0\",\n        reason=\"To be removed in 5.0.0. \"\n        \"Moved to synapseclient/core/download/download_functions.py::download_from_url\",\n    )\n    def _download_from_URL(\n        self,\n        url: str,\n        destination: str,\n        fileHandleId: Optional[str] = None,\n        expected_md5: Optional[str] = None,\n    ) -&gt; str:\n        \"\"\"\n        Download a file from the given URL to the local file system.\n\n        Arguments:\n            url:           The source of download\n            destination:   The destination on local file system\n            fileHandleId:  Optional. If given, the file will be given a temporary name that includes the file\n                                    handle id which allows resuming partial downloads of the same file from previous\n                                    sessions\n            expected_md5:  Optional. If given, check that the MD5 of the downloaded file matches the expected MD5\n\n        Raises:\n            IOError:                 If the local file does not exist.\n            SynapseError:            If fail to download the file.\n            SynapseHTTPError:        If there are too many redirects.\n            SynapseMd5MismatchError: If the actual MD5 does not match expected MD5.\n\n        Returns:\n            The path to downloaded file\n        \"\"\"\n        destination = os.path.abspath(destination)\n        actual_md5 = None\n        redirect_count = 0\n        delete_on_md5_mismatch = True\n        self.logger.debug(f\"Downloading from {url} to {destination}\")\n        while redirect_count &lt; REDIRECT_LIMIT:\n            redirect_count += 1\n            scheme = urllib_urlparse.urlparse(url).scheme\n            if scheme == \"file\":\n                delete_on_md5_mismatch = False\n                destination = utils.file_url_to_path(url, verify_exists=True)\n                if destination is None:\n                    raise IOError(\"Local file (%s) does not exist.\" % url)\n                break\n            elif scheme == \"sftp\":\n                username, password = self._getUserCredentials(url)\n                destination = SFTPWrapper.download_file(\n                    url, destination, username, password, show_progress=not self.silent\n                )\n                break\n            elif scheme == \"ftp\":\n                transfer_start_time = time.time()\n\n                def _ftp_report_hook(\n                    block_number: int, read_size: int, total_size: int\n                ) -&gt; None:\n                    show_progress = not self.silent\n                    if show_progress:\n                        self._print_transfer_progress(\n                            transferred=block_number * read_size,\n                            toBeTransferred=total_size,\n                            prefix=\"Downloading \",\n                            postfix=os.path.basename(destination),\n                            dt=time.time() - transfer_start_time,\n                        )\n\n                urllib_request.urlretrieve(\n                    url=url, filename=destination, reporthook=_ftp_report_hook\n                )\n                break\n            elif scheme == \"http\" or scheme == \"https\":\n                # if a partial download exists with the temporary name,\n                temp_destination = utils.temp_download_filename(\n                    destination, fileHandleId\n                )\n                range_header = (\n                    {\n                        \"Range\": \"bytes={start}-\".format(\n                            start=os.path.getsize(temp_destination)\n                        )\n                    }\n                    if os.path.exists(temp_destination)\n                    else {}\n                )\n\n                # pass along synapse auth credentials only if downloading directly from synapse\n                auth = self.credentials if self._is_synapse_uri(url) else None\n                response = with_retry(\n                    lambda: self._requests_session.get(\n                        url,\n                        headers=self._generate_headers(range_header),\n                        stream=True,\n                        allow_redirects=False,\n                        auth=auth,\n                    ),\n                    verbose=self.debug,\n                    **STANDARD_RETRY_PARAMS,\n                )\n                try:\n                    exceptions._raise_for_status(response, verbose=self.debug)\n                except SynapseHTTPError as err:\n                    if err.response.status_code == 404:\n                        raise SynapseError(\"Could not download the file at %s\" % url)\n                    elif (\n                        err.response.status_code == 416\n                    ):  # Requested Range Not Statisfiable\n                        # this is a weird error when the client already finished downloading but the loop continues\n                        # When this exception occurs, the range we request is guaranteed to be &gt;= file size so we\n                        # assume that the file has been fully downloaded, rename it to destination file\n                        # and break out of the loop to perform the MD5 check.\n                        # If it fails the user can retry with another download.\n                        shutil.move(temp_destination, destination)\n                        break\n                    raise\n\n                # handle redirects\n                if response.status_code in [301, 302, 303, 307, 308]:\n                    url = response.headers[\"location\"]\n                    # don't break, loop again\n                else:\n                    # get filename from content-disposition, if we don't have it already\n                    if os.path.isdir(destination):\n                        filename = utils.extract_filename(\n                            content_disposition_header=response.headers.get(\n                                \"content-disposition\", None\n                            ),\n                            default_filename=utils.guess_file_name(url),\n                        )\n                        destination = os.path.join(destination, filename)\n                    # Stream the file to disk\n                    if \"content-length\" in response.headers:\n                        toBeTransferred = float(response.headers[\"content-length\"])\n                    else:\n                        toBeTransferred = -1\n                    transferred = 0\n\n                    # Servers that respect the Range header return 206 Partial Content\n                    if response.status_code == 206:\n                        mode = \"ab\"\n                        previouslyTransferred = os.path.getsize(temp_destination)\n                        toBeTransferred += previouslyTransferred\n                        transferred += previouslyTransferred\n                        sig = utils.md5_for_file(temp_destination)\n                    else:\n                        mode = \"wb\"\n                        previouslyTransferred = 0\n                        sig = hashlib.new(\"md5\", usedforsecurity=False)  # nosec\n\n                    try:\n                        with open(temp_destination, mode) as fd:\n                            t0 = time.time()\n                            for nChunks, chunk in enumerate(\n                                response.iter_content(FILE_BUFFER_SIZE)\n                            ):\n                                fd.write(chunk)\n                                sig.update(chunk)\n\n                                # the 'content-length' header gives the total number of bytes that will be transferred\n                                # to us len(chunk) cannot be used to track progress because iter_content automatically\n                                # decodes the chunks if the response body is encoded so the len(chunk) could be\n                                # different from the total number of bytes we've read read from the response body\n                                # response.raw.tell() is the total number of response body bytes transferred over the\n                                # wire so far\n                                transferred = (\n                                    response.raw.tell() + previouslyTransferred\n                                )\n                                self._print_transfer_progress(\n                                    transferred,\n                                    toBeTransferred,\n                                    \"Downloading \",\n                                    os.path.basename(destination),\n                                    dt=time.time() - t0,\n                                )\n                    except (\n                        Exception\n                    ) as ex:  # We will add a progress parameter then push it back to retry.\n                        ex.progress = transferred - previouslyTransferred\n                        raise\n\n                    # verify that the file was completely downloaded and retry if it is not complete\n                    if toBeTransferred &gt; 0 and transferred &lt; toBeTransferred:\n                        self.logger.warning(\n                            \"\\nRetrying download because the connection ended early.\\n\"\n                        )\n                        continue\n\n                    actual_md5 = sig.hexdigest()\n                    # rename to final destination\n                    shutil.move(temp_destination, destination)\n                    break\n            else:\n                self.logger.error(\"Unable to download URLs of type %s\" % scheme)\n                return None\n\n        else:  # didn't break out of loop\n            raise SynapseHTTPError(\"Too many redirects\")\n\n        if (\n            actual_md5 is None\n        ):  # if md5 not set (should be the case for all except http download)\n            actual_md5 = utils.md5_for_file(destination).hexdigest()\n\n        # check md5 if given\n        if expected_md5 and actual_md5 != expected_md5:\n            if delete_on_md5_mismatch and os.path.exists(destination):\n                os.remove(destination)\n            raise SynapseMd5MismatchError(\n                \"Downloaded file {filename}'s md5 {md5} does not match expected MD5 of\"\n                \" {expected_md5}\".format(\n                    filename=destination, md5=actual_md5, expected_md5=expected_md5\n                )\n            )\n\n        return destination\n\n    def _createExternalFileHandle(\n        self,\n        externalURL: str,\n        mimetype: str = None,\n        md5: str = None,\n        fileSize: int = None,\n    ) -&gt; Dict[str, Union[str, int]]:\n        \"\"\"\n        Create a new FileHandle representing an external URL.\n\n        Arguments:\n            externalURL: An external URL\n            mimetype:    The Mimetype of the file, if known.\n            md5:         The file's content MD5.\n            fileSize:    The size of the file in bytes.\n\n        Returns:\n            A FileHandle for files that are stored externally.\n        \"\"\"\n        fileName = externalURL.split(\"/\")[-1]\n        externalURL = utils.as_url(externalURL)\n        fileHandle = {\n            \"concreteType\": concrete_types.EXTERNAL_FILE_HANDLE,\n            \"fileName\": fileName,\n            \"externalURL\": externalURL,\n            \"contentMd5\": md5,\n            \"contentSize\": fileSize,\n        }\n        if mimetype is None:\n            (mimetype, enc) = mimetypes.guess_type(externalURL, strict=False)\n        if mimetype is not None:\n            fileHandle[\"contentType\"] = mimetype\n        return self.restPOST(\n            \"/externalFileHandle\", json.dumps(fileHandle), self.fileHandleEndpoint\n        )\n\n    def _createExternalObjectStoreFileHandle(\n        self,\n        s3_file_key,\n        file_path: str,\n        storage_location_id: int,\n        mimetype: str = None,\n        md5: str = None,\n    ) -&gt; Dict[str, Union[str, int]]:\n        \"\"\"\n        Create a new FileHandle representing an external object.\n\n        Arguments:\n            s3_file_key:         S3 key of the uploaded object\n            file_path:           The local path of the uploaded file\n            storage_location_id: The optional storage location descriptor\n            mimetype:            The Mimetype of the file, if known.\n            md5:                 The file's content MD5, if known.\n\n        Returns:\n            A FileHandle for objects that are stored externally.\n        \"\"\"\n        if mimetype is None:\n            mimetype, _ = mimetypes.guess_type(file_path, strict=False)\n        file_handle = {\n            \"concreteType\": concrete_types.EXTERNAL_OBJECT_STORE_FILE_HANDLE,\n            \"fileKey\": s3_file_key,\n            \"fileName\": os.path.basename(file_path),\n            \"contentMd5\": md5 or utils.md5_for_file(file_path).hexdigest(),\n            \"contentSize\": os.stat(file_path).st_size,\n            \"storageLocationId\": storage_location_id,\n            \"contentType\": mimetype,\n        }\n\n        return self.restPOST(\n            \"/externalFileHandle\", json.dumps(file_handle), self.fileHandleEndpoint\n        )\n\n    def create_external_s3_file_handle(\n        self,\n        bucket_name,\n        s3_file_key,\n        file_path,\n        *,\n        parent=None,\n        storage_location_id=None,\n        mimetype=None,\n        md5: str = None,\n    ):\n        \"\"\"\n        Create an external S3 file handle for e.g. a file that has been uploaded directly to\n        an external S3 storage location.\n\n        Arguments:\n            bucket_name: Name of the S3 bucket\n            s3_file_key: S3 key of the uploaded object\n            file_path: Local path of the uploaded file\n            parent: Parent entity to create the file handle in, the file handle will be created\n                    in the default storage location of the parent. Mutually exclusive with\n                    storage_location_id\n            storage_location_id: Explicit storage location id to create the file handle in, mutually exclusive\n                    with parent\n            mimetype: Mimetype of the file, if known\n            md5: MD5 of the file, if known\n\n        Raises:\n            ValueError: If neither parent nor storage_location_id is specified, or if both are specified.\n        \"\"\"\n\n        if storage_location_id:\n            if parent:\n                raise ValueError(\"Pass parent or storage_location_id, not both\")\n        elif not parent:\n            raise ValueError(\"One of parent or storage_location_id is required\")\n        else:\n            upload_destination = self._getDefaultUploadDestination(parent)\n            storage_location_id = upload_destination[\"storageLocationId\"]\n\n        if mimetype is None:\n            mimetype, _ = mimetypes.guess_type(file_path, strict=False)\n\n        file_handle = {\n            \"concreteType\": concrete_types.S3_FILE_HANDLE,\n            \"key\": s3_file_key,\n            \"bucketName\": bucket_name,\n            \"fileName\": os.path.basename(file_path),\n            \"contentMd5\": md5 or utils.md5_for_file(file_path).hexdigest(),\n            \"contentSize\": os.stat(file_path).st_size,\n            \"storageLocationId\": storage_location_id,\n            \"contentType\": mimetype,\n        }\n\n        return self.restPOST(\n            \"/externalFileHandle/s3\",\n            json.dumps(file_handle),\n            endpoint=self.fileHandleEndpoint,\n        )\n\n    def _get_file_handle_as_creator(\n        self, fileHandle: Dict[str, Union[str, int]]\n    ) -&gt; Dict[str, Union[str, int]]:\n        \"\"\"\n        Retrieve a fileHandle from the fileHandle service.\n        Note: You must be the creator of the filehandle to use this method. Otherwise, an 403-Forbidden error will be raised.\n\n        Arguments:\n            fileHandle: A fileHandle\n\n        Returns:\n            A fileHandle retrieved from the fileHandle service.\n        \"\"\"\n        uri = \"/fileHandle/%s\" % (id_of(fileHandle),)\n        return self.restGET(uri, endpoint=self.fileHandleEndpoint)\n\n    def _deleteFileHandle(self, fileHandle: Dict[str, Union[str, int]]) -&gt; None:\n        \"\"\"\n        Delete the given file handle.\n\n        Note: Only the user that created the FileHandle can delete it. Also, a FileHandle cannot be deleted if it is\n        associated with a FileEntity or WikiPage.\n\n        Arguments:\n            fileHandle: A fileHandle\n        \"\"\"\n        uri = \"/fileHandle/%s\" % (id_of(fileHandle),)\n        self.restDELETE(uri, endpoint=self.fileHandleEndpoint)\n        return fileHandle\n\n    ############################################################\n    #                    SFTP                                  #\n    ############################################################\n\n    def _getDefaultUploadDestination(self, parent_entity):\n        return self.restGET(\n            \"/entity/%s/uploadDestination\" % id_of(parent_entity),\n            endpoint=self.fileHandleEndpoint,\n        )\n\n    def _getUserCredentials(\n        self, url: str, username: str = None, password: str = None\n    ) -&gt; Tuple[str, str]:\n        \"\"\"\n        Get user credentials for a specified URL by either looking in the configFile or querying the user.\n\n        Arguments:\n            username: The username on server (optionally specified).\n            password: The password for authentication on the server (optionally specified).\n\n        Returns:\n            A tuple of username, password.\n        \"\"\"\n        # Get authentication information from configFile\n        parsedURL = urllib_urlparse.urlparse(url)\n        baseURL = parsedURL.scheme + \"://\" + parsedURL.hostname\n\n        config = get_config_file(self.configPath)\n        if username is None and config.has_option(baseURL, \"username\"):\n            username = config.get(baseURL, \"username\")\n        if password is None and config.has_option(baseURL, \"password\"):\n            password = config.get(baseURL, \"password\")\n        # If I still don't have a username and password prompt for it\n        if username is None:\n            username = getpass.getuser()  # Default to login name\n            # Note that if we hit the following line from within nosetests in\n            # Python 3, we get \"TypeError: bad argument type for built-in operation\".\n            # Luckily, this case isn't covered in our test suite!\n            user = input(\"Username for %s (%s):\" % (baseURL, username))\n            username = username if user == \"\" else user\n        if password is None:\n            password = getpass.getpass(\"Password for %s:\" % baseURL)\n        return username, password\n\n    ############################################\n    # Project/Folder storage location settings #\n    ############################################\n\n    def createStorageLocationSetting(self, storage_type, **kwargs):\n        \"\"\"\n        Creates an IMMUTABLE storage location based on the specified type.\n\n        For each storage_type, the following kwargs should be specified:\n\n        **ExternalObjectStorage**: (S3-like (e.g. AWS S3 or Openstack) bucket not accessed by Synapse)\n\n        - `endpointUrl`: endpoint URL of the S3 service (for example: 'https://s3.amazonaws.com')\n        - `bucket`: the name of the bucket to use\n\n        **ExternalS3Storage**: (Amazon S3 bucket accessed by Synapse)\n\n        - `bucket`: the name of the bucket to use\n\n        **ExternalStorage**: (SFTP or FTP storage location not accessed by Synapse)\n\n        - `url`: the base URL for uploading to the external destination\n        - `supportsSubfolders(optional)`: does the destination support creating subfolders under the base url\n            (default: false)\n\n        **ProxyStorage**: (a proxy server that controls access to a storage)\n\n        - `secretKey`: The encryption key used to sign all pre-signed URLs used to communicate with the proxy.\n        - `proxyUrl`: The HTTPS URL of the proxy used for upload and download.\n\n        Arguments:\n            storage_type: The type of the StorageLocationSetting to create\n            banner: (Optional) The optional banner to show every time a file is uploaded\n            description: (Optional) The description to show the user when the user has to choose which upload destination to use\n            kwargs: fields necessary for creation of the specified storage_type\n\n        Returns:\n            A dict of the created StorageLocationSetting\n        \"\"\"\n        upload_type_dict = {\n            \"ExternalObjectStorage\": \"S3\",\n            \"ExternalS3Storage\": \"S3\",\n            \"ExternalStorage\": \"SFTP\",\n            \"ProxyStorage\": \"PROXYLOCAL\",\n        }\n\n        if storage_type not in upload_type_dict:\n            raise ValueError(\"Unknown storage_type: %s\", storage_type)\n\n        # ProxyStorageLocationSettings has an extra 's' at the end &gt;:(\n        kwargs[\"concreteType\"] = (\n            \"org.sagebionetworks.repo.model.project.\"\n            + storage_type\n            + \"LocationSetting\"\n            + (\"s\" if storage_type == \"ProxyStorage\" else \"\")\n        )\n        kwargs[\"uploadType\"] = upload_type_dict[storage_type]\n\n        return self.restPOST(\"/storageLocation\", body=json.dumps(kwargs))\n\n    def getMyStorageLocationSetting(self, storage_location_id):\n        \"\"\"\n        Get a StorageLocationSetting by its id.\n\n        Arguments:\n            storage_location_id: id of the StorageLocationSetting to retrieve.\n                                    The corresponding StorageLocationSetting must have been created by this user.\n\n        Returns:\n            A dict describing the StorageLocationSetting retrieved by its id\n        \"\"\"\n        return self.restGET(\"/storageLocation/%s\" % storage_location_id)\n\n    def setStorageLocation(self, entity, storage_location_id):\n        \"\"\"\n        Sets the storage location for a Project or Folder\n\n        Arguments:\n            entity: A Project or Folder to which the StorageLocationSetting is set\n            storage_location_id: A StorageLocation id or a list of StorageLocation ids. Pass in None for the default\n                                    Synapse storage.\n\n        Returns:\n            The created or updated settings as a dict.\n        \"\"\"\n        if storage_location_id is None:\n            storage_location_id = DEFAULT_STORAGE_LOCATION_ID\n        locations = (\n            storage_location_id\n            if isinstance(storage_location_id, list)\n            else [storage_location_id]\n        )\n\n        existing_setting = self.getProjectSetting(entity, \"upload\")\n        if existing_setting is not None:\n            existing_setting[\"locations\"] = locations\n            self.restPUT(\"/projectSettings\", body=json.dumps(existing_setting))\n            return self.getProjectSetting(entity, \"upload\")\n        else:\n            project_destination = {\n                \"concreteType\": \"org.sagebionetworks.repo.model.project.UploadDestinationListSetting\",\n                \"settingsType\": \"upload\",\n                \"locations\": locations,\n                \"projectId\": id_of(entity),\n            }\n\n            return self.restPOST(\n                \"/projectSettings\", body=json.dumps(project_destination)\n            )\n\n    def getProjectSetting(self, project, setting_type):\n        \"\"\"\n        Gets the ProjectSetting for a project.\n\n        Arguments:\n            project: Project entity or its id as a string\n            setting_type: Type of setting. Choose from:\n\n                - `upload`\n                - `external_sync`\n                - `requester_pays`\n\n        Returns:\n            The ProjectSetting as a dict or None if no settings of the specified type exist.\n        \"\"\"\n        if setting_type not in {\"upload\", \"external_sync\", \"requester_pays\"}:\n            raise ValueError(\"Invalid project_type: %s\" % setting_type)\n\n        response = self.restGET(\n            \"/projectSettings/{projectId}/type/{type}\".format(\n                projectId=id_of(project), type=setting_type\n            )\n        )\n        return (\n            response if response else None\n        )  # if no project setting, a empty string is returned as the response\n\n    def get_sts_storage_token(\n        self, entity, permission, *, output_format=\"json\", min_remaining_life=None\n    ):\n        \"\"\"Get STS credentials for the given entity_id and permission, outputting it in the given format\n\n        Arguments:\n            entity: The entity or entity id whose credentials are being returned\n            permission: One of:\n\n                - `read_only`\n                - `read_write`\n\n            output_format: One of:\n\n                - `json`: the dictionary returned from the Synapse STS API including expiration\n                - `boto`: a dictionary compatible with a boto session (aws_access_key_id, etc)\n                - `shell`: output commands for exporting credentials appropriate for the detected shell\n                - `bash`: output commands for exporting credentials into a bash shell\n                - `cmd`: output commands for exporting credentials into a windows cmd shell\n                - `powershell`: output commands for exporting credentials into a windows powershell\n\n            min_remaining_life: The minimum allowable remaining life on a cached token to return. If a cached token\n                                has left than this amount of time left a fresh token will be fetched\n        \"\"\"\n        return sts_transfer.get_sts_credentials(\n            self,\n            id_of(entity),\n            permission,\n            output_format=output_format,\n            min_remaining_life=min_remaining_life,\n        )\n\n    def create_s3_storage_location(\n        self,\n        *,\n        parent=None,\n        folder_name=None,\n        folder=None,\n        bucket_name=None,\n        base_key=None,\n        sts_enabled=False,\n    ) -&gt; Tuple[Folder, Dict[str, str], Dict[str, str]]:\n        \"\"\"\n        Create a storage location in the given parent, either in the given folder or by creating a new\n        folder in that parent with the given name. This will both create a StorageLocationSetting,\n        and a ProjectSetting together, optionally creating a new folder in which to locate it,\n        and optionally enabling this storage location for access via STS. If enabling an existing folder for STS,\n        it must be empty.\n\n        Arguments:\n            parent: The parent in which to locate the storage location (mutually exclusive with folder)\n            folder_name: The name of a new folder to create (mutually exclusive with folder)\n            folder: The existing folder in which to create the storage location (mutually exclusive with folder_name)\n            bucket_name: The name of an S3 bucket, if this is an external storage location,\n                            if None will use Synapse S3 storage\n            base_key: The base key of within the bucket, None to use the bucket root,\n                            only applicable if bucket_name is passed\n            sts_enabled: Whether this storage location should be STS enabled\n\n        Returns:\n            A 3-tuple of the synapse Folder, a the storage location setting, and the project setting dictionaries.\n        \"\"\"\n        if folder_name and parent:\n            if folder:\n                raise ValueError(\n                    \"folder and  folder_name are mutually exclusive, only one should be passed\"\n                )\n\n            folder = self.store(Folder(name=folder_name, parent=parent))\n\n        elif not folder:\n            raise ValueError(\"either folder or folder_name should be required\")\n\n        storage_location_kwargs = {\n            \"uploadType\": \"S3\",\n            \"stsEnabled\": sts_enabled,\n        }\n\n        if bucket_name:\n            storage_location_kwargs[\n                \"concreteType\"\n            ] = concrete_types.EXTERNAL_S3_STORAGE_LOCATION_SETTING\n            storage_location_kwargs[\"bucket\"] = bucket_name\n            if base_key:\n                storage_location_kwargs[\"baseKey\"] = base_key\n        else:\n            storage_location_kwargs[\n                \"concreteType\"\n            ] = concrete_types.SYNAPSE_S3_STORAGE_LOCATION_SETTING\n\n        storage_location_setting = self.restPOST(\n            \"/storageLocation\", json.dumps(storage_location_kwargs)\n        )\n\n        storage_location_id = storage_location_setting[\"storageLocationId\"]\n        project_setting = self.setStorageLocation(\n            folder,\n            storage_location_id,\n        )\n\n        return folder, storage_location_setting, project_setting\n\n    ############################################################\n    #                   CRUD for Evaluations                   #\n    ############################################################\n\n    def getEvaluation(self, id):\n        \"\"\"\n        Gets an Evaluation object from Synapse.\n\n        Arguments:\n            id: The ID of the [synapseclient.evaluation.Evaluation][] to return.\n\n        Returns:\n            An [synapseclient.evaluation.Evaluation][] object\n\n        Example: Using this function\n            Creating an Evaluation instance\n\n                evaluation = syn.getEvaluation(2005090)\n        \"\"\"\n\n        evaluation_id = id_of(id)\n        uri = Evaluation.getURI(evaluation_id)\n        return Evaluation(**self.restGET(uri))\n\n    # TODO: Should this be combined with getEvaluation?\n    def getEvaluationByName(self, name):\n        \"\"\"\n        Gets an Evaluation object from Synapse.\n\n        Arguments:\n            Name: The name of the [synapseclient.evaluation.Evaluation][] to return.\n\n        Returns:\n            An [synapseclient.evaluation.Evaluation][] object\n        \"\"\"\n        uri = Evaluation.getByNameURI(name)\n        return Evaluation(**self.restGET(uri))\n\n    def getEvaluationByContentSource(self, entity):\n        \"\"\"\n        Returns a generator over evaluations that derive their content from the given entity\n\n        Arguments:\n            entity: The [synapseclient.entity.Project][] whose Evaluations are to be fetched.\n\n        Yields:\n            A generator over [synapseclient.evaluation.Evaluation][] objects for the given [synapseclient.entity.Project][].\n        \"\"\"\n\n        entityId = id_of(entity)\n        url = \"/entity/%s/evaluation\" % entityId\n\n        for result in self._GET_paginated(url):\n            yield Evaluation(**result)\n\n    def _findTeam(self, name: str) -&gt; typing.Iterator[Team]:\n        \"\"\"\n        Retrieve a Teams matching the supplied name fragment\n\n        Arguments:\n            name: A team name\n\n        Yields:\n            A generator that yields objects of type [Team][synapseclient.team.Team]\n        \"\"\"\n        for result in self._GET_paginated(\"/teams?fragment=%s\" % name):\n            yield Team(**result)\n\n    def _find_teams_for_principal(self, principal_id: str) -&gt; typing.Iterator[Team]:\n        \"\"\"\n        Retrieve a list of teams for the matching principal ID. If the principalId that is passed in is a team itself,\n        or not found, this will return a generator that yields no results.\n\n        Arguments:\n            principal_id: Identifier of a user or group.\n\n        Yields:\n            A generator that yields objects of type [Team][synapseclient.team.Team]\n        \"\"\"\n        for result in self._GET_paginated(f\"/user/{principal_id}/team\"):\n            yield Team(**result)\n\n    def create_team(\n        self,\n        name: str,\n        description: str = None,\n        icon: str = None,\n        can_public_join: bool = False,\n        can_request_membership: bool = True,\n    ) -&gt; Team:\n        \"\"\"\n        Creates a new team.\n\n        Arguments:\n            name: The name of the team to create.\n            description: A description of the team.\n            icon: The FileHandleID of the icon to be used for the team.\n            canPublicJoin: Whether the team can be joined by anyone. Defaults to False.\n            canRequestMembership: Whether the team can request membership. Defaults to True.\n\n        Returns:\n            An object of type [synapseclient.team.Team][]\n        \"\"\"\n        request_body = {\n            \"name\": name,\n            \"description\": description,\n            \"icon\": icon,\n            \"canPublicJoin\": can_public_join,\n            \"canRequestMembership\": can_request_membership,\n        }\n        return Team(\n            **self.restPOST(\n                \"/team\",\n                json.dumps(request_body),\n            )\n        )\n\n    def delete_team(self, id: int) -&gt; None:\n        \"\"\"\n        Deletes a team.\n\n        Arguments:\n            id: The ID of the team to delete.\n\n        \"\"\"\n        return self.restDELETE(f\"/team/{id}\")\n\n    def getTeam(self, id: Union[int, str]) -&gt; Team:\n        \"\"\"\n        Finds a team with a given ID or name.\n\n        Arguments:\n            id: The ID or name of the team or a Team object to retrieve.\n\n        Returns:\n            An object of type [synapseclient.team.Team][]\n        \"\"\"\n        # Retrieves team id\n        teamid = id_of(id)\n        try:\n            int(teamid)\n        except (TypeError, ValueError):\n            if isinstance(id, str):\n                for team in self._findTeam(id):\n                    if team.name == id:\n                        teamid = team.id\n                        break\n                else:\n                    raise ValueError('Can\\'t find team \"{}\"'.format(teamid))\n            else:\n                raise ValueError('Can\\'t find team \"{}\"'.format(teamid))\n        return Team(**self.restGET(\"/team/%s\" % teamid))\n\n    def getTeamMembers(\n        self, team: Union[Team, int, str]\n    ) -&gt; typing.Generator[TeamMember, None, None]:\n        \"\"\"\n        Lists the members of the given team.\n\n        Arguments:\n            team: A [synapseclient.team.Team][] object or a team's ID.\n\n        Yields:\n            A generator over [synapseclient.team.TeamMember][] objects.\n\n        \"\"\"\n        for result in self._GET_paginated(\"/teamMembers/{id}\".format(id=id_of(team))):\n            yield TeamMember(**result)\n\n    def _get_docker_digest(\n        self, entity: Union[Entity, str], docker_tag: str = \"latest\"\n    ) -&gt; str:\n        \"\"\"\n        Get matching Docker sha-digest of a DockerRepository given a Docker tag\n\n        Arguments:\n            entity:      Synapse ID or Entity of Docker repository\n            docker_tag:  Docker tag\n\n        Returns:\n            Docker digest matching Docker tag\n        \"\"\"\n        entityid = id_of(entity)\n        uri = \"/entity/{entityId}/dockerTag\".format(entityId=entityid)\n\n        docker_commits = self._GET_paginated(uri)\n        docker_digest = None\n        for commit in docker_commits:\n            if docker_tag == commit[\"tag\"]:\n                docker_digest = commit[\"digest\"]\n        if docker_digest is None:\n            raise ValueError(\n                \"Docker tag {docker_tag} not found.  Please specify a \"\n                \"docker tag that exists. 'latest' is used as \"\n                \"default.\".format(docker_tag=docker_tag)\n            )\n        return docker_digest\n\n    def get_team_open_invitations(\n        self, team: Union[Team, int, str]\n    ) -&gt; typing.Generator[dict, None, None]:\n        \"\"\"Retrieve the open requests submitted to a Team\n        &lt;https://rest-docs.synapse.org/rest/GET/team/id/openInvitation.html&gt;\n\n        Arguments:\n            team: A [synapseclient.team.Team][] object or a team's ID.\n\n        Yields:\n            Generator of MembershipRequest dictionaries\n        \"\"\"\n        teamid = id_of(team)\n        request = \"/team/{team}/openInvitation\".format(team=teamid)\n        open_requests = self._GET_paginated(request)\n        return open_requests\n\n    def get_membership_status(self, userid, team):\n        \"\"\"Retrieve a user's Team Membership Status bundle.\n        &lt;https://rest-docs.synapse.org/rest/GET/team/id/member/principalId/membershipStatus.html&gt;\n\n        Arguments:\n            user: Synapse user ID\n            team: A [synapseclient.team.Team][] object or a team's ID.\n\n        Returns:\n            dict of TeamMembershipStatus\n        \"\"\"\n        teamid = id_of(team)\n        request = \"/team/{team}/member/{user}/membershipStatus\".format(\n            team=teamid, user=userid\n        )\n        membership_status = self.restGET(request)\n        return membership_status\n\n    def _delete_membership_invitation(self, invitationid: str) -&gt; None:\n        \"\"\"\n        Delete an invitation Note: The client must be an administrator of the\n        Team referenced by the invitation or the invitee to make this request.\n\n        Arguments:\n            invitationid: Open invitation id\n        \"\"\"\n        self.restDELETE(\"/membershipInvitation/{id}\".format(id=invitationid))\n\n    def send_membership_invitation(\n        self, teamId, inviteeId=None, inviteeEmail=None, message=None\n    ):\n        \"\"\"Create a membership invitation and send an email notification\n        to the invitee.\n\n        Arguments:\n            teamId: Synapse teamId\n            inviteeId: Synapse username or profile id of user\n            inviteeEmail: Email of user\n            message: Additional message for the user getting invited to the\n                     team.\n\n        Returns:\n            MembershipInvitation\n        \"\"\"\n\n        invite_request = {\"teamId\": str(teamId), \"message\": message}\n        if inviteeEmail is not None:\n            invite_request[\"inviteeEmail\"] = str(inviteeEmail)\n        if inviteeId is not None:\n            invite_request[\"inviteeId\"] = str(inviteeId)\n\n        response = self.restPOST(\n            \"/membershipInvitation\", body=json.dumps(invite_request)\n        )\n        return response\n\n    def invite_to_team(\n        self,\n        team: Union[Team, int, str],\n        user: str = None,\n        inviteeEmail: str = None,\n        message: str = None,\n        force: bool = False,\n    ):\n        \"\"\"Invite user to a Synapse team via Synapse username or email\n        (choose one or the other)\n\n        Arguments:\n            syn: Synapse object\n            team: A [synapseclient.team.Team][] object or a team's ID.\n            user: Synapse username or profile id of user\n            inviteeEmail: Email of user\n            message: Additional message for the user getting invited to the team.\n            force: If an open invitation exists for the invitee, the old invite will be cancelled.\n\n        Returns:\n            MembershipInvitation or None if user is already a member\n        \"\"\"\n        # Throw error if both user and email is specified and if both not\n        # specified\n        id_email_specified = inviteeEmail is not None and user is not None\n        id_email_notspecified = inviteeEmail is None and user is None\n        if id_email_specified or id_email_notspecified:\n            raise ValueError(\"Must specify either 'user' or 'inviteeEmail'\")\n\n        teamid = id_of(team)\n        is_member = False\n        open_invitations = self.get_team_open_invitations(teamid)\n\n        if user is not None:\n            inviteeId = self.getUserProfile(user)[\"ownerId\"]\n            membership_status = self.get_membership_status(inviteeId, teamid)\n            is_member = membership_status[\"isMember\"]\n            open_invites_to_user = [\n                invitation\n                for invitation in open_invitations\n                if invitation.get(\"inviteeId\") == inviteeId\n            ]\n        else:\n            inviteeId = None\n            open_invites_to_user = [\n                invitation\n                for invitation in open_invitations\n                if invitation.get(\"inviteeEmail\") == inviteeEmail\n            ]\n        # Only invite if the invitee is not a member and\n        # if invitee doesn't have an open invitation unless force=True\n        if not is_member and (not open_invites_to_user or force):\n            # Delete all old invitations\n            for invite in open_invites_to_user:\n                self._delete_membership_invitation(invite[\"id\"])\n            return self.send_membership_invitation(\n                teamid,\n                inviteeId=inviteeId,\n                inviteeEmail=inviteeEmail,\n                message=message,\n            )\n        if is_member:\n            not_sent_reason = \"invitee is already a member\"\n        else:\n            not_sent_reason = (\n                \"invitee already has an open invitation \"\n                \"Set force=True to send new invite.\"\n            )\n\n        self.logger.warning(\"No invitation sent: {}\".format(not_sent_reason))\n        # Return None if no invite is sent.\n        return None\n\n    def submit(\n        self,\n        evaluation,\n        entity,\n        name=None,\n        team=None,\n        silent=False,\n        submitterAlias=None,\n        teamName=None,\n        dockerTag=\"latest\",\n    ):\n        \"\"\"\n        Submit an Entity for [evaluation][synapseclient.evaluation.Evaluation].\n\n        Arguments:\n            evalation: Evaluation queue to submit to\n            entity: The Entity containing the Submissions\n            name: A name for this submission. In the absent of this parameter, the entity name will be used.\n                    (Optional) A [synapseclient.team.Team][] object, ID or name of a Team that is registered for the challenge\n            team: (optional) A [synapseclient.team.Team][] object, ID or name of a Team that is registered for the challenge\n            silent: Set to True to suppress output.\n            submitterAlias: (optional) A nickname, possibly for display in leaderboards in place of the submitter's name\n            teamName: (deprecated) A synonym for submitterAlias\n            dockerTag: (optional) The Docker tag must be specified if the entity is a DockerRepository.\n\n        Returns:\n            A [synapseclient.evaluation.Submission][] object\n\n\n        In the case of challenges, a team can optionally be provided to give credit to members of the team that\n        contributed to the submission. The team must be registered for the challenge with which the given evaluation is\n        associated. The caller must be a member of the submitting team.\n\n        Example: Using this function\n            Getting and submitting an evaluation\n\n                evaluation = syn.getEvaluation(123)\n                entity = syn.get('syn456')\n                submission = syn.submit(evaluation, entity, name='Our Final Answer', team='Blue Team')\n        \"\"\"\n\n        require_param(evaluation, \"evaluation\")\n        require_param(entity, \"entity\")\n\n        evaluation_id = id_of(evaluation)\n\n        entity_id = id_of(entity)\n        if isinstance(entity, synapseclient.DockerRepository):\n            # Edge case if dockerTag is specified as None\n            if dockerTag is None:\n                raise ValueError(\n                    \"A dockerTag is required to submit a DockerEntity. Cannot be None\"\n                )\n            docker_repository = entity[\"repositoryName\"]\n        else:\n            docker_repository = None\n\n        if \"versionNumber\" not in entity:\n            entity = self.get(entity, downloadFile=False)\n        # version defaults to 1 to hack around required version field and allow submission of files/folders\n        entity_version = entity.get(\"versionNumber\", 1)\n\n        # default name of submission to name of entity\n        if name is None and \"name\" in entity:\n            name = entity[\"name\"]\n\n        team_id = None\n        if team:\n            team = self.getTeam(team)\n            team_id = id_of(team)\n\n        contributors, eligibility_hash = self._get_contributors(evaluation_id, team)\n\n        # for backward compatible until we remove supports for teamName\n        if not submitterAlias:\n            if teamName:\n                submitterAlias = teamName\n            elif team and \"name\" in team:\n                submitterAlias = team[\"name\"]\n\n        if isinstance(entity, synapseclient.DockerRepository):\n            docker_digest = self._get_docker_digest(entity, dockerTag)\n        else:\n            docker_digest = None\n\n        submission = {\n            \"evaluationId\": evaluation_id,\n            \"name\": name,\n            \"entityId\": entity_id,\n            \"versionNumber\": entity_version,\n            \"dockerDigest\": docker_digest,\n            \"dockerRepositoryName\": docker_repository,\n            \"teamId\": team_id,\n            \"contributors\": contributors,\n            \"submitterAlias\": submitterAlias,\n        }\n\n        submitted = self._submit(submission, entity[\"etag\"], eligibility_hash)\n\n        # if we want to display the receipt message, we need the full object\n        if not silent:\n            if not (isinstance(evaluation, Evaluation)):\n                evaluation = self.getEvaluation(evaluation_id)\n            if \"submissionReceiptMessage\" in evaluation:\n                self.logger.info(evaluation[\"submissionReceiptMessage\"])\n\n        return Submission(**submitted)\n\n    def _submit(self, submission, entity_etag, eligibility_hash):\n        require_param(submission, \"submission\")\n        require_param(entity_etag, \"entity_etag\")\n        # URI requires the etag of the entity and, in the case of a team submission, requires an eligibilityStateHash\n        uri = \"/evaluation/submission?etag=%s\" % entity_etag\n        if eligibility_hash:\n            uri += \"&amp;submissionEligibilityHash={0}\".format(eligibility_hash)\n        submitted = self.restPOST(uri, json.dumps(submission))\n        return submitted\n\n    def _get_contributors(self, evaluation_id, team):\n        if not evaluation_id or not team:\n            return None, None\n\n        team_id = id_of(team)\n        # see &lt;https://rest-docs.synapse.org/rest/GET/evaluation/evalId/team/id/submissionEligibility.html&gt;\n        eligibility = self.restGET(\n            \"/evaluation/{evalId}/team/{id}/submissionEligibility\".format(\n                evalId=evaluation_id, id=team_id\n            )\n        )\n\n        if not eligibility[\"teamEligibility\"][\"isEligible\"]:\n            # Check team eligibility and raise an exception if not eligible\n            if not eligibility[\"teamEligibility\"][\"isRegistered\"]:\n                raise SynapseError(\n                    'Team \"{team}\" is not registered.'.format(team=team.name)\n                )\n            if eligibility[\"teamEligibility\"][\"isQuotaFilled\"]:\n                raise SynapseError(\n                    'Team \"{team}\" has already submitted the full quota of submissions.'.format(\n                        team=team.name\n                    )\n                )\n            raise SynapseError('Team \"{team}\" is not eligible.'.format(team=team.name))\n\n        # Include all team members who are eligible.\n        contributors = [\n            {\"principalId\": member[\"principalId\"]}\n            for member in eligibility[\"membersEligibility\"]\n            if member[\"isEligible\"] and not member[\"hasConflictingSubmission\"]\n        ]\n        return contributors, eligibility[\"eligibilityStateHash\"]\n\n    def _allowParticipation(\n        self,\n        evaluation: Union[Evaluation, str],\n        user: str,\n        rights: list = [\"READ\", \"PARTICIPATE\", \"SUBMIT\", \"UPDATE_SUBMISSION\"],\n    ) -&gt; Dict[str, Union[str, list]]:\n        \"\"\"\n        Grants the given user the minimal access rights to join and submit to an Evaluation.\n        Note: The specification of this method has not been decided yet, so the method is likely to change in future.\n\n        Arguments:\n            evaluation: An Evaluation object or Evaluation ID\n            user:       Either a user group or the principal ID of a user to grant rights to.\n\n                - To allow all users, use \"PUBLIC\".\n                - To allow authenticated users, use \"AUTHENTICATED_USERS\".\n\n            rights:     The access rights to give to the users.\n\n                - `READ`\n                - `PARTICIPATE`\n                - `SUBMIT`\n                - `UPDATE_SUBMISSION`\n\n        Raises:\n            SynapseError: If the user does not exist\n\n        Returns:\n            The new or updated ACL\n        \"\"\"\n        # Check to see if the user is an ID or group\n        userId = -1\n        try:\n            # TODO: is there a better way to differentiate between a userID and a group name?\n            # What if a group is named with just numbers?\n            userId = int(user)\n\n            # Verify that the user exists\n            try:\n                self.getUserProfile(userId)\n            except SynapseHTTPError as err:\n                if err.response.status_code == 404:\n                    raise SynapseError(\"The user (%s) does not exist\" % str(userId))\n                raise\n\n        except ValueError:\n            # Fetch the ID of the user group\n            userId = self._getUserbyPrincipalIdOrName(user)\n\n        if not isinstance(evaluation, Evaluation):\n            evaluation = self.getEvaluation(id_of(evaluation))\n\n        self.setPermissions(evaluation, userId, accessType=rights, overwrite=False)\n\n    def getSubmissions(self, evaluation, status=None, myOwn=False, limit=20, offset=0):\n        \"\"\"\n        Arguments:\n            evaluation: Evaluation to get submissions from.\n            status: Optionally filter submissions for a specific status.\n                    One of:\n\n                - `OPEN`\n                - `CLOSED`\n                - `SCORED`\n                - `INVALID`\n                - `VALIDATED`\n                - `EVALUATION_IN_PROGRESS`\n                - `RECEIVED`\n                - `REJECTED`\n                - `ACCEPTED`\n\n            myOwn: Determines if only your Submissions should be fetched.\n                     Defaults to False (all Submissions)\n            limit: Limits the number of submissions in a single response.\n                        Because this method returns a generator and repeatedly\n                        fetches submissions, this argument is limiting the\n                        size of a single request and NOT the number of sub-\n                        missions returned in total.\n            offset: Start iterating at a submission offset from the first submission.\n\n        Yields:\n            A generator over [synapseclient.evaluation.Submission][] objects for an Evaluation\n\n        Example: Using this function\n            Print submissions\n\n                for submission in syn.getSubmissions(1234567):\n                    print(submission['entityId'])\n\n        See:\n\n        - [synapseclient.evaluation][]\n        \"\"\"\n\n        evaluation_id = id_of(evaluation)\n        uri = \"/evaluation/%s/submission%s\" % (evaluation_id, \"\" if myOwn else \"/all\")\n\n        if status is not None:\n            uri += \"?status=%s\" % status\n\n        for result in self._GET_paginated(uri, limit=limit, offset=offset):\n            yield Submission(**result)\n\n    def _getSubmissionBundles(\n        self,\n        evaluation: Union[Evaluation, str],\n        status: str = None,\n        myOwn: bool = False,\n        limit: int = 20,\n        offset: int = 0,\n    ) -&gt; typing.Iterator[Dict[str, Union[Submission, dict]]]:\n        \"\"\"\n        Gets the requesting user's bundled Submissions and SubmissionStatuses to a specified Evaluation.\n\n        Arguments:\n            evaluation: Evaluation to get submissions from.\n            status:     Optionally filter submissions for a specific status.\n                        One of {OPEN, CLOSED, SCORED, INVALID}\n            myOwn:      Determines if only your Submissions should be fetched.\n                        Defaults to False (all Submissions)\n            limit:      Limits the number of submissions coming back from the\n                        service in a single response.\n            offset:     Start iterating at a submission offset from the first\n                        submission.\n\n        Returns:\n            A generator over dictionaries with keys 'submission' and 'submissionStatus'.\n\n        Example:\n\n            for sb in syn._getSubmissionBundles(1234567):\n                print(sb['submission']['name'],\n                      sb['submission']['submitterAlias'],\n                      sb['submissionStatus']['status'],\n                      sb['submissionStatus']['score'])\n\n        This may later be changed to return objects, pending some thought on how submissions along with related status\n        and annotations should be represented in the clients.\n\n        See: [synapseclient.evaluation][]\n        \"\"\"\n\n        evaluation_id = id_of(evaluation)\n        url = \"/evaluation/%s/submission/bundle%s\" % (\n            evaluation_id,\n            \"\" if myOwn else \"/all\",\n        )\n        if status is not None:\n            url += \"?status=%s\" % status\n\n        return self._GET_paginated(url, limit=limit, offset=offset)\n\n    def getSubmissionBundles(\n        self, evaluation, status=None, myOwn=False, limit=20, offset=0\n    ):\n        \"\"\"\n        Retrieve submission bundles (submission and submissions status) for an evaluation queue, optionally filtered by\n        submission status and/or owner.\n\n        Arguments:\n            evaluation: Evaluation to get submissions from.\n            status:     Optionally filter submissions for a specific status.\n                        One of:\n\n                - `OPEN`\n                - `CLOSED`\n                - `SCORED`\n                - `INVALID`\n\n            myOwn:      Determines if only your Submissions should be fetched.\n                        Defaults to False (all Submissions)\n            limit:      Limits the number of submissions coming back from the\n                        service in a single response.\n            offset:     Start iterating at a submission offset from the first submission.\n\n        Yields:\n            A generator over tuples containing a [synapseclient.evaluation.Submission][] and a [synapseclient.evaluation.SubmissionStatus][].\n\n        Example: Using this function\n            Loop over submissions\n\n                for submission, status in syn.getSubmissionBundles(evaluation):\n                    print(submission.name,\n                          submission.submitterAlias,\n                          status.status,\n                          status.score)\n\n        This may later be changed to return objects, pending some thought on how submissions along with related status\n        and annotations should be represented in the clients.\n\n        See:\n        - [synapseclient.evaluation][]\n        \"\"\"\n        for bundle in self._getSubmissionBundles(\n            evaluation, status=status, myOwn=myOwn, limit=limit, offset=offset\n        ):\n            yield (\n                Submission(**bundle[\"submission\"]),\n                SubmissionStatus(**bundle[\"submissionStatus\"]),\n            )\n\n    def _GET_paginated(self, uri: str, limit: int = 20, offset: int = 0):\n        \"\"\"\n        Get paginated results\n\n        Arguments:\n            uri:     A URI that returns paginated results\n            limit:   How many records should be returned per request\n            offset:  At what record offset from the first should iteration start\n\n        Returns:\n            A generator over some paginated results\n\n        The limit parameter is set at 20 by default. Using a larger limit results in fewer calls to the service, but if\n        responses are large enough to be a burden on the service they may be truncated.\n        \"\"\"\n        prev_num_results = sys.maxsize\n        while prev_num_results &gt; 0:\n            uri = utils._limit_and_offset(uri, limit=limit, offset=offset)\n            page = self.restGET(uri)\n            results = page[\"results\"] if \"results\" in page else page[\"children\"]\n            prev_num_results = len(results)\n\n            for result in results:\n                offset += 1\n                yield result\n\n    def _POST_paginated(self, uri: str, body, **kwargs):\n        \"\"\"\n        Get paginated results\n\n        Arguments:\n            uri:     A URI that returns paginated results\n            body:    POST request payload\n\n        Returns:\n            A generator over some paginated results\n        \"\"\"\n\n        next_page_token = None\n        while True:\n            body[\"nextPageToken\"] = next_page_token\n            response = self.restPOST(uri, body=json.dumps(body), **kwargs)\n            next_page_token = response.get(\"nextPageToken\")\n            for item in response[\"page\"]:\n                yield item\n            if next_page_token is None:\n                break\n\n    def getSubmission(self, id, **kwargs):\n        \"\"\"\n        Gets a [synapseclient.evaluation.Submission][] object by its id.\n\n        Arguments:\n            id: The id of the submission to retrieve\n\n        Returns:\n            A [synapseclient.evaluation.Submission][] object\n\n        See:\n\n        - [synapseclient.Synapse.get][] for information\n             on the *downloadFile*, *downloadLocation*, and *ifcollision* parameters\n        \"\"\"\n\n        submission_id = id_of(id)\n        uri = Submission.getURI(submission_id)\n        submission = Submission(**self.restGET(uri))\n\n        # Pre-fetch the Entity tied to the Submission, if there is one\n        if \"entityId\" in submission and submission[\"entityId\"] is not None:\n            entityBundleJSON = json.loads(submission[\"entityBundleJSON\"])\n\n            # getWithEntityBundle expects a bundle services v2 style\n            # annotations dict, but the evaluations API may return\n            # an older format annotations object in the encoded JSON\n            # depending on when the original submission was made.\n            annotations = entityBundleJSON.get(\"annotations\")\n            if annotations:\n                entityBundleJSON[\"annotations\"] = convert_old_annotation_json(\n                    annotations\n                )\n\n            related = self._getWithEntityBundle(\n                entityBundle=entityBundleJSON,\n                entity=submission[\"entityId\"],\n                submission=submission_id,\n                **kwargs,\n            )\n            submission.entity = related\n            submission.filePath = related.get(\"path\", None)\n\n        return submission\n\n    def getSubmissionStatus(self, submission):\n        \"\"\"\n        Downloads the status of a Submission.\n\n        Arguments:\n            submission: The submission to lookup\n\n        Returns:\n            A [synapseclient.evaluation.SubmissionStatus][] object\n        \"\"\"\n\n        submission_id = id_of(submission)\n        uri = SubmissionStatus.getURI(submission_id)\n        val = self.restGET(uri)\n        return SubmissionStatus(**val)\n\n    ############################################################\n    #                      CRUD for Wikis                      #\n    ############################################################\n\n    def getWiki(self, owner, subpageId=None, version=None):\n        \"\"\"\n        Get a [synapseclient.wiki.Wiki][] object from Synapse. Uses wiki2 API which supports versioning.\n\n        Arguments:\n            owner: The entity to which the Wiki is attached\n            subpageId: The id of the specific sub-page or None to get the root Wiki page\n            version: The version of the page to retrieve or None to retrieve the latest\n\n        Returns:\n            A [synapseclient.wiki.Wiki][] object\n        \"\"\"\n        uri = \"/entity/{ownerId}/wiki2\".format(ownerId=id_of(owner))\n        if subpageId is not None:\n            uri += \"/{wikiId}\".format(wikiId=subpageId)\n        if version is not None:\n            uri += \"?wikiVersion={version}\".format(version=version)\n\n        wiki = self.restGET(uri)\n        wiki[\"owner\"] = owner\n        wiki = Wiki(**wiki)\n\n        path = self.cache.get(wiki.markdownFileHandleId)\n        if not path:\n            cache_dir = self.cache.get_cache_dir(wiki.markdownFileHandleId)\n            if not os.path.exists(cache_dir):\n                os.makedirs(cache_dir)\n            path = wrap_async_to_sync(\n                coroutine=download_by_file_handle(\n                    file_handle_id=wiki[\"markdownFileHandleId\"],\n                    synapse_id=wiki[\"id\"],\n                    entity_type=\"WikiMarkdown\",\n                    destination=os.path.join(\n                        cache_dir, str(wiki.markdownFileHandleId) + \".md\"\n                    ),\n                ),\n                syn=self,\n            )\n        try:\n            import gzip\n\n            with gzip.open(path) as f:\n                markdown = f.read().decode(\"utf-8\")\n        except IOError:\n            with open(path) as f:\n                markdown = f.read().decode(\"utf-8\")\n\n        wiki.markdown = markdown\n        wiki.markdown_path = path\n\n        return wiki\n\n    def getWikiHeaders(self, owner):\n        \"\"\"\n        Retrieves the headers of all Wikis belonging to the owner (the entity to which the Wiki is attached).\n\n        Arguments:\n            owner: An Entity\n\n        Returns:\n            A list of Objects with three fields: id, title and parentId.\n        \"\"\"\n\n        uri = \"/entity/%s/wikiheadertree\" % id_of(owner)\n        return [DictObject(**header) for header in self._GET_paginated(uri)]\n\n    def _storeWiki(self, wiki: Wiki, createOrUpdate: bool) -&gt; Wiki:\n        \"\"\"\n        Stores or updates the given Wiki.\n\n        Arguments:\n            wiki:           A Wiki object\n            createOrUpdate: Indicates whether the method should automatically perform an update if the 'obj'\n                            conflicts with an existing Synapse object.\n\n        Returns:\n            An updated Wiki object\n        \"\"\"\n        # Make sure the file handle field is a list\n        if \"attachmentFileHandleIds\" not in wiki:\n            wiki[\"attachmentFileHandleIds\"] = []\n\n        # Convert all attachments into file handles\n        if wiki.get(\"attachments\") is not None:\n            for attachment in wiki[\"attachments\"]:\n                fileHandle = wrap_async_to_sync(\n                    upload_synapse_s3(self, attachment), self\n                )\n                wiki[\"attachmentFileHandleIds\"].append(fileHandle[\"id\"])\n            del wiki[\"attachments\"]\n\n        # Perform an update if the Wiki has an ID\n        if \"id\" in wiki:\n            updated_wiki = Wiki(\n                owner=wiki.ownerId, **self.restPUT(wiki.putURI(), wiki.json())\n            )\n\n        # Perform a create if the Wiki has no ID\n        else:\n            try:\n                updated_wiki = Wiki(\n                    owner=wiki.ownerId, **self.restPOST(wiki.postURI(), wiki.json())\n                )\n            except SynapseHTTPError as err:\n                # If already present we get an unhelpful SQL error\n                if createOrUpdate and (\n                    (\n                        err.response.status_code == 400\n                        and \"DuplicateKeyException\" in err.message\n                    )\n                    or err.response.status_code == 409\n                ):\n                    existing_wiki = self.getWiki(wiki.ownerId)\n\n                    # overwrite everything except for the etag (this will keep unmodified fields in the existing wiki)\n                    etag = existing_wiki[\"etag\"]\n                    existing_wiki.update(wiki)\n                    existing_wiki.etag = etag\n\n                    updated_wiki = Wiki(\n                        owner=wiki.ownerId,\n                        **self.restPUT(existing_wiki.putURI(), existing_wiki.json()),\n                    )\n                else:\n                    raise\n        return updated_wiki\n\n    def getWikiAttachments(self, wiki):\n        \"\"\"\n        Retrieve the attachments to a wiki page.\n\n        Arguments:\n            wiki: The Wiki object for which the attachments are to be returned.\n\n        Returns:\n            A list of file handles for the files attached to the Wiki.\n        \"\"\"\n        uri = \"/entity/%s/wiki/%s/attachmenthandles\" % (wiki.ownerId, wiki.id)\n        results = self.restGET(uri)\n        file_handles = list(WikiAttachment(**fh) for fh in results[\"list\"])\n        return file_handles\n\n    ############################################################\n    #                      Tables                              #\n    ############################################################\n\n    def _waitForAsync(self, uri, request, endpoint=None):\n        if endpoint is None:\n            endpoint = self.repoEndpoint\n        async_job_id = self.restPOST(\n            uri + \"/start\", body=json.dumps(request), endpoint=endpoint\n        )\n\n        # https://rest-docs.synapse.org/rest/org/sagebionetworks/repo/model/asynch/AsynchronousJobStatus.html\n        sleep = self.table_query_sleep\n        start_time = time.time()\n        lastMessage, lastProgress, lastTotal, progressed = \"\", 0, 1, False\n        while time.time() - start_time &lt; self.table_query_timeout:\n            result = self.restGET(\n                uri + \"/get/%s\" % async_job_id[\"token\"], endpoint=endpoint\n            )\n            if result.get(\"jobState\", None) == \"PROCESSING\":\n                progressed = True\n                message = result.get(\"progressMessage\", lastMessage)\n                progress = result.get(\"progressCurrent\", lastProgress)\n                total = result.get(\"progressTotal\", lastTotal)\n                if message != \"\":\n                    self._print_transfer_progress(\n                        progress, total, message, isBytes=False\n                    )\n                # Reset the time if we made progress (fix SYNPY-214)\n                if message != lastMessage or lastProgress != progress:\n                    start_time = time.time()\n                    lastMessage, lastProgress, lastTotal = message, progress, total\n                sleep = min(\n                    self.table_query_max_sleep, sleep * self.table_query_backoff\n                )\n                doze(sleep)\n            else:\n                break\n        else:\n            raise SynapseTimeoutError(\n                \"Timeout waiting for query results: %0.1f seconds \"\n                % (time.time() - start_time)\n            )\n        if result.get(\"jobState\", None) == \"FAILED\":\n            raise SynapseError(\n                result.get(\"errorMessage\", None)\n                + \"\\n\"\n                + result.get(\"errorDetails\", None),\n                asynchronousJobStatus=result,\n            )\n        if progressed:\n            self._print_transfer_progress(total, total, message, isBytes=False)\n        return result\n\n    def getColumn(self, id):\n        \"\"\"\n        Gets a Column object from Synapse by ID.\n\n        See: [synapseclient.table.Column][]\n\n        Arguments:\n            id: The ID of the column to retrieve\n\n        Returns:\n            An object of type [synapseclient.table.Column][]\n\n\n        Example: Using this function\n            Getting a column\n\n                column = syn.getColumn(123)\n        \"\"\"\n        return Column(**self.restGET(Column.getURI(id)))\n\n    def getColumns(self, x, limit=100, offset=0):\n        \"\"\"\n        Get the columns defined in Synapse either (1) corresponding to a set of column headers, (2) those for a given\n        schema, or (3) those whose names start with a given prefix.\n\n        Arguments:\n            x: A list of column headers, a Table Entity object (Schema/EntityViewSchema), a Table's Synapse ID, or a\n                string prefix\n            limit: maximum number of columns to return (pagination parameter)\n            offset: the index of the first column to return (pagination parameter)\n\n        Yields:\n            A generator over [synapseclient.table.Column][] objects\n        \"\"\"\n        if x is None:\n            uri = \"/column\"\n            for result in self._GET_paginated(uri, limit=limit, offset=offset):\n                yield Column(**result)\n        elif isinstance(x, (list, tuple)):\n            for header in x:\n                try:\n                    # if header is an integer, it's a columnID, otherwise it's an aggregate column, like \"AVG(Foo)\"\n                    int(header)\n                    yield self.getColumn(header)\n                except ValueError:\n                    # ignore aggregate column\n                    pass\n        elif isinstance(x, SchemaBase) or utils.is_synapse_id_str(x):\n            for col in self.getTableColumns(x):\n                yield col\n        elif isinstance(x, str):\n            uri = \"/column?prefix=\" + x\n            for result in self._GET_paginated(uri, limit=limit, offset=offset):\n                yield Column(**result)\n        else:\n            ValueError(\"Can't get columns for a %s\" % type(x))\n\n    def create_snapshot_version(\n        self,\n        table: typing.Union[\n            EntityViewSchema, Schema, str, SubmissionViewSchema, Dataset\n        ],\n        comment: str = None,\n        label: str = None,\n        activity: typing.Union[Activity, str] = None,\n        wait: bool = True,\n    ) -&gt; int:\n        \"\"\"Create a new Table Version, new View version, or new Dataset version.\n\n        Arguments:\n            table: The schema of the Table/View, or its ID.\n            comment: Optional snapshot comment.\n            label: Optional snapshot label.\n            activity: Optional activity ID applied to snapshot version.\n            wait: True if this method should return the snapshot version after waiting for any necessary\n                    asynchronous table updates to complete. If False this method will return\n                    as soon as any updates are initiated.\n\n        Returns:\n            The snapshot version number if wait=True, None if wait=False\n        \"\"\"\n        ent = self.get(id_of(table), downloadFile=False)\n        if isinstance(ent, (EntityViewSchema, SubmissionViewSchema, Dataset)):\n            result = self._async_table_update(\n                table,\n                create_snapshot=True,\n                comment=comment,\n                label=label,\n                activity=activity,\n                wait=wait,\n            )\n        elif isinstance(ent, Schema):\n            result = self._create_table_snapshot(\n                table,\n                comment=comment,\n                label=label,\n                activity=activity,\n            )\n        else:\n            raise ValueError(\n                \"This function only accepts Synapse ids of Tables or Views\"\n            )\n\n        # for consistency we return nothing if wait=False since we can't\n        # supply the snapshot version on an async table update without waiting\n        return result[\"snapshotVersionNumber\"] if wait else None\n\n    def _create_table_snapshot(\n        self,\n        table: typing.Union[Schema, str],\n        comment: str = None,\n        label: str = None,\n        activity: typing.Union[Activity, str] = None,\n    ) -&gt; dict:\n        \"\"\"\n        Creates Table snapshot\n\n        Arguments:\n            table:  The schema of the Table\n            comment:  Optional snapshot comment.\n            label:  Optional snapshot label.\n            activity:  Optional activity ID or activity instance applied to snapshot version.\n\n        Returns:\n            Snapshot Response\n        \"\"\"\n\n        # check the activity id or object is provided\n        activity_id = None\n        if isinstance(activity, collections.abc.Mapping):\n            if \"id\" not in activity:\n                activity = self._saveActivity(activity)\n            activity_id = activity[\"id\"]\n        elif activity is not None:\n            activity_id = str(activity)\n\n        snapshot_body = {\n            \"snapshotComment\": comment,\n            \"snapshotLabel\": label,\n            \"snapshotActivityId\": activity_id,\n        }\n        new_body = {\n            key: value for key, value in snapshot_body.items() if value is not None\n        }\n        snapshot = self.restPOST(\n            \"/entity/{}/table/snapshot\".format(id_of(table)), body=json.dumps(new_body)\n        )\n        return snapshot\n\n    def _async_table_update(\n        self,\n        table: typing.Union[EntityViewSchema, Schema, str, SubmissionViewSchema],\n        changes: typing.List[dict] = [],\n        create_snapshot: bool = False,\n        comment: str = None,\n        label: str = None,\n        activity: str = None,\n        wait: bool = True,\n    ) -&gt; dict:\n        \"\"\"\n        Creates view updates and snapshots\n\n        Arguments:\n            table:           The schema of the EntityView or its ID.\n            changes:         Array of Table changes\n            create_snapshot: Create snapshot\n            comment:         Optional snapshot comment.\n            label:           Optional snapshot label.\n            activity:        Optional activity ID applied to snapshot version.\n            wait:            True to wait for async table update to complete\n\n        Returns:\n            A Snapshot Response\n        \"\"\"\n        snapshot_options = {\n            \"snapshotComment\": comment,\n            \"snapshotLabel\": label,\n            \"snapshotActivityId\": activity,\n        }\n        new_snapshot = {\n            key: value for key, value in snapshot_options.items() if value is not None\n        }\n        table_update_body = {\n            \"changes\": changes,\n            \"createSnapshot\": create_snapshot,\n            \"snapshotOptions\": new_snapshot,\n        }\n\n        uri = \"/entity/{}/table/transaction/async\".format(id_of(table))\n\n        if wait:\n            result = self._waitForAsync(uri, table_update_body)\n\n        else:\n            result = self.restPOST(\n                \"{}/start\".format(uri), body=json.dumps(table_update_body)\n            )\n\n        return result\n\n    def getTableColumns(self, table):\n        \"\"\"\n        Retrieve the column models used in the given table schema.\n\n        Arguments:\n            table: The schema of the Table whose columns are to be retrieved\n\n        Yields:\n            A Generator over the Table's [columns][synapseclient.table.Column]\n        \"\"\"\n        uri = \"/entity/{id}/column\".format(id=id_of(table))\n        # The returned object type for this service, PaginatedColumnModels, is a misnomer.\n        # This service always returns the full list of results so the pagination does not not actually matter.\n        for result in self.restGET(uri)[\"results\"]:\n            yield Column(**result)\n\n    def tableQuery(self, query: str, resultsAs: str = \"csv\", **kwargs):\n        \"\"\"\n        Query a Synapse Table.\n\n        You can receive query results either as a generator over rows or as a CSV file. For smallish tables, either\n        method will work equally well. Use of a \"rowset\" generator allows rows to be processed one at a time and\n        processing may be stopped before downloading the entire table.\n\n        Optional keyword arguments differ for the two return types of `rowset` or `csv`\n\n        Arguments:\n            query: Query string in a [SQL-like syntax](https://rest-docs.synapse.org/rest/org/sagebionetworks/repo/web/controller/TableExamples.html), for example: `\"SELECT * from syn12345\"`\n            resultsAs: select whether results are returned as a CSV file (\"csv\") or incrementally downloaded as sets of rows (\"rowset\")\n            limit: (rowset only) Specify the maximum number of rows to be returned, defaults to None\n            offset: (rowset only) Don't return the first n rows, defaults to None\n            quoteCharacter: (csv only) default double quote\n            escapeCharacter: (csv only) default backslash\n            lineEnd: (csv only) defaults to os.linesep\n            separator: (csv only) defaults to comma\n            header: (csv only) True by default\n            includeRowIdAndRowVersion: (csv only) True by default\n            downloadLocation: (csv only) directory path to download the CSV file to\n\n        Returns:\n            A [TableQueryResult][synapseclient.table.TableQueryResult] or [CsvFileTable][synapseclient.table.CsvFileTable] object\n\n        NOTE:\n            When performing queries on frequently updated tables, the table can be inaccessible for a period leading\n              to a timeout of the query.  Since the results are guaranteed to eventually be returned you can change the\n              max timeout by setting the table_query_timeout variable of the Synapse object:\n\n                  # Sets the max timeout to 5 minutes.\n                  syn.table_query_timeout = 300\n\n        \"\"\"\n        if resultsAs.lower() == \"rowset\":\n            return TableQueryResult(self, query, **kwargs)\n        elif resultsAs.lower() == \"csv\":\n            # TODO: remove isConsistent because it has now been deprecated\n            # from the backend\n            if kwargs.get(\"isConsistent\") is not None:\n                kwargs.pop(\"isConsistent\")\n            return CsvFileTable.from_table_query(self, query, **kwargs)\n        else:\n            raise ValueError(\n                \"Unknown return type requested from tableQuery: \" + str(resultsAs)\n            )\n\n    def _queryTable(\n        self,\n        query: str,\n        limit: int = None,\n        offset: int = None,\n        isConsistent: bool = True,\n        partMask=None,\n    ) -&gt; TableQueryResult:\n        \"\"\"\n        Query a table and return the first page of results as a [QueryResultBundle](https://rest-docs.synapse.org/rest/org/sagebionetworks/repo/model/table/QueryResultBundle.html).\n        If the result contains a *nextPageToken*, following pages a retrieved by calling [_queryTableNext][].\n\n        Arguments:\n            query:        A sql query\n            limit:        The optional limit to the results\n            offset:       The optional offset into the results\n            isConsistent: Whether the index is inconsistent with the true state of the table\n            partMask:     Optional, default all. The 'partsMask' is a bit field for requesting\n                          different elements in the resulting JSON bundle.\n                          Query Results (queryResults) = 0x1\n                          Query Count (queryCount) = 0x2\n                          Select Columns (selectColumns) = 0x4\n                          Max Rows Per Page (maxRowsPerPage) = 0x8\n\n        Returns:\n            The first page of results as a QueryResultBundle\n        \"\"\"\n        # See: &lt;https://rest-docs.synapse.org/rest/org/sagebionetworks/repo/model/table/QueryBundleRequest.html&gt;\n        query_bundle_request = {\n            \"concreteType\": \"org.sagebionetworks.repo.model.table.QueryBundleRequest\",\n            \"query\": {\n                \"sql\": query,\n                \"isConsistent\": isConsistent,\n                \"includeEntityEtag\": True,\n            },\n        }\n\n        if partMask:\n            query_bundle_request[\"partMask\"] = partMask\n        if limit is not None:\n            query_bundle_request[\"query\"][\"limit\"] = limit\n        if offset is not None:\n            query_bundle_request[\"query\"][\"offset\"] = offset\n        query_bundle_request[\"query\"][\"isConsistent\"] = isConsistent\n\n        uri = \"/entity/{id}/table/query/async\".format(\n            id=extract_synapse_id_from_query(query)\n        )\n\n        return self._waitForAsync(uri=uri, request=query_bundle_request)\n\n    def _queryTableNext(self, nextPageToken: str, tableId: str) -&gt; TableQueryResult:\n        \"\"\"\n        Retrieve following pages if the result contains a *nextPageToken*\n\n        Arguments:\n            nextPageToken: Forward this token to get the next page of results.\n            tableId:       The Synapse ID of the table\n\n        Returns:\n            The following page of results as a QueryResultBundle\n        \"\"\"\n        uri = \"/entity/{id}/table/query/nextPage/async\".format(id=tableId)\n        return self._waitForAsync(uri=uri, request=nextPageToken)\n\n    def _uploadCsv(\n        self,\n        filepath: str,\n        schema: Union[Entity, str],\n        updateEtag: str = None,\n        quoteCharacter: str = '\"',\n        escapeCharacter: str = \"\\\\\",\n        lineEnd: str = os.linesep,\n        separator: str = \",\",\n        header: bool = True,\n        linesToSkip: int = 0,\n    ) -&gt; dict:\n        \"\"\"\n        Send an [UploadToTableRequest](https://rest-docs.synapse.org/rest/org/sagebionetworks/repo/model/table/UploadToTableRequest.html) to Synapse.\n\n        Arguments:\n            filepath:        Path of a [CSV](https://en.wikipedia.org/wiki/Comma-separated_values) file.\n            schema:          A table entity or its Synapse ID.\n            updateEtag:      Any RowSet returned from Synapse will contain the current etag of the change set.\n                             To update any rows from a RowSet the etag must be provided with the POST.\n            quoteCharacter:  Quotation character\n            escapeCharacter: Escape character\n            lineEnd:         The string used to separate lines\n            separator:       Separator character\n            header:          Whether to set the first line as header.\n            linesToSkip:     The number of lines to skip from the start of the file.\n                             The default value of 0 will be used if this is not provided by the caller.\n\n        Returns:\n            [UploadToTableResult](https://rest-docs.synapse.org/rest/org/sagebionetworks/repo/model/table/UploadToTableResult.html)\n        \"\"\"\n\n        fileHandleId = wrap_async_to_sync(\n            multipart_upload_file_async(self, filepath, content_type=\"text/csv\"), self\n        )\n\n        uploadRequest = {\n            \"concreteType\": \"org.sagebionetworks.repo.model.table.UploadToTableRequest\",\n            \"csvTableDescriptor\": {\n                \"isFirstLineHeader\": header,\n                \"quoteCharacter\": quoteCharacter,\n                \"escapeCharacter\": escapeCharacter,\n                \"lineEnd\": lineEnd,\n                \"separator\": separator,\n            },\n            \"linesToSkip\": linesToSkip,\n            \"tableId\": id_of(schema),\n            \"uploadFileHandleId\": fileHandleId,\n        }\n\n        if updateEtag:\n            uploadRequest[\"updateEtag\"] = updateEtag\n\n        response = self._async_table_update(schema, changes=[uploadRequest], wait=True)\n        self._check_table_transaction_response(response)\n\n        return response\n\n    def _check_table_transaction_response(self, response):\n        for result in response[\"results\"]:\n            result_type = result[\"concreteType\"]\n\n            if result_type in {\n                concrete_types.ROW_REFERENCE_SET_RESULTS,\n                concrete_types.TABLE_SCHEMA_CHANGE_RESPONSE,\n                concrete_types.UPLOAD_TO_TABLE_RESULT,\n            }:\n                # if these fail, it we would have gotten an HttpError before the results came back\n                pass\n            elif result_type == concrete_types.ENTITY_UPDATE_RESULTS:\n                # TODO: output full response to error file when the logging JIRA issue gets pulled in\n                successful_updates = []\n                failed_updates = []\n                for update_result in result[\"updateResults\"]:\n                    failure_code = update_result.get(\"failureCode\")\n                    failure_message = update_result.get(\"failureMessage\")\n                    entity_id = update_result.get(\"entityId\")\n                    if failure_code or failure_message:\n                        failed_updates.append(update_result)\n                    else:\n                        successful_updates.append(entity_id)\n\n                if failed_updates:\n                    raise SynapseError(\n                        \"Not all of the entities were updated.\"\n                        \" Successful updates: %s.  Failed updates: %s\"\n                        % (successful_updates, failed_updates)\n                    )\n\n            else:\n                warnings.warn(\n                    \"Unexpected result from a table transaction of type [%s].\"\n                    \" Please check the result to make sure it is correct. %s\"\n                    % (result_type, result)\n                )\n\n    def _queryTableCsv(\n        self,\n        query: str,\n        quoteCharacter: str = '\"',\n        escapeCharacter: str = \"\\\\\",\n        lineEnd: str = os.linesep,\n        separator: str = \",\",\n        header: bool = True,\n        includeRowIdAndRowVersion: bool = True,\n        downloadLocation: str = None,\n    ) -&gt; Tuple:\n        \"\"\"\n        Query a Synapse Table and download a CSV file containing the results.\n\n        Sends a [DownloadFromTableRequest](https://rest-docs.synapse.org/rest/org/sagebionetworks/repo/model/table/DownloadFromTableRequest.html) to Synapse.\n\n        Arguments:\n            query:                     A sql query\n            quoteCharacter:            Quotation character\n            escapeCharacter:           Escape character\n            lineEnd:                   The string used to separate lines\n            separator:                 Separator character\n            header:                    Whether to set the first line as header.\n            includeRowIdAndRowVersion: Whether to set the first two columns contains the row ID and row version.\n            downloadLocation:          The download location\n\n        Returns:\n            A tuple containing a [DownloadFromTableResult](https://rest-docs.synapse.org/rest/org/sagebionetworks/repo/model/table/DownloadFromTableResult.html)\n\n        The DownloadFromTableResult object contains these fields:\n         * headers:             ARRAY&lt;STRING&gt;, The list of ColumnModel IDs that describes the rows of this set.\n         * resultsFileHandleId: STRING, The resulting file handle ID can be used to download the CSV file created by\n                                this query.\n         * concreteType:        STRING\n         * etag:                STRING, Any RowSet returned from Synapse will contain the current etag of the change\n                                set.\n                                To update any rows from a RowSet the etag must be provided with the POST.\n         * tableId:             STRING, The ID of the table identified in the from clause of the table query.\n        \"\"\"\n        download_from_table_request = {\n            \"concreteType\": \"org.sagebionetworks.repo.model.table.DownloadFromTableRequest\",\n            \"csvTableDescriptor\": {\n                \"isFirstLineHeader\": header,\n                \"quoteCharacter\": quoteCharacter,\n                \"escapeCharacter\": escapeCharacter,\n                \"lineEnd\": lineEnd,\n                \"separator\": separator,\n            },\n            \"sql\": query,\n            \"writeHeader\": header,\n            \"includeRowIdAndRowVersion\": includeRowIdAndRowVersion,\n            \"includeEntityEtag\": True,\n        }\n\n        uri = \"/entity/{id}/table/download/csv/async\".format(\n            id=extract_synapse_id_from_query(query)\n        )\n        download_from_table_result = self._waitForAsync(\n            uri=uri, request=download_from_table_request\n        )\n        file_handle_id = download_from_table_result[\"resultsFileHandleId\"]\n        cached_file_path = self.cache.get(\n            file_handle_id=file_handle_id, path=downloadLocation\n        )\n        if cached_file_path is not None:\n            return download_from_table_result, cached_file_path\n\n        if downloadLocation:\n            download_dir = ensure_download_location_is_directory(\n                download_location=downloadLocation\n            )\n        else:\n            download_dir = self.cache.get_cache_dir(file_handle_id=file_handle_id)\n\n        os.makedirs(download_dir, exist_ok=True)\n        filename = f\"SYNAPSE_TABLE_QUERY_{file_handle_id}.csv\"\n        path = wrap_async_to_sync(\n            coroutine=download_by_file_handle(\n                file_handle_id=file_handle_id,\n                synapse_id=extract_synapse_id_from_query(query),\n                entity_type=\"TableEntity\",\n                destination=os.path.join(download_dir, filename),\n            ),\n            syn=self,\n        )\n\n        return download_from_table_result, path\n\n    # This is redundant with syn.store(Column(...)) and will be removed unless people prefer this method.\n    def createColumn(\n        self,\n        name,\n        columnType,\n        maximumSize=None,\n        defaultValue=None,\n        enumValues=None,\n    ):\n        columnModel = Column(\n            name=name,\n            columnType=columnType,\n            maximumSize=maximumSize,\n            defaultValue=defaultValue,\n            enumValue=enumValues,\n        )\n        return Column(**self.restPOST(\"/column\", json.dumps(columnModel)))\n\n    def createColumns(self, columns: typing.List[Column]) -&gt; typing.List[Column]:\n        \"\"\"\n        Creates a batch of [synapseclient.table.Column][]'s within a single request.\n\n        Arguments:\n            columns: A list of [synapseclient.table.Column][]'s\n\n        Returns:\n            A list of [synapseclient.table.Column][]'s that have been created in Synapse\n        \"\"\"\n        request_body = {\n            \"concreteType\": \"org.sagebionetworks.repo.model.ListWrapper\",\n            \"list\": list(columns),\n        }\n        response = self.restPOST(\"/column/batch\", json.dumps(request_body))\n        return [Column(**col) for col in response[\"list\"]]\n\n    def _getColumnByName(self, schema: Schema, column_name: str) -&gt; Column:\n        \"\"\"\n        Given a schema and a column name, get the corresponding [Column][synapseclient.table.Column] object.\n\n        Arguments:\n            schema: The Schema is an [Entity][synapseclient.entity.Entity] that defines a set of columns in a table.\n            column_name: The column name\n\n        Returns:\n            A Column object\n        \"\"\"\n        for column in self.getColumns(schema):\n            if column.name == column_name:\n                return column\n        return None\n\n    def downloadTableColumns(self, table, columns, downloadLocation=None, **kwargs):\n        \"\"\"\n        Bulk download of table-associated files.\n\n        Arguments:\n            table: Table query result\n            columns: A list of column names as strings\n            downloadLocation: Directory into which to download the files\n\n        Returns:\n            A dictionary from file handle ID to path in the local file system.\n\n        For example, consider a Synapse table whose ID is \"syn12345\" with two columns of type FILEHANDLEID named 'foo'\n        and 'bar'. The associated files are JSON encoded, so we might retrieve the files from Synapse and load for the\n        second 100 of those rows as shown here:\n\n            import json\n\n            results = syn.tableQuery('SELECT * FROM syn12345 LIMIT 100 OFFSET 100')\n            file_map = syn.downloadTableColumns(results, ['foo', 'bar'])\n\n            for file_handle_id, path in file_map.items():\n                with open(path) as f:\n                    data[file_handle_id] = f.read()\n\n        \"\"\"\n\n        RETRIABLE_FAILURE_CODES = [\"EXCEEDS_SIZE_LIMIT\"]\n        MAX_DOWNLOAD_TRIES = 100\n        max_files_per_request = kwargs.get(\"max_files_per_request\", 2500)\n        # Rowset tableQuery result not allowed\n        if isinstance(table, TableQueryResult):\n            raise ValueError(\n                \"downloadTableColumn doesn't work with rowsets. Please use default tableQuery settings.\"\n            )\n        if isinstance(columns, str):\n            columns = [columns]\n        if not isinstance(columns, collections.abc.Iterable):\n            raise TypeError(\"Columns parameter requires a list of column names\")\n\n        (\n            file_handle_associations,\n            file_handle_to_path_map,\n        ) = self._build_table_download_file_handle_list(\n            table,\n            columns,\n            downloadLocation,\n        )\n\n        self.logger.info(\n            \"Downloading %d files, %d cached locally\"\n            % (len(file_handle_associations), len(file_handle_to_path_map))\n        )\n\n        permanent_failures = collections.OrderedDict()\n\n        attempts = 0\n        while len(file_handle_associations) &gt; 0 and attempts &lt; MAX_DOWNLOAD_TRIES:\n            attempts += 1\n\n            file_handle_associations_batch = file_handle_associations[\n                :max_files_per_request\n            ]\n\n            # ------------------------------------------------------------\n            # call async service to build zip file\n            # ------------------------------------------------------------\n\n            # returns a BulkFileDownloadResponse:\n            #   &lt;https://rest-docs.synapse.org/rest/org/sagebionetworks/repo/model/file/BulkFileDownloadResponse.html&gt;\n            request = dict(\n                concreteType=\"org.sagebionetworks.repo.model.file.BulkFileDownloadRequest\",\n                requestedFiles=file_handle_associations_batch,\n            )\n            response = self._waitForAsync(\n                uri=\"/file/bulk/async\",\n                request=request,\n                endpoint=self.fileHandleEndpoint,\n            )\n\n            # ------------------------------------------------------------\n            # download zip file\n            # ------------------------------------------------------------\n\n            temp_dir = tempfile.mkdtemp()\n            zipfilepath = os.path.join(temp_dir, \"table_file_download.zip\")\n            try:\n                zipfilepath = wrap_async_to_sync(\n                    download_by_file_handle(\n                        file_handle_id=response[\"resultZipFileHandleId\"],\n                        synapse_id=table.tableId,\n                        entity_type=\"TableEntity\",\n                        destination=zipfilepath,\n                    ),\n                    syn=self,\n                )\n                # TODO handle case when no zip file is returned\n                # TODO test case when we give it partial or all bad file handles\n                # TODO test case with deleted fileHandleID\n                # TODO return null for permanent failures\n\n                # ------------------------------------------------------------\n                # unzip into cache\n                # ------------------------------------------------------------\n\n                if downloadLocation:\n                    download_dir = ensure_download_location_is_directory(\n                        downloadLocation\n                    )\n\n                with zipfile.ZipFile(zipfilepath) as zf:\n                    # the directory structure within the zip follows that of the cache:\n                    # {fileHandleId modulo 1000}/{fileHandleId}/{fileName}\n                    for summary in response[\"fileSummary\"]:\n                        if summary[\"status\"] == \"SUCCESS\":\n                            if not downloadLocation:\n                                download_dir = self.cache.get_cache_dir(\n                                    summary[\"fileHandleId\"]\n                                )\n\n                            filepath = extract_zip_file_to_directory(\n                                zf, summary[\"zipEntryName\"], download_dir\n                            )\n                            self.cache.add(summary[\"fileHandleId\"], filepath)\n                            file_handle_to_path_map[summary[\"fileHandleId\"]] = filepath\n                        elif summary[\"failureCode\"] not in RETRIABLE_FAILURE_CODES:\n                            permanent_failures[summary[\"fileHandleId\"]] = summary\n            finally:\n                if os.path.exists(zipfilepath):\n                    os.remove(zipfilepath)\n\n            # Do we have remaining files to download?\n            file_handle_associations = [\n                fha\n                for fha in file_handle_associations\n                if fha[\"fileHandleId\"] not in file_handle_to_path_map\n                and fha[\"fileHandleId\"] not in permanent_failures.keys()\n            ]\n\n        # TODO if there are files we still haven't downloaded\n\n        return file_handle_to_path_map\n\n    def _build_table_download_file_handle_list(self, table, columns, downloadLocation):\n        # ------------------------------------------------------------\n        # build list of file handles to download\n        # ------------------------------------------------------------\n        cols_not_found = [\n            c for c in columns if c not in [h.name for h in table.headers]\n        ]\n        if len(cols_not_found) &gt; 0:\n            raise ValueError(\n                \"Columns not found: \"\n                + \", \".join('\"' + col + '\"' for col in cols_not_found)\n            )\n        col_indices = [i for i, h in enumerate(table.headers) if h.name in columns]\n        # see: &lt;https://rest-docs.synapse.org/rest/org/sagebionetworks/repo/model/file/BulkFileDownloadRequest.html&gt;\n        file_handle_associations = []\n        file_handle_to_path_map = collections.OrderedDict()\n        seen_file_handle_ids = (\n            set()\n        )  # ensure not sending duplicate requests for the same FileHandle IDs\n        for row in table:\n            for col_index in col_indices:\n                file_handle_id = row[col_index]\n                if is_integer(file_handle_id):\n                    path_to_cached_file = self.cache.get(\n                        file_handle_id, path=downloadLocation\n                    )\n                    if path_to_cached_file:\n                        file_handle_to_path_map[file_handle_id] = path_to_cached_file\n                    elif file_handle_id not in seen_file_handle_ids:\n                        file_handle_associations.append(\n                            dict(\n                                associateObjectType=\"TableEntity\",\n                                fileHandleId=file_handle_id,\n                                associateObjectId=table.tableId,\n                            )\n                        )\n                    seen_file_handle_ids.add(file_handle_id)\n                else:\n                    warnings.warn(\"Weird file handle: %s\" % file_handle_id)\n        return file_handle_associations, file_handle_to_path_map\n\n    def _get_default_view_columns(self, view_type, view_type_mask=None):\n        \"\"\"Get default view columns\"\"\"\n        uri = f\"/column/tableview/defaults?viewEntityType={view_type}\"\n        if view_type_mask:\n            uri += f\"&amp;viewTypeMask={view_type_mask}\"\n        return [Column(**col) for col in self.restGET(uri)[\"list\"]]\n\n    def _get_annotation_view_columns(\n        self, scope_ids: list, view_type: str, view_type_mask: str = None\n    ) -&gt; list:\n        \"\"\"\n        Get all the columns of a submission of entity view based on existing annotations\n\n        Arguments:\n            scope_ids:      List of Evaluation Queue or Project/Folder Ids\n            view_type:      The submissionview or entityview\n            view_type_mask: Bit mask representing the types to include in the view.\n\n        Returns:\n            The list of columns\n        \"\"\"\n        columns = []\n        next_page_token = None\n        while True:\n            view_scope = {\n                \"concreteType\": \"org.sagebionetworks.repo.model.table.ViewColumnModelRequest\",\n                \"viewScope\": {\n                    \"scope\": scope_ids,\n                    \"viewEntityType\": view_type,\n                    \"viewTypeMask\": view_type_mask,\n                },\n            }\n            if next_page_token:\n                view_scope[\"nextPageToken\"] = next_page_token\n            response = self._waitForAsync(\n                uri=\"/column/view/scope/async\", request=view_scope\n            )\n            columns.extend(Column(**column) for column in response[\"results\"])\n            next_page_token = response.get(\"nextPageToken\")\n            if next_page_token is None:\n                break\n        return columns\n\n    ############################################################\n    #              CRUD for Entities (properties)              #\n    ############################################################\n\n    def _getEntity(\n        self, entity: Union[str, dict, Entity], version: int = None\n    ) -&gt; Dict[str, Union[str, bool]]:\n        \"\"\"\n        Get an entity from Synapse.\n\n        Arguments:\n            entity:  A Synapse ID, a dictionary representing an Entity, or a Synapse Entity object\n            version: The version number to fetch\n\n        Returns:\n            A dictionary containing an Entity's properties\n        \"\"\"\n\n        uri = \"/entity/\" + id_of(entity)\n        if version:\n            uri += \"/version/%d\" % version\n        return self.restGET(uri)\n\n    def _createEntity(self, entity: Union[dict, Entity]) -&gt; Dict[str, Union[str, bool]]:\n        \"\"\"\n        Create a new entity in Synapse.\n\n        Arguments:\n            entity: A dictionary representing an Entity or a Synapse Entity object\n\n        Returns:\n            A dictionary containing an Entity's properties\n        \"\"\"\n\n        return self.restPOST(uri=\"/entity\", body=json.dumps(get_properties(entity)))\n\n    def _updateEntity(\n        self,\n        entity: Union[dict, Entity],\n        incrementVersion: bool = True,\n        versionLabel: str = None,\n    ) -&gt; Dict[str, Union[str, bool]]:\n        \"\"\"\n        Update an existing entity in Synapse.\n\n        Arguments:\n            entity:           A dictionary representing an Entity or a Synapse Entity object\n            incrementVersion: Whether to increment the entity version (if Versionable)\n            versionLabel:     A label for the entity version (if Versionable)\n\n        Returns:\n            A dictionary containing an Entity's properties\n        \"\"\"\n\n        uri = \"/entity/%s\" % id_of(entity)\n\n        params = {}\n        if is_versionable(entity):\n            if versionLabel:\n                # a versionLabel implicitly implies incrementing\n                incrementVersion = True\n            elif incrementVersion and \"versionNumber\" in entity:\n                versionLabel = str(entity[\"versionNumber\"] + 1)\n\n            if incrementVersion:\n                entity[\"versionLabel\"] = versionLabel\n                params[\"newVersion\"] = \"true\"\n\n        return self.restPUT(uri, body=json.dumps(get_properties(entity)), params=params)\n\n    def findEntityId(self, name, parent=None):\n        \"\"\"\n        Find an Entity given its name and parent.\n\n        Arguments:\n            name: Name of the entity to find\n            parent: An Entity object or the Id of an entity as a string. Omit if searching for a Project by name\n\n        Returns:\n            The Entity ID or None if not found\n        \"\"\"\n        # when we want to search for a project by name. set parentId as None instead of ROOT_ENTITY\n        entity_lookup_request = {\n            \"parentId\": id_of(parent) if parent else None,\n            \"entityName\": name,\n        }\n        try:\n            return self.restPOST(\n                \"/entity/child\", body=json.dumps(entity_lookup_request)\n            ).get(\"id\")\n        except SynapseHTTPError as e:\n            if (\n                e.response.status_code == 404\n            ):  # a 404 error is raised if the entity does not exist\n                return None\n            raise\n\n    ############################################################\n    #                       Send Message                       #\n    ############################################################\n    def sendMessage(\n        self, userIds, messageSubject, messageBody, contentType=\"text/plain\"\n    ):\n        \"\"\"\n        send a message via Synapse.\n\n        Arguments:\n            userIds: A list of user IDs to which the message is to be sent\n            messageSubject: The subject for the message\n            messageBody: The body of the message\n            contentType: optional contentType of message body (default=\"text/plain\")\n                            Should be one of \"text/plain\" or \"text/html\"\n\n        Returns:\n            The metadata of the created message\n        \"\"\"\n\n        fileHandleId = wrap_async_to_sync(\n            multipart_upload_string_async(self, messageBody, content_type=contentType),\n            self,\n        )\n        message = dict(\n            recipients=userIds, subject=messageSubject, fileHandleId=fileHandleId\n        )\n        return self.restPOST(uri=\"/message\", body=json.dumps(message))\n\n    ############################################################\n    #                   Low level Rest calls                   #\n    ############################################################\n\n    def _generate_headers(self, headers: Dict[str, str] = None) -&gt; Dict[str, str]:\n        \"\"\"\n        Generate headers (auth headers produced separately by credentials object)\n\n        \"\"\"\n        if headers is None:\n            headers = dict(self.default_headers)\n        headers.update(synapseclient.USER_AGENT)\n\n        return headers\n\n    def _handle_synapse_http_error(self, response):\n        \"\"\"Raise errors as appropriate for returned Synapse http status codes\"\"\"\n\n        try:\n            exceptions._raise_for_status(response, verbose=self.debug)\n        except exceptions.SynapseHTTPError as ex:\n            # if we get a unauthenticated or forbidden error and the user is not logged in\n            # then we raise it as an authentication error.\n            # we can't know for certain that logging in to their particular account will grant them\n            # access to this resource but more than likely it's the cause of this error.\n            if response.status_code in (401, 403) and not self.credentials:\n                raise SynapseAuthenticationError(\n                    \"You are not logged in and do not have access to a requested resource.\"\n                ) from ex\n\n            raise\n\n    def _handle_httpx_synapse_http_error(self, response: httpx.Response) -&gt; None:\n        \"\"\"Raise errors as appropriate for the HTTPX library returned Synapse http\n        status codes\n\n        Arguments:\n            response: The HTTPX response object\n        \"\"\"\n\n        try:\n            exceptions._raise_for_status_httpx(\n                response=response, verbose=self.debug, logger=self.logger\n            )\n        except exceptions.SynapseHTTPError as ex:\n            # if we get a unauthenticated or forbidden error and the user is not logged in\n            # then we raise it as an authentication error.\n            # we can't know for certain that logging in to their particular account will grant them\n            # access to this resource but more than likely it's the cause of this error.\n            if response.status_code in (401, 403) and not self.credentials:\n                raise SynapseAuthenticationError(\n                    \"You are not logged in and do not have access to a requested resource.\"\n                ) from ex\n\n            raise\n\n    def _attach_rest_data_to_otel(\n        self,\n        method: str,\n        uri: str,\n        data: typing.Union[str, bytes],\n        current_span: trace.Span,\n    ) -&gt; None:\n        \"\"\"Handle attaching a few piece of data from the REST call into the OTEL span.\n        This is used for easier tracking of data that is being sent out of this service.\n\n        Arguments:\n            method: The HTTP method used in the REST call.\n            uri: The URI of the REST call.\n            data: The data being sent in the REST call.\n        \"\"\"\n        current_span.set_attributes({\"url\": uri, \"http.method\": method.upper()})\n        if current_span.is_recording() and data:\n            try:\n                if isinstance(data, str):\n                    data_to_parse = data\n                elif isinstance(data, bytes):\n                    data_to_parse = data.decode(\"utf-8\")\n                else:\n                    return\n                data_dict = json.loads(data_to_parse)\n                if \"parentId\" in data_dict:\n                    current_span.set_attribute(\n                        \"synapse.parent_id\", data_dict[\"parentId\"]\n                    )\n                if \"id\" in data_dict:\n                    current_span.set_attribute(\"synapse.id\", data_dict[\"id\"])\n                if \"concreteType\" in data_dict:\n                    current_span.set_attribute(\n                        \"synapse.concrete_type\", data_dict[\"concreteType\"]\n                    )\n                if \"entityName\" in data_dict:\n                    current_span.set_attribute(\n                        \"synapse.entity_name\", data_dict[\"entityName\"]\n                    )\n                elif \"name\" in data_dict:\n                    current_span.set_attribute(\"synapse.name\", data_dict[\"name\"])\n            except Exception as ex:\n                self.logger.debug(\n                    \"Failed to parse data for OTEL span in _rest_call\", ex\n                )\n\n    def _rest_call(\n        self,\n        method,\n        uri,\n        data,\n        endpoint,\n        headers,\n        retryPolicy,\n        requests_session,\n        **kwargs,\n    ):\n        \"\"\"\n        Sends an HTTP request to the Synapse server.\n\n        Arguments:\n            method:           The method to implement Create, Read, Update, Delete operations.\n                              Should be post, get, put, delete.\n            uri:              URI on which the method is performed\n            endpoint:         Server endpoint, defaults to self.repoEndpoint\n            headers:          Dictionary of headers to use rather than the API-key-signed default set of headers\n            retryPolicy:      A retry policy\n            requests_session: An external [requests.Session object](https://requests.readthedocs.io/en/latest/user/advanced/) to use when making this specific call\n            kwargs:           Any other arguments taken by a\n                              [request](http://docs.python-requests.org/en/latest/) method\n\n        Returns:\n            JSON encoding of response\n        \"\"\"\n        self.logger.debug(f\"Sending {method} request to {uri}\")\n        uri, headers = self._build_uri_and_headers(\n            uri, endpoint=endpoint, headers=headers\n        )\n\n        retryPolicy = self._build_retry_policy(retryPolicy)\n        requests_session = requests_session or self._requests_session\n\n        auth = kwargs.pop(\"auth\", self.credentials)\n        requests_method_fn = getattr(requests_session, method)\n        current_span = trace.get_current_span()\n        if current_span.is_recording():\n            current_span = tracer.start_span(\n                f\"{method.upper()} {uri}\", kind=SpanKind.CLIENT\n            )\n            self._attach_rest_data_to_otel(method, uri, data, current_span)\n        response = with_retry(\n            lambda: requests_method_fn(\n                uri,\n                data=data,\n                headers=headers,\n                auth=auth,\n                **kwargs,\n            ),\n            verbose=self.debug,\n            **retryPolicy,\n        )\n        if current_span.is_recording():\n            current_span.end()\n        self._handle_synapse_http_error(response)\n        return response\n\n    def restGET(\n        self,\n        uri,\n        endpoint=None,\n        headers=None,\n        retryPolicy={},\n        requests_session=None,\n        **kwargs,\n    ):\n        \"\"\"\n        Sends an HTTP GET request to the Synapse server.\n\n        Arguments:\n            uri: URI on which get is performed\n            endpoint: Server endpoint, defaults to self.repoEndpoint\n            headers: Dictionary of headers to use rather than the API-key-signed default set of headers\n            requests_session: An external [requests.Session object](https://requests.readthedocs.io/en/latest/user/advanced/) to use when making this specific call\n            kwargs: Any other arguments taken by a [request](http://docs.python-requests.org/en/latest/) method\n\n        Returns:\n            JSON encoding of response\n        \"\"\"\n        response = self._rest_call(\n            \"get\", uri, None, endpoint, headers, retryPolicy, requests_session, **kwargs\n        )\n        return self._return_rest_body(response)\n\n    def restPOST(\n        self,\n        uri,\n        body,\n        endpoint=None,\n        headers=None,\n        retryPolicy={},\n        requests_session=None,\n        **kwargs,\n    ):\n        \"\"\"\n        Sends an HTTP POST request to the Synapse server.\n\n        Arguments:\n            uri: URI on which get is performed\n            endpoint: Server endpoint, defaults to self.repoEndpoint\n            body: The payload to be delivered\n            headers: Dictionary of headers to use rather than the API-key-signed default set of headers\n            requests_session: An external [requests.Session object](https://requests.readthedocs.io/en/latest/user/advanced/) to use when making this specific call\n            kwargs: Any other arguments taken by a [request](http://docs.python-requests.org/en/latest/) method\n\n        Returns:\n            JSON encoding of response\n        \"\"\"\n        response = self._rest_call(\n            \"post\",\n            uri,\n            body,\n            endpoint,\n            headers,\n            retryPolicy,\n            requests_session,\n            **kwargs,\n        )\n        return self._return_rest_body(response)\n\n    def restPUT(\n        self,\n        uri,\n        body=None,\n        endpoint=None,\n        headers=None,\n        retryPolicy={},\n        requests_session=None,\n        **kwargs,\n    ):\n        \"\"\"\n        Sends an HTTP PUT request to the Synapse server.\n\n        Arguments:\n            uri: URI on which get is performed\n            endpoint: Server endpoint, defaults to self.repoEndpoint\n            body: The payload to be delivered\n            headers: Dictionary of headers to use rather than the API-key-signed default set of headers\n            requests_session: An external [requests.Session object](https://requests.readthedocs.io/en/latest/user/advanced/) to use when making this specific call\n            kwargs: Any other arguments taken by a [request](http://docs.python-requests.org/en/latest/) method\n\n        Returns\n            JSON encoding of response\n        \"\"\"\n        response = self._rest_call(\n            \"put\",\n            uri,\n            body,\n            endpoint,\n            headers,\n            retryPolicy,\n            requests_session,\n            **kwargs,\n        )\n        return self._return_rest_body(response)\n\n    def restDELETE(\n        self,\n        uri,\n        endpoint=None,\n        headers=None,\n        retryPolicy={},\n        requests_session=None,\n        **kwargs,\n    ):\n        \"\"\"\n        Sends an HTTP DELETE request to the Synapse server.\n\n        Arguments:\n            uri: URI of resource to be deleted\n            endpoint: Server endpoint, defaults to self.repoEndpoint\n            headers: Dictionary of headers to use rather than the API-key-signed default set of headers\n            requests_session: An external [requests.Session object](https://requests.readthedocs.io/en/latest/user/advanced/) to use when making this specific call\n            kwargs: Any other arguments taken by a [request](http://docs.python-requests.org/en/latest/) method\n\n        \"\"\"\n        self._rest_call(\n            \"delete\",\n            uri,\n            None,\n            endpoint,\n            headers,\n            retryPolicy,\n            requests_session,\n            **kwargs,\n        )\n\n    def _build_uri_and_headers(\n        self, uri: str, endpoint: str = None, headers: Dict[str, str] = None\n    ) -&gt; Tuple[str, Dict[str, str]]:\n        \"\"\"Returns a tuple of the URI and headers to request with.\"\"\"\n\n        if endpoint is None:\n            endpoint = self.repoEndpoint\n\n        trace.get_current_span().set_attributes({\"server.address\": endpoint})\n\n        # Check to see if the URI is incomplete (i.e. a Synapse URL)\n        # In that case, append a Synapse endpoint to the URI\n        parsedURL = urllib_urlparse.urlparse(uri)\n        if parsedURL.netloc == \"\":\n            uri = endpoint + uri\n\n        if headers is None:\n            headers = self._generate_headers()\n        return uri, headers\n\n    def _build_retry_policy(self, retryPolicy={}):\n        \"\"\"Returns a retry policy to be passed onto _with_retry.\"\"\"\n\n        defaults = dict(STANDARD_RETRY_PARAMS)\n        defaults.update(retryPolicy)\n        return defaults\n\n    def _build_retry_policy_async(\n        self, retry_policy: Dict[str, Any] = {}\n    ) -&gt; Dict[str, Any]:\n        \"\"\"Returns a retry policy to be passed onto with_retry_time_based_async.\"\"\"\n\n        defaults = dict(STANDARD_RETRY_ASYNC_PARAMS)\n        defaults.update(retry_policy)\n        return defaults\n\n    def _return_rest_body(self, response) -&gt; Union[Dict[str, Any], str]:\n        \"\"\"Returns either a dictionary or a string depending on the 'content-type' of the response.\"\"\"\n        trace.get_current_span().set_attributes(\n            {\"http.response.status_code\": response.status_code}\n        )\n        if is_json(response.headers.get(\"content-type\", None)):\n            return response.json()\n        return response.text\n\n    async def _rest_call_async(\n        self,\n        method: str,\n        uri: str,\n        data: Any,\n        endpoint: str,\n        headers: Dict[str, str],\n        retry_policy: Dict[str, Any],\n        requests_session_async_synapse: httpx.AsyncClient,\n        **kwargs,\n    ) -&gt; Union[httpx.Response, None]:\n        \"\"\"\n        Sends an HTTP request to the Synapse server.\n\n        Arguments:\n            method: The method to implement Create, Read, Update, Delete operations.\n                Should be post, get, put, delete.\n            uri: URI on which the method is performed.\n            data: The payload to be delivered.\n            endpoint: Server endpoint, defaults to self.repoEndpoint\n            headers: Dictionary of headers to use.\n            retry_policy: A retry policy that matches the arguments of\n                [synapseclient.core.retry.with_retry_time_based_async][].\n            requests_session_async_synapse: The async client to use when making this\n                specific call.\n            kwargs: Any other arguments taken by a\n                [request](https://www.python-httpx.org/api/) method\n\n        Returns:\n            JSON encoding of response\n        \"\"\"\n        uri, headers = self._build_uri_and_headers(\n            uri, endpoint=endpoint, headers=headers\n        )\n\n        retry_policy = self._build_retry_policy_async(retry_policy)\n        requests_session = (\n            requests_session_async_synapse\n            or self._get_requests_session_async_synapse(\n                asyncio_event_loop=asyncio.get_running_loop()\n            )\n        )\n\n        auth = kwargs.pop(\"auth\", self.credentials)\n        requests_method_fn = getattr(requests_session, method)\n        if data:\n            response = await with_retry_time_based_async(\n                lambda: requests_method_fn(\n                    uri,\n                    content=data,\n                    headers=headers,\n                    auth=auth,\n                    **kwargs,\n                ),\n                verbose=self.debug,\n                **retry_policy,\n            )\n        else:\n            response = await with_retry_time_based_async(\n                lambda: requests_method_fn(\n                    uri,\n                    headers=headers,\n                    auth=auth,\n                    **kwargs,\n                ),\n                verbose=self.debug,\n                **retry_policy,\n            )\n\n        self._handle_httpx_synapse_http_error(response)\n\n        return response\n\n    async def rest_get_async(\n        self,\n        uri: str,\n        endpoint: str = None,\n        headers: httpx.Headers = None,\n        retry_policy: Dict[str, Any] = {},\n        requests_session_async_synapse: httpx.AsyncClient = None,\n        **kwargs,\n    ) -&gt; Union[Dict[str, Any], str, None]:\n        \"\"\"\n        Sends an HTTP GET request to the Synapse server.\n\n        Arguments:\n            uri: URI on which get is performed\n            endpoint: Server endpoint, defaults to self.repoEndpoint\n            headers: Dictionary of headers to use.\n            retry_policy: A retry policy that matches the arguments of\n                [synapseclient.core.retry.with_retry_time_based_async][].\n            requests_session_async_synapse: The async client to use when making this\n                specific call.\n            kwargs: Any other arguments taken by a\n                [request](https://www.python-httpx.org/api/) method\n\n        Returns:\n            JSON encoding of response\n        \"\"\"\n        try:\n            response = await self._rest_call_async(\n                \"get\",\n                uri,\n                None,\n                endpoint,\n                headers,\n                retry_policy,\n                requests_session_async_synapse,\n                **kwargs,\n            )\n            return self._return_rest_body(response)\n        except Exception:\n            self.logger.exception(\"Error in rest_get_async\")\n\n    async def rest_post_async(\n        self,\n        uri: str,\n        body: Any = None,\n        endpoint: str = None,\n        headers: httpx.Headers = None,\n        retry_policy: Dict[str, Any] = {},\n        requests_session_async_synapse: httpx.AsyncClient = None,\n        **kwargs,\n    ) -&gt; Union[Dict[str, Any], str]:\n        \"\"\"\n        Sends an HTTP POST request to the Synapse server.\n\n        Arguments:\n            uri: URI on which get is performed\n            body: The payload to be delivered\n            endpoint: Server endpoint, defaults to self.repoEndpoint\n            headers: Dictionary of headers to use.\n            retry_policy: A retry policy that matches the arguments of\n                [synapseclient.core.retry.with_retry_time_based_async][].\n            requests_session_async_synapse: The async client to use when making this\n                specific call.\n            kwargs: Any other arguments taken by a\n                [request](https://www.python-httpx.org/api/) method\n\n        Returns:\n            JSON encoding of response\n        \"\"\"\n        response = await self._rest_call_async(\n            \"post\",\n            uri,\n            body,\n            endpoint,\n            headers,\n            retry_policy,\n            requests_session_async_synapse,\n            **kwargs,\n        )\n        return self._return_rest_body(response)\n\n    async def rest_put_async(\n        self,\n        uri: str,\n        body: Any = None,\n        endpoint: str = None,\n        headers: httpx.Headers = None,\n        retry_policy: Dict[str, Any] = {},\n        requests_session_async_synapse: httpx.AsyncClient = None,\n        **kwargs,\n    ) -&gt; Union[Dict[str, Any], str]:\n        \"\"\"\n        Sends an HTTP PUT request to the Synapse server.\n\n        Arguments:\n            uri: URI on which get is performed\n            body: The payload to be delivered.\n            endpoint: Server endpoint, defaults to self.repoEndpoint\n            headers: Dictionary of headers to use.\n            retry_policy: A retry policy that matches the arguments of\n                [synapseclient.core.retry.with_retry_time_based_async][].\n            requests_session_async_synapse: The async client to use when making this\n                specific call.\n            kwargs: Any other arguments taken by a\n                [request](https://www.python-httpx.org/api/) method\n\n        Returns\n            JSON encoding of response\n        \"\"\"\n        response = await self._rest_call_async(\n            \"put\",\n            uri,\n            body,\n            endpoint,\n            headers,\n            retry_policy,\n            requests_session_async_synapse,\n            **kwargs,\n        )\n        return self._return_rest_body(response)\n\n    async def rest_delete_async(\n        self,\n        uri: str,\n        endpoint: str = None,\n        headers: httpx.Headers = None,\n        retry_policy: Dict[str, Any] = {},\n        requests_session_async_synapse: httpx.AsyncClient = None,\n        **kwargs,\n    ) -&gt; None:\n        \"\"\"\n        Sends an HTTP DELETE request to the Synapse server.\n\n        Arguments:\n            uri: URI of resource to be deleted\n            endpoint: Server endpoint, defaults to self.repoEndpoint\n            headers: Dictionary of headers to use.\n            retry_policy: A retry policy that matches the arguments of\n                [synapseclient.core.retry.with_retry_time_based_async][].\n            requests_session_async_synapse: The async client to use when making this\n                specific call\n            kwargs: Any other arguments taken by a [request](https://www.python-httpx.org/api/) method\n\n        \"\"\"\n        await self._rest_call_async(\n            \"delete\",\n            uri,\n            None,\n            endpoint,\n            headers,\n            retry_policy,\n            requests_session_async_synapse,\n            **kwargs,\n        )\n</code></pre>"},{"location":"reference/client/#synapseclient.Synapse-functions","title":"Functions","text":""},{"location":"reference/client/#synapseclient.Synapse.login","title":"<code>login(email=None, silent=False, authToken=None, cache_client=True)</code>","text":"<p>Valid combinations of login() arguments:</p> <ul> <li>authToken</li> </ul> <p>If no login arguments are provided or only username is provided, login() will attempt to log in using  information from these sources (in order of preference):</p> <ol> <li>.synapseConfig file (in user home folder unless configured otherwise)</li> <li>User defined arguments during a CLI session</li> <li>User's Personal Access Token (aka: Synapse Auth Token)     from the environment variable: SYNAPSE_AUTH_TOKEN</li> <li>Retrieves user's authentication token from AWS SSM Parameter store (if configured)</li> </ol> PARAMETER DESCRIPTION <code>email</code> <p>Synapse user name (or an email address associated with a Synapse account)</p> <p> TYPE: <code>str</code> DEFAULT: <code>None</code> </p> <code>authToken</code> <p>A bearer authorization token, e.g. a personal access token.</p> <p> TYPE: <code>str</code> DEFAULT: <code>None</code> </p> <code>silent</code> <p>Defaults to False.  Suppresses the \"Welcome ...!\" message.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>cache_client</code> <p>Whether to cache the Synapse client object in the Synapse module. Defaults to True.              When set to True anywhere a <code>Synapse</code> object is optional you do not need to pass an              instance of <code>Synapse</code> to that function, method, or class.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> Logging in <p>Using an auth token:</p> <pre><code>syn.login(authToken=\"authtoken\")\n&gt; Welcome, Me!\n</code></pre> <p>Using an auth token and username. The username is optional but verified against the username in the auth token:</p> <pre><code>syn.login(email=\"my-username\", authToken=\"authtoken\")\n&gt; Welcome, Me!\n</code></pre> Source code in <code>synapseclient/client.py</code> <pre><code>def login(\n    self,\n    email: str = None,\n    silent: bool = False,\n    authToken: str = None,\n    cache_client: bool = True,\n) -&gt; None:\n    \"\"\"\n    Valid combinations of login() arguments:\n\n    - authToken\n\n    If no login arguments are provided or only username is provided, login() will attempt to log in using\n     information from these sources (in order of preference):\n\n    1. .synapseConfig file (in user home folder unless configured otherwise)\n    2. User defined arguments during a CLI session\n    3. User's Personal Access Token (aka: Synapse Auth Token)\n        from the environment variable: SYNAPSE_AUTH_TOKEN\n    4. Retrieves user's authentication token from AWS SSM Parameter store (if configured)\n\n    Arguments:\n        email:        Synapse user name (or an email address associated with a Synapse account)\n        authToken:    A bearer authorization token, e.g. a\n            [personal access token](https://python-docs.synapse.org/tutorials/authentication/).\n        silent:       Defaults to False.  Suppresses the \"Welcome ...!\" message.\n        cache_client: Whether to cache the Synapse client object in the Synapse module. Defaults to True.\n                         When set to True anywhere a `Synapse` object is optional you do not need to pass an\n                         instance of `Synapse` to that function, method, or class.\n\n    Example: Logging in\n        Using an auth token:\n\n            syn.login(authToken=\"authtoken\")\n            &gt; Welcome, Me!\n\n        Using an auth token and username. The username is optional but verified\n        against the username in the auth token:\n\n            syn.login(email=\"my-username\", authToken=\"authtoken\")\n            &gt; Welcome, Me!\n\n    \"\"\"\n    # Note: the order of the logic below reflects the ordering in the docstring above.\n\n    # Check version before logging in\n    if not self.skip_checks:\n        version_check()\n\n    # Make sure to invalidate the existing session\n    self.logout()\n\n    credential_provider_chain = get_default_credential_chain()\n\n    self.credentials = credential_provider_chain.get_credentials(\n        syn=self,\n        user_login_args=UserLoginArgs(\n            email,\n            authToken,\n        ),\n    )\n\n    # Final check on login success\n    if not self.credentials:\n        raise SynapseNoCredentialsError(\"No credentials provided.\")\n\n    if not silent:\n        profile = self.getUserProfile()\n        display_name = (\n            profile[\"displayName\"]\n            if \"displayName\" in profile\n            else self.credentials.username\n        )\n        self.logger.info(f\"Welcome, {display_name}!\\n\")\n\n    if cache_client:\n        Synapse.set_client(self)\n</code></pre>"},{"location":"reference/client/#synapseclient.Synapse.logout","title":"<code>logout()</code>","text":"<p>Removes authentication information from the Synapse client.</p> RETURNS DESCRIPTION <code>None</code> <p>None</p> Source code in <code>synapseclient/client.py</code> <pre><code>def logout(self) -&gt; None:\n    \"\"\"\n    Removes authentication information from the Synapse client.\n\n    Returns:\n        None\n    \"\"\"\n    self.credentials = None\n</code></pre>"},{"location":"reference/client/#synapseclient.Synapse.get","title":"<code>get(entity, **kwargs)</code>","text":"<p>Gets a Synapse entity from the repository service.</p> PARAMETER DESCRIPTION <code>entity</code> <p>A Synapse ID (e.g. syn123 or syn123.1, with .1 denoting version), a Synapse Entity object,               a plain dictionary in which 'id' maps to a Synapse ID or a local file that is stored in               Synapse (found by the file MD5)</p> <p> </p> <code>version</code> <p>The specific version to get.                 Defaults to the most recent version. If not denoted in the entity input.</p> <p> </p> <code>downloadFile</code> <p>Whether associated files(s) should be downloaded.                 Defaults to True.</p> <p> </p> <code>downloadLocation</code> <p>Directory where to download the Synapse File Entity.                 Defaults to the local cache.</p> <p> </p> <code>followLink</code> <p>Whether the link returns the target Entity.                 Defaults to False.</p> <p> </p> <code>ifcollision</code> <p>Determines how to handle file collisions.                 May be \"overwrite.local\", \"keep.local\", or \"keep.both\".                 Defaults to \"keep.both\".</p> <p> </p> <code>limitSearch</code> <p>A Synanpse ID used to limit the search in Synapse if entity is specified as a local                 file.  That is, if the file is stored in multiple locations in Synapse only the ones                 in the specified folder/project will be returned.</p> <p> </p> <code>md5</code> <p>The MD5 checksum for the file, if known. Otherwise if the file is a local file, it will be calculated automatically.</p> <p> </p> RETURNS DESCRIPTION <p>A new Synapse Entity object of the appropriate type.</p> Using this function <p>Download file into cache</p> <pre><code>entity = syn.get('syn1906479')\nprint(entity.name)\nprint(entity.path)\n</code></pre> <p>Download file into current working directory</p> <pre><code>entity = syn.get('syn1906479', downloadLocation='.')\nprint(entity.name)\nprint(entity.path)\n</code></pre> <p>Determine the provenance of a locally stored file as indicated in Synapse</p> <pre><code>entity = syn.get('/path/to/file.txt', limitSearch='syn12312')\nprint(syn.getProvenance(entity))\n</code></pre> Source code in <code>synapseclient/client.py</code> <pre><code>def get(self, entity, **kwargs):\n    \"\"\"\n    Gets a Synapse entity from the repository service.\n\n    Arguments:\n        entity:           A Synapse ID (e.g. syn123 or syn123.1, with .1 denoting version), a Synapse Entity object,\n                          a plain dictionary in which 'id' maps to a Synapse ID or a local file that is stored in\n                          Synapse (found by the file MD5)\n        version:          The specific version to get.\n                            Defaults to the most recent version. If not denoted in the entity input.\n        downloadFile:     Whether associated files(s) should be downloaded.\n                            Defaults to True.\n        downloadLocation: Directory where to download the Synapse File Entity.\n                            Defaults to the local cache.\n        followLink:       Whether the link returns the target Entity.\n                            Defaults to False.\n        ifcollision:      Determines how to handle file collisions.\n                            May be \"overwrite.local\", \"keep.local\", or \"keep.both\".\n                            Defaults to \"keep.both\".\n        limitSearch:      A Synanpse ID used to limit the search in Synapse if entity is specified as a local\n                            file.  That is, if the file is stored in multiple locations in Synapse only the ones\n                            in the specified folder/project will be returned.\n        md5: The MD5 checksum for the file, if known. Otherwise if the file is a\n            local file, it will be calculated automatically.\n\n    Returns:\n        A new Synapse Entity object of the appropriate type.\n\n    Example: Using this function\n        Download file into cache\n\n            entity = syn.get('syn1906479')\n            print(entity.name)\n            print(entity.path)\n\n        Download file into current working directory\n\n            entity = syn.get('syn1906479', downloadLocation='.')\n            print(entity.name)\n            print(entity.path)\n\n        Determine the provenance of a locally stored file as indicated in Synapse\n\n            entity = syn.get('/path/to/file.txt', limitSearch='syn12312')\n            print(syn.getProvenance(entity))\n    \"\"\"\n    # If entity is a local file determine the corresponding synapse entity\n    if isinstance(entity, str) and os.path.isfile(entity):\n        bundle = self._getFromFile(\n            entity, kwargs.pop(\"limitSearch\", None), md5=kwargs.get(\"md5\", None)\n        )\n        kwargs[\"downloadFile\"] = False\n        kwargs[\"path\"] = entity\n\n    elif isinstance(entity, str) and not utils.is_synapse_id_str(entity):\n        raise SynapseFileNotFoundError(\n            (\n                \"The parameter %s is neither a local file path \"\n                \" or a valid entity id\" % entity\n            )\n        )\n    # have not been saved entities\n    elif isinstance(entity, Entity) and not entity.get(\"id\"):\n        raise ValueError(\n            \"Cannot retrieve entity that has not been saved.\"\n            \" Please use syn.store() to save your entity and try again.\"\n        )\n    else:\n        input_version = kwargs.get(\"version\", None)\n        synid_and_version = utils.get_synid_and_version(entity)\n        version = (\n            input_version if input_version is not None else synid_and_version[1]\n        )\n        # If ``version`` is None, the arg will be ignored\n        bundle = self._getEntityBundle(synid_and_version[0], version)\n\n    # Check and warn for unmet access requirements\n    self._check_entity_restrictions(\n        bundle, entity, kwargs.get(\"downloadFile\", True)\n    )\n\n    return_data = self._getWithEntityBundle(\n        entityBundle=bundle, entity=entity, **kwargs\n    )\n    trace.get_current_span().set_attributes(\n        {\n            \"synapse.id\": return_data.get(\"id\", \"\"),\n            \"synapse.concrete_type\": return_data.get(\"concreteType\", \"\"),\n        }\n    )\n    return return_data\n</code></pre>"},{"location":"reference/client/#synapseclient.Synapse.store","title":"<code>store(obj, *, createOrUpdate=True, forceVersion=True, versionLabel=None, isRestricted=False, activity=None, used=None, executed=None, activityName=None, activityDescription=None, set_annotations=True)</code>","text":"<p>Creates a new Entity or updates an existing Entity, uploading any files in the process.</p> PARAMETER DESCRIPTION <code>obj</code> <p>A Synapse Entity, Evaluation, or Wiki</p> <p> </p> <code>used</code> <p>The Entity, Synapse ID, or URL used to create the object (can also be a list of these)</p> <p> DEFAULT: <code>None</code> </p> <code>executed</code> <p>The Entity, Synapse ID, or URL representing code executed to create the object         (can also be a list of these)</p> <p> DEFAULT: <code>None</code> </p> <code>activity</code> <p>Activity object specifying the user's provenance.</p> <p> DEFAULT: <code>None</code> </p> <code>activityName</code> <p>Activity name to be used in conjunction with used and executed.</p> <p> DEFAULT: <code>None</code> </p> <code>activityDescription</code> <p>Activity description to be used in conjunction with used and executed.</p> <p> DEFAULT: <code>None</code> </p> <code>createOrUpdate</code> <p>Indicates whether the method should automatically perform an update if the 'obj'             conflicts with an existing Synapse object.</p> <p> DEFAULT: <code>True</code> </p> <code>forceVersion</code> <p>Indicates whether the method should increment the version of the object even if nothing             has changed.</p> <p> DEFAULT: <code>True</code> </p> <code>versionLabel</code> <p>Arbitrary string used to label the version.</p> <p> DEFAULT: <code>None</code> </p> <code>isRestricted</code> <p>If set to true, an email will be sent to the Synapse access control team to start the             process of adding terms-of-use or review board approval for this entity.             You will be contacted with regards to the specific data being restricted and the             requirements of access.</p> <p> DEFAULT: <code>False</code> </p> <code>set_annotations</code> <p>If True, set the annotations on the entity. If False, do not set the annotations.</p> <p> DEFAULT: <code>True</code> </p> RETURNS DESCRIPTION <p>A Synapse Entity, Evaluation, or Wiki</p> Using this function <p>Creating a new Project:</p> <pre><code>from synapseclient import Project\n\nproject = Project('My uniquely named project')\nproject = syn.store(project)\n</code></pre> <p>Adding files with provenance (aka: Activity):</p> <pre><code>from synapseclient import File, Activity\n</code></pre> <p>A synapse entity syn1906480 contains data and an entity syn1917825 contains code</p> <pre><code>activity = Activity(\n    'Fancy Processing',\n    description='No seriously, really fancy processing',\n    used=['syn1906480', 'http://data_r_us.com/fancy/data.txt'],\n    executed='syn1917825')\n\ntest_entity = File('/path/to/data/file.xyz', description='Fancy new data', parent=project)\ntest_entity = syn.store(test_entity, activity=activity)\n</code></pre> Source code in <code>synapseclient/client.py</code> <pre><code>def store(\n    self,\n    obj,\n    *,\n    createOrUpdate=True,\n    forceVersion=True,\n    versionLabel=None,\n    isRestricted=False,\n    activity=None,\n    used=None,\n    executed=None,\n    activityName=None,\n    activityDescription=None,\n    set_annotations=True,\n):\n    \"\"\"\n    Creates a new Entity or updates an existing Entity, uploading any files in the process.\n\n    Arguments:\n        obj: A Synapse Entity, Evaluation, or Wiki\n        used: The Entity, Synapse ID, or URL used to create the object (can also be a list of these)\n        executed: The Entity, Synapse ID, or URL representing code executed to create the object\n                    (can also be a list of these)\n        activity: Activity object specifying the user's provenance.\n        activityName: Activity name to be used in conjunction with *used* and *executed*.\n        activityDescription: Activity description to be used in conjunction with *used* and *executed*.\n        createOrUpdate: Indicates whether the method should automatically perform an update if the 'obj'\n                        conflicts with an existing Synapse object.\n        forceVersion: Indicates whether the method should increment the version of the object even if nothing\n                        has changed.\n        versionLabel: Arbitrary string used to label the version.\n        isRestricted: If set to true, an email will be sent to the Synapse access control team to start the\n                        process of adding terms-of-use or review board approval for this entity.\n                        You will be contacted with regards to the specific data being restricted and the\n                        requirements of access.\n        set_annotations: If True, set the annotations on the entity. If False, do not set the annotations.\n\n    Returns:\n        A Synapse Entity, Evaluation, or Wiki\n\n    Example: Using this function\n        Creating a new Project:\n\n            from synapseclient import Project\n\n            project = Project('My uniquely named project')\n            project = syn.store(project)\n\n        Adding files with [provenance (aka: Activity)][synapseclient.Activity]:\n\n            from synapseclient import File, Activity\n\n        A synapse entity *syn1906480* contains data and an entity *syn1917825* contains code\n\n            activity = Activity(\n                'Fancy Processing',\n                description='No seriously, really fancy processing',\n                used=['syn1906480', 'http://data_r_us.com/fancy/data.txt'],\n                executed='syn1917825')\n\n            test_entity = File('/path/to/data/file.xyz', description='Fancy new data', parent=project)\n            test_entity = syn.store(test_entity, activity=activity)\n\n    \"\"\"\n    trace.get_current_span().set_attributes({\"thread.id\": threading.get_ident()})\n    # SYNPY-1031: activity must be Activity object or code will fail later\n    if activity:\n        if not isinstance(activity, synapseclient.Activity):\n            raise ValueError(\"activity should be synapseclient.Activity object\")\n    # _before_store hook\n    # give objects a chance to do something before being stored\n    if hasattr(obj, \"_before_synapse_store\"):\n        obj._before_synapse_store(self)\n\n    # _synapse_store hook\n    # for objects that know how to store themselves\n    if hasattr(obj, \"_synapse_store\"):\n        return obj._synapse_store(self)\n\n    # Handle all non-Entity objects\n    if not (isinstance(obj, Entity) or type(obj) == dict):\n        if isinstance(obj, Wiki):\n            return self._storeWiki(obj, createOrUpdate)\n\n        if \"id\" in obj:  # If ID is present, update\n            trace.get_current_span().set_attributes({\"synapse.id\": obj[\"id\"]})\n            return type(obj)(**self.restPUT(obj.putURI(), obj.json()))\n\n        try:  # If no ID is present, attempt to POST the object\n            trace.get_current_span().set_attributes({\"synapse.id\": \"\"})\n            return type(obj)(**self.restPOST(obj.postURI(), obj.json()))\n\n        except SynapseHTTPError as err:\n            # If already present and we want to update attempt to get the object content\n            if createOrUpdate and err.response.status_code == 409:\n                newObj = self.restGET(obj.getByNameURI(obj.name))\n                newObj.update(obj)\n                obj = type(obj)(**newObj)\n                trace.get_current_span().set_attributes({\"synapse.id\": obj[\"id\"]})\n                obj.update(self.restPUT(obj.putURI(), obj.json()))\n                return obj\n            raise\n\n    # If the input object is an Entity or a dictionary\n    entity = obj\n    properties, annotations, local_state = split_entity_namespaces(entity)\n    bundle = None\n    # Explicitly set an empty versionComment property if none is supplied,\n    # otherwise an existing entity bundle's versionComment will be copied to the update.\n    properties[\"versionComment\"] = (\n        properties[\"versionComment\"] if \"versionComment\" in properties else None\n    )\n\n    # Anything with a path is treated as a cache-able item\n    # Only Files are expected in the following logic\n    if entity.get(\"path\", False) and not isinstance(obj, Folder):\n        local_file_md5_hex = None\n        if \"concreteType\" not in properties:\n            properties[\"concreteType\"] = File._synapse_entity_type\n        # Make sure the path is fully resolved\n        entity[\"path\"] = os.path.expanduser(entity[\"path\"])\n\n        # Check if the File already exists in Synapse by fetching metadata on it\n        bundle = self._getEntityBundle(entity)\n\n        if bundle:\n            if createOrUpdate:\n                # update our properties from the existing bundle so that we have\n                # enough to process this as an entity update.\n                properties = {**bundle[\"entity\"], **properties}\n\n            # Check if the file should be uploaded\n            fileHandle = find_data_file_handle(bundle)\n            if (\n                fileHandle\n                and fileHandle[\"concreteType\"]\n                == \"org.sagebionetworks.repo.model.file.ExternalFileHandle\"\n            ):\n                # switching away from ExternalFileHandle or the url was updated\n                needs_upload = entity[\"synapseStore\"] or (\n                    fileHandle[\"externalURL\"] != entity[\"externalURL\"]\n                )\n            else:\n                synapse_store_flag = entity[\"synapseStore\"] or local_state.get(\n                    \"synapseStore\"\n                )\n                # Check if we need to upload a new version of an existing\n                # file. If the file referred to by entity['path'] has been\n                # modified, we want to upload the new version.\n                # If synapeStore is false then we must upload a ExternalFileHandle\n                needs_upload = not synapse_store_flag or not self.cache.contains(\n                    bundle[\"entity\"][\"dataFileHandleId\"], entity[\"path\"]\n                )\n\n                md5_stored_in_synapse = local_state.get(\"_file_handle\", {}).get(\n                    \"contentMd5\", None\n                ) or (fileHandle or {}).get(\"contentMd5\", None)\n\n                # Check if we got an MD5 checksum from Synapse and compare it to the local file\n                if (\n                    synapse_store_flag\n                    and needs_upload\n                    and os.path.isfile(entity[\"path\"])\n                    and md5_stored_in_synapse\n                    and md5_stored_in_synapse\n                    == (\n                        local_file_md5_hex := utils.md5_for_file(\n                            entity[\"path\"]\n                        ).hexdigest()\n                    )\n                ):\n                    needs_upload = False\n        elif entity.get(\"dataFileHandleId\", None) is not None:\n            needs_upload = False\n        else:\n            needs_upload = True\n\n        if needs_upload:\n            local_state_fh = local_state.get(\"_file_handle\", {})\n            synapseStore = local_state.get(\"synapseStore\", True)\n\n            # parent_id_for_upload is allowing `store` to be called on files that have\n            # already been stored to Synapse, but did not specify a parentId in the\n            # FileEntity. This is useful as it prevents the need to specify the\n            # parentId every time a file is stored to Synapse when the ID is\n            # already known.\n            parent_id_for_upload = entity.get(\"parentId\", None)\n            if not parent_id_for_upload and bundle and bundle.get(\"entity\", None):\n                parent_id_for_upload = bundle[\"entity\"][\"parentId\"]\n\n            if not parent_id_for_upload:\n                raise SynapseMalformedEntityError(\n                    \"Entities of type File must have a parentId.\"\n                )\n\n            fileHandle = wrap_async_to_sync(\n                upload_file_handle_async(\n                    self,\n                    parent_id_for_upload,\n                    local_state[\"path\"]\n                    if (synapseStore or local_state_fh.get(\"externalURL\") is None)\n                    else local_state_fh.get(\"externalURL\"),\n                    synapse_store=synapseStore,\n                    md5=local_file_md5_hex or local_state_fh.get(\"contentMd5\"),\n                    file_size=local_state_fh.get(\"contentSize\"),\n                    mimetype=local_state_fh.get(\"contentType\"),\n                ),\n                self,\n            )\n            properties[\"dataFileHandleId\"] = fileHandle[\"id\"]\n            local_state[\"_file_handle\"] = fileHandle\n\n        elif \"dataFileHandleId\" not in properties:\n            # Handle the case where the Entity lacks an ID\n            # But becomes an update() due to conflict\n            properties[\"dataFileHandleId\"] = bundle[\"entity\"][\"dataFileHandleId\"]\n\n        # update the file_handle metadata if the FileEntity's FileHandle id has changed\n        local_state_fh_id = local_state.get(\"_file_handle\", {}).get(\"id\")\n        if (\n            local_state_fh_id\n            and properties[\"dataFileHandleId\"] != local_state_fh_id\n        ):\n            local_state[\"_file_handle\"] = find_data_file_handle(\n                self._getEntityBundle(\n                    properties[\"id\"],\n                    requestedObjects={\n                        \"includeEntity\": True,\n                        \"includeFileHandles\": True,\n                    },\n                )\n            )\n\n            # check if we already have the filehandleid cached somewhere\n            cached_path = self.cache.get(properties[\"dataFileHandleId\"])\n            if cached_path is None:\n                local_state[\"path\"] = None\n                local_state[\"cacheDir\"] = None\n                local_state[\"files\"] = []\n            else:\n                local_state[\"path\"] = cached_path\n                local_state[\"cacheDir\"] = os.path.dirname(cached_path)\n                local_state[\"files\"] = [os.path.basename(cached_path)]\n\n    # Create or update Entity in Synapse\n    if \"id\" in properties:\n        trace.get_current_span().set_attributes({\"synapse.id\": properties[\"id\"]})\n        properties = self._updateEntity(properties, forceVersion, versionLabel)\n    else:\n        # If Link, get the target name, version number and concrete type and store in link properties\n        if properties[\"concreteType\"] == \"org.sagebionetworks.repo.model.Link\":\n            target_properties = self._getEntity(\n                properties[\"linksTo\"][\"targetId\"],\n                version=properties[\"linksTo\"].get(\"targetVersionNumber\"),\n            )\n            if target_properties[\"parentId\"] == properties[\"parentId\"]:\n                raise ValueError(\n                    \"Cannot create a Link to an entity under the same parent.\"\n                )\n            properties[\"linksToClassName\"] = target_properties[\"concreteType\"]\n            if (\n                target_properties.get(\"versionNumber\") is not None\n                and properties[\"linksTo\"].get(\"targetVersionNumber\") is not None\n            ):\n                properties[\"linksTo\"][\"targetVersionNumber\"] = target_properties[\n                    \"versionNumber\"\n                ]\n            properties[\"name\"] = target_properties[\"name\"]\n        try:\n            properties = self._createEntity(properties)\n        except SynapseHTTPError as ex:\n            if createOrUpdate and ex.response.status_code == 409:\n                # Get the existing Entity's ID via the name and parent\n                existing_entity_id = self.findEntityId(\n                    properties[\"name\"], properties.get(\"parentId\", None)\n                )\n                if existing_entity_id is None:\n                    raise\n\n                # get existing properties and annotations\n                if not bundle:\n                    bundle = self._getEntityBundle(\n                        existing_entity_id,\n                        requestedObjects={\n                            \"includeEntity\": True,\n                            \"includeAnnotations\": True,\n                        },\n                    )\n\n                properties = {**bundle[\"entity\"], **properties}\n\n                # we additionally merge the annotations under the assumption that a missing annotation\n                # from a resolved conflict represents an newer annotation that should be preserved\n                # rather than an intentionally deleted annotation.\n                annotations = {\n                    **from_synapse_annotations(bundle[\"annotations\"]),\n                    **annotations,\n                }\n\n                properties = self._updateEntity(\n                    properties, forceVersion, versionLabel\n                )\n\n            else:\n                raise\n\n    # Deal with access restrictions\n    if isRestricted:\n        self._createAccessRequirementIfNone(properties)\n\n    # Update annotations\n    if set_annotations and (\n        (not bundle and annotations)\n        or (\n            bundle and check_annotations_changed(bundle[\"annotations\"], annotations)\n        )\n    ):\n        annotations = self.set_annotations(\n            Annotations(properties[\"id\"], properties[\"etag\"], annotations)\n        )\n        properties[\"etag\"] = annotations.etag\n\n    # If the parameters 'used' or 'executed' are given, create an Activity object\n    if used or executed:\n        if activity is not None:\n            raise SynapseProvenanceError(\n                \"Provenance can be specified as an Activity object or as used/executed\"\n                \" item(s), but not both.\"\n            )\n        activity = Activity(\n            name=activityName,\n            description=activityDescription,\n            used=used,\n            executed=executed,\n        )\n\n    # If we have an Activity, set it as the Entity's provenance record\n    if activity:\n        self.setProvenance(properties, activity)\n\n        # 'etag' has changed, so get the new Entity\n        properties = self._getEntity(properties)\n\n    # Return the updated Entity object\n    entity = Entity.create(properties, annotations, local_state)\n    return_data = self.get(entity, downloadFile=False)\n\n    trace.get_current_span().set_attributes(\n        {\n            \"synapse.id\": return_data.get(\"id\", \"\"),\n            \"synapse.concrete_type\": entity.get(\"concreteType\", \"\"),\n        }\n    )\n    return return_data\n</code></pre>"},{"location":"reference/client/#synapseclient.Synapse.move","title":"<code>move(entity, new_parent)</code>","text":"<p>Move a Synapse entity to a new container.</p> PARAMETER DESCRIPTION <code>entity</code> <p>A Synapse ID, a Synapse Entity object, or a local file that is stored in Synapse</p> <p> </p> <code>new_parent</code> <p>The new parent container (Folder or Project) to which the entity should be moved.</p> <p> </p> RETURNS DESCRIPTION <p>The Synapse Entity object that has been moved.</p> Using this function <p>Move a Synapse Entity object to a new parent container</p> <pre><code>entity = syn.move('syn456', 'syn123')\n</code></pre> Source code in <code>synapseclient/client.py</code> <pre><code>def move(self, entity, new_parent):\n    \"\"\"\n    Move a Synapse entity to a new container.\n\n    Arguments:\n        entity:     A Synapse ID, a Synapse Entity object, or a local file that is stored in Synapse\n        new_parent: The new parent container (Folder or Project) to which the entity should be moved.\n\n    Returns:\n        The Synapse Entity object that has been moved.\n\n    Example: Using this function\n        Move a Synapse Entity object to a new parent container\n\n            entity = syn.move('syn456', 'syn123')\n    \"\"\"\n\n    entity = self.get(entity, downloadFile=False)\n    entity.parentId = id_of(new_parent)\n    entity = self.store(entity, forceVersion=False)\n    trace.get_current_span().set_attributes(\n        {\n            \"synapse.id\": entity.get(\"id\", \"\"),\n            \"synapse.parent_id\": entity.get(\"parentId\", \"\"),\n        }\n    )\n\n    return entity\n</code></pre>"},{"location":"reference/client/#synapseclient.Synapse.delete","title":"<code>delete(obj, version=None)</code>","text":"<p>Removes an object from Synapse.</p> PARAMETER DESCRIPTION <code>obj</code> <p>An existing object stored on Synapse such as Evaluation, File, Project, or Wiki</p> <p> </p> <code>version</code> <p>For entities, specify a particular version to delete.</p> <p> DEFAULT: <code>None</code> </p> Source code in <code>synapseclient/client.py</code> <pre><code>def delete(\n    self,\n    obj,\n    version=None,\n):\n    \"\"\"\n    Removes an object from Synapse.\n\n    Arguments:\n        obj: An existing object stored on Synapse such as Evaluation, File, Project, or Wiki\n        version: For entities, specify a particular version to delete.\n    \"\"\"\n    # Handle all strings as the Entity ID for backward compatibility\n    if isinstance(obj, str):\n        entity_id = id_of(obj)\n        trace.get_current_span().set_attributes({\"synapse.id\": entity_id})\n        if version:\n            self.restDELETE(uri=f\"/entity/{entity_id}/version/{version}\")\n        else:\n            self.restDELETE(uri=f\"/entity/{entity_id}\")\n    elif hasattr(obj, \"_synapse_delete\"):\n        return obj._synapse_delete(self)\n    else:\n        try:\n            if isinstance(obj, Versionable):\n                self.restDELETE(obj.deleteURI(versionNumber=version))\n            else:\n                self.restDELETE(obj.deleteURI())\n        except AttributeError:\n            raise SynapseError(\n                f\"Can't delete a {type(obj)}. Please specify a Synapse object or id\"\n            )\n</code></pre>"},{"location":"reference/client/#synapseclient.Synapse.get_annotations","title":"<code>get_annotations(entity, version=None)</code>","text":"<p>Retrieve annotations for an Entity from the Synapse Repository as a Python dict.</p> <p>Note that collapsing annotations from the native Synapse format to a Python dict may involve some loss of information. See <code>_getRawAnnotations</code> to get annotations in the native format.</p> PARAMETER DESCRIPTION <code>entity</code> <p>An Entity or Synapse ID to lookup</p> <p> TYPE: <code>Union[str, Entity]</code> </p> <code>version</code> <p>The version of the Entity to retrieve.</p> <p> TYPE: <code>Union[str, int]</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>Annotations</code> <p>A synapseclient.annotations.Annotations object, a dict that also has id and etag attributes</p> Source code in <code>synapseclient/client.py</code> <pre><code>def get_annotations(\n    self, entity: typing.Union[str, Entity], version: typing.Union[str, int] = None\n) -&gt; Annotations:\n    \"\"\"\n    Retrieve annotations for an Entity from the Synapse Repository as a Python dict.\n\n    Note that collapsing annotations from the native Synapse format to a Python dict may involve some loss of\n    information. See `_getRawAnnotations` to get annotations in the native format.\n\n    Arguments:\n        entity: An Entity or Synapse ID to lookup\n        version: The version of the Entity to retrieve.\n\n    Returns:\n        A [synapseclient.annotations.Annotations][] object, a dict that also has id and etag attributes\n    \"\"\"\n    return from_synapse_annotations(self._getRawAnnotations(entity, version))\n</code></pre>"},{"location":"reference/client/#synapseclient.Synapse.set_annotations","title":"<code>set_annotations(annotations)</code>","text":"<p>Store annotations for an Entity in the Synapse Repository.</p> PARAMETER DESCRIPTION <code>annotations</code> <p>A synapseclient.annotations.Annotations of annotation names and values,             with the id and etag attribute set</p> <p> TYPE: <code>Annotations</code> </p> RETURNS DESCRIPTION <p>The updated synapseclient.annotations.Annotations for the entity</p> Using this function <p>Getting annotations, adding a new annotation, and updating the annotations:</p> <pre><code>annos = syn.get_annotations('syn123')\n</code></pre> <p><code>annos</code> will contain the id and etag associated with the entity upon retrieval</p> <pre><code>print(annos.id)\n&gt; syn123\nprint(annos.etag)\n&gt; 7bdb83e9-a50a-46e4-987a-4962559f090f   (Usually some UUID in the form of a string)\n</code></pre> <p>Returned <code>annos</code> object from <code>get_annotations()</code> can be used as if it were a dict. Set key 'foo' to have value of 'bar' and 'baz'</p> <pre><code>annos['foo'] = ['bar', 'baz']\n</code></pre> <p>Single values will automatically be wrapped in a list once stored</p> <pre><code>annos['qwerty'] = 'asdf'\n</code></pre> <p>Store the annotations</p> <pre><code>annos = syn.set_annotations(annos)\n\nprint(annos)\n&gt; {'foo':['bar','baz], 'qwerty':['asdf']}\n</code></pre> Source code in <code>synapseclient/client.py</code> <pre><code>def set_annotations(self, annotations: Annotations):\n    \"\"\"\n    Store annotations for an Entity in the Synapse Repository.\n\n    Arguments:\n        annotations: A [synapseclient.annotations.Annotations][] of annotation names and values,\n                        with the id and etag attribute set\n\n    Returns:\n        The updated [synapseclient.annotations.Annotations][] for the entity\n\n    Example: Using this function\n        Getting annotations, adding a new annotation, and updating the annotations:\n\n            annos = syn.get_annotations('syn123')\n\n        `annos` will contain the id and etag associated with the entity upon retrieval\n\n            print(annos.id)\n            &gt; syn123\n            print(annos.etag)\n            &gt; 7bdb83e9-a50a-46e4-987a-4962559f090f   (Usually some UUID in the form of a string)\n\n        Returned `annos` object from `get_annotations()` can be used as if it were a dict.\n        Set key 'foo' to have value of 'bar' and 'baz'\n\n            annos['foo'] = ['bar', 'baz']\n\n        Single values will automatically be wrapped in a list once stored\n\n            annos['qwerty'] = 'asdf'\n\n        Store the annotations\n\n            annos = syn.set_annotations(annos)\n\n            print(annos)\n            &gt; {'foo':['bar','baz], 'qwerty':['asdf']}\n    \"\"\"\n\n    if not isinstance(annotations, Annotations):\n        raise TypeError(\"Expected a synapseclient.Annotations object\")\n\n    synapseAnnos = to_synapse_annotations(annotations)\n\n    entity_id = id_of(annotations)\n    trace.get_current_span().set_attributes({\"synapse.id\": entity_id})\n\n    return from_synapse_annotations(\n        self.restPUT(\n            f\"/entity/{entity_id}/annotations2\",\n            body=json.dumps(synapseAnnos),\n        )\n    )\n</code></pre>"},{"location":"reference/client/#synapseclient.Synapse.tableQuery","title":"<code>tableQuery(query, resultsAs='csv', **kwargs)</code>","text":"<p>Query a Synapse Table.</p> <p>You can receive query results either as a generator over rows or as a CSV file. For smallish tables, either method will work equally well. Use of a \"rowset\" generator allows rows to be processed one at a time and processing may be stopped before downloading the entire table.</p> <p>Optional keyword arguments differ for the two return types of <code>rowset</code> or <code>csv</code></p> PARAMETER DESCRIPTION <code>query</code> <p>Query string in a SQL-like syntax, for example: <code>\"SELECT * from syn12345\"</code></p> <p> TYPE: <code>str</code> </p> <code>resultsAs</code> <p>select whether results are returned as a CSV file (\"csv\") or incrementally downloaded as sets of rows (\"rowset\")</p> <p> TYPE: <code>str</code> DEFAULT: <code>'csv'</code> </p> <code>limit</code> <p>(rowset only) Specify the maximum number of rows to be returned, defaults to None</p> <p> </p> <code>offset</code> <p>(rowset only) Don't return the first n rows, defaults to None</p> <p> </p> <code>quoteCharacter</code> <p>(csv only) default double quote</p> <p> </p> <code>escapeCharacter</code> <p>(csv only) default backslash</p> <p> </p> <code>lineEnd</code> <p>(csv only) defaults to os.linesep</p> <p> </p> <code>separator</code> <p>(csv only) defaults to comma</p> <p> </p> <code>header</code> <p>(csv only) True by default</p> <p> </p> <code>includeRowIdAndRowVersion</code> <p>(csv only) True by default</p> <p> </p> <code>downloadLocation</code> <p>(csv only) directory path to download the CSV file to</p> <p> </p> RETURNS DESCRIPTION <p>A TableQueryResult or CsvFileTable object</p> NOTE <p>When performing queries on frequently updated tables, the table can be inaccessible for a period leading   to a timeout of the query.  Since the results are guaranteed to eventually be returned you can change the   max timeout by setting the table_query_timeout variable of the Synapse object:</p> <pre><code>  # Sets the max timeout to 5 minutes.\n  syn.table_query_timeout = 300\n</code></pre> Source code in <code>synapseclient/client.py</code> <pre><code>def tableQuery(self, query: str, resultsAs: str = \"csv\", **kwargs):\n    \"\"\"\n    Query a Synapse Table.\n\n    You can receive query results either as a generator over rows or as a CSV file. For smallish tables, either\n    method will work equally well. Use of a \"rowset\" generator allows rows to be processed one at a time and\n    processing may be stopped before downloading the entire table.\n\n    Optional keyword arguments differ for the two return types of `rowset` or `csv`\n\n    Arguments:\n        query: Query string in a [SQL-like syntax](https://rest-docs.synapse.org/rest/org/sagebionetworks/repo/web/controller/TableExamples.html), for example: `\"SELECT * from syn12345\"`\n        resultsAs: select whether results are returned as a CSV file (\"csv\") or incrementally downloaded as sets of rows (\"rowset\")\n        limit: (rowset only) Specify the maximum number of rows to be returned, defaults to None\n        offset: (rowset only) Don't return the first n rows, defaults to None\n        quoteCharacter: (csv only) default double quote\n        escapeCharacter: (csv only) default backslash\n        lineEnd: (csv only) defaults to os.linesep\n        separator: (csv only) defaults to comma\n        header: (csv only) True by default\n        includeRowIdAndRowVersion: (csv only) True by default\n        downloadLocation: (csv only) directory path to download the CSV file to\n\n    Returns:\n        A [TableQueryResult][synapseclient.table.TableQueryResult] or [CsvFileTable][synapseclient.table.CsvFileTable] object\n\n    NOTE:\n        When performing queries on frequently updated tables, the table can be inaccessible for a period leading\n          to a timeout of the query.  Since the results are guaranteed to eventually be returned you can change the\n          max timeout by setting the table_query_timeout variable of the Synapse object:\n\n              # Sets the max timeout to 5 minutes.\n              syn.table_query_timeout = 300\n\n    \"\"\"\n    if resultsAs.lower() == \"rowset\":\n        return TableQueryResult(self, query, **kwargs)\n    elif resultsAs.lower() == \"csv\":\n        # TODO: remove isConsistent because it has now been deprecated\n        # from the backend\n        if kwargs.get(\"isConsistent\") is not None:\n            kwargs.pop(\"isConsistent\")\n        return CsvFileTable.from_table_query(self, query, **kwargs)\n    else:\n        raise ValueError(\n            \"Unknown return type requested from tableQuery: \" + str(resultsAs)\n        )\n</code></pre>"},{"location":"reference/client/#synapseclient.Synapse.createColumns","title":"<code>createColumns(columns)</code>","text":"<p>Creates a batch of synapseclient.table.Column's within a single request.</p> PARAMETER DESCRIPTION <code>columns</code> <p>A list of synapseclient.table.Column's</p> <p> TYPE: <code>List[Column]</code> </p> RETURNS DESCRIPTION <code>List[Column]</code> <p>A list of synapseclient.table.Column's that have been created in Synapse</p> Source code in <code>synapseclient/client.py</code> <pre><code>def createColumns(self, columns: typing.List[Column]) -&gt; typing.List[Column]:\n    \"\"\"\n    Creates a batch of [synapseclient.table.Column][]'s within a single request.\n\n    Arguments:\n        columns: A list of [synapseclient.table.Column][]'s\n\n    Returns:\n        A list of [synapseclient.table.Column][]'s that have been created in Synapse\n    \"\"\"\n    request_body = {\n        \"concreteType\": \"org.sagebionetworks.repo.model.ListWrapper\",\n        \"list\": list(columns),\n    }\n    response = self.restPOST(\"/column/batch\", json.dumps(request_body))\n    return [Column(**col) for col in response[\"list\"]]\n</code></pre>"},{"location":"reference/client/#synapseclient.Synapse.getColumn","title":"<code>getColumn(id)</code>","text":"<p>Gets a Column object from Synapse by ID.</p> <p>See: synapseclient.table.Column</p> PARAMETER DESCRIPTION <code>id</code> <p>The ID of the column to retrieve</p> <p> </p> RETURNS DESCRIPTION <p>An object of type synapseclient.table.Column</p> Using this function <p>Getting a column</p> <pre><code>column = syn.getColumn(123)\n</code></pre> Source code in <code>synapseclient/client.py</code> <pre><code>def getColumn(self, id):\n    \"\"\"\n    Gets a Column object from Synapse by ID.\n\n    See: [synapseclient.table.Column][]\n\n    Arguments:\n        id: The ID of the column to retrieve\n\n    Returns:\n        An object of type [synapseclient.table.Column][]\n\n\n    Example: Using this function\n        Getting a column\n\n            column = syn.getColumn(123)\n    \"\"\"\n    return Column(**self.restGET(Column.getURI(id)))\n</code></pre>"},{"location":"reference/client/#synapseclient.Synapse.getColumns","title":"<code>getColumns(x, limit=100, offset=0)</code>","text":"<p>Get the columns defined in Synapse either (1) corresponding to a set of column headers, (2) those for a given schema, or (3) those whose names start with a given prefix.</p> PARAMETER DESCRIPTION <code>x</code> <p>A list of column headers, a Table Entity object (Schema/EntityViewSchema), a Table's Synapse ID, or a string prefix</p> <p> </p> <code>limit</code> <p>maximum number of columns to return (pagination parameter)</p> <p> DEFAULT: <code>100</code> </p> <code>offset</code> <p>the index of the first column to return (pagination parameter)</p> <p> DEFAULT: <code>0</code> </p> YIELDS DESCRIPTION <p>A generator over synapseclient.table.Column objects</p> Source code in <code>synapseclient/client.py</code> <pre><code>def getColumns(self, x, limit=100, offset=0):\n    \"\"\"\n    Get the columns defined in Synapse either (1) corresponding to a set of column headers, (2) those for a given\n    schema, or (3) those whose names start with a given prefix.\n\n    Arguments:\n        x: A list of column headers, a Table Entity object (Schema/EntityViewSchema), a Table's Synapse ID, or a\n            string prefix\n        limit: maximum number of columns to return (pagination parameter)\n        offset: the index of the first column to return (pagination parameter)\n\n    Yields:\n        A generator over [synapseclient.table.Column][] objects\n    \"\"\"\n    if x is None:\n        uri = \"/column\"\n        for result in self._GET_paginated(uri, limit=limit, offset=offset):\n            yield Column(**result)\n    elif isinstance(x, (list, tuple)):\n        for header in x:\n            try:\n                # if header is an integer, it's a columnID, otherwise it's an aggregate column, like \"AVG(Foo)\"\n                int(header)\n                yield self.getColumn(header)\n            except ValueError:\n                # ignore aggregate column\n                pass\n    elif isinstance(x, SchemaBase) or utils.is_synapse_id_str(x):\n        for col in self.getTableColumns(x):\n            yield col\n    elif isinstance(x, str):\n        uri = \"/column?prefix=\" + x\n        for result in self._GET_paginated(uri, limit=limit, offset=offset):\n            yield Column(**result)\n    else:\n        ValueError(\"Can't get columns for a %s\" % type(x))\n</code></pre>"},{"location":"reference/client/#synapseclient.Synapse.getTableColumns","title":"<code>getTableColumns(table)</code>","text":"<p>Retrieve the column models used in the given table schema.</p> PARAMETER DESCRIPTION <code>table</code> <p>The schema of the Table whose columns are to be retrieved</p> <p> </p> YIELDS DESCRIPTION <p>A Generator over the Table's columns</p> Source code in <code>synapseclient/client.py</code> <pre><code>def getTableColumns(self, table):\n    \"\"\"\n    Retrieve the column models used in the given table schema.\n\n    Arguments:\n        table: The schema of the Table whose columns are to be retrieved\n\n    Yields:\n        A Generator over the Table's [columns][synapseclient.table.Column]\n    \"\"\"\n    uri = \"/entity/{id}/column\".format(id=id_of(table))\n    # The returned object type for this service, PaginatedColumnModels, is a misnomer.\n    # This service always returns the full list of results so the pagination does not not actually matter.\n    for result in self.restGET(uri)[\"results\"]:\n        yield Column(**result)\n</code></pre>"},{"location":"reference/client/#synapseclient.Synapse.downloadTableColumns","title":"<code>downloadTableColumns(table, columns, downloadLocation=None, **kwargs)</code>","text":"<p>Bulk download of table-associated files.</p> PARAMETER DESCRIPTION <code>table</code> <p>Table query result</p> <p> </p> <code>columns</code> <p>A list of column names as strings</p> <p> </p> <code>downloadLocation</code> <p>Directory into which to download the files</p> <p> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <p>A dictionary from file handle ID to path in the local file system.</p> <p>For example, consider a Synapse table whose ID is \"syn12345\" with two columns of type FILEHANDLEID named 'foo' and 'bar'. The associated files are JSON encoded, so we might retrieve the files from Synapse and load for the second 100 of those rows as shown here:</p> <pre><code>import json\n\nresults = syn.tableQuery('SELECT * FROM syn12345 LIMIT 100 OFFSET 100')\nfile_map = syn.downloadTableColumns(results, ['foo', 'bar'])\n\nfor file_handle_id, path in file_map.items():\n    with open(path) as f:\n        data[file_handle_id] = f.read()\n</code></pre> Source code in <code>synapseclient/client.py</code> <pre><code>def downloadTableColumns(self, table, columns, downloadLocation=None, **kwargs):\n    \"\"\"\n    Bulk download of table-associated files.\n\n    Arguments:\n        table: Table query result\n        columns: A list of column names as strings\n        downloadLocation: Directory into which to download the files\n\n    Returns:\n        A dictionary from file handle ID to path in the local file system.\n\n    For example, consider a Synapse table whose ID is \"syn12345\" with two columns of type FILEHANDLEID named 'foo'\n    and 'bar'. The associated files are JSON encoded, so we might retrieve the files from Synapse and load for the\n    second 100 of those rows as shown here:\n\n        import json\n\n        results = syn.tableQuery('SELECT * FROM syn12345 LIMIT 100 OFFSET 100')\n        file_map = syn.downloadTableColumns(results, ['foo', 'bar'])\n\n        for file_handle_id, path in file_map.items():\n            with open(path) as f:\n                data[file_handle_id] = f.read()\n\n    \"\"\"\n\n    RETRIABLE_FAILURE_CODES = [\"EXCEEDS_SIZE_LIMIT\"]\n    MAX_DOWNLOAD_TRIES = 100\n    max_files_per_request = kwargs.get(\"max_files_per_request\", 2500)\n    # Rowset tableQuery result not allowed\n    if isinstance(table, TableQueryResult):\n        raise ValueError(\n            \"downloadTableColumn doesn't work with rowsets. Please use default tableQuery settings.\"\n        )\n    if isinstance(columns, str):\n        columns = [columns]\n    if not isinstance(columns, collections.abc.Iterable):\n        raise TypeError(\"Columns parameter requires a list of column names\")\n\n    (\n        file_handle_associations,\n        file_handle_to_path_map,\n    ) = self._build_table_download_file_handle_list(\n        table,\n        columns,\n        downloadLocation,\n    )\n\n    self.logger.info(\n        \"Downloading %d files, %d cached locally\"\n        % (len(file_handle_associations), len(file_handle_to_path_map))\n    )\n\n    permanent_failures = collections.OrderedDict()\n\n    attempts = 0\n    while len(file_handle_associations) &gt; 0 and attempts &lt; MAX_DOWNLOAD_TRIES:\n        attempts += 1\n\n        file_handle_associations_batch = file_handle_associations[\n            :max_files_per_request\n        ]\n\n        # ------------------------------------------------------------\n        # call async service to build zip file\n        # ------------------------------------------------------------\n\n        # returns a BulkFileDownloadResponse:\n        #   &lt;https://rest-docs.synapse.org/rest/org/sagebionetworks/repo/model/file/BulkFileDownloadResponse.html&gt;\n        request = dict(\n            concreteType=\"org.sagebionetworks.repo.model.file.BulkFileDownloadRequest\",\n            requestedFiles=file_handle_associations_batch,\n        )\n        response = self._waitForAsync(\n            uri=\"/file/bulk/async\",\n            request=request,\n            endpoint=self.fileHandleEndpoint,\n        )\n\n        # ------------------------------------------------------------\n        # download zip file\n        # ------------------------------------------------------------\n\n        temp_dir = tempfile.mkdtemp()\n        zipfilepath = os.path.join(temp_dir, \"table_file_download.zip\")\n        try:\n            zipfilepath = wrap_async_to_sync(\n                download_by_file_handle(\n                    file_handle_id=response[\"resultZipFileHandleId\"],\n                    synapse_id=table.tableId,\n                    entity_type=\"TableEntity\",\n                    destination=zipfilepath,\n                ),\n                syn=self,\n            )\n            # TODO handle case when no zip file is returned\n            # TODO test case when we give it partial or all bad file handles\n            # TODO test case with deleted fileHandleID\n            # TODO return null for permanent failures\n\n            # ------------------------------------------------------------\n            # unzip into cache\n            # ------------------------------------------------------------\n\n            if downloadLocation:\n                download_dir = ensure_download_location_is_directory(\n                    downloadLocation\n                )\n\n            with zipfile.ZipFile(zipfilepath) as zf:\n                # the directory structure within the zip follows that of the cache:\n                # {fileHandleId modulo 1000}/{fileHandleId}/{fileName}\n                for summary in response[\"fileSummary\"]:\n                    if summary[\"status\"] == \"SUCCESS\":\n                        if not downloadLocation:\n                            download_dir = self.cache.get_cache_dir(\n                                summary[\"fileHandleId\"]\n                            )\n\n                        filepath = extract_zip_file_to_directory(\n                            zf, summary[\"zipEntryName\"], download_dir\n                        )\n                        self.cache.add(summary[\"fileHandleId\"], filepath)\n                        file_handle_to_path_map[summary[\"fileHandleId\"]] = filepath\n                    elif summary[\"failureCode\"] not in RETRIABLE_FAILURE_CODES:\n                        permanent_failures[summary[\"fileHandleId\"]] = summary\n        finally:\n            if os.path.exists(zipfilepath):\n                os.remove(zipfilepath)\n\n        # Do we have remaining files to download?\n        file_handle_associations = [\n            fha\n            for fha in file_handle_associations\n            if fha[\"fileHandleId\"] not in file_handle_to_path_map\n            and fha[\"fileHandleId\"] not in permanent_failures.keys()\n        ]\n\n    # TODO if there are files we still haven't downloaded\n\n    return file_handle_to_path_map\n</code></pre>"},{"location":"reference/client/#synapseclient.Synapse.get_acl","title":"<code>get_acl(entity, principal_id=None)</code>","text":"<p>Get the ACL that a user or group has on an Entity.</p> PARAMETER DESCRIPTION <code>entity</code> <p>An Entity or Synapse ID to lookup</p> <p> TYPE: <code>Union[Entity, Evaluation, str, Mapping]</code> </p> <code>principal_id</code> <p>Identifier of a user or group (defaults to PUBLIC users)</p> <p> TYPE: <code>str</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>List[str]</code> <p>An array containing some combination of ['READ', 'UPDATE', 'CREATE', 'DELETE', 'DOWNLOAD', 'MODERATE', 'CHANGE_PERMISSIONS', 'CHANGE_SETTINGS'] or an empty array</p> Source code in <code>synapseclient/client.py</code> <pre><code>def get_acl(\n    self,\n    entity: Union[Entity, Evaluation, str, collections.abc.Mapping],\n    principal_id: str = None,\n) -&gt; typing.List[str]:\n    \"\"\"\n    Get the [ACL](https://rest-docs.synapse.org/rest/org/\n    sagebionetworks/repo/model/ACCESS_TYPE.html)\n    that a user or group has on an Entity.\n\n    Arguments:\n        entity:      An Entity or Synapse ID to lookup\n        principal_id: Identifier of a user or group (defaults to PUBLIC users)\n\n    Returns:\n        An array containing some combination of\n            ['READ', 'UPDATE', 'CREATE', 'DELETE', 'DOWNLOAD', 'MODERATE',\n            'CHANGE_PERMISSIONS', 'CHANGE_SETTINGS']\n            or an empty array\n    \"\"\"\n\n    principal_id = self._getUserbyPrincipalIdOrName(principal_id)\n\n    trace.get_current_span().set_attributes(\n        {\"synapse.id\": id_of(entity), \"synapse.principal_id\": principal_id}\n    )\n\n    acl = self._getACL(entity)\n\n    team_list = self._find_teams_for_principal(principal_id)\n    team_ids = [int(team.id) for team in team_list]\n    effective_permission_set = set()\n\n    # This user_profile_bundle is being used to verify that the principal_id\n    #  is a registered user of the system\n    user_profile_bundle = self._get_user_bundle(principal_id, 1)\n\n    # Loop over all permissions in the returned ACL and add it to the effective_permission_set\n    # if the principalId in the ACL matches\n    # 1) the one we are looking for,\n    # 2) a team the entity is a member of,\n    # 3) PUBLIC\n    # 4) A user_profile_bundle exists for the principal_id\n    for permissions in acl[\"resourceAccess\"]:\n        if \"principalId\" in permissions and (\n            permissions[\"principalId\"] == principal_id\n            or permissions[\"principalId\"] in team_ids\n            or permissions[\"principalId\"] == PUBLIC\n            or (\n                permissions[\"principalId\"] == AUTHENTICATED_USERS\n                and user_profile_bundle is not None\n            )\n        ):\n            effective_permission_set = effective_permission_set.union(\n                permissions[\"accessType\"]\n            )\n    return list(effective_permission_set)\n</code></pre>"},{"location":"reference/client/#synapseclient.Synapse.get_permissions","title":"<code>get_permissions(entity)</code>","text":"<p>Get the permissions that the caller has on an Entity.</p> PARAMETER DESCRIPTION <code>entity</code> <p>An Entity or Synapse ID to lookup</p> <p> TYPE: <code>Union[Entity, Evaluation, str, Mapping]</code> </p> RETURNS DESCRIPTION <code>Permissions</code> <p>An Permissions object</p> Using this function: <p>Getting permissions for a Synapse Entity</p> <pre><code>permissions = syn.get_permissions(Entity)\n</code></pre> <p>Getting permissions for a Synapse ID</p> <pre><code>permissions = syn.get_permissions(\"syn12345\")\n</code></pre> <p>Getting access types list from the Permissions object</p> <pre><code>permissions.access_types\n</code></pre> Source code in <code>synapseclient/client.py</code> <pre><code>def get_permissions(\n    self, entity: Union[Entity, Evaluation, str, collections.abc.Mapping]\n) -&gt; Permissions:\n    \"\"\"\n    Get the [permissions](https://rest-docs.synapse.org/rest/org/\n    sagebionetworks/repo/model/auth/UserEntityPermissions.html)\n    that the caller has on an Entity.\n\n    Arguments:\n        entity: An Entity or Synapse ID to lookup\n\n    Returns:\n        An Permissions object\n\n\n    Example: Using this function:\n        Getting permissions for a Synapse Entity\n\n            permissions = syn.get_permissions(Entity)\n\n        Getting permissions for a Synapse ID\n\n            permissions = syn.get_permissions(\"syn12345\")\n\n        Getting access types list from the Permissions object\n\n            permissions.access_types\n    \"\"\"\n\n    entity_id = id_of(entity)\n\n    trace.get_current_span().set_attributes({\"synapse.id\": entity_id})\n\n    url = f\"/entity/{entity_id}/permissions\"\n    data = self.restGET(url)\n    return Permissions.from_dict(data)\n</code></pre>"},{"location":"reference/client/#synapseclient.Synapse.getPermissions","title":"<code>getPermissions(entity, principal_id=None)</code>","text":"<p>Deprecated and replaced with get_acl.</p> <p>Get the permissions that a user or group has on an Entity.</p> PARAMETER DESCRIPTION <code>entity</code> <p>An Entity or Synapse ID to lookup</p> <p> TYPE: <code>Union[Entity, Evaluation, str, Mapping]</code> </p> <code>principal_id</code> <p>Identifier of a user or group (defaults to PUBLIC users)</p> <p> TYPE: <code>str</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>List[str]</code> <p>An array containing some combination of ['READ', 'UPDATE', 'CREATE', 'DELETE', 'DOWNLOAD', 'MODERATE', 'CHANGE_PERMISSIONS', 'CHANGE_SETTINGS'] or an empty array</p> Source code in <code>synapseclient/client.py</code> <pre><code>@deprecated(\n    version=\"4.0.0\",\n    reason=\"deprecated and replaced with synapseclient.Synapse.get_acl\",\n)\ndef getPermissions(\n    self,\n    entity: Union[Entity, Evaluation, str, collections.abc.Mapping],\n    principal_id: str = None,\n) -&gt; typing.List[str]:\n    \"\"\"\n    **Deprecated** and replaced with [get_acl][synapseclient.Synapse.get_acl].\n\n\n    Get the permissions that a user or group has on an Entity.\n\n    Arguments:\n        entity:      An Entity or Synapse ID to lookup\n        principal_id: Identifier of a user or group (defaults to PUBLIC users)\n\n    Returns:\n        An array containing some combination of\n            ['READ', 'UPDATE', 'CREATE', 'DELETE', 'DOWNLOAD', 'MODERATE',\n            'CHANGE_PERMISSIONS', 'CHANGE_SETTINGS']\n            or an empty array\n    \"\"\"\n\n    return self.get_acl(entity=entity, principal_id=principal_id)\n</code></pre>"},{"location":"reference/client/#synapseclient.Synapse.setPermissions","title":"<code>setPermissions(entity, principalId=None, accessType=['READ', 'DOWNLOAD'], modify_benefactor=False, warn_if_inherits=True, overwrite=True)</code>","text":"<p>Sets permission that a user or group has on an Entity. An Entity may have its own ACL or inherit its ACL from a benefactor.</p> PARAMETER DESCRIPTION <code>entity</code> <p>An Entity or Synapse ID to modify</p> <p> </p> <code>principalId</code> <p>Identifier of a user or group. '273948' is for all registered Synapse users             and '273949' is for public access. None implies public access.</p> <p> DEFAULT: <code>None</code> </p> <code>accessType</code> <p>Type of permission to be granted. One or more of CREATE, READ, DOWNLOAD, UPDATE,             DELETE, CHANGE_PERMISSIONS</p> <p> DEFAULT: <code>['READ', 'DOWNLOAD']</code> </p> <code>modify_benefactor</code> <p>Set as True when modifying a benefactor's ACL</p> <p> DEFAULT: <code>False</code> </p> <code>warn_if_inherits</code> <p>Set as False, when creating a new ACL.                 Trying to modify the ACL of an Entity that inherits its ACL will result in a warning</p> <p> DEFAULT: <code>True</code> </p> <code>overwrite</code> <p>By default this function overwrites existing permissions for the specified user.         Set this flag to False to add new permissions non-destructively.</p> <p> DEFAULT: <code>True</code> </p> RETURNS DESCRIPTION <p>An Access Control List object</p> Setting permissions <p>Grant all registered users download access</p> <pre><code>syn.setPermissions('syn1234','273948',['READ','DOWNLOAD'])\n</code></pre> <p>Grant the public view access</p> <pre><code>syn.setPermissions('syn1234','273949',['READ'])\n</code></pre> Source code in <code>synapseclient/client.py</code> <pre><code>def setPermissions(\n    self,\n    entity,\n    principalId=None,\n    accessType=[\"READ\", \"DOWNLOAD\"],\n    modify_benefactor=False,\n    warn_if_inherits=True,\n    overwrite=True,\n):\n    \"\"\"\n    Sets permission that a user or group has on an Entity.\n    An Entity may have its own ACL or inherit its ACL from a benefactor.\n\n    Arguments:\n        entity: An Entity or Synapse ID to modify\n        principalId: Identifier of a user or group. '273948' is for all registered Synapse users\n                        and '273949' is for public access. None implies public access.\n        accessType: Type of permission to be granted. One or more of CREATE, READ, DOWNLOAD, UPDATE,\n                        DELETE, CHANGE_PERMISSIONS\n        modify_benefactor: Set as True when modifying a benefactor's ACL\n        warn_if_inherits: Set as False, when creating a new ACL.\n                            Trying to modify the ACL of an Entity that inherits its ACL will result in a warning\n        overwrite: By default this function overwrites existing permissions for the specified user.\n                    Set this flag to False to add new permissions non-destructively.\n\n    Returns:\n        An Access Control List object\n\n    Example: Setting permissions\n        Grant all registered users download access\n\n            syn.setPermissions('syn1234','273948',['READ','DOWNLOAD'])\n\n        Grant the public view access\n\n            syn.setPermissions('syn1234','273949',['READ'])\n    \"\"\"\n    entity_id = id_of(entity)\n    trace.get_current_span().set_attributes({\"synapse.id\": entity_id})\n\n    benefactor = self._getBenefactor(entity)\n    if benefactor[\"id\"] != entity_id:\n        if modify_benefactor:\n            entity = benefactor\n        elif warn_if_inherits:\n            self.logger.warning(\n                \"Creating an ACL for entity %s, which formerly inherited access control from a\"\n                ' benefactor entity, \"%s\" (%s).\\n'\n                % (entity_id, benefactor[\"name\"], benefactor[\"id\"])\n            )\n\n    acl = self._getACL(entity)\n\n    principalId = self._getUserbyPrincipalIdOrName(principalId)\n\n    # Find existing permissions\n    permissions_to_update = None\n    for permissions in acl[\"resourceAccess\"]:\n        if (\n            \"principalId\" in permissions\n            and permissions[\"principalId\"] == principalId\n        ):\n            permissions_to_update = permissions\n            break\n\n    if accessType is None or accessType == []:\n        # remove permissions\n        if permissions_to_update and overwrite:\n            acl[\"resourceAccess\"].remove(permissions_to_update)\n    else:\n        # add a 'resourceAccess' entry, if necessary\n        if not permissions_to_update:\n            permissions_to_update = {\"accessType\": [], \"principalId\": principalId}\n            acl[\"resourceAccess\"].append(permissions_to_update)\n        if overwrite:\n            permissions_to_update[\"accessType\"] = accessType\n        else:\n            permissions_to_update[\"accessType\"] = list(\n                set(permissions_to_update[\"accessType\"]) | set(accessType)\n            )\n    return self._storeACL(entity, acl)\n</code></pre>"},{"location":"reference/client/#synapseclient.Synapse.getProvenance","title":"<code>getProvenance(entity, version=None)</code>","text":"<p>Retrieve provenance information for a Synapse Entity.</p> PARAMETER DESCRIPTION <code>entity</code> <p>An Entity or Synapse ID to lookup</p> <p> TYPE: <code>Union[str, Mapping, Number]</code> </p> <code>version</code> <p>The version of the Entity to retrieve. Gets the most recent version if omitted</p> <p> TYPE: <code>int</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>Activity</code> <p>An Activity object or raises exception if no provenance record exists</p> RAISES DESCRIPTION <code>SynapseHTTPError</code> <p>if no provenance record exists</p> Source code in <code>synapseclient/client.py</code> <pre><code>def getProvenance(\n    self,\n    entity: typing.Union[str, collections.abc.Mapping, numbers.Number],\n    version: int = None,\n) -&gt; Activity:\n    \"\"\"\n    Retrieve provenance information for a Synapse Entity.\n\n    Arguments:\n        entity:  An Entity or Synapse ID to lookup\n        version: The version of the Entity to retrieve. Gets the most recent version if omitted\n\n    Returns:\n        An Activity object or raises exception if no provenance record exists\n\n    Raises:\n        SynapseHTTPError: if no provenance record exists\n    \"\"\"\n    # Get versionNumber from Entity\n    if version is None and \"versionNumber\" in entity:\n        version = entity[\"versionNumber\"]\n    entity_id = id_of(entity)\n    if version:\n        uri = \"/entity/%s/version/%d/generatedBy\" % (entity_id, version)\n    else:\n        uri = \"/entity/%s/generatedBy\" % entity_id\n\n    trace.get_current_span().set_attributes({\"synapse.id\": entity_id})\n    return Activity(data=self.restGET(uri))\n</code></pre>"},{"location":"reference/client/#synapseclient.Synapse.setProvenance","title":"<code>setProvenance(entity, activity)</code>","text":"<p>Stores a record of the code and data used to derive a Synapse entity.</p> PARAMETER DESCRIPTION <code>entity</code> <p>An Entity or Synapse ID to modify</p> <p> TYPE: <code>Union[str, Mapping, Number]</code> </p> <code>activity</code> <p>A synapseclient.activity.Activity</p> <p> TYPE: <code>Activity</code> </p> RETURNS DESCRIPTION <code>Activity</code> <p>An updated synapseclient.activity.Activity object</p> Source code in <code>synapseclient/client.py</code> <pre><code>def setProvenance(\n    self,\n    entity: typing.Union[str, collections.abc.Mapping, numbers.Number],\n    activity: Activity,\n) -&gt; Activity:\n    \"\"\"\n    Stores a record of the code and data used to derive a Synapse entity.\n\n    Arguments:\n        entity:   An Entity or Synapse ID to modify\n        activity: A [synapseclient.activity.Activity][]\n\n    Returns:\n        An updated [synapseclient.activity.Activity][] object\n    \"\"\"\n    # Assert that the entity was generated by a given Activity.\n    activity = self._saveActivity(activity)\n\n    entity_id = id_of(entity)\n    # assert that an entity is generated by an activity\n    uri = \"/entity/%s/generatedBy?generatedBy=%s\" % (entity_id, activity[\"id\"])\n    activity = Activity(data=self.restPUT(uri))\n\n    trace.get_current_span().set_attributes({\"synapse.id\": entity_id})\n    return activity\n</code></pre>"},{"location":"reference/client/#synapseclient.Synapse.deleteProvenance","title":"<code>deleteProvenance(entity)</code>","text":"<p>Removes provenance information from an Entity and deletes the associated Activity.</p> PARAMETER DESCRIPTION <code>entity</code> <p>An Entity or Synapse ID to modify</p> <p> TYPE: <code>Union[str, Mapping, Number]</code> </p> Source code in <code>synapseclient/client.py</code> <pre><code>def deleteProvenance(\n    self,\n    entity: typing.Union[str, collections.abc.Mapping, numbers.Number],\n) -&gt; None:\n    \"\"\"\n    Removes provenance information from an Entity and deletes the associated Activity.\n\n    Arguments:\n        entity: An Entity or Synapse ID to modify\n    \"\"\"\n    activity = self.getProvenance(entity)\n    if not activity:\n        return\n    entity_id = id_of(entity)\n    trace.get_current_span().set_attributes({\"synapse.id\": entity_id})\n\n    uri = \"/entity/%s/generatedBy\" % entity_id\n    self.restDELETE(uri)\n\n    # If the activity is shared by more than one entity you recieve an HTTP 400 error:\n    # \"If you wish to delete this activity, please first delete all Entities generated by this Activity.\"\"\n    uri = \"/activity/%s\" % activity[\"id\"]\n    self.restDELETE(uri)\n</code></pre>"},{"location":"reference/client/#synapseclient.Synapse.updateActivity","title":"<code>updateActivity(activity)</code>","text":"<p>Modifies an existing Activity.</p> PARAMETER DESCRIPTION <code>activity</code> <p>The Activity to be updated.</p> <p> </p> RETURNS DESCRIPTION <code>Activity</code> <p>An updated Activity object</p> Source code in <code>synapseclient/client.py</code> <pre><code>def updateActivity(self, activity) -&gt; Activity:\n    \"\"\"\n    Modifies an existing Activity.\n\n    Arguments:\n        activity: The Activity to be updated.\n\n    Returns:\n        An updated Activity object\n    \"\"\"\n    if \"id\" not in activity:\n        raise ValueError(\"The activity you want to update must exist on Synapse\")\n    trace.get_current_span().set_attributes({\"synapse.id\": activity[\"id\"]})\n    return self._saveActivity(activity)\n</code></pre>"},{"location":"reference/client/#synapseclient.Synapse.findEntityId","title":"<code>findEntityId(name, parent=None)</code>","text":"<p>Find an Entity given its name and parent.</p> PARAMETER DESCRIPTION <code>name</code> <p>Name of the entity to find</p> <p> </p> <code>parent</code> <p>An Entity object or the Id of an entity as a string. Omit if searching for a Project by name</p> <p> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <p>The Entity ID or None if not found</p> Source code in <code>synapseclient/client.py</code> <pre><code>def findEntityId(self, name, parent=None):\n    \"\"\"\n    Find an Entity given its name and parent.\n\n    Arguments:\n        name: Name of the entity to find\n        parent: An Entity object or the Id of an entity as a string. Omit if searching for a Project by name\n\n    Returns:\n        The Entity ID or None if not found\n    \"\"\"\n    # when we want to search for a project by name. set parentId as None instead of ROOT_ENTITY\n    entity_lookup_request = {\n        \"parentId\": id_of(parent) if parent else None,\n        \"entityName\": name,\n    }\n    try:\n        return self.restPOST(\n            \"/entity/child\", body=json.dumps(entity_lookup_request)\n        ).get(\"id\")\n    except SynapseHTTPError as e:\n        if (\n            e.response.status_code == 404\n        ):  # a 404 error is raised if the entity does not exist\n            return None\n        raise\n</code></pre>"},{"location":"reference/client/#synapseclient.Synapse.getChildren","title":"<code>getChildren(parent, includeTypes=['folder', 'file', 'table', 'link', 'entityview', 'dockerrepo', 'submissionview', 'dataset', 'materializedview'], sortBy='NAME', sortDirection='ASC')</code>","text":"<p>Retrieves all of the entities stored within a parent such as folder or project.</p> PARAMETER DESCRIPTION <code>parent</code> <p>An id or an object of a Synapse container or None to retrieve all projects</p> <p> </p> <code>includeTypes</code> <p>Must be a list of entity types (ie. [\"folder\",\"file\"]) which can be found here</p> <p> DEFAULT: <code>['folder', 'file', 'table', 'link', 'entityview', 'dockerrepo', 'submissionview', 'dataset', 'materializedview']</code> </p> <code>sortBy</code> <p>How results should be sorted. Can be NAME, or CREATED_ON</p> <p> DEFAULT: <code>'NAME'</code> </p> <code>sortDirection</code> <p>The direction of the result sort. Can be ASC, or DESC</p> <p> DEFAULT: <code>'ASC'</code> </p> YIELDS DESCRIPTION <p>An iterator that shows all the children of the container.</p> <p>Also see:</p> <ul> <li>synapseutils.walk</li> </ul> Source code in <code>synapseclient/client.py</code> <pre><code>def getChildren(\n    self,\n    parent,\n    includeTypes=[\n        \"folder\",\n        \"file\",\n        \"table\",\n        \"link\",\n        \"entityview\",\n        \"dockerrepo\",\n        \"submissionview\",\n        \"dataset\",\n        \"materializedview\",\n    ],\n    sortBy=\"NAME\",\n    sortDirection=\"ASC\",\n):\n    \"\"\"\n    Retrieves all of the entities stored within a parent such as folder or project.\n\n    Arguments:\n        parent: An id or an object of a Synapse container or None to retrieve all projects\n        includeTypes: Must be a list of entity types (ie. [\"folder\",\"file\"]) which can be found [here](http://docs.synapse.org/rest/org/sagebionetworks/repo/model/EntityType.html)\n        sortBy: How results should be sorted. Can be NAME, or CREATED_ON\n        sortDirection: The direction of the result sort. Can be ASC, or DESC\n\n    Yields:\n        An iterator that shows all the children of the container.\n\n    Also see:\n\n    - [synapseutils.walk][]\n    \"\"\"\n    parentId = id_of(parent) if parent is not None else None\n\n    trace.get_current_span().set_attributes({\"synapse.parent_id\": parentId})\n    entityChildrenRequest = {\n        \"parentId\": parentId,\n        \"includeTypes\": includeTypes,\n        \"sortBy\": sortBy,\n        \"sortDirection\": sortDirection,\n        \"nextPageToken\": None,\n    }\n    entityChildrenResponse = {\"nextPageToken\": \"first\"}\n    while entityChildrenResponse.get(\"nextPageToken\") is not None:\n        entityChildrenResponse = self.restPOST(\n            \"/entity/children\", body=json.dumps(entityChildrenRequest)\n        )\n        for child in entityChildrenResponse[\"page\"]:\n            yield child\n        if entityChildrenResponse.get(\"nextPageToken\") is not None:\n            entityChildrenRequest[\"nextPageToken\"] = entityChildrenResponse[\n                \"nextPageToken\"\n            ]\n</code></pre>"},{"location":"reference/client/#synapseclient.Synapse.getTeam","title":"<code>getTeam(id)</code>","text":"<p>Finds a team with a given ID or name.</p> PARAMETER DESCRIPTION <code>id</code> <p>The ID or name of the team or a Team object to retrieve.</p> <p> TYPE: <code>Union[int, str]</code> </p> RETURNS DESCRIPTION <code>Team</code> <p>An object of type synapseclient.team.Team</p> Source code in <code>synapseclient/client.py</code> <pre><code>def getTeam(self, id: Union[int, str]) -&gt; Team:\n    \"\"\"\n    Finds a team with a given ID or name.\n\n    Arguments:\n        id: The ID or name of the team or a Team object to retrieve.\n\n    Returns:\n        An object of type [synapseclient.team.Team][]\n    \"\"\"\n    # Retrieves team id\n    teamid = id_of(id)\n    try:\n        int(teamid)\n    except (TypeError, ValueError):\n        if isinstance(id, str):\n            for team in self._findTeam(id):\n                if team.name == id:\n                    teamid = team.id\n                    break\n            else:\n                raise ValueError('Can\\'t find team \"{}\"'.format(teamid))\n        else:\n            raise ValueError('Can\\'t find team \"{}\"'.format(teamid))\n    return Team(**self.restGET(\"/team/%s\" % teamid))\n</code></pre>"},{"location":"reference/client/#synapseclient.Synapse.getTeamMembers","title":"<code>getTeamMembers(team)</code>","text":"<p>Lists the members of the given team.</p> PARAMETER DESCRIPTION <code>team</code> <p>A synapseclient.team.Team object or a team's ID.</p> <p> TYPE: <code>Union[Team, int, str]</code> </p> YIELDS DESCRIPTION <code>TeamMember</code> <p>A generator over synapseclient.team.TeamMember objects.</p> Source code in <code>synapseclient/client.py</code> <pre><code>def getTeamMembers(\n    self, team: Union[Team, int, str]\n) -&gt; typing.Generator[TeamMember, None, None]:\n    \"\"\"\n    Lists the members of the given team.\n\n    Arguments:\n        team: A [synapseclient.team.Team][] object or a team's ID.\n\n    Yields:\n        A generator over [synapseclient.team.TeamMember][] objects.\n\n    \"\"\"\n    for result in self._GET_paginated(\"/teamMembers/{id}\".format(id=id_of(team))):\n        yield TeamMember(**result)\n</code></pre>"},{"location":"reference/client/#synapseclient.Synapse.invite_to_team","title":"<code>invite_to_team(team, user=None, inviteeEmail=None, message=None, force=False)</code>","text":"<p>Invite user to a Synapse team via Synapse username or email (choose one or the other)</p> PARAMETER DESCRIPTION <code>syn</code> <p>Synapse object</p> <p> </p> <code>team</code> <p>A synapseclient.team.Team object or a team's ID.</p> <p> TYPE: <code>Union[Team, int, str]</code> </p> <code>user</code> <p>Synapse username or profile id of user</p> <p> TYPE: <code>str</code> DEFAULT: <code>None</code> </p> <code>inviteeEmail</code> <p>Email of user</p> <p> TYPE: <code>str</code> DEFAULT: <code>None</code> </p> <code>message</code> <p>Additional message for the user getting invited to the team.</p> <p> TYPE: <code>str</code> DEFAULT: <code>None</code> </p> <code>force</code> <p>If an open invitation exists for the invitee, the old invite will be cancelled.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> RETURNS DESCRIPTION <p>MembershipInvitation or None if user is already a member</p> Source code in <code>synapseclient/client.py</code> <pre><code>def invite_to_team(\n    self,\n    team: Union[Team, int, str],\n    user: str = None,\n    inviteeEmail: str = None,\n    message: str = None,\n    force: bool = False,\n):\n    \"\"\"Invite user to a Synapse team via Synapse username or email\n    (choose one or the other)\n\n    Arguments:\n        syn: Synapse object\n        team: A [synapseclient.team.Team][] object or a team's ID.\n        user: Synapse username or profile id of user\n        inviteeEmail: Email of user\n        message: Additional message for the user getting invited to the team.\n        force: If an open invitation exists for the invitee, the old invite will be cancelled.\n\n    Returns:\n        MembershipInvitation or None if user is already a member\n    \"\"\"\n    # Throw error if both user and email is specified and if both not\n    # specified\n    id_email_specified = inviteeEmail is not None and user is not None\n    id_email_notspecified = inviteeEmail is None and user is None\n    if id_email_specified or id_email_notspecified:\n        raise ValueError(\"Must specify either 'user' or 'inviteeEmail'\")\n\n    teamid = id_of(team)\n    is_member = False\n    open_invitations = self.get_team_open_invitations(teamid)\n\n    if user is not None:\n        inviteeId = self.getUserProfile(user)[\"ownerId\"]\n        membership_status = self.get_membership_status(inviteeId, teamid)\n        is_member = membership_status[\"isMember\"]\n        open_invites_to_user = [\n            invitation\n            for invitation in open_invitations\n            if invitation.get(\"inviteeId\") == inviteeId\n        ]\n    else:\n        inviteeId = None\n        open_invites_to_user = [\n            invitation\n            for invitation in open_invitations\n            if invitation.get(\"inviteeEmail\") == inviteeEmail\n        ]\n    # Only invite if the invitee is not a member and\n    # if invitee doesn't have an open invitation unless force=True\n    if not is_member and (not open_invites_to_user or force):\n        # Delete all old invitations\n        for invite in open_invites_to_user:\n            self._delete_membership_invitation(invite[\"id\"])\n        return self.send_membership_invitation(\n            teamid,\n            inviteeId=inviteeId,\n            inviteeEmail=inviteeEmail,\n            message=message,\n        )\n    if is_member:\n        not_sent_reason = \"invitee is already a member\"\n    else:\n        not_sent_reason = (\n            \"invitee already has an open invitation \"\n            \"Set force=True to send new invite.\"\n        )\n\n    self.logger.warning(\"No invitation sent: {}\".format(not_sent_reason))\n    # Return None if no invite is sent.\n    return None\n</code></pre>"},{"location":"reference/client/#synapseclient.Synapse.get_membership_status","title":"<code>get_membership_status(userid, team)</code>","text":"<p>Retrieve a user's Team Membership Status bundle. https://rest-docs.synapse.org/rest/GET/team/id/member/principalId/membershipStatus.html</p> PARAMETER DESCRIPTION <code>user</code> <p>Synapse user ID</p> <p> </p> <code>team</code> <p>A synapseclient.team.Team object or a team's ID.</p> <p> </p> RETURNS DESCRIPTION <p>dict of TeamMembershipStatus</p> Source code in <code>synapseclient/client.py</code> <pre><code>def get_membership_status(self, userid, team):\n    \"\"\"Retrieve a user's Team Membership Status bundle.\n    &lt;https://rest-docs.synapse.org/rest/GET/team/id/member/principalId/membershipStatus.html&gt;\n\n    Arguments:\n        user: Synapse user ID\n        team: A [synapseclient.team.Team][] object or a team's ID.\n\n    Returns:\n        dict of TeamMembershipStatus\n    \"\"\"\n    teamid = id_of(team)\n    request = \"/team/{team}/member/{user}/membershipStatus\".format(\n        team=teamid, user=userid\n    )\n    membership_status = self.restGET(request)\n    return membership_status\n</code></pre>"},{"location":"reference/client/#synapseclient.Synapse.get_team_open_invitations","title":"<code>get_team_open_invitations(team)</code>","text":"<p>Retrieve the open requests submitted to a Team https://rest-docs.synapse.org/rest/GET/team/id/openInvitation.html</p> PARAMETER DESCRIPTION <code>team</code> <p>A synapseclient.team.Team object or a team's ID.</p> <p> TYPE: <code>Union[Team, int, str]</code> </p> YIELDS DESCRIPTION <code>dict</code> <p>Generator of MembershipRequest dictionaries</p> Source code in <code>synapseclient/client.py</code> <pre><code>def get_team_open_invitations(\n    self, team: Union[Team, int, str]\n) -&gt; typing.Generator[dict, None, None]:\n    \"\"\"Retrieve the open requests submitted to a Team\n    &lt;https://rest-docs.synapse.org/rest/GET/team/id/openInvitation.html&gt;\n\n    Arguments:\n        team: A [synapseclient.team.Team][] object or a team's ID.\n\n    Yields:\n        Generator of MembershipRequest dictionaries\n    \"\"\"\n    teamid = id_of(team)\n    request = \"/team/{team}/openInvitation\".format(team=teamid)\n    open_requests = self._GET_paginated(request)\n    return open_requests\n</code></pre>"},{"location":"reference/client/#synapseclient.Synapse.send_membership_invitation","title":"<code>send_membership_invitation(teamId, inviteeId=None, inviteeEmail=None, message=None)</code>","text":"<p>Create a membership invitation and send an email notification to the invitee.</p> PARAMETER DESCRIPTION <code>teamId</code> <p>Synapse teamId</p> <p> </p> <code>inviteeId</code> <p>Synapse username or profile id of user</p> <p> DEFAULT: <code>None</code> </p> <code>inviteeEmail</code> <p>Email of user</p> <p> DEFAULT: <code>None</code> </p> <code>message</code> <p>Additional message for the user getting invited to the      team.</p> <p> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <p>MembershipInvitation</p> Source code in <code>synapseclient/client.py</code> <pre><code>def send_membership_invitation(\n    self, teamId, inviteeId=None, inviteeEmail=None, message=None\n):\n    \"\"\"Create a membership invitation and send an email notification\n    to the invitee.\n\n    Arguments:\n        teamId: Synapse teamId\n        inviteeId: Synapse username or profile id of user\n        inviteeEmail: Email of user\n        message: Additional message for the user getting invited to the\n                 team.\n\n    Returns:\n        MembershipInvitation\n    \"\"\"\n\n    invite_request = {\"teamId\": str(teamId), \"message\": message}\n    if inviteeEmail is not None:\n        invite_request[\"inviteeEmail\"] = str(inviteeEmail)\n    if inviteeId is not None:\n        invite_request[\"inviteeId\"] = str(inviteeId)\n\n    response = self.restPOST(\n        \"/membershipInvitation\", body=json.dumps(invite_request)\n    )\n    return response\n</code></pre>"},{"location":"reference/client/#synapseclient.Synapse.submit","title":"<code>submit(evaluation, entity, name=None, team=None, silent=False, submitterAlias=None, teamName=None, dockerTag='latest')</code>","text":"<p>Submit an Entity for evaluation.</p> PARAMETER DESCRIPTION <code>evalation</code> <p>Evaluation queue to submit to</p> <p> </p> <code>entity</code> <p>The Entity containing the Submissions</p> <p> </p> <code>name</code> <p>A name for this submission. In the absent of this parameter, the entity name will be used.     (Optional) A synapseclient.team.Team object, ID or name of a Team that is registered for the challenge</p> <p> DEFAULT: <code>None</code> </p> <code>team</code> <p>(optional) A synapseclient.team.Team object, ID or name of a Team that is registered for the challenge</p> <p> DEFAULT: <code>None</code> </p> <code>silent</code> <p>Set to True to suppress output.</p> <p> DEFAULT: <code>False</code> </p> <code>submitterAlias</code> <p>(optional) A nickname, possibly for display in leaderboards in place of the submitter's name</p> <p> DEFAULT: <code>None</code> </p> <code>teamName</code> <p>(deprecated) A synonym for submitterAlias</p> <p> DEFAULT: <code>None</code> </p> <code>dockerTag</code> <p>(optional) The Docker tag must be specified if the entity is a DockerRepository.</p> <p> DEFAULT: <code>'latest'</code> </p> RETURNS DESCRIPTION <p>A synapseclient.evaluation.Submission object</p> <p>In the case of challenges, a team can optionally be provided to give credit to members of the team that contributed to the submission. The team must be registered for the challenge with which the given evaluation is associated. The caller must be a member of the submitting team.</p> Using this function <p>Getting and submitting an evaluation</p> <pre><code>evaluation = syn.getEvaluation(123)\nentity = syn.get('syn456')\nsubmission = syn.submit(evaluation, entity, name='Our Final Answer', team='Blue Team')\n</code></pre> Source code in <code>synapseclient/client.py</code> <pre><code>def submit(\n    self,\n    evaluation,\n    entity,\n    name=None,\n    team=None,\n    silent=False,\n    submitterAlias=None,\n    teamName=None,\n    dockerTag=\"latest\",\n):\n    \"\"\"\n    Submit an Entity for [evaluation][synapseclient.evaluation.Evaluation].\n\n    Arguments:\n        evalation: Evaluation queue to submit to\n        entity: The Entity containing the Submissions\n        name: A name for this submission. In the absent of this parameter, the entity name will be used.\n                (Optional) A [synapseclient.team.Team][] object, ID or name of a Team that is registered for the challenge\n        team: (optional) A [synapseclient.team.Team][] object, ID or name of a Team that is registered for the challenge\n        silent: Set to True to suppress output.\n        submitterAlias: (optional) A nickname, possibly for display in leaderboards in place of the submitter's name\n        teamName: (deprecated) A synonym for submitterAlias\n        dockerTag: (optional) The Docker tag must be specified if the entity is a DockerRepository.\n\n    Returns:\n        A [synapseclient.evaluation.Submission][] object\n\n\n    In the case of challenges, a team can optionally be provided to give credit to members of the team that\n    contributed to the submission. The team must be registered for the challenge with which the given evaluation is\n    associated. The caller must be a member of the submitting team.\n\n    Example: Using this function\n        Getting and submitting an evaluation\n\n            evaluation = syn.getEvaluation(123)\n            entity = syn.get('syn456')\n            submission = syn.submit(evaluation, entity, name='Our Final Answer', team='Blue Team')\n    \"\"\"\n\n    require_param(evaluation, \"evaluation\")\n    require_param(entity, \"entity\")\n\n    evaluation_id = id_of(evaluation)\n\n    entity_id = id_of(entity)\n    if isinstance(entity, synapseclient.DockerRepository):\n        # Edge case if dockerTag is specified as None\n        if dockerTag is None:\n            raise ValueError(\n                \"A dockerTag is required to submit a DockerEntity. Cannot be None\"\n            )\n        docker_repository = entity[\"repositoryName\"]\n    else:\n        docker_repository = None\n\n    if \"versionNumber\" not in entity:\n        entity = self.get(entity, downloadFile=False)\n    # version defaults to 1 to hack around required version field and allow submission of files/folders\n    entity_version = entity.get(\"versionNumber\", 1)\n\n    # default name of submission to name of entity\n    if name is None and \"name\" in entity:\n        name = entity[\"name\"]\n\n    team_id = None\n    if team:\n        team = self.getTeam(team)\n        team_id = id_of(team)\n\n    contributors, eligibility_hash = self._get_contributors(evaluation_id, team)\n\n    # for backward compatible until we remove supports for teamName\n    if not submitterAlias:\n        if teamName:\n            submitterAlias = teamName\n        elif team and \"name\" in team:\n            submitterAlias = team[\"name\"]\n\n    if isinstance(entity, synapseclient.DockerRepository):\n        docker_digest = self._get_docker_digest(entity, dockerTag)\n    else:\n        docker_digest = None\n\n    submission = {\n        \"evaluationId\": evaluation_id,\n        \"name\": name,\n        \"entityId\": entity_id,\n        \"versionNumber\": entity_version,\n        \"dockerDigest\": docker_digest,\n        \"dockerRepositoryName\": docker_repository,\n        \"teamId\": team_id,\n        \"contributors\": contributors,\n        \"submitterAlias\": submitterAlias,\n    }\n\n    submitted = self._submit(submission, entity[\"etag\"], eligibility_hash)\n\n    # if we want to display the receipt message, we need the full object\n    if not silent:\n        if not (isinstance(evaluation, Evaluation)):\n            evaluation = self.getEvaluation(evaluation_id)\n        if \"submissionReceiptMessage\" in evaluation:\n            self.logger.info(evaluation[\"submissionReceiptMessage\"])\n\n    return Submission(**submitted)\n</code></pre>"},{"location":"reference/client/#synapseclient.Synapse.getConfigFile","title":"<code>getConfigFile(configPath)</code>  <code>cached</code>","text":"<p>Retrieves the client configuration information.</p> PARAMETER DESCRIPTION <code>configPath</code> <p>Path to configuration file on local file system</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>RawConfigParser</code> <p>A RawConfigParser populated with properties from the user's configuration file.</p> Source code in <code>synapseclient/client.py</code> <pre><code>@deprecated(\n    version=\"4.4.0\",\n    reason=\"To be removed in 5.0.0. \"\n    \"Moved to synapseclient/api/configuration_services.py::get_config_file\",\n)\n@functools.lru_cache()\ndef getConfigFile(self, configPath: str) -&gt; configparser.RawConfigParser:\n    \"\"\"\n    Retrieves the client configuration information.\n\n    Arguments:\n        configPath:  Path to configuration file on local file system\n\n    Returns:\n        A RawConfigParser populated with properties from the user's configuration file.\n    \"\"\"\n\n    try:\n        config = configparser.RawConfigParser()\n        config.read(configPath)  # Does not fail if the file does not exist\n        return config\n    except configparser.Error as ex:\n        raise ValueError(\n            \"Error parsing Synapse config file: {}\".format(configPath)\n        ) from ex\n</code></pre>"},{"location":"reference/client/#synapseclient.Synapse.setEndpoints","title":"<code>setEndpoints(repoEndpoint=None, authEndpoint=None, fileHandleEndpoint=None, portalEndpoint=None, skip_checks=False)</code>","text":"<p>Sets the locations for each of the Synapse services (mostly useful for testing).</p> PARAMETER DESCRIPTION <code>repoEndpoint</code> <p>Location of synapse repository</p> <p> TYPE: <code>str</code> DEFAULT: <code>None</code> </p> <code>authEndpoint</code> <p>Location of authentication service</p> <p> TYPE: <code>str</code> DEFAULT: <code>None</code> </p> <code>fileHandleEndpoint</code> <p>Location of file service</p> <p> TYPE: <code>str</code> DEFAULT: <code>None</code> </p> <code>portalEndpoint</code> <p>Location of the website</p> <p> TYPE: <code>str</code> DEFAULT: <code>None</code> </p> <code>skip_checks</code> <p>Skip version and endpoint checks</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> Switching endpoints <p>To switch between staging and production endpoints</p> <pre><code>syn.setEndpoints(**synapseclient.client.STAGING_ENDPOINTS)\nsyn.setEndpoints(**synapseclient.client.PRODUCTION_ENDPOINTS)\n</code></pre> Source code in <code>synapseclient/client.py</code> <pre><code>def setEndpoints(\n    self,\n    repoEndpoint: str = None,\n    authEndpoint: str = None,\n    fileHandleEndpoint: str = None,\n    portalEndpoint: str = None,\n    skip_checks: bool = False,\n) -&gt; None:\n    \"\"\"\n    Sets the locations for each of the Synapse services (mostly useful for testing).\n\n    Arguments:\n        repoEndpoint:          Location of synapse repository\n        authEndpoint:          Location of authentication service\n        fileHandleEndpoint:    Location of file service\n        portalEndpoint:        Location of the website\n        skip_checks:           Skip version and endpoint checks\n\n    Example: Switching endpoints\n        To switch between staging and production endpoints\n\n            syn.setEndpoints(**synapseclient.client.STAGING_ENDPOINTS)\n            syn.setEndpoints(**synapseclient.client.PRODUCTION_ENDPOINTS)\n\n    \"\"\"\n\n    endpoints = {\n        \"repoEndpoint\": repoEndpoint,\n        \"authEndpoint\": authEndpoint,\n        \"fileHandleEndpoint\": fileHandleEndpoint,\n        \"portalEndpoint\": portalEndpoint,\n    }\n\n    # For unspecified endpoints, first look in the config file\n    config = get_config_file(self.configPath)\n    for point in endpoints.keys():\n        if endpoints[point] is None and config.has_option(\"endpoints\", point):\n            endpoints[point] = config.get(\"endpoints\", point)\n\n    # Endpoints default to production\n    for point in endpoints.keys():\n        if endpoints[point] is None:\n            endpoints[point] = PRODUCTION_ENDPOINTS[point]\n\n        # Update endpoints if we get redirected\n        if not skip_checks:\n            response = self._requests_session.get(\n                endpoints[point],\n                allow_redirects=False,\n                headers=synapseclient.USER_AGENT,\n            )\n            if response.status_code == 301:\n                endpoints[point] = response.headers[\"location\"]\n\n    self.repoEndpoint = endpoints[\"repoEndpoint\"]\n    self.authEndpoint = endpoints[\"authEndpoint\"]\n    self.fileHandleEndpoint = endpoints[\"fileHandleEndpoint\"]\n    self.portalEndpoint = endpoints[\"portalEndpoint\"]\n</code></pre>"},{"location":"reference/client/#synapseclient.Synapse.invalidateAPIKey","title":"<code>invalidateAPIKey()</code>","text":"<p>Deprecated with no replacement. The client does not support API keys for authentication. Please use a personal access token instead. This method will be removed in a future release.</p> <p>Invalidates authentication across all clients.</p> RETURNS DESCRIPTION <p>None</p> Source code in <code>synapseclient/client.py</code> <pre><code>@deprecated(\n    version=\"4.0.0\",\n    reason=\"deprecated with no replacement. The client does not support API keys for \"\n    \"authentication. Please use a personal access token instead. This method will \"\n    \"be removed in a future release.\",\n)\ndef invalidateAPIKey(self):\n    \"\"\"\n    **Deprecated with no replacement.** The client does not support API keys for\n    authentication. Please use a\n    [personal access token](https://python-docs.synapse.org/tutorials/authentication/)\n    instead. This method will be removed in a future release.\n\n\n    Invalidates authentication across all clients.\n\n    Returns:\n        None\n    \"\"\"\n\n    # Logout globally\n    if self._is_logged_in():\n        self.restDELETE(\"/secretKey\", endpoint=self.authEndpoint)\n</code></pre>"},{"location":"reference/client/#synapseclient.Synapse.get_user_profile_by_username","title":"<code>get_user_profile_by_username(username=None, sessionToken=None)</code>  <code>cached</code>","text":"<p>Get the details about a Synapse user. Retrieves information on the current user if 'id' is omitted or is empty string.</p> PARAMETER DESCRIPTION <code>username</code> <p>The userName of a user</p> <p> TYPE: <code>str</code> DEFAULT: <code>None</code> </p> <code>sessionToken</code> <p>The session token to use to find the user profile</p> <p> TYPE: <code>str</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>UserProfile</code> <p>The user profile for the user of interest.</p> Using this function <p>Getting your own profile</p> <pre><code>my_profile = syn.get_user_profile_by_username()\n</code></pre> <p>Getting another user's profile</p> <pre><code>freds_profile = syn.get_user_profile_by_username('fredcommo')\n</code></pre> Source code in <code>synapseclient/client.py</code> <pre><code>@functools.lru_cache()\ndef get_user_profile_by_username(\n    self,\n    username: str = None,\n    sessionToken: str = None,\n) -&gt; UserProfile:\n    \"\"\"\n    Get the details about a Synapse user.\n    Retrieves information on the current user if 'id' is omitted or is empty string.\n\n    Arguments:\n        username:     The userName of a user\n        sessionToken: The session token to use to find the user profile\n\n    Returns:\n        The user profile for the user of interest.\n\n    Example: Using this function\n        Getting your own profile\n\n            my_profile = syn.get_user_profile_by_username()\n\n        Getting another user's profile\n\n            freds_profile = syn.get_user_profile_by_username('fredcommo')\n    \"\"\"\n    is_none = username is None\n    is_str = isinstance(username, str)\n    if not is_str and not is_none:\n        raise TypeError(\"username must be string or None\")\n    if is_str:\n        principals = self._findPrincipals(username)\n        for principal in principals:\n            if principal.get(\"userName\", None).lower() == username.lower():\n                id = principal[\"ownerId\"]\n                break\n        else:\n            raise ValueError(f\"Can't find user '{username}'\")\n    else:\n        id = \"\"\n    uri = f\"/userProfile/{id}\"\n    return UserProfile(\n        **self.restGET(\n            uri, headers={\"sessionToken\": sessionToken} if sessionToken else None\n        )\n    )\n</code></pre>"},{"location":"reference/client/#synapseclient.Synapse.get_user_profile_by_id","title":"<code>get_user_profile_by_id(id=None, sessionToken=None)</code>  <code>cached</code>","text":"<p>Get the details about a Synapse user. Retrieves information on the current user if 'id' is omitted.</p> PARAMETER DESCRIPTION <code>id</code> <p>The ownerId of a user</p> <p> TYPE: <code>int</code> DEFAULT: <code>None</code> </p> <code>sessionToken</code> <p>The session token to use to find the user profile</p> <p> TYPE: <code>str</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>UserProfile</code> <p>The user profile for the user of interest.</p> Using this function <p>Getting your own profile</p> <pre><code>my_profile = syn.get_user_profile_by_id()\n</code></pre> <p>Getting another user's profile</p> <pre><code>freds_profile = syn.get_user_profile_by_id(1234567)\n</code></pre> Source code in <code>synapseclient/client.py</code> <pre><code>@functools.lru_cache()\ndef get_user_profile_by_id(\n    self,\n    id: int = None,\n    sessionToken: str = None,\n) -&gt; UserProfile:\n    \"\"\"\n    Get the details about a Synapse user.\n    Retrieves information on the current user if 'id' is omitted.\n\n    Arguments:\n        id:           The ownerId of a user\n        sessionToken: The session token to use to find the user profile\n\n    Returns:\n        The user profile for the user of interest.\n\n\n    Example: Using this function\n        Getting your own profile\n\n            my_profile = syn.get_user_profile_by_id()\n\n        Getting another user's profile\n\n            freds_profile = syn.get_user_profile_by_id(1234567)\n    \"\"\"\n    if id:\n        if not isinstance(id, int):\n            raise TypeError(\"id must be an 'ownerId' integer\")\n    else:\n        id = \"\"\n    uri = f\"/userProfile/{id}\"\n    return UserProfile(\n        **self.restGET(\n            uri, headers={\"sessionToken\": sessionToken} if sessionToken else None\n        )\n    )\n</code></pre>"},{"location":"reference/client/#synapseclient.Synapse.getUserProfile","title":"<code>getUserProfile(id=None, sessionToken=None)</code>  <code>cached</code>","text":"<p>Get the details about a Synapse user. Retrieves information on the current user if 'id' is omitted.</p> PARAMETER DESCRIPTION <code>id</code> <p>The 'userId' (aka 'ownerId') of a user or the userName</p> <p> TYPE: <code>Union[str, int, UserProfile, TeamMember]</code> DEFAULT: <code>None</code> </p> <code>sessionToken</code> <p>The session token to use to find the user profile</p> <p> TYPE: <code>str</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>UserProfile</code> <p>The user profile for the user of interest.</p> Using this function <p>Getting your own profile</p> <pre><code>my_profile = syn.getUserProfile()\n</code></pre> <p>Getting another user's profile</p> <pre><code>freds_profile = syn.getUserProfile('fredcommo')\n</code></pre> Source code in <code>synapseclient/client.py</code> <pre><code>@functools.lru_cache()\ndef getUserProfile(\n    self,\n    id: Union[str, int, UserProfile, TeamMember] = None,\n    sessionToken: str = None,\n) -&gt; UserProfile:\n    \"\"\"\n    Get the details about a Synapse user.\n    Retrieves information on the current user if 'id' is omitted.\n\n    Arguments:\n        id:           The 'userId' (aka 'ownerId') of a user or the userName\n        sessionToken: The session token to use to find the user profile\n\n    Returns:\n        The user profile for the user of interest.\n\n    Example: Using this function\n        Getting your own profile\n\n            my_profile = syn.getUserProfile()\n\n        Getting another user's profile\n\n            freds_profile = syn.getUserProfile('fredcommo')\n    \"\"\"\n    try:\n        # if id is unset or a userID, this will succeed\n        id = \"\" if id is None else int(id)\n    except (TypeError, ValueError):\n        if isinstance(id, collections.abc.Mapping) and \"ownerId\" in id:\n            id = id.ownerId\n        elif isinstance(id, TeamMember):\n            id = id.member.ownerId\n        else:\n            principals = self._findPrincipals(id)\n            if len(principals) == 1:\n                id = principals[0][\"ownerId\"]\n            else:\n                for principal in principals:\n                    if principal.get(\"userName\", None).lower() == id.lower():\n                        id = principal[\"ownerId\"]\n                        break\n                else:  # no break\n                    raise ValueError('Can\\'t find user \"%s\": ' % id)\n    uri = \"/userProfile/%s\" % id\n    return UserProfile(\n        **self.restGET(\n            uri, headers={\"sessionToken\": sessionToken} if sessionToken else None\n        )\n    )\n</code></pre>"},{"location":"reference/client/#synapseclient.Synapse.is_certified","title":"<code>is_certified(user)</code>","text":"<p>Determines whether a Synapse user is a certified user.</p> PARAMETER DESCRIPTION <code>user</code> <p>Synapse username or Id</p> <p> TYPE: <code>Union[str, int]</code> </p> RETURNS DESCRIPTION <code>bool</code> <p>True if the Synapse user is certified</p> Source code in <code>synapseclient/client.py</code> <pre><code>def is_certified(self, user: typing.Union[str, int]) -&gt; bool:\n    \"\"\"Determines whether a Synapse user is a certified user.\n\n    Arguments:\n        user: Synapse username or Id\n\n    Returns:\n        True if the Synapse user is certified\n    \"\"\"\n    # Check if userid or username exists\n    syn_user = self.getUserProfile(user)\n    # Get passing record\n\n    try:\n        certification_status = self._get_certified_passing_record(\n            syn_user[\"ownerId\"]\n        )\n        return certification_status[\"passed\"]\n    except SynapseHTTPError as ex:\n        if ex.response.status_code == 404:\n            # user hasn't taken the quiz\n            return False\n        raise\n</code></pre>"},{"location":"reference/client/#synapseclient.Synapse.is_synapse_id","title":"<code>is_synapse_id(syn_id)</code>","text":"<p>Checks if given synID is valid (attached to actual entity?)</p> PARAMETER DESCRIPTION <code>syn_id</code> <p>A Synapse ID</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>bool</code> <p>True if the Synapse ID is valid</p> Source code in <code>synapseclient/client.py</code> <pre><code>def is_synapse_id(self, syn_id: str) -&gt; bool:\n    \"\"\"Checks if given synID is valid (attached to actual entity?)\n\n    Arguments:\n        syn_id: A Synapse ID\n\n    Returns:\n        True if the Synapse ID is valid\n    \"\"\"\n    if isinstance(syn_id, str):\n        try:\n            self.get(syn_id, downloadFile=False)\n        except SynapseFileNotFoundError:\n            return False\n        except (\n            SynapseHTTPError,\n            SynapseAuthenticationError,\n        ) as err:\n            status = (\n                err.__context__.response.status_code or err.response.status_code\n            )\n            if status in (400, 404):\n                return False\n            # Valid ID but user lacks permission or is not logged in\n            elif status == 403:\n                return True\n        return True\n    self.logger.warning(\"synID must be a string\")\n    return False\n</code></pre>"},{"location":"reference/client/#synapseclient.Synapse.onweb","title":"<code>onweb(entity, subpageId=None)</code>","text":"<p>Opens up a browser window to the entity page or wiki-subpage.</p> PARAMETER DESCRIPTION <code>entity</code> <p>Either an Entity or a Synapse ID</p> <p> </p> <code>subpageId</code> <p>(Optional) ID of one of the wiki's sub-pages</p> <p> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <p>None</p> Source code in <code>synapseclient/client.py</code> <pre><code>def onweb(self, entity, subpageId=None):\n    \"\"\"Opens up a browser window to the entity page or wiki-subpage.\n\n    Arguments:\n        entity:    Either an Entity or a Synapse ID\n        subpageId: (Optional) ID of one of the wiki's sub-pages\n\n    Returns:\n        None\n    \"\"\"\n    if isinstance(entity, str) and os.path.isfile(entity):\n        entity = self.get(entity, downloadFile=False)\n    synId = id_of(entity)\n    if subpageId is None:\n        webbrowser.open(\"%s#!Synapse:%s\" % (self.portalEndpoint, synId))\n    else:\n        webbrowser.open(\n            \"%s#!Wiki:%s/ENTITY/%s\" % (self.portalEndpoint, synId, subpageId)\n        )\n</code></pre>"},{"location":"reference/client/#synapseclient.Synapse.printEntity","title":"<code>printEntity(entity, ensure_ascii=True)</code>","text":"<p>Pretty prints an Entity.</p> PARAMETER DESCRIPTION <code>entity</code> <p>The entity to be printed.</p> <p> </p> <code>ensure_ascii</code> <p>If True, escapes all non-ASCII characters</p> <p> DEFAULT: <code>True</code> </p> RETURNS DESCRIPTION <code>None</code> <p>None</p> Source code in <code>synapseclient/client.py</code> <pre><code>def printEntity(self, entity, ensure_ascii=True) -&gt; None:\n    \"\"\"\n    Pretty prints an Entity.\n\n    Arguments:\n        entity: The entity to be printed.\n        ensure_ascii: If True, escapes all non-ASCII characters\n\n    Returns:\n        None\n    \"\"\"\n\n    if utils.is_synapse_id_str(entity):\n        synid, version = utils.get_synid_and_version(entity)\n        entity = self._getEntity(synid, version)\n    try:\n        self.logger.info(\n            json.dumps(entity, sort_keys=True, indent=2, ensure_ascii=ensure_ascii)\n        )\n    except TypeError:\n        self.logger.info(str(entity))\n</code></pre>"},{"location":"reference/client/#synapseclient.Synapse.get_available_services","title":"<code>get_available_services()</code>","text":"<p>Get available Synapse services This is a beta feature and is subject to change</p> RETURNS DESCRIPTION <code>List[str]</code> <p>List of available services</p> Source code in <code>synapseclient/client.py</code> <pre><code>def get_available_services(self) -&gt; typing.List[str]:\n    \"\"\"Get available Synapse services\n    This is a beta feature and is subject to change\n\n    Returns:\n        List of available services\n    \"\"\"\n    services = self._services.keys()\n    return list(services)\n</code></pre>"},{"location":"reference/client/#synapseclient.Synapse.service","title":"<code>service(service_name)</code>","text":"<p>Get available Synapse services This is a beta feature and is subject to change</p> PARAMETER DESCRIPTION <code>service_name</code> <p>name of the service</p> <p> TYPE: <code>str</code> </p> Source code in <code>synapseclient/client.py</code> <pre><code>def service(self, service_name: str):\n    \"\"\"Get available Synapse services\n    This is a beta feature and is subject to change\n\n    Arguments:\n        service_name: name of the service\n    \"\"\"\n    # This is to avoid circular imports\n    # TODO: revisit the import order and method https://stackoverflow.com/a/37126790\n    # To move this to the top\n    import synapseclient.services\n\n    assert isinstance(service_name, str)\n    service_name = service_name.lower().replace(\" \", \"_\")\n    assert service_name in self._services, (\n        f\"Unrecognized service ({service_name}). Run the 'get_available_\"\n        \"services()' method to get a list of available services.\"\n    )\n    service_attr = self._services[service_name]\n    service_cls = getattr(synapseclient.services, service_attr)\n    service = service_cls(self)\n    return service\n</code></pre>"},{"location":"reference/client/#synapseclient.Synapse.clear_download_list","title":"<code>clear_download_list()</code>","text":"<p>Clear all files from download list</p> Source code in <code>synapseclient/client.py</code> <pre><code>def clear_download_list(self):\n    \"\"\"Clear all files from download list\"\"\"\n    self.restDELETE(\"/download/list\")\n</code></pre>"},{"location":"reference/client/#synapseclient.Synapse.create_external_s3_file_handle","title":"<code>create_external_s3_file_handle(bucket_name, s3_file_key, file_path, *, parent=None, storage_location_id=None, mimetype=None, md5=None)</code>","text":"<p>Create an external S3 file handle for e.g. a file that has been uploaded directly to an external S3 storage location.</p> PARAMETER DESCRIPTION <code>bucket_name</code> <p>Name of the S3 bucket</p> <p> </p> <code>s3_file_key</code> <p>S3 key of the uploaded object</p> <p> </p> <code>file_path</code> <p>Local path of the uploaded file</p> <p> </p> <code>parent</code> <p>Parent entity to create the file handle in, the file handle will be created     in the default storage location of the parent. Mutually exclusive with     storage_location_id</p> <p> DEFAULT: <code>None</code> </p> <code>storage_location_id</code> <p>Explicit storage location id to create the file handle in, mutually exclusive     with parent</p> <p> DEFAULT: <code>None</code> </p> <code>mimetype</code> <p>Mimetype of the file, if known</p> <p> DEFAULT: <code>None</code> </p> <code>md5</code> <p>MD5 of the file, if known</p> <p> TYPE: <code>str</code> DEFAULT: <code>None</code> </p> RAISES DESCRIPTION <code>ValueError</code> <p>If neither parent nor storage_location_id is specified, or if both are specified.</p> Source code in <code>synapseclient/client.py</code> <pre><code>def create_external_s3_file_handle(\n    self,\n    bucket_name,\n    s3_file_key,\n    file_path,\n    *,\n    parent=None,\n    storage_location_id=None,\n    mimetype=None,\n    md5: str = None,\n):\n    \"\"\"\n    Create an external S3 file handle for e.g. a file that has been uploaded directly to\n    an external S3 storage location.\n\n    Arguments:\n        bucket_name: Name of the S3 bucket\n        s3_file_key: S3 key of the uploaded object\n        file_path: Local path of the uploaded file\n        parent: Parent entity to create the file handle in, the file handle will be created\n                in the default storage location of the parent. Mutually exclusive with\n                storage_location_id\n        storage_location_id: Explicit storage location id to create the file handle in, mutually exclusive\n                with parent\n        mimetype: Mimetype of the file, if known\n        md5: MD5 of the file, if known\n\n    Raises:\n        ValueError: If neither parent nor storage_location_id is specified, or if both are specified.\n    \"\"\"\n\n    if storage_location_id:\n        if parent:\n            raise ValueError(\"Pass parent or storage_location_id, not both\")\n    elif not parent:\n        raise ValueError(\"One of parent or storage_location_id is required\")\n    else:\n        upload_destination = self._getDefaultUploadDestination(parent)\n        storage_location_id = upload_destination[\"storageLocationId\"]\n\n    if mimetype is None:\n        mimetype, _ = mimetypes.guess_type(file_path, strict=False)\n\n    file_handle = {\n        \"concreteType\": concrete_types.S3_FILE_HANDLE,\n        \"key\": s3_file_key,\n        \"bucketName\": bucket_name,\n        \"fileName\": os.path.basename(file_path),\n        \"contentMd5\": md5 or utils.md5_for_file(file_path).hexdigest(),\n        \"contentSize\": os.stat(file_path).st_size,\n        \"storageLocationId\": storage_location_id,\n        \"contentType\": mimetype,\n    }\n\n    return self.restPOST(\n        \"/externalFileHandle/s3\",\n        json.dumps(file_handle),\n        endpoint=self.fileHandleEndpoint,\n    )\n</code></pre>"},{"location":"reference/client/#synapseclient.Synapse.getMyStorageLocationSetting","title":"<code>getMyStorageLocationSetting(storage_location_id)</code>","text":"<p>Get a StorageLocationSetting by its id.</p> PARAMETER DESCRIPTION <code>storage_location_id</code> <p>id of the StorageLocationSetting to retrieve.                     The corresponding StorageLocationSetting must have been created by this user.</p> <p> </p> RETURNS DESCRIPTION <p>A dict describing the StorageLocationSetting retrieved by its id</p> Source code in <code>synapseclient/client.py</code> <pre><code>def getMyStorageLocationSetting(self, storage_location_id):\n    \"\"\"\n    Get a StorageLocationSetting by its id.\n\n    Arguments:\n        storage_location_id: id of the StorageLocationSetting to retrieve.\n                                The corresponding StorageLocationSetting must have been created by this user.\n\n    Returns:\n        A dict describing the StorageLocationSetting retrieved by its id\n    \"\"\"\n    return self.restGET(\"/storageLocation/%s\" % storage_location_id)\n</code></pre>"},{"location":"reference/client/#synapseclient.Synapse.createStorageLocationSetting","title":"<code>createStorageLocationSetting(storage_type, **kwargs)</code>","text":"<p>Creates an IMMUTABLE storage location based on the specified type.</p> <p>For each storage_type, the following kwargs should be specified:</p> <p>ExternalObjectStorage: (S3-like (e.g. AWS S3 or Openstack) bucket not accessed by Synapse)</p> <ul> <li><code>endpointUrl</code>: endpoint URL of the S3 service (for example: 'https://s3.amazonaws.com')</li> <li><code>bucket</code>: the name of the bucket to use</li> </ul> <p>ExternalS3Storage: (Amazon S3 bucket accessed by Synapse)</p> <ul> <li><code>bucket</code>: the name of the bucket to use</li> </ul> <p>ExternalStorage: (SFTP or FTP storage location not accessed by Synapse)</p> <ul> <li><code>url</code>: the base URL for uploading to the external destination</li> <li><code>supportsSubfolders(optional)</code>: does the destination support creating subfolders under the base url     (default: false)</li> </ul> <p>ProxyStorage: (a proxy server that controls access to a storage)</p> <ul> <li><code>secretKey</code>: The encryption key used to sign all pre-signed URLs used to communicate with the proxy.</li> <li><code>proxyUrl</code>: The HTTPS URL of the proxy used for upload and download.</li> </ul> PARAMETER DESCRIPTION <code>storage_type</code> <p>The type of the StorageLocationSetting to create</p> <p> </p> <code>banner</code> <p>(Optional) The optional banner to show every time a file is uploaded</p> <p> </p> <code>description</code> <p>(Optional) The description to show the user when the user has to choose which upload destination to use</p> <p> </p> <code>kwargs</code> <p>fields necessary for creation of the specified storage_type</p> <p> DEFAULT: <code>{}</code> </p> RETURNS DESCRIPTION <p>A dict of the created StorageLocationSetting</p> Source code in <code>synapseclient/client.py</code> <pre><code>def createStorageLocationSetting(self, storage_type, **kwargs):\n    \"\"\"\n    Creates an IMMUTABLE storage location based on the specified type.\n\n    For each storage_type, the following kwargs should be specified:\n\n    **ExternalObjectStorage**: (S3-like (e.g. AWS S3 or Openstack) bucket not accessed by Synapse)\n\n    - `endpointUrl`: endpoint URL of the S3 service (for example: 'https://s3.amazonaws.com')\n    - `bucket`: the name of the bucket to use\n\n    **ExternalS3Storage**: (Amazon S3 bucket accessed by Synapse)\n\n    - `bucket`: the name of the bucket to use\n\n    **ExternalStorage**: (SFTP or FTP storage location not accessed by Synapse)\n\n    - `url`: the base URL for uploading to the external destination\n    - `supportsSubfolders(optional)`: does the destination support creating subfolders under the base url\n        (default: false)\n\n    **ProxyStorage**: (a proxy server that controls access to a storage)\n\n    - `secretKey`: The encryption key used to sign all pre-signed URLs used to communicate with the proxy.\n    - `proxyUrl`: The HTTPS URL of the proxy used for upload and download.\n\n    Arguments:\n        storage_type: The type of the StorageLocationSetting to create\n        banner: (Optional) The optional banner to show every time a file is uploaded\n        description: (Optional) The description to show the user when the user has to choose which upload destination to use\n        kwargs: fields necessary for creation of the specified storage_type\n\n    Returns:\n        A dict of the created StorageLocationSetting\n    \"\"\"\n    upload_type_dict = {\n        \"ExternalObjectStorage\": \"S3\",\n        \"ExternalS3Storage\": \"S3\",\n        \"ExternalStorage\": \"SFTP\",\n        \"ProxyStorage\": \"PROXYLOCAL\",\n    }\n\n    if storage_type not in upload_type_dict:\n        raise ValueError(\"Unknown storage_type: %s\", storage_type)\n\n    # ProxyStorageLocationSettings has an extra 's' at the end &gt;:(\n    kwargs[\"concreteType\"] = (\n        \"org.sagebionetworks.repo.model.project.\"\n        + storage_type\n        + \"LocationSetting\"\n        + (\"s\" if storage_type == \"ProxyStorage\" else \"\")\n    )\n    kwargs[\"uploadType\"] = upload_type_dict[storage_type]\n\n    return self.restPOST(\"/storageLocation\", body=json.dumps(kwargs))\n</code></pre>"},{"location":"reference/client/#synapseclient.Synapse.create_s3_storage_location","title":"<code>create_s3_storage_location(*, parent=None, folder_name=None, folder=None, bucket_name=None, base_key=None, sts_enabled=False)</code>","text":"<p>Create a storage location in the given parent, either in the given folder or by creating a new folder in that parent with the given name. This will both create a StorageLocationSetting, and a ProjectSetting together, optionally creating a new folder in which to locate it, and optionally enabling this storage location for access via STS. If enabling an existing folder for STS, it must be empty.</p> PARAMETER DESCRIPTION <code>parent</code> <p>The parent in which to locate the storage location (mutually exclusive with folder)</p> <p> DEFAULT: <code>None</code> </p> <code>folder_name</code> <p>The name of a new folder to create (mutually exclusive with folder)</p> <p> DEFAULT: <code>None</code> </p> <code>folder</code> <p>The existing folder in which to create the storage location (mutually exclusive with folder_name)</p> <p> DEFAULT: <code>None</code> </p> <code>bucket_name</code> <p>The name of an S3 bucket, if this is an external storage location,             if None will use Synapse S3 storage</p> <p> DEFAULT: <code>None</code> </p> <code>base_key</code> <p>The base key of within the bucket, None to use the bucket root,             only applicable if bucket_name is passed</p> <p> DEFAULT: <code>None</code> </p> <code>sts_enabled</code> <p>Whether this storage location should be STS enabled</p> <p> DEFAULT: <code>False</code> </p> RETURNS DESCRIPTION <code>Tuple[Folder, Dict[str, str], Dict[str, str]]</code> <p>A 3-tuple of the synapse Folder, a the storage location setting, and the project setting dictionaries.</p> Source code in <code>synapseclient/client.py</code> <pre><code>def create_s3_storage_location(\n    self,\n    *,\n    parent=None,\n    folder_name=None,\n    folder=None,\n    bucket_name=None,\n    base_key=None,\n    sts_enabled=False,\n) -&gt; Tuple[Folder, Dict[str, str], Dict[str, str]]:\n    \"\"\"\n    Create a storage location in the given parent, either in the given folder or by creating a new\n    folder in that parent with the given name. This will both create a StorageLocationSetting,\n    and a ProjectSetting together, optionally creating a new folder in which to locate it,\n    and optionally enabling this storage location for access via STS. If enabling an existing folder for STS,\n    it must be empty.\n\n    Arguments:\n        parent: The parent in which to locate the storage location (mutually exclusive with folder)\n        folder_name: The name of a new folder to create (mutually exclusive with folder)\n        folder: The existing folder in which to create the storage location (mutually exclusive with folder_name)\n        bucket_name: The name of an S3 bucket, if this is an external storage location,\n                        if None will use Synapse S3 storage\n        base_key: The base key of within the bucket, None to use the bucket root,\n                        only applicable if bucket_name is passed\n        sts_enabled: Whether this storage location should be STS enabled\n\n    Returns:\n        A 3-tuple of the synapse Folder, a the storage location setting, and the project setting dictionaries.\n    \"\"\"\n    if folder_name and parent:\n        if folder:\n            raise ValueError(\n                \"folder and  folder_name are mutually exclusive, only one should be passed\"\n            )\n\n        folder = self.store(Folder(name=folder_name, parent=parent))\n\n    elif not folder:\n        raise ValueError(\"either folder or folder_name should be required\")\n\n    storage_location_kwargs = {\n        \"uploadType\": \"S3\",\n        \"stsEnabled\": sts_enabled,\n    }\n\n    if bucket_name:\n        storage_location_kwargs[\n            \"concreteType\"\n        ] = concrete_types.EXTERNAL_S3_STORAGE_LOCATION_SETTING\n        storage_location_kwargs[\"bucket\"] = bucket_name\n        if base_key:\n            storage_location_kwargs[\"baseKey\"] = base_key\n    else:\n        storage_location_kwargs[\n            \"concreteType\"\n        ] = concrete_types.SYNAPSE_S3_STORAGE_LOCATION_SETTING\n\n    storage_location_setting = self.restPOST(\n        \"/storageLocation\", json.dumps(storage_location_kwargs)\n    )\n\n    storage_location_id = storage_location_setting[\"storageLocationId\"]\n    project_setting = self.setStorageLocation(\n        folder,\n        storage_location_id,\n    )\n\n    return folder, storage_location_setting, project_setting\n</code></pre>"},{"location":"reference/client/#synapseclient.Synapse.setStorageLocation","title":"<code>setStorageLocation(entity, storage_location_id)</code>","text":"<p>Sets the storage location for a Project or Folder</p> PARAMETER DESCRIPTION <code>entity</code> <p>A Project or Folder to which the StorageLocationSetting is set</p> <p> </p> <code>storage_location_id</code> <p>A StorageLocation id or a list of StorageLocation ids. Pass in None for the default                     Synapse storage.</p> <p> </p> RETURNS DESCRIPTION <p>The created or updated settings as a dict.</p> Source code in <code>synapseclient/client.py</code> <pre><code>def setStorageLocation(self, entity, storage_location_id):\n    \"\"\"\n    Sets the storage location for a Project or Folder\n\n    Arguments:\n        entity: A Project or Folder to which the StorageLocationSetting is set\n        storage_location_id: A StorageLocation id or a list of StorageLocation ids. Pass in None for the default\n                                Synapse storage.\n\n    Returns:\n        The created or updated settings as a dict.\n    \"\"\"\n    if storage_location_id is None:\n        storage_location_id = DEFAULT_STORAGE_LOCATION_ID\n    locations = (\n        storage_location_id\n        if isinstance(storage_location_id, list)\n        else [storage_location_id]\n    )\n\n    existing_setting = self.getProjectSetting(entity, \"upload\")\n    if existing_setting is not None:\n        existing_setting[\"locations\"] = locations\n        self.restPUT(\"/projectSettings\", body=json.dumps(existing_setting))\n        return self.getProjectSetting(entity, \"upload\")\n    else:\n        project_destination = {\n            \"concreteType\": \"org.sagebionetworks.repo.model.project.UploadDestinationListSetting\",\n            \"settingsType\": \"upload\",\n            \"locations\": locations,\n            \"projectId\": id_of(entity),\n        }\n\n        return self.restPOST(\n            \"/projectSettings\", body=json.dumps(project_destination)\n        )\n</code></pre>"},{"location":"reference/client/#synapseclient.Synapse.get_sts_storage_token","title":"<code>get_sts_storage_token(entity, permission, *, output_format='json', min_remaining_life=None)</code>","text":"<p>Get STS credentials for the given entity_id and permission, outputting it in the given format</p> PARAMETER DESCRIPTION <code>entity</code> <p>The entity or entity id whose credentials are being returned</p> <p> </p> <code>permission</code> <p>One of:</p> <ul> <li><code>read_only</code></li> <li><code>read_write</code></li> </ul> <p> </p> <code>output_format</code> <p>One of:</p> <ul> <li><code>json</code>: the dictionary returned from the Synapse STS API including expiration</li> <li><code>boto</code>: a dictionary compatible with a boto session (aws_access_key_id, etc)</li> <li><code>shell</code>: output commands for exporting credentials appropriate for the detected shell</li> <li><code>bash</code>: output commands for exporting credentials into a bash shell</li> <li><code>cmd</code>: output commands for exporting credentials into a windows cmd shell</li> <li><code>powershell</code>: output commands for exporting credentials into a windows powershell</li> </ul> <p> DEFAULT: <code>'json'</code> </p> <code>min_remaining_life</code> <p>The minimum allowable remaining life on a cached token to return. If a cached token                 has left than this amount of time left a fresh token will be fetched</p> <p> DEFAULT: <code>None</code> </p> Source code in <code>synapseclient/client.py</code> <pre><code>def get_sts_storage_token(\n    self, entity, permission, *, output_format=\"json\", min_remaining_life=None\n):\n    \"\"\"Get STS credentials for the given entity_id and permission, outputting it in the given format\n\n    Arguments:\n        entity: The entity or entity id whose credentials are being returned\n        permission: One of:\n\n            - `read_only`\n            - `read_write`\n\n        output_format: One of:\n\n            - `json`: the dictionary returned from the Synapse STS API including expiration\n            - `boto`: a dictionary compatible with a boto session (aws_access_key_id, etc)\n            - `shell`: output commands for exporting credentials appropriate for the detected shell\n            - `bash`: output commands for exporting credentials into a bash shell\n            - `cmd`: output commands for exporting credentials into a windows cmd shell\n            - `powershell`: output commands for exporting credentials into a windows powershell\n\n        min_remaining_life: The minimum allowable remaining life on a cached token to return. If a cached token\n                            has left than this amount of time left a fresh token will be fetched\n    \"\"\"\n    return sts_transfer.get_sts_credentials(\n        self,\n        id_of(entity),\n        permission,\n        output_format=output_format,\n        min_remaining_life=min_remaining_life,\n    )\n</code></pre>"},{"location":"reference/client/#synapseclient.Synapse.create_snapshot_version","title":"<code>create_snapshot_version(table, comment=None, label=None, activity=None, wait=True)</code>","text":"<p>Create a new Table Version, new View version, or new Dataset version.</p> PARAMETER DESCRIPTION <code>table</code> <p>The schema of the Table/View, or its ID.</p> <p> TYPE: <code>Union[EntityViewSchema, Schema, str, SubmissionViewSchema, Dataset]</code> </p> <code>comment</code> <p>Optional snapshot comment.</p> <p> TYPE: <code>str</code> DEFAULT: <code>None</code> </p> <code>label</code> <p>Optional snapshot label.</p> <p> TYPE: <code>str</code> DEFAULT: <code>None</code> </p> <code>activity</code> <p>Optional activity ID applied to snapshot version.</p> <p> TYPE: <code>Union[Activity, str]</code> DEFAULT: <code>None</code> </p> <code>wait</code> <p>True if this method should return the snapshot version after waiting for any necessary     asynchronous table updates to complete. If False this method will return     as soon as any updates are initiated.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> RETURNS DESCRIPTION <code>int</code> <p>The snapshot version number if wait=True, None if wait=False</p> Source code in <code>synapseclient/client.py</code> <pre><code>def create_snapshot_version(\n    self,\n    table: typing.Union[\n        EntityViewSchema, Schema, str, SubmissionViewSchema, Dataset\n    ],\n    comment: str = None,\n    label: str = None,\n    activity: typing.Union[Activity, str] = None,\n    wait: bool = True,\n) -&gt; int:\n    \"\"\"Create a new Table Version, new View version, or new Dataset version.\n\n    Arguments:\n        table: The schema of the Table/View, or its ID.\n        comment: Optional snapshot comment.\n        label: Optional snapshot label.\n        activity: Optional activity ID applied to snapshot version.\n        wait: True if this method should return the snapshot version after waiting for any necessary\n                asynchronous table updates to complete. If False this method will return\n                as soon as any updates are initiated.\n\n    Returns:\n        The snapshot version number if wait=True, None if wait=False\n    \"\"\"\n    ent = self.get(id_of(table), downloadFile=False)\n    if isinstance(ent, (EntityViewSchema, SubmissionViewSchema, Dataset)):\n        result = self._async_table_update(\n            table,\n            create_snapshot=True,\n            comment=comment,\n            label=label,\n            activity=activity,\n            wait=wait,\n        )\n    elif isinstance(ent, Schema):\n        result = self._create_table_snapshot(\n            table,\n            comment=comment,\n            label=label,\n            activity=activity,\n        )\n    else:\n        raise ValueError(\n            \"This function only accepts Synapse ids of Tables or Views\"\n        )\n\n    # for consistency we return nothing if wait=False since we can't\n    # supply the snapshot version on an async table update without waiting\n    return result[\"snapshotVersionNumber\"] if wait else None\n</code></pre>"},{"location":"reference/client/#synapseclient.Synapse.getConfigFile","title":"<code>getConfigFile(configPath)</code>  <code>cached</code>","text":"<p>Retrieves the client configuration information.</p> PARAMETER DESCRIPTION <code>configPath</code> <p>Path to configuration file on local file system</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>RawConfigParser</code> <p>A RawConfigParser populated with properties from the user's configuration file.</p> Source code in <code>synapseclient/client.py</code> <pre><code>@deprecated(\n    version=\"4.4.0\",\n    reason=\"To be removed in 5.0.0. \"\n    \"Moved to synapseclient/api/configuration_services.py::get_config_file\",\n)\n@functools.lru_cache()\ndef getConfigFile(self, configPath: str) -&gt; configparser.RawConfigParser:\n    \"\"\"\n    Retrieves the client configuration information.\n\n    Arguments:\n        configPath:  Path to configuration file on local file system\n\n    Returns:\n        A RawConfigParser populated with properties from the user's configuration file.\n    \"\"\"\n\n    try:\n        config = configparser.RawConfigParser()\n        config.read(configPath)  # Does not fail if the file does not exist\n        return config\n    except configparser.Error as ex:\n        raise ValueError(\n            \"Error parsing Synapse config file: {}\".format(configPath)\n        ) from ex\n</code></pre>"},{"location":"reference/client/#synapseclient.Synapse.getEvaluation","title":"<code>getEvaluation(id)</code>","text":"<p>Gets an Evaluation object from Synapse.</p> PARAMETER DESCRIPTION <code>id</code> <p>The ID of the synapseclient.evaluation.Evaluation to return.</p> <p> </p> RETURNS DESCRIPTION <p>An synapseclient.evaluation.Evaluation object</p> Using this function <p>Creating an Evaluation instance</p> <pre><code>evaluation = syn.getEvaluation(2005090)\n</code></pre> Source code in <code>synapseclient/client.py</code> <pre><code>def getEvaluation(self, id):\n    \"\"\"\n    Gets an Evaluation object from Synapse.\n\n    Arguments:\n        id: The ID of the [synapseclient.evaluation.Evaluation][] to return.\n\n    Returns:\n        An [synapseclient.evaluation.Evaluation][] object\n\n    Example: Using this function\n        Creating an Evaluation instance\n\n            evaluation = syn.getEvaluation(2005090)\n    \"\"\"\n\n    evaluation_id = id_of(id)\n    uri = Evaluation.getURI(evaluation_id)\n    return Evaluation(**self.restGET(uri))\n</code></pre>"},{"location":"reference/client/#synapseclient.Synapse.getEvaluationByContentSource","title":"<code>getEvaluationByContentSource(entity)</code>","text":"<p>Returns a generator over evaluations that derive their content from the given entity</p> PARAMETER DESCRIPTION <code>entity</code> <p>The synapseclient.entity.Project whose Evaluations are to be fetched.</p> <p> </p> YIELDS DESCRIPTION <p>A generator over synapseclient.evaluation.Evaluation objects for the given synapseclient.entity.Project.</p> Source code in <code>synapseclient/client.py</code> <pre><code>def getEvaluationByContentSource(self, entity):\n    \"\"\"\n    Returns a generator over evaluations that derive their content from the given entity\n\n    Arguments:\n        entity: The [synapseclient.entity.Project][] whose Evaluations are to be fetched.\n\n    Yields:\n        A generator over [synapseclient.evaluation.Evaluation][] objects for the given [synapseclient.entity.Project][].\n    \"\"\"\n\n    entityId = id_of(entity)\n    url = \"/entity/%s/evaluation\" % entityId\n\n    for result in self._GET_paginated(url):\n        yield Evaluation(**result)\n</code></pre>"},{"location":"reference/client/#synapseclient.Synapse.getEvaluationByName","title":"<code>getEvaluationByName(name)</code>","text":"<p>Gets an Evaluation object from Synapse.</p> PARAMETER DESCRIPTION <code>Name</code> <p>The name of the synapseclient.evaluation.Evaluation to return.</p> <p> </p> RETURNS DESCRIPTION <p>An synapseclient.evaluation.Evaluation object</p> Source code in <code>synapseclient/client.py</code> <pre><code>def getEvaluationByName(self, name):\n    \"\"\"\n    Gets an Evaluation object from Synapse.\n\n    Arguments:\n        Name: The name of the [synapseclient.evaluation.Evaluation][] to return.\n\n    Returns:\n        An [synapseclient.evaluation.Evaluation][] object\n    \"\"\"\n    uri = Evaluation.getByNameURI(name)\n    return Evaluation(**self.restGET(uri))\n</code></pre>"},{"location":"reference/client/#synapseclient.Synapse.create_team","title":"<code>create_team(name, description=None, icon=None, can_public_join=False, can_request_membership=True)</code>","text":"<p>Creates a new team.</p> PARAMETER DESCRIPTION <code>name</code> <p>The name of the team to create.</p> <p> TYPE: <code>str</code> </p> <code>description</code> <p>A description of the team.</p> <p> TYPE: <code>str</code> DEFAULT: <code>None</code> </p> <code>icon</code> <p>The FileHandleID of the icon to be used for the team.</p> <p> TYPE: <code>str</code> DEFAULT: <code>None</code> </p> <code>canPublicJoin</code> <p>Whether the team can be joined by anyone. Defaults to False.</p> <p> </p> <code>canRequestMembership</code> <p>Whether the team can request membership. Defaults to True.</p> <p> </p> RETURNS DESCRIPTION <code>Team</code> <p>An object of type synapseclient.team.Team</p> Source code in <code>synapseclient/client.py</code> <pre><code>def create_team(\n    self,\n    name: str,\n    description: str = None,\n    icon: str = None,\n    can_public_join: bool = False,\n    can_request_membership: bool = True,\n) -&gt; Team:\n    \"\"\"\n    Creates a new team.\n\n    Arguments:\n        name: The name of the team to create.\n        description: A description of the team.\n        icon: The FileHandleID of the icon to be used for the team.\n        canPublicJoin: Whether the team can be joined by anyone. Defaults to False.\n        canRequestMembership: Whether the team can request membership. Defaults to True.\n\n    Returns:\n        An object of type [synapseclient.team.Team][]\n    \"\"\"\n    request_body = {\n        \"name\": name,\n        \"description\": description,\n        \"icon\": icon,\n        \"canPublicJoin\": can_public_join,\n        \"canRequestMembership\": can_request_membership,\n    }\n    return Team(\n        **self.restPOST(\n            \"/team\",\n            json.dumps(request_body),\n        )\n    )\n</code></pre>"},{"location":"reference/client/#synapseclient.Synapse.delete_team","title":"<code>delete_team(id)</code>","text":"<p>Deletes a team.</p> PARAMETER DESCRIPTION <code>id</code> <p>The ID of the team to delete.</p> <p> TYPE: <code>int</code> </p> Source code in <code>synapseclient/client.py</code> <pre><code>def delete_team(self, id: int) -&gt; None:\n    \"\"\"\n    Deletes a team.\n\n    Arguments:\n        id: The ID of the team to delete.\n\n    \"\"\"\n    return self.restDELETE(f\"/team/{id}\")\n</code></pre>"},{"location":"reference/client/#synapseclient.Synapse.getProjectSetting","title":"<code>getProjectSetting(project, setting_type)</code>","text":"<p>Gets the ProjectSetting for a project.</p> PARAMETER DESCRIPTION <code>project</code> <p>Project entity or its id as a string</p> <p> </p> <code>setting_type</code> <p>Type of setting. Choose from:</p> <ul> <li><code>upload</code></li> <li><code>external_sync</code></li> <li><code>requester_pays</code></li> </ul> <p> </p> RETURNS DESCRIPTION <p>The ProjectSetting as a dict or None if no settings of the specified type exist.</p> Source code in <code>synapseclient/client.py</code> <pre><code>def getProjectSetting(self, project, setting_type):\n    \"\"\"\n    Gets the ProjectSetting for a project.\n\n    Arguments:\n        project: Project entity or its id as a string\n        setting_type: Type of setting. Choose from:\n\n            - `upload`\n            - `external_sync`\n            - `requester_pays`\n\n    Returns:\n        The ProjectSetting as a dict or None if no settings of the specified type exist.\n    \"\"\"\n    if setting_type not in {\"upload\", \"external_sync\", \"requester_pays\"}:\n        raise ValueError(\"Invalid project_type: %s\" % setting_type)\n\n    response = self.restGET(\n        \"/projectSettings/{projectId}/type/{type}\".format(\n            projectId=id_of(project), type=setting_type\n        )\n    )\n    return (\n        response if response else None\n    )  # if no project setting, a empty string is returned as the response\n</code></pre>"},{"location":"reference/client/#synapseclient.Synapse.getSubmission","title":"<code>getSubmission(id, **kwargs)</code>","text":"<p>Gets a synapseclient.evaluation.Submission object by its id.</p> PARAMETER DESCRIPTION <code>id</code> <p>The id of the submission to retrieve</p> <p> </p> RETURNS DESCRIPTION <p>A synapseclient.evaluation.Submission object</p> <p>See:</p> <ul> <li>synapseclient.Synapse.get for information      on the downloadFile, downloadLocation, and ifcollision parameters</li> </ul> Source code in <code>synapseclient/client.py</code> <pre><code>def getSubmission(self, id, **kwargs):\n    \"\"\"\n    Gets a [synapseclient.evaluation.Submission][] object by its id.\n\n    Arguments:\n        id: The id of the submission to retrieve\n\n    Returns:\n        A [synapseclient.evaluation.Submission][] object\n\n    See:\n\n    - [synapseclient.Synapse.get][] for information\n         on the *downloadFile*, *downloadLocation*, and *ifcollision* parameters\n    \"\"\"\n\n    submission_id = id_of(id)\n    uri = Submission.getURI(submission_id)\n    submission = Submission(**self.restGET(uri))\n\n    # Pre-fetch the Entity tied to the Submission, if there is one\n    if \"entityId\" in submission and submission[\"entityId\"] is not None:\n        entityBundleJSON = json.loads(submission[\"entityBundleJSON\"])\n\n        # getWithEntityBundle expects a bundle services v2 style\n        # annotations dict, but the evaluations API may return\n        # an older format annotations object in the encoded JSON\n        # depending on when the original submission was made.\n        annotations = entityBundleJSON.get(\"annotations\")\n        if annotations:\n            entityBundleJSON[\"annotations\"] = convert_old_annotation_json(\n                annotations\n            )\n\n        related = self._getWithEntityBundle(\n            entityBundle=entityBundleJSON,\n            entity=submission[\"entityId\"],\n            submission=submission_id,\n            **kwargs,\n        )\n        submission.entity = related\n        submission.filePath = related.get(\"path\", None)\n\n    return submission\n</code></pre>"},{"location":"reference/client/#synapseclient.Synapse.getSubmissions","title":"<code>getSubmissions(evaluation, status=None, myOwn=False, limit=20, offset=0)</code>","text":"PARAMETER DESCRIPTION <code>evaluation</code> <p>Evaluation to get submissions from.</p> <p> </p> <code>status</code> <p>Optionally filter submissions for a specific status.     One of:</p> <ul> <li><code>OPEN</code></li> <li><code>CLOSED</code></li> <li><code>SCORED</code></li> <li><code>INVALID</code></li> <li><code>VALIDATED</code></li> <li><code>EVALUATION_IN_PROGRESS</code></li> <li><code>RECEIVED</code></li> <li><code>REJECTED</code></li> <li><code>ACCEPTED</code></li> </ul> <p> DEFAULT: <code>None</code> </p> <code>myOwn</code> <p>Determines if only your Submissions should be fetched.      Defaults to False (all Submissions)</p> <p> DEFAULT: <code>False</code> </p> <code>limit</code> <p>Limits the number of submissions in a single response.         Because this method returns a generator and repeatedly         fetches submissions, this argument is limiting the         size of a single request and NOT the number of sub-         missions returned in total.</p> <p> DEFAULT: <code>20</code> </p> <code>offset</code> <p>Start iterating at a submission offset from the first submission.</p> <p> DEFAULT: <code>0</code> </p> YIELDS DESCRIPTION <p>A generator over synapseclient.evaluation.Submission objects for an Evaluation</p> Using this function <p>Print submissions</p> <pre><code>for submission in syn.getSubmissions(1234567):\n    print(submission['entityId'])\n</code></pre> <p>See:</p> <ul> <li>synapseclient.evaluation</li> </ul> Source code in <code>synapseclient/client.py</code> <pre><code>def getSubmissions(self, evaluation, status=None, myOwn=False, limit=20, offset=0):\n    \"\"\"\n    Arguments:\n        evaluation: Evaluation to get submissions from.\n        status: Optionally filter submissions for a specific status.\n                One of:\n\n            - `OPEN`\n            - `CLOSED`\n            - `SCORED`\n            - `INVALID`\n            - `VALIDATED`\n            - `EVALUATION_IN_PROGRESS`\n            - `RECEIVED`\n            - `REJECTED`\n            - `ACCEPTED`\n\n        myOwn: Determines if only your Submissions should be fetched.\n                 Defaults to False (all Submissions)\n        limit: Limits the number of submissions in a single response.\n                    Because this method returns a generator and repeatedly\n                    fetches submissions, this argument is limiting the\n                    size of a single request and NOT the number of sub-\n                    missions returned in total.\n        offset: Start iterating at a submission offset from the first submission.\n\n    Yields:\n        A generator over [synapseclient.evaluation.Submission][] objects for an Evaluation\n\n    Example: Using this function\n        Print submissions\n\n            for submission in syn.getSubmissions(1234567):\n                print(submission['entityId'])\n\n    See:\n\n    - [synapseclient.evaluation][]\n    \"\"\"\n\n    evaluation_id = id_of(evaluation)\n    uri = \"/evaluation/%s/submission%s\" % (evaluation_id, \"\" if myOwn else \"/all\")\n\n    if status is not None:\n        uri += \"?status=%s\" % status\n\n    for result in self._GET_paginated(uri, limit=limit, offset=offset):\n        yield Submission(**result)\n</code></pre>"},{"location":"reference/client/#synapseclient.Synapse.getSubmissionBundles","title":"<code>getSubmissionBundles(evaluation, status=None, myOwn=False, limit=20, offset=0)</code>","text":"<p>Retrieve submission bundles (submission and submissions status) for an evaluation queue, optionally filtered by submission status and/or owner.</p> PARAMETER DESCRIPTION <code>evaluation</code> <p>Evaluation to get submissions from.</p> <p> </p> <code>status</code> <p>Optionally filter submissions for a specific status.         One of:</p> <ul> <li><code>OPEN</code></li> <li><code>CLOSED</code></li> <li><code>SCORED</code></li> <li><code>INVALID</code></li> </ul> <p> DEFAULT: <code>None</code> </p> <code>myOwn</code> <p>Determines if only your Submissions should be fetched.         Defaults to False (all Submissions)</p> <p> DEFAULT: <code>False</code> </p> <code>limit</code> <p>Limits the number of submissions coming back from the         service in a single response.</p> <p> DEFAULT: <code>20</code> </p> <code>offset</code> <p>Start iterating at a submission offset from the first submission.</p> <p> DEFAULT: <code>0</code> </p> YIELDS DESCRIPTION <p>A generator over tuples containing a synapseclient.evaluation.Submission and a synapseclient.evaluation.SubmissionStatus.</p> Using this function <p>Loop over submissions</p> <pre><code>for submission, status in syn.getSubmissionBundles(evaluation):\n    print(submission.name,\n          submission.submitterAlias,\n          status.status,\n          status.score)\n</code></pre> <p>This may later be changed to return objects, pending some thought on how submissions along with related status and annotations should be represented in the clients.</p> <p>See: - synapseclient.evaluation</p> Source code in <code>synapseclient/client.py</code> <pre><code>def getSubmissionBundles(\n    self, evaluation, status=None, myOwn=False, limit=20, offset=0\n):\n    \"\"\"\n    Retrieve submission bundles (submission and submissions status) for an evaluation queue, optionally filtered by\n    submission status and/or owner.\n\n    Arguments:\n        evaluation: Evaluation to get submissions from.\n        status:     Optionally filter submissions for a specific status.\n                    One of:\n\n            - `OPEN`\n            - `CLOSED`\n            - `SCORED`\n            - `INVALID`\n\n        myOwn:      Determines if only your Submissions should be fetched.\n                    Defaults to False (all Submissions)\n        limit:      Limits the number of submissions coming back from the\n                    service in a single response.\n        offset:     Start iterating at a submission offset from the first submission.\n\n    Yields:\n        A generator over tuples containing a [synapseclient.evaluation.Submission][] and a [synapseclient.evaluation.SubmissionStatus][].\n\n    Example: Using this function\n        Loop over submissions\n\n            for submission, status in syn.getSubmissionBundles(evaluation):\n                print(submission.name,\n                      submission.submitterAlias,\n                      status.status,\n                      status.score)\n\n    This may later be changed to return objects, pending some thought on how submissions along with related status\n    and annotations should be represented in the clients.\n\n    See:\n    - [synapseclient.evaluation][]\n    \"\"\"\n    for bundle in self._getSubmissionBundles(\n        evaluation, status=status, myOwn=myOwn, limit=limit, offset=offset\n    ):\n        yield (\n            Submission(**bundle[\"submission\"]),\n            SubmissionStatus(**bundle[\"submissionStatus\"]),\n        )\n</code></pre>"},{"location":"reference/client/#synapseclient.Synapse.getSubmissionStatus","title":"<code>getSubmissionStatus(submission)</code>","text":"<p>Downloads the status of a Submission.</p> PARAMETER DESCRIPTION <code>submission</code> <p>The submission to lookup</p> <p> </p> RETURNS DESCRIPTION <p>A synapseclient.evaluation.SubmissionStatus object</p> Source code in <code>synapseclient/client.py</code> <pre><code>def getSubmissionStatus(self, submission):\n    \"\"\"\n    Downloads the status of a Submission.\n\n    Arguments:\n        submission: The submission to lookup\n\n    Returns:\n        A [synapseclient.evaluation.SubmissionStatus][] object\n    \"\"\"\n\n    submission_id = id_of(submission)\n    uri = SubmissionStatus.getURI(submission_id)\n    val = self.restGET(uri)\n    return SubmissionStatus(**val)\n</code></pre>"},{"location":"reference/client/#synapseclient.Synapse.getWiki","title":"<code>getWiki(owner, subpageId=None, version=None)</code>","text":"<p>Get a synapseclient.wiki.Wiki object from Synapse. Uses wiki2 API which supports versioning.</p> PARAMETER DESCRIPTION <code>owner</code> <p>The entity to which the Wiki is attached</p> <p> </p> <code>subpageId</code> <p>The id of the specific sub-page or None to get the root Wiki page</p> <p> DEFAULT: <code>None</code> </p> <code>version</code> <p>The version of the page to retrieve or None to retrieve the latest</p> <p> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <p>A synapseclient.wiki.Wiki object</p> Source code in <code>synapseclient/client.py</code> <pre><code>def getWiki(self, owner, subpageId=None, version=None):\n    \"\"\"\n    Get a [synapseclient.wiki.Wiki][] object from Synapse. Uses wiki2 API which supports versioning.\n\n    Arguments:\n        owner: The entity to which the Wiki is attached\n        subpageId: The id of the specific sub-page or None to get the root Wiki page\n        version: The version of the page to retrieve or None to retrieve the latest\n\n    Returns:\n        A [synapseclient.wiki.Wiki][] object\n    \"\"\"\n    uri = \"/entity/{ownerId}/wiki2\".format(ownerId=id_of(owner))\n    if subpageId is not None:\n        uri += \"/{wikiId}\".format(wikiId=subpageId)\n    if version is not None:\n        uri += \"?wikiVersion={version}\".format(version=version)\n\n    wiki = self.restGET(uri)\n    wiki[\"owner\"] = owner\n    wiki = Wiki(**wiki)\n\n    path = self.cache.get(wiki.markdownFileHandleId)\n    if not path:\n        cache_dir = self.cache.get_cache_dir(wiki.markdownFileHandleId)\n        if not os.path.exists(cache_dir):\n            os.makedirs(cache_dir)\n        path = wrap_async_to_sync(\n            coroutine=download_by_file_handle(\n                file_handle_id=wiki[\"markdownFileHandleId\"],\n                synapse_id=wiki[\"id\"],\n                entity_type=\"WikiMarkdown\",\n                destination=os.path.join(\n                    cache_dir, str(wiki.markdownFileHandleId) + \".md\"\n                ),\n            ),\n            syn=self,\n        )\n    try:\n        import gzip\n\n        with gzip.open(path) as f:\n            markdown = f.read().decode(\"utf-8\")\n    except IOError:\n        with open(path) as f:\n            markdown = f.read().decode(\"utf-8\")\n\n    wiki.markdown = markdown\n    wiki.markdown_path = path\n\n    return wiki\n</code></pre>"},{"location":"reference/client/#synapseclient.Synapse.getWikiAttachments","title":"<code>getWikiAttachments(wiki)</code>","text":"<p>Retrieve the attachments to a wiki page.</p> PARAMETER DESCRIPTION <code>wiki</code> <p>The Wiki object for which the attachments are to be returned.</p> <p> </p> RETURNS DESCRIPTION <p>A list of file handles for the files attached to the Wiki.</p> Source code in <code>synapseclient/client.py</code> <pre><code>def getWikiAttachments(self, wiki):\n    \"\"\"\n    Retrieve the attachments to a wiki page.\n\n    Arguments:\n        wiki: The Wiki object for which the attachments are to be returned.\n\n    Returns:\n        A list of file handles for the files attached to the Wiki.\n    \"\"\"\n    uri = \"/entity/%s/wiki/%s/attachmenthandles\" % (wiki.ownerId, wiki.id)\n    results = self.restGET(uri)\n    file_handles = list(WikiAttachment(**fh) for fh in results[\"list\"])\n    return file_handles\n</code></pre>"},{"location":"reference/client/#synapseclient.Synapse.getWikiHeaders","title":"<code>getWikiHeaders(owner)</code>","text":"<p>Retrieves the headers of all Wikis belonging to the owner (the entity to which the Wiki is attached).</p> PARAMETER DESCRIPTION <code>owner</code> <p>An Entity</p> <p> </p> RETURNS DESCRIPTION <p>A list of Objects with three fields: id, title and parentId.</p> Source code in <code>synapseclient/client.py</code> <pre><code>def getWikiHeaders(self, owner):\n    \"\"\"\n    Retrieves the headers of all Wikis belonging to the owner (the entity to which the Wiki is attached).\n\n    Arguments:\n        owner: An Entity\n\n    Returns:\n        A list of Objects with three fields: id, title and parentId.\n    \"\"\"\n\n    uri = \"/entity/%s/wikiheadertree\" % id_of(owner)\n    return [DictObject(**header) for header in self._GET_paginated(uri)]\n</code></pre>"},{"location":"reference/client/#synapseclient.Synapse.get_download_list","title":"<code>get_download_list(downloadLocation=None)</code>","text":"<p>Download all files from your Synapse download list</p> PARAMETER DESCRIPTION <code>downloadLocation</code> <p>Directory to download files to.</p> <p> TYPE: <code>str</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>str</code> <p>Manifest file with file paths</p> Source code in <code>synapseclient/client.py</code> <pre><code>def get_download_list(self, downloadLocation: str = None) -&gt; str:\n    \"\"\"Download all files from your Synapse download list\n\n    Arguments:\n        downloadLocation: Directory to download files to.\n\n    Returns:\n        Manifest file with file paths\n    \"\"\"\n    dl_list_path = self.get_download_list_manifest()\n    downloaded_files = []\n    new_manifest_path = f\"manifest_{time.time_ns()}.csv\"\n    with open(dl_list_path) as manifest_f, open(\n        new_manifest_path, \"w\"\n    ) as write_obj:\n        reader = csv.DictReader(manifest_f)\n        columns = reader.fieldnames\n        columns.extend([\"path\", \"error\"])\n        # Write the downloaded paths to a new manifest file\n        writer = csv.DictWriter(write_obj, fieldnames=columns)\n        writer.writeheader()\n\n        for row in reader:\n            # You can add things to the download list that you don't have access to\n            # So there must be a try catch here\n            try:\n                entity = self.get(row[\"ID\"], downloadLocation=downloadLocation)\n                # Must include version number because you can have multiple versions of a\n                # file in the download list\n                downloaded_files.append(\n                    {\n                        \"fileEntityId\": row[\"ID\"],\n                        \"versionNumber\": row[\"versionNumber\"],\n                    }\n                )\n                row[\"path\"] = entity.path\n                row[\"error\"] = \"\"\n            except Exception:\n                row[\"path\"] = \"\"\n                row[\"error\"] = \"DOWNLOAD FAILED\"\n                self.logger.exception(\"Unable to download file\")\n            writer.writerow(row)\n\n    # Don't want to clear all the download list because you can add things\n    # to the download list after initiating this command.\n    # Files that failed to download should not be removed from download list\n    # Remove all files from download list after the entire download is complete.\n    # This is because if download fails midway, we want to return the full manifest\n    if downloaded_files:\n        # Only want to invoke this if there is a list of files to remove\n        # or the API call will error\n        self.remove_from_download_list(list_of_files=downloaded_files)\n    else:\n        self.logger.warning(\"A manifest was created, but no files were downloaded\")\n\n    # Always remove original manifest file\n    os.remove(dl_list_path)\n\n    return new_manifest_path\n</code></pre>"},{"location":"reference/client/#synapseclient.Synapse.get_download_list_manifest","title":"<code>get_download_list_manifest()</code>","text":"<p>Get the path of the download list manifest file</p> RETURNS DESCRIPTION <p>Path of download list manifest file</p> Source code in <code>synapseclient/client.py</code> <pre><code>def get_download_list_manifest(self):\n    \"\"\"Get the path of the download list manifest file\n\n    Returns:\n        Path of download list manifest file\n    \"\"\"\n    manifest = self._generate_manifest_from_download_list()\n    # Get file handle download link\n    file_result = get_file_handle_for_download(\n        file_handle_id=manifest[\"resultFileHandleId\"],\n        synapse_id=manifest[\"resultFileHandleId\"],\n        entity_type=\"FileEntity\",\n        synapse_client=self,\n    )\n    # Download the manifest\n    downloaded_path = self._download_from_URL(\n        url=file_result[\"preSignedURL\"],\n        destination=\"./\",\n        fileHandleId=file_result[\"fileHandleId\"],\n        expected_md5=file_result[\"fileHandle\"].get(\"contentMd5\"),\n    )\n    trace.get_current_span().set_attributes(\n        {\"synapse.file_handle_id\": file_result[\"fileHandleId\"]}\n    )\n    return downloaded_path\n</code></pre>"},{"location":"reference/client/#synapseclient.Synapse.remove_from_download_list","title":"<code>remove_from_download_list(list_of_files)</code>","text":"<p>Remove a batch of files from download list</p> PARAMETER DESCRIPTION <code>list_of_files</code> <p>Array of files in the format of a mapping {fileEntityId: synid, versionNumber: version}</p> <p> TYPE: <code>List[Dict]</code> </p> RETURNS DESCRIPTION <code>int</code> <p>Number of files removed from download list</p> Source code in <code>synapseclient/client.py</code> <pre><code>def remove_from_download_list(self, list_of_files: typing.List[typing.Dict]) -&gt; int:\n    \"\"\"Remove a batch of files from download list\n\n    Arguments:\n        list_of_files: Array of files in the format of a mapping {fileEntityId: synid, versionNumber: version}\n\n    Returns:\n        Number of files removed from download list\n    \"\"\"\n    request_body = {\"batchToRemove\": list_of_files}\n    num_files_removed = self.restPOST(\n        \"/download/list/remove\", body=json.dumps(request_body)\n    )\n    return num_files_removed\n</code></pre>"},{"location":"reference/client/#synapseclient.Synapse.md5Query","title":"<code>md5Query(md5)</code>","text":"<p>Find the Entities which have attached file(s) which have the given MD5 hash.</p> PARAMETER DESCRIPTION <code>md5</code> <p>The MD5 to query for (hexadecimal string)</p> <p> </p> RETURNS DESCRIPTION <p>A list of Entity headers</p> Source code in <code>synapseclient/client.py</code> <pre><code>def md5Query(self, md5):\n    \"\"\"\n    Find the Entities which have attached file(s) which have the given MD5 hash.\n\n    Arguments:\n        md5: The MD5 to query for (hexadecimal string)\n\n    Returns:\n        A list of Entity headers\n    \"\"\"\n\n    return self.restGET(\"/entity/md5/%s\" % md5)[\"results\"]\n</code></pre>"},{"location":"reference/client/#synapseclient.Synapse.sendMessage","title":"<code>sendMessage(userIds, messageSubject, messageBody, contentType='text/plain')</code>","text":"<p>send a message via Synapse.</p> PARAMETER DESCRIPTION <code>userIds</code> <p>A list of user IDs to which the message is to be sent</p> <p> </p> <code>messageSubject</code> <p>The subject for the message</p> <p> </p> <code>messageBody</code> <p>The body of the message</p> <p> </p> <code>contentType</code> <p>optional contentType of message body (default=\"text/plain\")             Should be one of \"text/plain\" or \"text/html\"</p> <p> DEFAULT: <code>'text/plain'</code> </p> RETURNS DESCRIPTION <p>The metadata of the created message</p> Source code in <code>synapseclient/client.py</code> <pre><code>def sendMessage(\n    self, userIds, messageSubject, messageBody, contentType=\"text/plain\"\n):\n    \"\"\"\n    send a message via Synapse.\n\n    Arguments:\n        userIds: A list of user IDs to which the message is to be sent\n        messageSubject: The subject for the message\n        messageBody: The body of the message\n        contentType: optional contentType of message body (default=\"text/plain\")\n                        Should be one of \"text/plain\" or \"text/html\"\n\n    Returns:\n        The metadata of the created message\n    \"\"\"\n\n    fileHandleId = wrap_async_to_sync(\n        multipart_upload_string_async(self, messageBody, content_type=contentType),\n        self,\n    )\n    message = dict(\n        recipients=userIds, subject=messageSubject, fileHandleId=fileHandleId\n    )\n    return self.restPOST(uri=\"/message\", body=json.dumps(message))\n</code></pre>"},{"location":"reference/client/#synapseclient.Synapse.uploadFileHandle","title":"<code>uploadFileHandle(path, parent, synapseStore=True, mimetype=None, md5=None, file_size=None)</code>","text":"<p>Uploads the file in the provided path (if necessary) to a storage location based on project settings. Returns a new FileHandle as a dict to represent the stored file.</p> PARAMETER DESCRIPTION <code>parent</code> <p>Parent of the entity to which we upload.</p> <p> </p> <code>path</code> <p>File path to the file being uploaded</p> <p> </p> <code>synapseStore</code> <p>If False, will not upload the file, but instead create an ExternalFileHandle that references             the file on the local machine.             If True, will upload the file based on StorageLocation determined by the entity_parent_id</p> <p> DEFAULT: <code>True</code> </p> <code>mimetype</code> <p>The MIME type metadata for the uploaded file</p> <p> DEFAULT: <code>None</code> </p> <code>md5</code> <p>The MD5 checksum for the file, if known. Otherwise if the file is a local file, it will be calculated     automatically.</p> <p> DEFAULT: <code>None</code> </p> <code>file_size</code> <p>The size the file, if known. Otherwise if the file is a local file, it will be calculated         automatically.</p> <p> DEFAULT: <code>None</code> </p> <code>file_type</code> <p>The MIME type the file, if known. Otherwise if the file is a local file, it will be calculated         automatically.</p> <p> </p> RETURNS DESCRIPTION <p>A dict of a new FileHandle as a dict that represents the uploaded file</p> Source code in <code>synapseclient/client.py</code> <pre><code>def uploadFileHandle(\n    self, path, parent, synapseStore=True, mimetype=None, md5=None, file_size=None\n):\n    \"\"\"Uploads the file in the provided path (if necessary) to a storage location based on project settings.\n    Returns a new FileHandle as a dict to represent the stored file.\n\n    Arguments:\n        parent: Parent of the entity to which we upload.\n        path:   File path to the file being uploaded\n        synapseStore: If False, will not upload the file, but instead create an ExternalFileHandle that references\n                        the file on the local machine.\n                        If True, will upload the file based on StorageLocation determined by the entity_parent_id\n        mimetype: The MIME type metadata for the uploaded file\n        md5: The MD5 checksum for the file, if known. Otherwise if the file is a local file, it will be calculated\n                automatically.\n        file_size: The size the file, if known. Otherwise if the file is a local file, it will be calculated\n                    automatically.\n        file_type: The MIME type the file, if known. Otherwise if the file is a local file, it will be calculated\n                    automatically.\n\n    Returns:\n        A dict of a new FileHandle as a dict that represents the uploaded file\n    \"\"\"\n    return wrap_async_to_sync(\n        upload_file_handle_async(\n            self, parent, path, synapseStore, md5, file_size, mimetype\n        ),\n        self,\n    )\n</code></pre>"},{"location":"reference/client/#synapseclient.Synapse.restGET","title":"<code>restGET(uri, endpoint=None, headers=None, retryPolicy={}, requests_session=None, **kwargs)</code>","text":"<p>Sends an HTTP GET request to the Synapse server.</p> PARAMETER DESCRIPTION <code>uri</code> <p>URI on which get is performed</p> <p> </p> <code>endpoint</code> <p>Server endpoint, defaults to self.repoEndpoint</p> <p> DEFAULT: <code>None</code> </p> <code>headers</code> <p>Dictionary of headers to use rather than the API-key-signed default set of headers</p> <p> DEFAULT: <code>None</code> </p> <code>requests_session</code> <p>An external requests.Session object to use when making this specific call</p> <p> DEFAULT: <code>None</code> </p> <code>kwargs</code> <p>Any other arguments taken by a request method</p> <p> DEFAULT: <code>{}</code> </p> RETURNS DESCRIPTION <p>JSON encoding of response</p> Source code in <code>synapseclient/client.py</code> <pre><code>def restGET(\n    self,\n    uri,\n    endpoint=None,\n    headers=None,\n    retryPolicy={},\n    requests_session=None,\n    **kwargs,\n):\n    \"\"\"\n    Sends an HTTP GET request to the Synapse server.\n\n    Arguments:\n        uri: URI on which get is performed\n        endpoint: Server endpoint, defaults to self.repoEndpoint\n        headers: Dictionary of headers to use rather than the API-key-signed default set of headers\n        requests_session: An external [requests.Session object](https://requests.readthedocs.io/en/latest/user/advanced/) to use when making this specific call\n        kwargs: Any other arguments taken by a [request](http://docs.python-requests.org/en/latest/) method\n\n    Returns:\n        JSON encoding of response\n    \"\"\"\n    response = self._rest_call(\n        \"get\", uri, None, endpoint, headers, retryPolicy, requests_session, **kwargs\n    )\n    return self._return_rest_body(response)\n</code></pre>"},{"location":"reference/client/#synapseclient.Synapse.restPOST","title":"<code>restPOST(uri, body, endpoint=None, headers=None, retryPolicy={}, requests_session=None, **kwargs)</code>","text":"<p>Sends an HTTP POST request to the Synapse server.</p> PARAMETER DESCRIPTION <code>uri</code> <p>URI on which get is performed</p> <p> </p> <code>endpoint</code> <p>Server endpoint, defaults to self.repoEndpoint</p> <p> DEFAULT: <code>None</code> </p> <code>body</code> <p>The payload to be delivered</p> <p> </p> <code>headers</code> <p>Dictionary of headers to use rather than the API-key-signed default set of headers</p> <p> DEFAULT: <code>None</code> </p> <code>requests_session</code> <p>An external requests.Session object to use when making this specific call</p> <p> DEFAULT: <code>None</code> </p> <code>kwargs</code> <p>Any other arguments taken by a request method</p> <p> DEFAULT: <code>{}</code> </p> RETURNS DESCRIPTION <p>JSON encoding of response</p> Source code in <code>synapseclient/client.py</code> <pre><code>def restPOST(\n    self,\n    uri,\n    body,\n    endpoint=None,\n    headers=None,\n    retryPolicy={},\n    requests_session=None,\n    **kwargs,\n):\n    \"\"\"\n    Sends an HTTP POST request to the Synapse server.\n\n    Arguments:\n        uri: URI on which get is performed\n        endpoint: Server endpoint, defaults to self.repoEndpoint\n        body: The payload to be delivered\n        headers: Dictionary of headers to use rather than the API-key-signed default set of headers\n        requests_session: An external [requests.Session object](https://requests.readthedocs.io/en/latest/user/advanced/) to use when making this specific call\n        kwargs: Any other arguments taken by a [request](http://docs.python-requests.org/en/latest/) method\n\n    Returns:\n        JSON encoding of response\n    \"\"\"\n    response = self._rest_call(\n        \"post\",\n        uri,\n        body,\n        endpoint,\n        headers,\n        retryPolicy,\n        requests_session,\n        **kwargs,\n    )\n    return self._return_rest_body(response)\n</code></pre>"},{"location":"reference/client/#synapseclient.Synapse.restPUT","title":"<code>restPUT(uri, body=None, endpoint=None, headers=None, retryPolicy={}, requests_session=None, **kwargs)</code>","text":"<p>Sends an HTTP PUT request to the Synapse server.</p> PARAMETER DESCRIPTION <code>uri</code> <p>URI on which get is performed</p> <p> </p> <code>endpoint</code> <p>Server endpoint, defaults to self.repoEndpoint</p> <p> DEFAULT: <code>None</code> </p> <code>body</code> <p>The payload to be delivered</p> <p> DEFAULT: <code>None</code> </p> <code>headers</code> <p>Dictionary of headers to use rather than the API-key-signed default set of headers</p> <p> DEFAULT: <code>None</code> </p> <code>requests_session</code> <p>An external requests.Session object to use when making this specific call</p> <p> DEFAULT: <code>None</code> </p> <code>kwargs</code> <p>Any other arguments taken by a request method</p> <p> DEFAULT: <code>{}</code> </p> <p>Returns     JSON encoding of response</p> Source code in <code>synapseclient/client.py</code> <pre><code>def restPUT(\n    self,\n    uri,\n    body=None,\n    endpoint=None,\n    headers=None,\n    retryPolicy={},\n    requests_session=None,\n    **kwargs,\n):\n    \"\"\"\n    Sends an HTTP PUT request to the Synapse server.\n\n    Arguments:\n        uri: URI on which get is performed\n        endpoint: Server endpoint, defaults to self.repoEndpoint\n        body: The payload to be delivered\n        headers: Dictionary of headers to use rather than the API-key-signed default set of headers\n        requests_session: An external [requests.Session object](https://requests.readthedocs.io/en/latest/user/advanced/) to use when making this specific call\n        kwargs: Any other arguments taken by a [request](http://docs.python-requests.org/en/latest/) method\n\n    Returns\n        JSON encoding of response\n    \"\"\"\n    response = self._rest_call(\n        \"put\",\n        uri,\n        body,\n        endpoint,\n        headers,\n        retryPolicy,\n        requests_session,\n        **kwargs,\n    )\n    return self._return_rest_body(response)\n</code></pre>"},{"location":"reference/client/#synapseclient.Synapse.restDELETE","title":"<code>restDELETE(uri, endpoint=None, headers=None, retryPolicy={}, requests_session=None, **kwargs)</code>","text":"<p>Sends an HTTP DELETE request to the Synapse server.</p> PARAMETER DESCRIPTION <code>uri</code> <p>URI of resource to be deleted</p> <p> </p> <code>endpoint</code> <p>Server endpoint, defaults to self.repoEndpoint</p> <p> DEFAULT: <code>None</code> </p> <code>headers</code> <p>Dictionary of headers to use rather than the API-key-signed default set of headers</p> <p> DEFAULT: <code>None</code> </p> <code>requests_session</code> <p>An external requests.Session object to use when making this specific call</p> <p> DEFAULT: <code>None</code> </p> <code>kwargs</code> <p>Any other arguments taken by a request method</p> <p> DEFAULT: <code>{}</code> </p> Source code in <code>synapseclient/client.py</code> <pre><code>def restDELETE(\n    self,\n    uri,\n    endpoint=None,\n    headers=None,\n    retryPolicy={},\n    requests_session=None,\n    **kwargs,\n):\n    \"\"\"\n    Sends an HTTP DELETE request to the Synapse server.\n\n    Arguments:\n        uri: URI of resource to be deleted\n        endpoint: Server endpoint, defaults to self.repoEndpoint\n        headers: Dictionary of headers to use rather than the API-key-signed default set of headers\n        requests_session: An external [requests.Session object](https://requests.readthedocs.io/en/latest/user/advanced/) to use when making this specific call\n        kwargs: Any other arguments taken by a [request](http://docs.python-requests.org/en/latest/) method\n\n    \"\"\"\n    self._rest_call(\n        \"delete\",\n        uri,\n        None,\n        endpoint,\n        headers,\n        retryPolicy,\n        requests_session,\n        **kwargs,\n    )\n</code></pre>"},{"location":"reference/client/#synapseclient.Synapse.rest_get_async","title":"<code>rest_get_async(uri, endpoint=None, headers=None, retry_policy={}, requests_session_async_synapse=None, **kwargs)</code>  <code>async</code>","text":"<p>Sends an HTTP GET request to the Synapse server.</p> PARAMETER DESCRIPTION <code>uri</code> <p>URI on which get is performed</p> <p> TYPE: <code>str</code> </p> <code>endpoint</code> <p>Server endpoint, defaults to self.repoEndpoint</p> <p> TYPE: <code>str</code> DEFAULT: <code>None</code> </p> <code>headers</code> <p>Dictionary of headers to use.</p> <p> TYPE: <code>Headers</code> DEFAULT: <code>None</code> </p> <code>retry_policy</code> <p>A retry policy that matches the arguments of synapseclient.core.retry.with_retry_time_based_async.</p> <p> TYPE: <code>Dict[str, Any]</code> DEFAULT: <code>{}</code> </p> <code>requests_session_async_synapse</code> <p>The async client to use when making this specific call.</p> <p> TYPE: <code>AsyncClient</code> DEFAULT: <code>None</code> </p> <code>kwargs</code> <p>Any other arguments taken by a request method</p> <p> DEFAULT: <code>{}</code> </p> RETURNS DESCRIPTION <code>Union[Dict[str, Any], str, None]</code> <p>JSON encoding of response</p> Source code in <code>synapseclient/client.py</code> <pre><code>async def rest_get_async(\n    self,\n    uri: str,\n    endpoint: str = None,\n    headers: httpx.Headers = None,\n    retry_policy: Dict[str, Any] = {},\n    requests_session_async_synapse: httpx.AsyncClient = None,\n    **kwargs,\n) -&gt; Union[Dict[str, Any], str, None]:\n    \"\"\"\n    Sends an HTTP GET request to the Synapse server.\n\n    Arguments:\n        uri: URI on which get is performed\n        endpoint: Server endpoint, defaults to self.repoEndpoint\n        headers: Dictionary of headers to use.\n        retry_policy: A retry policy that matches the arguments of\n            [synapseclient.core.retry.with_retry_time_based_async][].\n        requests_session_async_synapse: The async client to use when making this\n            specific call.\n        kwargs: Any other arguments taken by a\n            [request](https://www.python-httpx.org/api/) method\n\n    Returns:\n        JSON encoding of response\n    \"\"\"\n    try:\n        response = await self._rest_call_async(\n            \"get\",\n            uri,\n            None,\n            endpoint,\n            headers,\n            retry_policy,\n            requests_session_async_synapse,\n            **kwargs,\n        )\n        return self._return_rest_body(response)\n    except Exception:\n        self.logger.exception(\"Error in rest_get_async\")\n</code></pre>"},{"location":"reference/client/#synapseclient.Synapse.rest_post_async","title":"<code>rest_post_async(uri, body=None, endpoint=None, headers=None, retry_policy={}, requests_session_async_synapse=None, **kwargs)</code>  <code>async</code>","text":"<p>Sends an HTTP POST request to the Synapse server.</p> PARAMETER DESCRIPTION <code>uri</code> <p>URI on which get is performed</p> <p> TYPE: <code>str</code> </p> <code>body</code> <p>The payload to be delivered</p> <p> TYPE: <code>Any</code> DEFAULT: <code>None</code> </p> <code>endpoint</code> <p>Server endpoint, defaults to self.repoEndpoint</p> <p> TYPE: <code>str</code> DEFAULT: <code>None</code> </p> <code>headers</code> <p>Dictionary of headers to use.</p> <p> TYPE: <code>Headers</code> DEFAULT: <code>None</code> </p> <code>retry_policy</code> <p>A retry policy that matches the arguments of synapseclient.core.retry.with_retry_time_based_async.</p> <p> TYPE: <code>Dict[str, Any]</code> DEFAULT: <code>{}</code> </p> <code>requests_session_async_synapse</code> <p>The async client to use when making this specific call.</p> <p> TYPE: <code>AsyncClient</code> DEFAULT: <code>None</code> </p> <code>kwargs</code> <p>Any other arguments taken by a request method</p> <p> DEFAULT: <code>{}</code> </p> RETURNS DESCRIPTION <code>Union[Dict[str, Any], str]</code> <p>JSON encoding of response</p> Source code in <code>synapseclient/client.py</code> <pre><code>async def rest_post_async(\n    self,\n    uri: str,\n    body: Any = None,\n    endpoint: str = None,\n    headers: httpx.Headers = None,\n    retry_policy: Dict[str, Any] = {},\n    requests_session_async_synapse: httpx.AsyncClient = None,\n    **kwargs,\n) -&gt; Union[Dict[str, Any], str]:\n    \"\"\"\n    Sends an HTTP POST request to the Synapse server.\n\n    Arguments:\n        uri: URI on which get is performed\n        body: The payload to be delivered\n        endpoint: Server endpoint, defaults to self.repoEndpoint\n        headers: Dictionary of headers to use.\n        retry_policy: A retry policy that matches the arguments of\n            [synapseclient.core.retry.with_retry_time_based_async][].\n        requests_session_async_synapse: The async client to use when making this\n            specific call.\n        kwargs: Any other arguments taken by a\n            [request](https://www.python-httpx.org/api/) method\n\n    Returns:\n        JSON encoding of response\n    \"\"\"\n    response = await self._rest_call_async(\n        \"post\",\n        uri,\n        body,\n        endpoint,\n        headers,\n        retry_policy,\n        requests_session_async_synapse,\n        **kwargs,\n    )\n    return self._return_rest_body(response)\n</code></pre>"},{"location":"reference/client/#synapseclient.Synapse.rest_put_async","title":"<code>rest_put_async(uri, body=None, endpoint=None, headers=None, retry_policy={}, requests_session_async_synapse=None, **kwargs)</code>  <code>async</code>","text":"<p>Sends an HTTP PUT request to the Synapse server.</p> PARAMETER DESCRIPTION <code>uri</code> <p>URI on which get is performed</p> <p> TYPE: <code>str</code> </p> <code>body</code> <p>The payload to be delivered.</p> <p> TYPE: <code>Any</code> DEFAULT: <code>None</code> </p> <code>endpoint</code> <p>Server endpoint, defaults to self.repoEndpoint</p> <p> TYPE: <code>str</code> DEFAULT: <code>None</code> </p> <code>headers</code> <p>Dictionary of headers to use.</p> <p> TYPE: <code>Headers</code> DEFAULT: <code>None</code> </p> <code>retry_policy</code> <p>A retry policy that matches the arguments of synapseclient.core.retry.with_retry_time_based_async.</p> <p> TYPE: <code>Dict[str, Any]</code> DEFAULT: <code>{}</code> </p> <code>requests_session_async_synapse</code> <p>The async client to use when making this specific call.</p> <p> TYPE: <code>AsyncClient</code> DEFAULT: <code>None</code> </p> <code>kwargs</code> <p>Any other arguments taken by a request method</p> <p> DEFAULT: <code>{}</code> </p> <p>Returns     JSON encoding of response</p> Source code in <code>synapseclient/client.py</code> <pre><code>async def rest_put_async(\n    self,\n    uri: str,\n    body: Any = None,\n    endpoint: str = None,\n    headers: httpx.Headers = None,\n    retry_policy: Dict[str, Any] = {},\n    requests_session_async_synapse: httpx.AsyncClient = None,\n    **kwargs,\n) -&gt; Union[Dict[str, Any], str]:\n    \"\"\"\n    Sends an HTTP PUT request to the Synapse server.\n\n    Arguments:\n        uri: URI on which get is performed\n        body: The payload to be delivered.\n        endpoint: Server endpoint, defaults to self.repoEndpoint\n        headers: Dictionary of headers to use.\n        retry_policy: A retry policy that matches the arguments of\n            [synapseclient.core.retry.with_retry_time_based_async][].\n        requests_session_async_synapse: The async client to use when making this\n            specific call.\n        kwargs: Any other arguments taken by a\n            [request](https://www.python-httpx.org/api/) method\n\n    Returns\n        JSON encoding of response\n    \"\"\"\n    response = await self._rest_call_async(\n        \"put\",\n        uri,\n        body,\n        endpoint,\n        headers,\n        retry_policy,\n        requests_session_async_synapse,\n        **kwargs,\n    )\n    return self._return_rest_body(response)\n</code></pre>"},{"location":"reference/client/#synapseclient.Synapse.rest_delete_async","title":"<code>rest_delete_async(uri, endpoint=None, headers=None, retry_policy={}, requests_session_async_synapse=None, **kwargs)</code>  <code>async</code>","text":"<p>Sends an HTTP DELETE request to the Synapse server.</p> PARAMETER DESCRIPTION <code>uri</code> <p>URI of resource to be deleted</p> <p> TYPE: <code>str</code> </p> <code>endpoint</code> <p>Server endpoint, defaults to self.repoEndpoint</p> <p> TYPE: <code>str</code> DEFAULT: <code>None</code> </p> <code>headers</code> <p>Dictionary of headers to use.</p> <p> TYPE: <code>Headers</code> DEFAULT: <code>None</code> </p> <code>retry_policy</code> <p>A retry policy that matches the arguments of synapseclient.core.retry.with_retry_time_based_async.</p> <p> TYPE: <code>Dict[str, Any]</code> DEFAULT: <code>{}</code> </p> <code>requests_session_async_synapse</code> <p>The async client to use when making this specific call</p> <p> TYPE: <code>AsyncClient</code> DEFAULT: <code>None</code> </p> <code>kwargs</code> <p>Any other arguments taken by a request method</p> <p> DEFAULT: <code>{}</code> </p> Source code in <code>synapseclient/client.py</code> <pre><code>async def rest_delete_async(\n    self,\n    uri: str,\n    endpoint: str = None,\n    headers: httpx.Headers = None,\n    retry_policy: Dict[str, Any] = {},\n    requests_session_async_synapse: httpx.AsyncClient = None,\n    **kwargs,\n) -&gt; None:\n    \"\"\"\n    Sends an HTTP DELETE request to the Synapse server.\n\n    Arguments:\n        uri: URI of resource to be deleted\n        endpoint: Server endpoint, defaults to self.repoEndpoint\n        headers: Dictionary of headers to use.\n        retry_policy: A retry policy that matches the arguments of\n            [synapseclient.core.retry.with_retry_time_based_async][].\n        requests_session_async_synapse: The async client to use when making this\n            specific call\n        kwargs: Any other arguments taken by a [request](https://www.python-httpx.org/api/) method\n\n    \"\"\"\n    await self._rest_call_async(\n        \"delete\",\n        uri,\n        None,\n        endpoint,\n        headers,\n        retry_policy,\n        requests_session_async_synapse,\n        **kwargs,\n    )\n</code></pre>"},{"location":"reference/client/#more-information","title":"More information","text":"<p>See also the Synapse API documentation</p>"},{"location":"reference/core/","title":"Core","text":"<p>This section is for super users / developers only. These functions are subject to change as they are internal development functions.  Use at your own risk.</p>"},{"location":"reference/core/#upload","title":"Upload","text":""},{"location":"reference/core/#synapseclient.core.upload.upload_functions","title":"<code>synapseclient.core.upload.upload_functions</code>","text":"<p>This module handles the various ways that a user can upload a file to Synapse.</p>"},{"location":"reference/core/#synapseclient.core.upload.upload_functions-classes","title":"Classes","text":""},{"location":"reference/core/#synapseclient.core.upload.upload_functions-functions","title":"Functions","text":""},{"location":"reference/core/#synapseclient.core.upload.upload_functions.upload_file_handle","title":"<code>upload_file_handle(syn, parent_entity, path, synapseStore=True, md5=None, file_size=None, mimetype=None, max_threads=None)</code>","text":"<p>Uploads the file in the provided path (if necessary) to a storage location based on project settings. Returns a new FileHandle as a dict to represent the stored file.</p> PARAMETER DESCRIPTION <code>parent_entity</code> <p>Entity object or id of the parent entity.</p> <p> TYPE: <code>Union[str, Mapping, Number]</code> </p> <code>path</code> <p>The file path to the file being uploaded</p> <p> TYPE: <code>str</code> </p> <code>synapseStore</code> <p>If False, will not upload the file, but instead create an ExternalFileHandle that references            the file on the local machine.            If True, will upload the file based on StorageLocation determined by the entity_parent_id</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> <code>md5</code> <p>The MD5 checksum for the file, if known. Otherwise if the file is a local file, it will be            calculated automatically.</p> <p> TYPE: <code>str</code> DEFAULT: <code>None</code> </p> <code>file_size</code> <p>The size the file, if known. Otherwise if the file is a local file, it will be calculated            automatically.</p> <p> TYPE: <code>int</code> DEFAULT: <code>None</code> </p> <code>file_size</code> <p>The MIME type the file, if known. Otherwise if the file is a local file, it will be            calculated automatically.</p> <p> TYPE: <code>int</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <p>A dictionary of a new FileHandle as a dict that represents the uploaded file</p> Source code in <code>synapseclient/core/upload/upload_functions.py</code> <pre><code>def upload_file_handle(\n    syn: \"Synapse\",\n    parent_entity: Union[str, collections.abc.Mapping, numbers.Number],\n    path: str,\n    synapseStore: bool = True,\n    md5: str = None,\n    file_size: int = None,\n    mimetype: str = None,\n    max_threads: int = None,\n):\n    \"\"\"\n    Uploads the file in the provided path (if necessary) to a storage location based on project settings.\n    Returns a new FileHandle as a dict to represent the stored file.\n\n    Arguments:\n        parent_entity: Entity object or id of the parent entity.\n        path:          The file path to the file being uploaded\n        synapseStore:  If False, will not upload the file, but instead create an ExternalFileHandle that references\n                       the file on the local machine.\n                       If True, will upload the file based on StorageLocation determined by the entity_parent_id\n        md5:           The MD5 checksum for the file, if known. Otherwise if the file is a local file, it will be\n                       calculated automatically.\n        file_size:     The size the file, if known. Otherwise if the file is a local file, it will be calculated\n                       automatically.\n        file_size:     The MIME type the file, if known. Otherwise if the file is a local file, it will be\n                       calculated automatically.\n\n    Returns:\n        A dictionary of a new FileHandle as a dict that represents the uploaded file\n    \"\"\"\n    if path is None:\n        raise ValueError(\"path can not be None\")\n\n    # if doing a external file handle with no actual upload\n    if not synapseStore:\n        return create_external_file_handle(\n            syn, path, mimetype=mimetype, md5=md5, file_size=file_size\n        )\n\n    # expand the path because past this point an upload is required and some upload functions require an absolute path\n    expanded_upload_path = os.path.expandvars(os.path.expanduser(path))\n\n    if md5 is None and os.path.isfile(expanded_upload_path):\n        md5 = utils.md5_for_file(expanded_upload_path).hexdigest()\n\n    entity_parent_id = id_of(parent_entity)\n\n    # determine the upload function based on the UploadDestination\n    location = syn._getDefaultUploadDestination(entity_parent_id)\n    upload_destination_type = location[\"concreteType\"]\n    trace.get_current_span().set_attributes(\n        {\n            \"synapse.parent_id\": entity_parent_id,\n            \"synapse.upload_destination_type\": upload_destination_type,\n        }\n    )\n\n    if (\n        sts_transfer.is_boto_sts_transfer_enabled(syn)\n        and sts_transfer.is_storage_location_sts_enabled(\n            syn, entity_parent_id, location\n        )\n        and upload_destination_type == concrete_types.EXTERNAL_S3_UPLOAD_DESTINATION\n    ):\n        log_upload_message(\n            syn,\n            \"\\n\"\n            + \"#\" * 50\n            + \"\\n Uploading file to external S3 storage using boto3 \\n\"\n            + \"#\" * 50\n            + \"\\n\",\n        )\n\n        return upload_synapse_sts_boto_s3(\n            syn=syn,\n            parent_id=entity_parent_id,\n            upload_destination=location,\n            local_path=expanded_upload_path,\n            mimetype=mimetype,\n            md5=md5,\n        )\n\n    elif upload_destination_type in (\n        concrete_types.SYNAPSE_S3_UPLOAD_DESTINATION,\n        concrete_types.EXTERNAL_S3_UPLOAD_DESTINATION,\n        concrete_types.EXTERNAL_GCP_UPLOAD_DESTINATION,\n    ):\n        if upload_destination_type == concrete_types.SYNAPSE_S3_UPLOAD_DESTINATION:\n            storage_str = \"Synapse\"\n        elif upload_destination_type == concrete_types.EXTERNAL_S3_UPLOAD_DESTINATION:\n            storage_str = \"your external S3\"\n        else:\n            storage_str = \"your external Google Bucket\"\n\n        log_upload_message(\n            syn,\n            \"\\n\"\n            + \"#\" * 50\n            + \"\\n Uploading file to \"\n            + storage_str\n            + \" storage \\n\"\n            + \"#\" * 50\n            + \"\\n\",\n        )\n\n        return upload_synapse_s3(\n            syn=syn,\n            file_path=expanded_upload_path,\n            storageLocationId=location[\"storageLocationId\"],\n            mimetype=mimetype,\n            max_threads=max_threads,\n            md5=md5,\n        )\n    # external file handle (sftp)\n    elif upload_destination_type == concrete_types.EXTERNAL_UPLOAD_DESTINATION:\n        if location[\"uploadType\"] == \"SFTP\":\n            log_upload_message(\n                syn,\n                \"\\n%s\\n%s\\nUploading to: %s\\n%s\\n\"\n                % (\n                    \"#\" * 50,\n                    location.get(\"banner\", \"\"),\n                    urllib_parse.urlparse(location[\"url\"]).netloc,\n                    \"#\" * 50,\n                ),\n            )\n            return upload_external_file_handle_sftp(\n                syn=syn,\n                file_path=expanded_upload_path,\n                sftp_url=location[\"url\"],\n                mimetype=mimetype,\n                md5=md5,\n            )\n        else:\n            raise NotImplementedError(\"Can only handle SFTP upload locations.\")\n    # client authenticated S3\n    elif (\n        upload_destination_type\n        == concrete_types.EXTERNAL_OBJECT_STORE_UPLOAD_DESTINATION\n    ):\n        log_upload_message(\n            syn,\n            \"\\n%s\\n%s\\nUploading to endpoint: [%s] bucket: [%s]\\n%s\\n\"\n            % (\n                \"#\" * 50,\n                location.get(\"banner\", \"\"),\n                location.get(\"endpointUrl\"),\n                location.get(\"bucket\"),\n                \"#\" * 50,\n            ),\n        )\n        return upload_client_auth_s3(\n            syn=syn,\n            file_path=expanded_upload_path,\n            bucket=location[\"bucket\"],\n            endpoint_url=location[\"endpointUrl\"],\n            key_prefix=location[\"keyPrefixUUID\"],\n            storage_location_id=location[\"storageLocationId\"],\n            mimetype=mimetype,\n            md5=md5,\n        )\n    else:  # unknown storage location\n        log_upload_message(\n            syn,\n            \"\\n%s\\n%s\\nUNKNOWN STORAGE LOCATION. Defaulting upload to Synapse.\\n%s\\n\"\n            % (\"!\" * 50, location.get(\"banner\", \"\"), \"!\" * 50),\n        )\n        return upload_synapse_s3(\n            syn=syn,\n            file_path=expanded_upload_path,\n            storageLocationId=None,\n            mimetype=mimetype,\n            max_threads=max_threads,\n            md5=md5,\n        )\n</code></pre>"},{"location":"reference/core/#synapseclient.core.upload.upload_functions.upload_synapse_sts_boto_s3","title":"<code>upload_synapse_sts_boto_s3(syn, parent_id, upload_destination, local_path, mimetype=None, md5=None)</code>","text":"<p>When uploading to Synapse storage normally the back end will generate a random prefix for our uploaded object. Since in this case the client is responsible for the remote key, the client will instead generate a random prefix. this both ensures we don't have a collision with an existing S3 object and also mitigates potential performance issues, although key locality performance issues are likely resolved as of: https://aws.amazon.com/about-aws/whats-new/2018/07/amazon-s3-announces-increased-request-rate-performance/</p> PARAMETER DESCRIPTION <code>syn</code> <p>The synapse client</p> <p> TYPE: <code>Synapse</code> </p> <code>parent_id</code> <p>The synapse ID of the parent.</p> <p> TYPE: <code>str</code> </p> <code>upload_destination</code> <p>The upload destination</p> <p> </p> <code>local_path</code> <p>The local path to the file to upload.</p> <p> TYPE: <code>str</code> </p> <code>mimetype</code> <p>The mimetype is known. Defaults to None.</p> <p> TYPE: <code>str</code> DEFAULT: <code>None</code> </p> <code>md5</code> <p>MD5 checksum for the file, if known.</p> <p> TYPE: <code>str</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <p>description</p> Source code in <code>synapseclient/core/upload/upload_functions.py</code> <pre><code>def upload_synapse_sts_boto_s3(\n    syn: \"Synapse\",\n    parent_id: str,\n    upload_destination,\n    local_path: str,\n    mimetype: str = None,\n    md5: str = None,\n):\n    \"\"\"\n    When uploading to Synapse storage normally the back end will generate a random prefix\n    for our uploaded object. Since in this case the client is responsible for the remote\n    key, the client will instead generate a random prefix. this both ensures we don't have a collision\n    with an existing S3 object and also mitigates potential performance issues, although\n    key locality performance issues are likely resolved as of:\n    &lt;https://aws.amazon.com/about-aws/whats-new/2018/07/amazon-s3-announces-increased-request-rate-performance/&gt;\n\n    Arguments:\n        syn: The synapse client\n        parent_id: The synapse ID of the parent.\n        upload_destination: The upload destination\n        local_path: The local path to the file to upload.\n        mimetype: The mimetype is known. Defaults to None.\n        md5: MD5 checksum for the file, if known.\n\n    Returns:\n        _description_\n    \"\"\"\n    key_prefix = str(uuid.uuid4())\n\n    bucket_name = upload_destination[\"bucket\"]\n    storage_location_id = upload_destination[\"storageLocationId\"]\n    remote_file_key = \"/\".join(\n        [upload_destination[\"baseKey\"], key_prefix, os.path.basename(local_path)]\n    )\n\n    def upload_fn(credentials):\n        return S3ClientWrapper.upload_file(\n            bucket=bucket_name,\n            endpoint_url=None,\n            remote_file_key=remote_file_key,\n            upload_file_path=local_path,\n            credentials=credentials,\n            transfer_config_kwargs={\"max_concurrency\": syn.max_threads},\n        )\n\n    sts_transfer.with_boto_sts_credentials(upload_fn, syn, parent_id, \"read_write\")\n    return syn.create_external_s3_file_handle(\n        bucket_name=bucket_name,\n        s3_file_key=remote_file_key,\n        file_path=local_path,\n        storage_location_id=storage_location_id,\n        mimetype=mimetype,\n        md5=md5,\n    )\n</code></pre>"},{"location":"reference/core/#multipart-upload","title":"Multipart Upload","text":""},{"location":"reference/core/#synapseclient.core.upload.multipart_upload","title":"<code>synapseclient.core.upload.multipart_upload</code>","text":"<p>Implements the client side of Synapse's Multipart File Upload API, which provides a robust means of uploading large files (into the 10s of GiB). End users should not need to call any of the methods under UploadAttempt directly.</p>"},{"location":"reference/core/#synapseclient.core.upload.multipart_upload-classes","title":"Classes","text":""},{"location":"reference/core/#synapseclient.core.upload.multipart_upload.UploadAttempt","title":"<code>UploadAttempt</code>","text":"<p>Used to handle multi-threaded operations for uploading one or parts of a file.</p> Source code in <code>synapseclient/core/upload/multipart_upload.py</code> <pre><code>class UploadAttempt:\n    \"\"\"\n    Used to handle multi-threaded operations for uploading one or parts of a file.\n    \"\"\"\n\n    def __init__(\n        self,\n        syn,\n        dest_file_name,\n        upload_request_payload,\n        part_request_body_provider_fn,\n        md5_fn,\n        max_threads: int,\n        force_restart: bool,\n    ):\n        self._syn = syn\n        self._dest_file_name = dest_file_name\n        self._part_size = upload_request_payload[\"partSizeBytes\"]\n\n        self._upload_request_payload = upload_request_payload\n\n        self._part_request_body_provider_fn = part_request_body_provider_fn\n        self._md5_fn = md5_fn\n\n        self._max_threads = max_threads\n        self._force_restart = force_restart\n\n        self._lock = threading.Lock()\n        self._aborted = False\n\n        # populated later\n        self._upload_id: str = None\n        self._pre_signed_part_urls: Mapping[int, str] = None\n\n    @classmethod\n    def _get_remaining_part_numbers(cls, upload_status):\n        part_numbers = []\n        parts_state = upload_status[\"partsState\"]\n\n        # parts are 1-based\n        for i, part_status in enumerate(parts_state, 1):\n            if part_status == \"0\":\n                part_numbers.append(i)\n\n        return len(parts_state), part_numbers\n\n    @classmethod\n    def _get_thread_session(cls):\n        # get a lazily initialized requests.Session from the thread.\n        # we want to share a requests.Session over the course of a thread\n        # to take advantage of persistent http connection. we put it on a\n        # thread local rather that in the task closure since a connection can\n        # be reused across separate part uploads so no reason to restrict it\n        # per worker task.\n        session = getattr(_thread_local, \"session\", None)\n        if not session:\n            session = _thread_local.session = requests.Session()\n        return session\n\n    def _is_copy(self):\n        # is this a copy or upload request\n        return (\n            self._upload_request_payload.get(\"concreteType\")\n            == concrete_types.MULTIPART_UPLOAD_COPY_REQUEST\n        )\n\n    def _create_synapse_upload(self):\n        return self._syn.restPOST(\n            \"/file/multipart?forceRestart={}\".format(str(self._force_restart).lower()),\n            json.dumps(self._upload_request_payload),\n            endpoint=self._syn.fileHandleEndpoint,\n        )\n\n    def _fetch_pre_signed_part_urls(\n        self,\n        upload_id: str,\n        part_numbers: List[int],\n        requests_session: requests.Session = None,\n    ) -&gt; Mapping[int, str]:\n        uri = \"/file/multipart/{upload_id}/presigned/url/batch\".format(\n            upload_id=upload_id\n        )\n        body = {\n            \"uploadId\": upload_id,\n            \"partNumbers\": part_numbers,\n        }\n\n        response = self._syn.restPOST(\n            uri,\n            json.dumps(body),\n            requests_session=requests_session,\n            endpoint=self._syn.fileHandleEndpoint,\n        )\n\n        part_urls = {}\n        for part in response[\"partPresignedUrls\"]:\n            part_urls[part[\"partNumber\"]] = (\n                part[\"uploadPresignedUrl\"],\n                part.get(\"signedHeaders\", {}),\n            )\n\n        return part_urls\n\n    def _refresh_pre_signed_part_urls(\n        self,\n        part_number: int,\n        expired_url: str,\n    ):\n        \"\"\"Refresh all unfetched presigned urls, and return the refreshed\n        url for the given part number. If an existing expired_url is passed\n        and the url for the given part has already changed that new url\n        will be returned without a refresh (i.e. it is assumed that another\n        thread has already refreshed the url since the passed url expired).\n\n        Arguments:\n            part_number: the part number whose refreshed url should\n                         be returned\n            expired_url: the url that was detected as expired triggering\n                         this refresh\n        Returns:\n            refreshed URL\n\n        \"\"\"\n        with self._lock:\n            current_url = self._pre_signed_part_urls[part_number]\n            if current_url != expired_url:\n                # if the url has already changed since the given url\n                # was detected as expired we can assume that another\n                # thread already refreshed the url and can avoid the extra\n                # fetch.\n                refreshed_url = current_url\n            else:\n                self._pre_signed_part_urls = self._fetch_pre_signed_part_urls(\n                    self._upload_id,\n                    list(self._pre_signed_part_urls.keys()),\n                )\n\n                refreshed_url = self._pre_signed_part_urls[part_number]\n\n            return refreshed_url\n\n    def _handle_part(self, part_number, otel_context: typing.Union[Context, None]):\n        if otel_context:\n            context.attach(otel_context)\n        with tracer.start_as_current_span(\"UploadAttempt::_handle_part\"):\n            trace.get_current_span().set_attributes(\n                {\"thread.id\": threading.get_ident()}\n            )\n            with self._lock:\n                if self._aborted:\n                    # this upload attempt has already been aborted\n                    # so we short circuit the attempt to upload this part\n                    raise SynapseUploadAbortedException(\n                        \"Upload aborted, skipping part {}\".format(part_number)\n                    )\n\n                part_url, signed_headers = self._pre_signed_part_urls.get(part_number)\n\n            session = self._get_thread_session()\n\n            # obtain the body (i.e. the upload bytes) for the given part number.\n            body = (\n                self._part_request_body_provider_fn(part_number)\n                if self._part_request_body_provider_fn\n                else None\n            )\n            part_size = len(body) if body else 0\n            for retry in range(2):\n\n                def put_fn():\n                    with tracer.start_as_current_span(\"UploadAttempt::put_part\"):\n                        return session.put(part_url, body, headers=signed_headers)\n\n                try:\n                    # use our backoff mechanism here, we have encountered 500s on puts to AWS signed urls\n                    response = with_retry(\n                        put_fn, retry_exceptions=[requests.exceptions.ConnectionError]\n                    )\n                    _raise_for_status(response)\n\n                    # completed upload part to s3 successfully\n                    break\n\n                except SynapseHTTPError as ex:\n                    if ex.response.status_code == 403 and retry &lt; 1:\n                        # we interpret this to mean our pre_signed url expired.\n                        self._syn.logger.debug(\n                            \"The pre-signed upload URL for part {} has expired.\"\n                            \"Refreshing urls and retrying.\\n\".format(part_number)\n                        )\n\n                        # we refresh all the urls and obtain this part's\n                        # specific url for the retry\n                        with tracer.start_as_current_span(\n                            \"UploadAttempt::refresh_pre_signed_part_urls\"\n                        ):\n                            (\n                                part_url,\n                                signed_headers,\n                            ) = self._refresh_pre_signed_part_urls(\n                                part_number,\n                                part_url,\n                            )\n\n                    else:\n                        raise\n\n            md5_hex = self._md5_fn(body, response)\n\n            # now tell synapse that we uploaded that part successfully\n            self._syn.restPUT(\n                \"/file/multipart/{upload_id}/add/{part_number}?partMD5Hex={md5}\".format(\n                    upload_id=self._upload_id,\n                    part_number=part_number,\n                    md5=md5_hex,\n                ),\n                requests_session=session,\n                endpoint=self._syn.fileHandleEndpoint,\n            )\n\n            # remove so future batch pre_signed url fetches will exclude this part\n            with self._lock:\n                del self._pre_signed_part_urls[part_number]\n\n            return part_number, part_size\n\n    def _upload_parts(self, part_count, remaining_part_numbers):\n        trace.get_current_span().set_attributes({\"thread.id\": threading.get_ident()})\n        time_upload_started = time.time()\n        completed_part_count = part_count - len(remaining_part_numbers)\n        file_size = self._upload_request_payload.get(\"fileSizeBytes\")\n\n        if not self._is_copy():\n            # we won't have bytes to measure during a copy so the byte oriented progress bar is not useful\n            progress = previously_transferred = min(\n                completed_part_count * self._part_size,\n                file_size,\n            )\n\n            self._syn._print_transfer_progress(\n                progress,\n                file_size,\n                prefix=\"Uploading\",\n                postfix=self._dest_file_name,\n                previouslyTransferred=previously_transferred,\n            )\n\n        self._pre_signed_part_urls = self._fetch_pre_signed_part_urls(\n            self._upload_id,\n            remaining_part_numbers,\n        )\n\n        futures = []\n        with _executor(self._max_threads, False) as executor:\n            # we don't wait on the shutdown since we do so ourselves below\n\n            for part_number in remaining_part_numbers:\n                futures.append(\n                    executor.submit(\n                        self._handle_part,\n                        part_number,\n                        context.get_current(),\n                    )\n                )\n\n        for result in concurrent.futures.as_completed(futures):\n            try:\n                _, part_size = result.result()\n\n                if part_size and not self._is_copy():\n                    progress += part_size\n                    self._syn._print_transfer_progress(\n                        min(progress, file_size),\n                        file_size,\n                        prefix=\"Uploading\",\n                        postfix=self._dest_file_name,\n                        dt=time.time() - time_upload_started,\n                        previouslyTransferred=previously_transferred,\n                    )\n            except (Exception, KeyboardInterrupt) as cause:\n                with self._lock:\n                    self._aborted = True\n\n                # wait for all threads to complete before\n                # raising the exception, we don't want to return\n                # control while there are still threads from this\n                # upload attempt running\n                concurrent.futures.wait(futures)\n\n                if isinstance(cause, KeyboardInterrupt):\n                    raise SynapseUploadAbortedException(\"User interrupted upload\")\n                raise SynapseUploadFailedException(\"Part upload failed\") from cause\n\n    def _complete_upload(self):\n        upload_status_response = self._syn.restPUT(\n            \"/file/multipart/{upload_id}/complete\".format(\n                upload_id=self._upload_id,\n            ),\n            requests_session=self._get_thread_session(),\n            endpoint=self._syn.fileHandleEndpoint,\n        )\n\n        upload_state = upload_status_response.get(\"state\")\n        if upload_state != \"COMPLETED\":\n            # at this point we think successfully uploaded all the parts\n            # but the upload status isn't complete, we'll throw an error\n            # and let a subsequent attempt try to reconcile\n            raise SynapseUploadFailedException(\n                \"Upload status has an unexpected state {}\".format(upload_state)\n            )\n\n        return upload_status_response\n\n    def __call__(self):\n        upload_status_response = self._create_synapse_upload()\n        upload_state = upload_status_response.get(\"state\")\n\n        if upload_state != \"COMPLETED\":\n            self._upload_id = upload_status_response[\"uploadId\"]\n            part_count, remaining_part_numbers = self._get_remaining_part_numbers(\n                upload_status_response\n            )\n\n            # if no remaining part numbers then all the parts have been\n            # uploaded but the upload has not been marked complete.\n            if remaining_part_numbers:\n                self._upload_parts(part_count, remaining_part_numbers)\n            upload_status_response = self._complete_upload()\n\n        return upload_status_response\n</code></pre>"},{"location":"reference/core/#synapseclient.core.upload.multipart_upload-functions","title":"Functions","text":""},{"location":"reference/core/#synapseclient.core.upload.multipart_upload.multipart_upload_file","title":"<code>multipart_upload_file(syn, file_path, dest_file_name=None, content_type=None, part_size=None, storage_location_id=None, preview=True, force_restart=False, max_threads=None, md5=None)</code>","text":"<p>Upload a file to a Synapse upload destination in chunks.</p> PARAMETER DESCRIPTION <code>syn</code> <p>a Synapse object</p> <p> </p> <code>file_path</code> <p>the file to upload</p> <p> TYPE: <code>str</code> </p> <code>dest_file_name</code> <p>upload as a different filename</p> <p> TYPE: <code>str</code> DEFAULT: <code>None</code> </p> <code>content_type</code> <p>Refers to the Content-Type of the API request.</p> <p> TYPE: <code>str</code> DEFAULT: <code>None</code> </p> <code>part_size</code> <p>Number of bytes per part. Minimum is 5MiB (5 * 1024 * 1024 bytes).</p> <p> TYPE: <code>int</code> DEFAULT: <code>None</code> </p> <code>storage_location_id</code> <p>an id indicating where the file should be                  stored. Retrieved from Synapse's UploadDestination</p> <p> TYPE: <code>str</code> DEFAULT: <code>None</code> </p> <code>preview</code> <p>True to generate a preview</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> <code>force_restart</code> <p>True to restart a previously initiated upload            from scratch, False to try to resume</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>max_threads</code> <p>number of concurrent threads to devote          to upload</p> <p> TYPE: <code>int</code> DEFAULT: <code>None</code> </p> <code>md5</code> <p>The MD5 of the file. If not provided, it will be calculated.</p> <p> TYPE: <code>str</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>str</code> <p>a File Handle ID</p> <p>Keyword arguments are passed down to _multipart_upload().</p> Source code in <code>synapseclient/core/upload/multipart_upload.py</code> <pre><code>def multipart_upload_file(\n    syn,\n    file_path: str,\n    dest_file_name: str = None,\n    content_type: str = None,\n    part_size: int = None,\n    storage_location_id: str = None,\n    preview: bool = True,\n    force_restart: bool = False,\n    max_threads: int = None,\n    md5: str = None,\n) -&gt; str:\n    \"\"\"Upload a file to a Synapse upload destination in chunks.\n\n    Arguments:\n        syn: a Synapse object\n        file_path: the file to upload\n        dest_file_name: upload as a different filename\n        content_type: Refers to the Content-Type of the API request.\n        part_size: Number of bytes per part. Minimum is 5MiB (5 * 1024 * 1024 bytes).\n        storage_location_id: an id indicating where the file should be\n                             stored. Retrieved from Synapse's UploadDestination\n        preview: True to generate a preview\n        force_restart: True to restart a previously initiated upload\n                       from scratch, False to try to resume\n        max_threads: number of concurrent threads to devote\n                     to upload\n        md5: The MD5 of the file. If not provided, it will be calculated.\n\n    Returns:\n        a File Handle ID\n\n    Keyword arguments are passed down to\n    [_multipart_upload()][synapseclient.core.upload.multipart_upload._multipart_upload].\n\n    \"\"\"\n    trace.get_current_span().set_attributes(\n        {\n            \"synapse.storage_location_id\": (\n                storage_location_id if storage_location_id is not None else \"\"\n            )\n        }\n    )\n\n    if not os.path.exists(file_path):\n        raise IOError('File \"{}\" not found.'.format(file_path))\n    if os.path.isdir(file_path):\n        raise IOError('File \"{}\" is a directory.'.format(file_path))\n\n    file_size = os.path.getsize(file_path)\n    if not dest_file_name:\n        dest_file_name = os.path.basename(file_path)\n\n    if content_type is None:\n        mime_type, _ = mimetypes.guess_type(file_path, strict=False)\n        content_type = mime_type or \"application/octet-stream\"\n\n    callback_func = Spinner().print_tick if not syn.silent else None\n    md5_hex = md5 or md5_for_file(file_path, callback=callback_func).hexdigest()\n\n    part_size = get_part_size(\n        part_size or DEFAULT_PART_SIZE,\n        file_size,\n        MIN_PART_SIZE,\n        MAX_NUMBER_OF_PARTS,\n    )\n\n    upload_request = {\n        \"concreteType\": concrete_types.MULTIPART_UPLOAD_REQUEST,\n        \"contentType\": content_type,\n        \"contentMD5Hex\": md5_hex,\n        \"fileName\": dest_file_name,\n        \"fileSizeBytes\": file_size,\n        \"generatePreview\": preview,\n        \"partSizeBytes\": part_size,\n        \"storageLocationId\": storage_location_id,\n    }\n\n    def part_fn(part_number):\n        return get_file_chunk(file_path, part_number, part_size)\n\n    return _multipart_upload(\n        syn,\n        dest_file_name,\n        upload_request,\n        part_fn,\n        md5_fn,\n        force_restart=force_restart,\n        max_threads=max_threads,\n    )\n</code></pre>"},{"location":"reference/core/#synapseclient.core.upload.multipart_upload.multipart_upload_string","title":"<code>multipart_upload_string(syn, text, dest_file_name=None, part_size=None, content_type=None, storage_location_id=None, preview=True, force_restart=False, max_threads=None)</code>","text":"<p>Upload a file to a Synapse upload destination in chunks.</p> PARAMETER DESCRIPTION <code>syn</code> <p>a Synapse object</p> <p> </p> <code>text</code> <p>a string to upload as a file.</p> <p> TYPE: <code>str</code> </p> <code>dest_file_name</code> <p>upload as a different filename</p> <p> TYPE: <code>str</code> DEFAULT: <code>None</code> </p> <code>content_type</code> <p>Refers to the Content-Type of the API request.</p> <p> TYPE: <code>str</code> DEFAULT: <code>None</code> </p> <code>part_size</code> <p>number of bytes per part. Minimum 5MB.</p> <p> TYPE: <code>int</code> DEFAULT: <code>None</code> </p> <code>storage_location_id</code> <p>an id indicating where the file should be                  stored. Retrieved from Synapse's UploadDestination</p> <p> TYPE: <code>str</code> DEFAULT: <code>None</code> </p> <code>preview</code> <p>True to generate a preview</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> <code>force_restart</code> <p>True to restart a previously initiated upload            from scratch, False to try to resume</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>max_threads</code> <p>number of concurrent threads to devote          to upload</p> <p> TYPE: <code>int</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <p>a File Handle ID</p> <p>Keyword arguments are passed down to _multipart_upload().</p> Source code in <code>synapseclient/core/upload/multipart_upload.py</code> <pre><code>def multipart_upload_string(\n    syn,\n    text: str,\n    dest_file_name: str = None,\n    part_size: int = None,\n    content_type: str = None,\n    storage_location_id: str = None,\n    preview: bool = True,\n    force_restart: bool = False,\n    max_threads: int = None,\n):\n    \"\"\"Upload a file to a Synapse upload destination in chunks.\n\n    Arguments:\n        syn: a Synapse object\n        text: a string to upload as a file.\n        dest_file_name: upload as a different filename\n        content_type: Refers to the Content-Type of the API request.\n        part_size: number of bytes per part. Minimum 5MB.\n        storage_location_id: an id indicating where the file should be\n                             stored. Retrieved from Synapse's UploadDestination\n        preview: True to generate a preview\n        force_restart: True to restart a previously initiated upload\n                       from scratch, False to try to resume\n        max_threads: number of concurrent threads to devote\n                     to upload\n\n    Returns:\n        a File Handle ID\n\n    Keyword arguments are passed down to\n    [_multipart_upload()][synapseclient.core.upload.multipart_upload._multipart_upload].\n\n    \"\"\"\n    data = text.encode(\"utf-8\")\n    file_size = len(data)\n    md5_hex = md5_fn(data, None)\n\n    if not dest_file_name:\n        dest_file_name = \"message.txt\"\n\n    if not content_type:\n        content_type = \"text/plain; charset=utf-8\"\n\n    part_size = get_part_size(\n        part_size or DEFAULT_PART_SIZE,\n        file_size,\n        MIN_PART_SIZE,\n        MAX_NUMBER_OF_PARTS,\n    )\n\n    upload_request = {\n        \"concreteType\": concrete_types.MULTIPART_UPLOAD_REQUEST,\n        \"contentType\": content_type,\n        \"contentMD5Hex\": md5_hex,\n        \"fileName\": dest_file_name,\n        \"fileSizeBytes\": file_size,\n        \"generatePreview\": preview,\n        \"partSizeBytes\": part_size,\n        \"storageLocationId\": storage_location_id,\n    }\n\n    def part_fn(part_number):\n        return get_data_chunk(data, part_number, part_size)\n\n    part_size = get_part_size(\n        part_size or DEFAULT_PART_SIZE,\n        file_size,\n        MIN_PART_SIZE,\n        MAX_NUMBER_OF_PARTS,\n    )\n    return _multipart_upload(\n        syn,\n        dest_file_name,\n        upload_request,\n        part_fn,\n        md5_fn,\n        force_restart=force_restart,\n        max_threads=max_threads,\n    )\n</code></pre>"},{"location":"reference/core/#synapseclient.core.upload.multipart_upload.multipart_copy","title":"<code>multipart_copy(syn, source_file_handle_association, dest_file_name=None, part_size=None, storage_location_id=None, preview=True, force_restart=False, max_threads=None)</code>","text":"<p>Makes a Multipart Upload Copy Request. This request performs a copy of an existing file handle without data transfer from the client.</p> PARAMETER DESCRIPTION <code>syn</code> <p>A Synapse object</p> <p> </p> <code>source_file_handle_association</code> <p>Describes an association of a FileHandle with another object.</p> <p> </p> <code>dest_file_name</code> <p>The name of the file to be uploaded.</p> <p> TYPE: <code>str</code> DEFAULT: <code>None</code> </p> <code>part_size</code> <p>The size that each part will be (in bytes).</p> <p> TYPE: <code>int</code> DEFAULT: <code>None</code> </p> <code>storage_location_id</code> <p>The identifier of the storage location where this file should be copied to.                  The user must be the owner of the storage location.</p> <p> TYPE: <code>str</code> DEFAULT: <code>None</code> </p> <code>preview</code> <p>True to generate a preview of the data.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> <code>force_restart</code> <p>True to restart a previously initiated upload from scratch, False to try to resume.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>max_threads</code> <p>Number of concurrent threads to devote to copy.</p> <p> TYPE: <code>int</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <p>a File Handle ID</p> <p>Keyword arguments are passed down to _multipart_upload().</p> Source code in <code>synapseclient/core/upload/multipart_upload.py</code> <pre><code>def multipart_copy(\n    syn,\n    source_file_handle_association,\n    dest_file_name: str = None,\n    part_size: int = None,\n    storage_location_id: str = None,\n    preview: bool = True,\n    force_restart: bool = False,\n    max_threads: int = None,\n):\n    \"\"\"Makes a\n    [Multipart Upload Copy Request](https://rest-docs.synapse.org/rest/org/sagebionetworks/repo/model/file/MultipartUploadCopyRequest.html).\n    This request performs a copy of an existing file handle without data transfer from the client.\n\n    Arguments:\n        syn: A Synapse object\n        source_file_handle_association: Describes an association of a FileHandle with another object.\n        dest_file_name: The name of the file to be uploaded.\n        part_size: The size that each part will be (in bytes).\n        storage_location_id: The identifier of the storage location where this file should be copied to.\n                             The user must be the owner of the storage location.\n        preview: True to generate a preview of the data.\n        force_restart: True to restart a previously initiated upload from scratch, False to try to resume.\n        max_threads: Number of concurrent threads to devote to copy.\n\n    Returns:\n        a File Handle ID\n\n    Keyword arguments are passed down to\n    [_multipart_upload()][synapseclient.core.upload.multipart_upload._multipart_upload].\n\n    \"\"\"\n    part_size = part_size or DEFAULT_PART_SIZE\n\n    upload_request = {\n        \"concreteType\": concrete_types.MULTIPART_UPLOAD_COPY_REQUEST,\n        \"fileName\": dest_file_name,\n        \"generatePreview\": preview,\n        \"partSizeBytes\": part_size,\n        \"sourceFileHandleAssociation\": source_file_handle_association,\n        \"storageLocationId\": storage_location_id,\n    }\n\n    return _multipart_upload(\n        syn,\n        dest_file_name,\n        upload_request,\n        copy_part_request_body_provider_fn,\n        copy_md5_fn,\n        force_restart=force_restart,\n        max_threads=max_threads,\n    )\n</code></pre>"},{"location":"reference/core/#synapseclient.core.upload.multipart_upload._multipart_upload","title":"<code>_multipart_upload(syn, dest_file_name, upload_request, part_fn, md5_fn, force_restart=False, max_threads=None)</code>","text":"<p>Calls upon an UploadAttempt object to initiate and/or retry a multipart file upload or copy. This function is wrapped by multipart_upload_file, multipart_upload_string, and multipart_copy. Retries cannot exceed 7 retries per call.</p> PARAMETER DESCRIPTION <code>syn</code> <p>A Synapse object</p> <p> </p> <code>dest_file_name</code> <p>upload as a different filename</p> <p> </p> <code>upload_request</code> <p>A dictionary object with the user-fed logistical             details of the upload/copy request.</p> <p> </p> <code>part_fn</code> <p>Function to calculate the partSize of each part</p> <p> </p> <code>md5_fn</code> <p>Function to calculate the MD5 of the file-like object</p> <p> </p> <code>max_threads</code> <p>number of concurrent threads to devote to upload.</p> <p> TYPE: <code>int</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <p>A File Handle ID</p> Source code in <code>synapseclient/core/upload/multipart_upload.py</code> <pre><code>def _multipart_upload(\n    syn,\n    dest_file_name,\n    upload_request,\n    part_fn,\n    md5_fn,\n    force_restart: bool = False,\n    max_threads: int = None,\n):\n    \"\"\"Calls upon an [UploadAttempt][synapseclient.core.upload.multipart_upload.UploadAttempt]\n    object to initiate and/or retry a multipart file upload or copy. This function is wrapped by\n    [multipart_upload_file][synapseclient.core.upload.multipart_upload.multipart_upload_file],\n    [multipart_upload_string][synapseclient.core.upload.multipart_upload.multipart_upload_string], and\n    [multipart_copy][synapseclient.core.upload.multipart_upload.multipart_copy].\n    Retries cannot exceed 7 retries per call.\n\n    Arguments:\n        syn: A Synapse object\n        dest_file_name: upload as a different filename\n        upload_request: A dictionary object with the user-fed logistical\n                        details of the upload/copy request.\n        part_fn: Function to calculate the partSize of each part\n        md5_fn: Function to calculate the MD5 of the file-like object\n        max_threads: number of concurrent threads to devote to upload.\n\n    Returns:\n        A File Handle ID\n\n    \"\"\"\n    if max_threads is None:\n        max_threads = pool_provider.DEFAULT_NUM_THREADS\n\n    max_threads = max(max_threads, 1)\n\n    retry = 0\n    while True:\n        try:\n            upload_status_response = UploadAttempt(\n                syn,\n                dest_file_name,\n                upload_request,\n                part_fn,\n                md5_fn,\n                max_threads,\n                # only force_restart the first time through (if requested).\n                # a retry after a caught exception will not restart the upload\n                # from scratch.\n                force_restart and retry == 0,\n            )()\n\n            # success\n            return upload_status_response[\"resultFileHandleId\"]\n\n        except SynapseUploadFailedException:\n            if retry &lt; MAX_RETRIES:\n                retry += 1\n            else:\n                raise\n</code></pre>"},{"location":"reference/core/#upload-async","title":"Upload Async","text":""},{"location":"reference/core/#synapseclient.core.upload.upload_functions_async","title":"<code>synapseclient.core.upload.upload_functions_async</code>","text":"<p>This module handles the various ways that a user can upload a file to Synapse.</p>"},{"location":"reference/core/#synapseclient.core.upload.upload_functions_async-classes","title":"Classes","text":""},{"location":"reference/core/#synapseclient.core.upload.upload_functions_async-functions","title":"Functions","text":""},{"location":"reference/core/#synapseclient.core.upload.upload_functions_async.upload_file_handle","title":"<code>upload_file_handle(syn, parent_entity_id, path, synapse_store=True, md5=None, file_size=None, mimetype=None)</code>  <code>async</code>","text":"<p>Uploads the file in the provided path (if necessary) to a storage location based on project settings. Returns a new FileHandle as a dict to represent the stored file.</p> PARAMETER DESCRIPTION <code>syn</code> <p>The synapse client</p> <p> TYPE: <code>Synapse</code> </p> <code>parent_entity_id</code> <p>The ID of the parent entity that the file will be attached to.</p> <p> TYPE: <code>str</code> </p> <code>path</code> <p>The file path to the file being uploaded</p> <p> TYPE: <code>str</code> </p> <code>synapse_store</code> <p>If False, will not upload the file, but instead create an ExternalFileHandle that references the file on the local machine. If True, will upload the file based on StorageLocation determined by the parent_entity_id.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> <code>md5</code> <p>The MD5 checksum for the file, if known. Otherwise if the file is a local file, it will be calculated automatically.</p> <p> TYPE: <code>str</code> DEFAULT: <code>None</code> </p> <code>file_size</code> <p>The size the file, if known. Otherwise if the file is a local file, it will be calculated automatically.</p> <p> TYPE: <code>int</code> DEFAULT: <code>None</code> </p> <code>mimetype</code> <p>The MIME type the file, if known. Otherwise if the file is a local file, it will be calculated automatically.</p> <p> TYPE: <code>str</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>Dict[str, Union[str, int]]</code> <p>A dictionary of a new FileHandle as a dict that represents the uploaded file</p> Source code in <code>synapseclient/core/upload/upload_functions_async.py</code> <pre><code>async def upload_file_handle(\n    syn: \"Synapse\",\n    parent_entity_id: str,\n    path: str,\n    synapse_store: bool = True,\n    md5: str = None,\n    file_size: int = None,\n    mimetype: str = None,\n) -&gt; Dict[str, Union[str, int]]:\n    \"\"\"\n    Uploads the file in the provided path (if necessary) to a storage location based\n    on project settings. Returns a new FileHandle as a dict to represent the\n    stored file.\n\n    Arguments:\n        syn: The synapse client\n        parent_entity_id: The ID of the parent entity that the file will be attached to.\n        path: The file path to the file being uploaded\n        synapse_store: If False, will not upload the file, but instead create an\n            ExternalFileHandle that references the file on the local machine. If True,\n            will upload the file based on StorageLocation determined by the\n            parent_entity_id.\n        md5: The MD5 checksum for the file, if known. Otherwise if the file is a\n            local file, it will be calculated automatically.\n        file_size: The size the file, if known. Otherwise if the file is a local file,\n            it will be calculated automatically.\n        mimetype: The MIME type the file, if known. Otherwise if the file is a local\n            file, it will be calculated automatically.\n\n    Returns:\n        A dictionary of a new FileHandle as a dict that represents the uploaded file\n    \"\"\"\n    if path is None:\n        raise ValueError(\"path can not be None\")\n\n    # if doing a external file handle with no actual upload\n    if not synapse_store:\n        return await create_external_file_handle(\n            syn, path, mimetype=mimetype, md5=md5, file_size=file_size\n        )\n\n    # expand the path because past this point an upload is required and some upload functions require an absolute path\n    expanded_upload_path = os.path.expandvars(os.path.expanduser(path))\n\n    if md5 is None and os.path.isfile(expanded_upload_path):\n        md5 = await utils.md5_for_file_multiprocessing(\n            filename=expanded_upload_path,\n            process_pool_executor=syn._get_process_pool_executor(\n                asyncio_event_loop=asyncio.get_running_loop()\n            ),\n            md5_semaphore=syn._get_md5_semaphore(\n                asyncio_event_loop=asyncio.get_running_loop()\n            ),\n        )\n\n    entity_parent_id = id_of(parent_entity_id)\n\n    # determine the upload function based on the UploadDestination\n    location = await get_upload_destination(\n        entity_id=entity_parent_id, synapse_client=syn\n    )\n    upload_destination_type = location.get(\"concreteType\", None) if location else None\n    trace.get_current_span().set_attributes(\n        {\n            \"synapse.parent_id\": entity_parent_id,\n            \"synapse.upload_destination_type\": upload_destination_type,\n        }\n    )\n\n    if (\n        sts_transfer.is_boto_sts_transfer_enabled(syn)\n        and await sts_transfer.is_storage_location_sts_enabled_async(\n            syn, entity_parent_id, location\n        )\n        and upload_destination_type == concrete_types.EXTERNAL_S3_UPLOAD_DESTINATION\n    ):\n        return await upload_synapse_sts_boto_s3(\n            syn=syn,\n            parent_id=entity_parent_id,\n            upload_destination=location,\n            local_path=expanded_upload_path,\n            mimetype=mimetype,\n            md5=md5,\n            storage_str=\"Uploading file to external S3 storage using boto3\",\n        )\n\n    elif upload_destination_type in (\n        concrete_types.SYNAPSE_S3_UPLOAD_DESTINATION,\n        concrete_types.EXTERNAL_S3_UPLOAD_DESTINATION,\n        concrete_types.EXTERNAL_GCP_UPLOAD_DESTINATION,\n    ):\n        if upload_destination_type == concrete_types.SYNAPSE_S3_UPLOAD_DESTINATION:\n            storage_str = \"Uploading to Synapse storage\"\n        elif upload_destination_type == concrete_types.EXTERNAL_S3_UPLOAD_DESTINATION:\n            storage_str = \"Uploading to your external S3 storage\"\n        else:\n            storage_str = \"Uploading to your external Google Bucket storage\"\n\n        return await upload_synapse_s3(\n            syn=syn,\n            file_path=expanded_upload_path,\n            storage_location_id=location[\"storageLocationId\"],\n            mimetype=mimetype,\n            md5=md5,\n            storage_str=storage_str,\n        )\n    # external file handle (sftp)\n    elif upload_destination_type == concrete_types.EXTERNAL_UPLOAD_DESTINATION:\n        if location[\"uploadType\"] == \"SFTP\":\n            storage_str = (\n                f\"Uploading to: {urllib_parse.urlparse(location['url']).netloc}\"\n            )\n            banner = location.get(\"banner\", None)\n            if banner:\n                syn.logger.info(banner)\n            return await upload_external_file_handle_sftp(\n                syn=syn,\n                file_path=expanded_upload_path,\n                sftp_url=location[\"url\"],\n                mimetype=mimetype,\n                md5=md5,\n                storage_str=storage_str,\n            )\n        else:\n            raise NotImplementedError(\"Can only handle SFTP upload locations.\")\n    # client authenticated S3\n    elif (\n        upload_destination_type\n        == concrete_types.EXTERNAL_OBJECT_STORE_UPLOAD_DESTINATION\n    ):\n        storage_str = f\"Uploading to endpoint: [{location.get('endpointUrl')}] bucket: [{location.get('bucket')}]\"\n        banner = location.get(\"banner\", None)\n        if banner:\n            syn.logger.info(banner)\n        return await upload_client_auth_s3(\n            syn=syn,\n            file_path=expanded_upload_path,\n            bucket=location[\"bucket\"],\n            endpoint_url=location[\"endpointUrl\"],\n            key_prefix=location[\"keyPrefixUUID\"],\n            storage_location_id=location[\"storageLocationId\"],\n            mimetype=mimetype,\n            md5=md5,\n            storage_str=storage_str,\n        )\n    else:  # unknown storage location\n        return await upload_synapse_s3(\n            syn=syn,\n            file_path=expanded_upload_path,\n            storage_location_id=None,\n            mimetype=mimetype,\n            md5=md5,\n            storage_str=\"Uploading to Synapse storage\",\n        )\n</code></pre>"},{"location":"reference/core/#synapseclient.core.upload.upload_functions_async.create_external_file_handle","title":"<code>create_external_file_handle(syn, path, mimetype=None, md5=None, file_size=None)</code>  <code>async</code>","text":"<p>Create a file handle in Synapse without uploading any files. This is used in cases where one wishes to store a reference to a file that is not in Synapse.</p> Source code in <code>synapseclient/core/upload/upload_functions_async.py</code> <pre><code>async def create_external_file_handle(\n    syn: \"Synapse\",\n    path: str,\n    mimetype: str = None,\n    md5: str = None,\n    file_size: int = None,\n) -&gt; Dict[str, Union[str, int]]:\n    \"\"\"Create a file handle in Synapse without uploading any files. This is used in\n    cases where one wishes to store a reference to a file that is not in Synapse.\"\"\"\n    is_local_file = False  # defaults to false\n    url = as_url(os.path.expandvars(os.path.expanduser(path)))\n    if is_url(url):\n        parsed_url = urllib_parse.urlparse(url)\n        parsed_path = file_url_to_path(url)\n        if parsed_url.scheme == \"file\" and os.path.isfile(parsed_path):\n            actual_md5 = await utils.md5_for_file_multiprocessing(\n                filename=parsed_path,\n                process_pool_executor=syn._get_process_pool_executor(\n                    asyncio_event_loop=asyncio.get_running_loop()\n                ),\n                md5_semaphore=syn._get_md5_semaphore(\n                    asyncio_event_loop=asyncio.get_running_loop()\n                ),\n            )\n            if md5 is not None and md5 != actual_md5:\n                raise SynapseMd5MismatchError(\n                    f\"The specified md5 [{md5}] does not match the calculated md5 \"\n                    f\"[{actual_md5}] for local file [{parsed_path}]\",\n                )\n            md5 = actual_md5\n            file_size = os.stat(parsed_path).st_size\n            is_local_file = True\n    else:\n        raise ValueError(f\"externalUrl [{url}] is not a valid url\")\n\n    # just creates the file handle because there is nothing to upload\n    file_handle = await post_external_filehandle(\n        external_url=url, mimetype=mimetype, md5=md5, file_size=file_size\n    )\n    if is_local_file:\n        syn.cache.add(\n            file_handle_id=file_handle[\"id\"], path=file_url_to_path(url), md5=md5\n        )\n    trace.get_current_span().set_attributes(\n        {\"synapse.file_handle_id\": file_handle[\"id\"]}\n    )\n    return file_handle\n</code></pre>"},{"location":"reference/core/#synapseclient.core.upload.upload_functions_async.upload_external_file_handle_sftp","title":"<code>upload_external_file_handle_sftp(syn, file_path, sftp_url, mimetype=None, md5=None, storage_str=None)</code>  <code>async</code>","text":"<p>Upload a file to an SFTP server and create a file handle in Synapse.</p> Source code in <code>synapseclient/core/upload/upload_functions_async.py</code> <pre><code>async def upload_external_file_handle_sftp(\n    syn: \"Synapse\",\n    file_path: str,\n    sftp_url: str,\n    mimetype: str = None,\n    md5: str = None,\n    storage_str: str = None,\n) -&gt; Dict[str, Union[str, int]]:\n    \"\"\"Upload a file to an SFTP server and create a file handle in Synapse.\"\"\"\n    username, password = syn._getUserCredentials(url=sftp_url)\n    uploaded_url = SFTPWrapper.upload_file(\n        file_path,\n        urllib_parse.unquote(sftp_url),\n        username,\n        password,\n        storage_str=storage_str,\n    )\n\n    file_md5 = md5 or await utils.md5_for_file_multiprocessing(\n        filename=file_path,\n        process_pool_executor=syn._get_process_pool_executor(\n            asyncio_event_loop=asyncio.get_running_loop()\n        ),\n        md5_semaphore=syn._get_md5_semaphore(\n            asyncio_event_loop=asyncio.get_running_loop()\n        ),\n    )\n    file_handle = await post_external_filehandle(\n        external_url=uploaded_url,\n        mimetype=mimetype,\n        md5=file_md5,\n        file_size=os.stat(file_path).st_size,\n    )\n    syn.cache.add(file_handle_id=file_handle[\"id\"], path=file_path, md5=file_md5)\n    return file_handle\n</code></pre>"},{"location":"reference/core/#synapseclient.core.upload.upload_functions_async.upload_synapse_s3","title":"<code>upload_synapse_s3(syn, file_path, storage_location_id=None, mimetype=None, force_restart=False, md5=None, storage_str=None)</code>  <code>async</code>","text":"<p>Upload a file to Synapse storage and create a file handle in Synapse.</p> Argments <p>syn: The synapse client file_path: The path to the file to upload. storage_location_id: The storage location ID. mimetype: The mimetype of the file. force_restart: If True, will force the upload to restart. md5: The MD5 checksum for the file. storage_str: The storage string.</p> RETURNS DESCRIPTION <code>Dict[str, Union[str, int]]</code> <p>A dictionary of the file handle.</p> Source code in <code>synapseclient/core/upload/upload_functions_async.py</code> <pre><code>async def upload_synapse_s3(\n    syn: \"Synapse\",\n    file_path: str,\n    storage_location_id: Optional[int] = None,\n    mimetype: str = None,\n    force_restart: bool = False,\n    md5: str = None,\n    storage_str: str = None,\n) -&gt; Dict[str, Union[str, int]]:\n    \"\"\"Upload a file to Synapse storage and create a file handle in Synapse.\n\n    Argments:\n        syn: The synapse client\n        file_path: The path to the file to upload.\n        storage_location_id: The storage location ID.\n        mimetype: The mimetype of the file.\n        force_restart: If True, will force the upload to restart.\n        md5: The MD5 checksum for the file.\n        storage_str: The storage string.\n\n    Returns:\n        A dictionary of the file handle.\n    \"\"\"\n    file_handle_id = await multipart_upload_file_async(\n        syn=syn,\n        file_path=file_path,\n        content_type=mimetype,\n        storage_location_id=storage_location_id,\n        md5=md5,\n        force_restart=force_restart,\n        storage_str=storage_str,\n    )\n    syn.cache.add(file_handle_id=file_handle_id, path=file_path, md5=md5)\n\n    return await get_file_handle(file_handle_id=file_handle_id, synapse_client=syn)\n</code></pre>"},{"location":"reference/core/#synapseclient.core.upload.upload_functions_async.upload_synapse_sts_boto_s3","title":"<code>upload_synapse_sts_boto_s3(syn, parent_id, upload_destination, local_path, mimetype=None, md5=None, storage_str=None)</code>  <code>async</code>","text":"<p>When uploading to Synapse storage normally the back end will generate a random prefix for our uploaded object. Since in this case the client is responsible for the remote key, the client will instead generate a random prefix. this both ensures we don't have a collision with an existing S3 object and also mitigates potential performance issues, although key locality performance issues are likely resolved as of: https://aws.amazon.com/about-aws/whats-new/2018/07/amazon-s3-announces-increased-request-rate-performance/</p> PARAMETER DESCRIPTION <code>syn</code> <p>The synapse client</p> <p> TYPE: <code>Synapse</code> </p> <code>parent_id</code> <p>The synapse ID of the parent.</p> <p> TYPE: <code>str</code> </p> <code>upload_destination</code> <p>The upload destination</p> <p> TYPE: <code>Dict[str, Union[str, int]]</code> </p> <code>local_path</code> <p>The local path to the file to upload.</p> <p> TYPE: <code>str</code> </p> <code>mimetype</code> <p>The mimetype is known. Defaults to None.</p> <p> TYPE: <code>str</code> DEFAULT: <code>None</code> </p> <code>md5</code> <p>MD5 checksum for the file, if known.</p> <p> TYPE: <code>str</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>Dict[str, Union[str, int, bool]]</code> <p>description</p> Source code in <code>synapseclient/core/upload/upload_functions_async.py</code> <pre><code>async def upload_synapse_sts_boto_s3(\n    syn: \"Synapse\",\n    parent_id: str,\n    upload_destination: Dict[str, Union[str, int]],\n    local_path: str,\n    mimetype: str = None,\n    md5: str = None,\n    storage_str: str = None,\n) -&gt; Dict[str, Union[str, int, bool]]:\n    \"\"\"\n    When uploading to Synapse storage normally the back end will generate a random prefix\n    for our uploaded object. Since in this case the client is responsible for the remote\n    key, the client will instead generate a random prefix. this both ensures we don't have a collision\n    with an existing S3 object and also mitigates potential performance issues, although\n    key locality performance issues are likely resolved as of:\n    &lt;https://aws.amazon.com/about-aws/whats-new/2018/07/amazon-s3-announces-increased-request-rate-performance/&gt;\n\n    Arguments:\n        syn: The synapse client\n        parent_id: The synapse ID of the parent.\n        upload_destination: The upload destination\n        local_path: The local path to the file to upload.\n        mimetype: The mimetype is known. Defaults to None.\n        md5: MD5 checksum for the file, if known.\n\n    Returns:\n        _description_\n    \"\"\"\n    key_prefix = str(uuid.uuid4())\n\n    bucket_name = upload_destination[\"bucket\"]\n    storage_location_id = upload_destination[\"storageLocationId\"]\n    remote_file_key = \"/\".join(\n        [\n            upload_destination.get(\"baseKey\", \"\"),\n            key_prefix,\n            os.path.basename(local_path),\n        ]\n    )\n\n    def upload_fn(credentials: Dict[str, str]) -&gt; str:\n        \"\"\"Wrapper for the upload function.\"\"\"\n        return S3ClientWrapper.upload_file(\n            bucket=bucket_name,\n            endpoint_url=None,\n            remote_file_key=remote_file_key,\n            upload_file_path=local_path,\n            credentials=credentials,\n            transfer_config_kwargs={\"max_concurrency\": syn.max_threads},\n            storage_str=storage_str,\n        )\n\n    loop = asyncio.get_event_loop()\n\n    await loop.run_in_executor(\n        syn._get_thread_pool_executor(asyncio_event_loop=loop),\n        lambda: sts_transfer.with_boto_sts_credentials(\n            upload_fn, syn, parent_id, \"read_write\"\n        ),\n    )\n\n    return await post_external_s3_file_handle(\n        bucket_name=bucket_name,\n        s3_file_key=remote_file_key,\n        file_path=local_path,\n        storage_location_id=storage_location_id,\n        mimetype=mimetype,\n        md5=md5,\n        synapse_client=syn,\n    )\n</code></pre>"},{"location":"reference/core/#synapseclient.core.upload.upload_functions_async.upload_client_auth_s3","title":"<code>upload_client_auth_s3(syn, file_path, bucket, endpoint_url, key_prefix, storage_location_id, mimetype=None, md5=None, storage_str=None)</code>  <code>async</code>","text":"<p>Use the S3 client to upload a file to an S3 bucket.</p> Source code in <code>synapseclient/core/upload/upload_functions_async.py</code> <pre><code>async def upload_client_auth_s3(\n    syn: \"Synapse\",\n    file_path: str,\n    bucket: str,\n    endpoint_url: str,\n    key_prefix: str,\n    storage_location_id: int,\n    mimetype: str = None,\n    md5: str = None,\n    storage_str: str = None,\n) -&gt; Dict[str, Union[str, int]]:\n    \"\"\"Use the S3 client to upload a file to an S3 bucket.\"\"\"\n    profile = get_client_authenticated_s3_profile(\n        endpoint=endpoint_url, bucket=bucket, config_path=syn.configPath\n    )\n    file_key = key_prefix + \"/\" + os.path.basename(file_path)\n    loop = asyncio.get_event_loop()\n\n    await loop.run_in_executor(\n        syn._get_thread_pool_executor(asyncio_event_loop=loop),\n        lambda: S3ClientWrapper.upload_file(\n            bucket=bucket,\n            endpoint_url=endpoint_url,\n            remote_file_key=file_key,\n            upload_file_path=file_path,\n            profile_name=profile,\n            credentials=_get_aws_credentials(),\n            storage_str=storage_str,\n        ),\n    )\n\n    file_handle = await post_external_object_store_filehandle(\n        s3_file_key=file_key,\n        file_path=file_path,\n        storage_location_id=storage_location_id,\n        mimetype=mimetype,\n        md5=md5,\n        synapse_client=syn,\n    )\n    syn.cache.add(file_handle_id=file_handle[\"id\"], path=file_path, md5=md5)\n\n    return file_handle\n</code></pre>"},{"location":"reference/core/#multipart-upload-async","title":"Multipart Upload Async","text":""},{"location":"reference/core/#synapseclient.core.upload.multipart_upload_async","title":"<code>synapseclient.core.upload.multipart_upload_async</code>","text":"<p>Implements the client side of Synapse's Multipart File Upload API, which provides a robust means of uploading large files (into the 10s of GiB). End users should not need to call any of the methods under UploadAttempt directly.</p> <p>This mermaid flowchart illustrates the process of uploading a file to Synapse using the multipart upload API.</p> <pre><code>flowchart  TD\n    upload_file_handle --&gt; before-upload\n    subgraph before-upload\n        subgraph Disk I/O &amp; CPU\n            subgraph Multi-Processing\n                md5[\"Calculate MD5\"]\n            end\n            mime[\"Guess mime type\"]\n            file_size[\"Get file size\"]\n            file_name[\"Get file name\"]\n        end\n\n        subgraph HTTP\n            upload_destination[\"Find where to Upload \n GET /entity/{entity_id}/uploadDestination\"]\n            start_upload[\"Start upload with Synapse \n POST /file/multipart\"]\n            presigned_urls[\"Get URLs to upload to \n POST /file/multipart/{upload_id}/presigned/url/batch\"]\n        end\n    end\n\n    before-upload --&gt; during-upload\n\n    subgraph during-upload\n        subgraph multi-threaded[\"multi-threaded for each part\"]\n            read_part[\"Read part to upload into Memory\"]\n            read_part --&gt; put_part[\"HTTP PUT to storage provider\"]\n\n            subgraph thread_locked1[\"Lock thread\"]\n                refresh_check{\"New URl available?\"}\n                refresh_check --&gt; |no|refresh\n                refresh[\"Refresh remaining URLs to upload to \n POST /file/multipart/{upload_id}/presigned/url/batch\"]\n            end\n\n\n            put_part --&gt; |URL Expired|refresh_check\n            refresh_check --&gt; |yes|put_part\n            refresh --&gt; put_part\n            put_part --&gt; |Finished|md5_part[\"Calculate MD5 of part\"]\n        end\n        complete_part[\"PUT /file/multipart/{upload_id}/add/{part_number}?partMD5Hex={md5_hex}\"]\n        multi-threaded --&gt;|Upload finished| complete_part\n    end\n\n    during-upload --&gt; post-upload\n\n    subgraph post-upload\n        post_upload_compelete[\"PUT /file/multipart/{upload_id}/complete\"]\n        get_file_handle[\"GET /fileHandle/{file_handle_id}\"]\n    end\n\n    post-upload --&gt; entity[\"Create/Update Synapse entity\"]</code></pre>"},{"location":"reference/core/#synapseclient.core.upload.multipart_upload_async-classes","title":"Classes","text":""},{"location":"reference/core/#synapseclient.core.upload.multipart_upload_async.HandlePartResult","title":"<code>HandlePartResult</code>  <code>dataclass</code>","text":"<p>Result of a part upload.</p> ATTRIBUTE DESCRIPTION <code>part_number</code> <p>The part number that was uploaded.</p> <p> TYPE: <code>int</code> </p> <code>part_size</code> <p>The size of the part that was uploaded.</p> <p> TYPE: <code>int</code> </p> <code>md5_hex</code> <p>The MD5 hash of the part that was uploaded.</p> <p> TYPE: <code>str</code> </p> Source code in <code>synapseclient/core/upload/multipart_upload_async.py</code> <pre><code>@dataclass\nclass HandlePartResult:\n    \"\"\"Result of a part upload.\n\n    Attributes:\n        part_number: The part number that was uploaded.\n        part_size: The size of the part that was uploaded.\n        md5_hex: The MD5 hash of the part that was uploaded.\n    \"\"\"\n\n    part_number: int\n    part_size: int\n    md5_hex: str\n</code></pre>"},{"location":"reference/core/#synapseclient.core.upload.multipart_upload_async.UploadAttemptAsync","title":"<code>UploadAttemptAsync</code>","text":"<p>Used to handle multi-threaded operations for uploading one or parts of a file.</p> Source code in <code>synapseclient/core/upload/multipart_upload_async.py</code> <pre><code>class UploadAttemptAsync:\n    \"\"\"\n    Used to handle multi-threaded operations for uploading one or parts of a file.\n    \"\"\"\n\n    def __init__(\n        self,\n        syn: \"Synapse\",\n        dest_file_name: str,\n        upload_request_payload: Dict[str, Any],\n        part_request_body_provider_fn: Union[None, Callable[[int], bytes]],\n        md5_fn: Callable[[bytes, httpx.Response], str],\n        force_restart: bool,\n        storage_str: str = None,\n    ) -&gt; None:\n        self._syn = syn\n        self._dest_file_name = dest_file_name\n        self._part_size = upload_request_payload[\"partSizeBytes\"]\n\n        self._upload_request_payload = upload_request_payload\n\n        self._part_request_body_provider_fn = part_request_body_provider_fn\n        self._md5_fn = md5_fn\n\n        self._force_restart = force_restart\n\n        self._lock = asyncio.Lock()\n        self._thread_lock = threading.Lock()\n        self._aborted = False\n        self._storage_str = storage_str\n\n        self._close_progress_bar = getattr(_thread_local, \"progress_bar\", None) is None\n        # populated later\n        self._upload_id: Optional[str] = None\n        self._pre_signed_part_urls: Optional[Mapping[int, str]] = None\n        self._progress_bar = None\n\n    async def __call__(self) -&gt; Dict[str, str]:\n        \"\"\"Orchestrate the upload of a file to Synapse.\"\"\"\n        upload_status_response = await post_file_multipart(\n            upload_request_payload=self._upload_request_payload,\n            force_restart=self._force_restart,\n            endpoint=self._syn.fileHandleEndpoint,\n            synapse_client=self._syn,\n        )\n        upload_state = upload_status_response.get(\"state\")\n\n        if upload_state != \"COMPLETED\":\n            self._upload_id = upload_status_response[\"uploadId\"]\n            part_count, remaining_part_numbers = self._get_remaining_part_numbers(\n                upload_status_response\n            )\n\n            # if no remaining part numbers then all the parts have been\n            # uploaded but the upload has not been marked complete.\n            if remaining_part_numbers:\n                await self._upload_parts(part_count, remaining_part_numbers)\n            upload_status_response = await self._complete_upload()\n\n        return upload_status_response\n\n    @classmethod\n    def _get_remaining_part_numbers(\n        cls, upload_status: Dict[str, str]\n    ) -&gt; Tuple[int, List[int]]:\n        part_numbers = []\n        parts_state = upload_status[\"partsState\"]\n\n        # parts are 1-based\n        for i, part_status in enumerate(parts_state, 1):\n            if part_status == \"0\":\n                part_numbers.append(i)\n\n        return len(parts_state), part_numbers\n\n    def _is_copy(self) -&gt; bool:\n        # is this a copy or upload request\n        return (\n            self._upload_request_payload.get(\"concreteType\")\n            == concrete_types.MULTIPART_UPLOAD_COPY_REQUEST\n        )\n\n    async def _fetch_pre_signed_part_urls_async(\n        self,\n        upload_id: str,\n        part_numbers: List[int],\n    ) -&gt; Mapping[int, str]:\n        trace.get_current_span().set_attributes({\"synapse.upload_id\": upload_id})\n        response = await post_file_multipart_presigned_urls(\n            upload_id=upload_id,\n            part_numbers=part_numbers,\n            synapse_client=self._syn,\n        )\n\n        part_urls = {}\n        for part in response[\"partPresignedUrls\"]:\n            part_urls[part[\"partNumber\"]] = (\n                part[\"uploadPresignedUrl\"],\n                part.get(\"signedHeaders\", {}),\n            )\n\n        return part_urls\n\n    def _refresh_pre_signed_part_urls(\n        self,\n        part_number: int,\n        expired_url: str,\n    ) -&gt; Tuple[str, Dict[str, str]]:\n        \"\"\"Refresh all unfetched presigned urls, and return the refreshed\n        url for the given part number. If an existing expired_url is passed\n        and the url for the given part has already changed that new url\n        will be returned without a refresh (i.e. it is assumed that another\n        thread has already refreshed the url since the passed url expired).\n\n        Arguments:\n            part_number: the part number whose refreshed url should\n                         be returned\n            expired_url: the url that was detected as expired triggering\n                         this refresh\n        Returns:\n            refreshed URL\n\n        \"\"\"\n        with self._thread_lock:\n            current_url, headers = self._pre_signed_part_urls[part_number]\n            if current_url != expired_url:\n                # if the url has already changed since the given url\n                # was detected as expired we can assume that another\n                # thread already refreshed the url and can avoid the extra\n                # fetch.\n                refreshed_url = current_url, headers\n            else:\n                self._pre_signed_part_urls = wrap_async_to_sync(\n                    self._fetch_pre_signed_part_urls_async(\n                        self._upload_id,\n                        list(self._pre_signed_part_urls.keys()),\n                    ),\n                    syn=self._syn,\n                )\n\n                refreshed_url = self._pre_signed_part_urls[part_number]\n\n        return refreshed_url\n\n    async def _handle_part_wrapper(self, part_number: int) -&gt; HandlePartResult:\n        loop = asyncio.get_running_loop()\n        otel_context = context.get_current()\n\n        mem_info = psutil.virtual_memory()\n\n        if mem_info.available &lt;= self._part_size * 2:\n            gc.collect()\n\n        return await loop.run_in_executor(\n            self._syn._get_thread_pool_executor(asyncio_event_loop=loop),\n            self._handle_part,\n            part_number,\n            otel_context,\n        )\n\n    async def _upload_parts(\n        self, part_count: int, remaining_part_numbers: List[int]\n    ) -&gt; None:\n        \"\"\"Take a list of part numbers and upload them to the pre-signed URLs.\n\n        Arguments:\n            part_count: The total number of parts in the upload.\n            remaining_part_numbers: The parts that still need to be uploaded.\n        \"\"\"\n        completed_part_count = part_count - len(remaining_part_numbers)\n        file_size = self._upload_request_payload.get(\"fileSizeBytes\")\n\n        self._pre_signed_part_urls = await self._fetch_pre_signed_part_urls_async(\n            upload_id=self._upload_id,\n            part_numbers=remaining_part_numbers,\n        )\n\n        async_tasks = []\n\n        for part_number in remaining_part_numbers:\n            async_tasks.append(\n                asyncio.create_task(self._handle_part_wrapper(part_number=part_number))\n            )\n\n        if not self._syn.silent and not self._progress_bar:\n            if self._is_copy():\n                # we won't have bytes to measure during a copy so the byte oriented\n                # progress bar is not useful\n                self._progress_bar = getattr(\n                    _thread_local, \"progress_bar\", None\n                ) or tqdm(\n                    total=part_count,\n                    desc=self._storage_str or \"Copying\",\n                    unit_scale=True,\n                    postfix=self._dest_file_name,\n                    smoothing=0,\n                )\n                self._progress_bar.update(completed_part_count)\n            else:\n                previously_transferred = min(\n                    completed_part_count * self._part_size,\n                    file_size,\n                )\n\n                self._progress_bar = getattr(\n                    _thread_local, \"progress_bar\", None\n                ) or tqdm(\n                    total=file_size,\n                    desc=self._storage_str or \"Uploading\",\n                    unit=\"B\",\n                    unit_scale=True,\n                    postfix=self._dest_file_name,\n                    smoothing=0,\n                )\n                self._progress_bar.update(previously_transferred)\n\n        raised_exception = await self._orchestrate_upload_part_tasks(async_tasks)\n\n        if raised_exception is not None:\n            if isinstance(raised_exception, KeyboardInterrupt):\n                raise SynapseUploadAbortedException(\n                    \"User interrupted upload\"\n                ) from raised_exception\n            raise SynapseUploadFailedException(\n                \"Part upload failed\"\n            ) from raised_exception\n\n    def _update_progress_bar(self, part_size: int) -&gt; None:\n        \"\"\"Update the progress bar with the given part size.\"\"\"\n        if self._syn.silent or not self._progress_bar:\n            return\n        self._progress_bar.update(1 if self._is_copy() else part_size)\n\n    async def _orchestrate_upload_part_tasks(\n        self, async_tasks: List[asyncio.Task]\n    ) -&gt; Union[Exception, KeyboardInterrupt, None]:\n        \"\"\"\n        Orchestrate the result of the upload part tasks. If successful, send a\n        request to the server to add the part to the upload.\n\n        Arguments:\n            async_tasks: A set of tasks to orchestrate.\n\n        Returns:\n            An exception if one was raised, otherwise None.\n        \"\"\"\n        raised_exception = None\n\n        while async_tasks:\n            done_tasks, pending_tasks = await asyncio.wait(\n                async_tasks, return_when=asyncio.FIRST_COMPLETED\n            )\n            async_tasks = pending_tasks\n            for completed_task in done_tasks:\n                try:\n                    task_result = completed_task.result()\n\n                    if isinstance(task_result, HandlePartResult):\n                        part_number = task_result.part_number\n                        part_size = task_result.part_size\n                        part_md5_hex = task_result.md5_hex\n                    elif (\n                        isinstance(task_result, AddPartResponse)\n                        and task_result.add_part_state != \"ADD_SUCCESS\"\n                    ):\n                        # Restart the file upload process resuming where this left off.\n                        # Rest docs state:\n                        # \"If add part fails for any reason, the client must re-upload\n                        # the part and then re-attempt to add the part to the upload.\"\n                        raise SynapseUploadFailedException(\n                            (\n                                \"Adding individual part failed with unexpected state: \"\n                                f\"{task_result.add_part_state}, for upload \"\n                                f\"{task_result.upload_id} and part \"\n                                f\"{task_result.part_number} with message: \"\n                                f\"{task_result.error_message}\"\n                            )\n                        )\n                    else:\n                        continue\n\n                    async_tasks.add(\n                        asyncio.create_task(\n                            put_file_multipart_add(\n                                upload_id=self._upload_id,\n                                part_number=part_number,\n                                md5_hex=part_md5_hex,\n                                synapse_client=self._syn,\n                            )\n                        )\n                    )\n\n                    self._update_progress_bar(part_size=part_size)\n\n                except (Exception, KeyboardInterrupt) as cause:\n                    with self._thread_lock:\n                        if self._aborted:\n                            # we've already aborted, no need to raise\n                            # another exception\n                            continue\n                        self._aborted = True\n                    raised_exception = cause\n                    continue\n        return raised_exception\n\n    async def _complete_upload(self) -&gt; Dict[str, str]:\n        \"\"\"Close the upload and mark it as complete.\n\n        Returns:\n            The response from the server for the completed upload.\n        \"\"\"\n        if not self._syn.silent and self._progress_bar and self._close_progress_bar:\n            self._progress_bar.close()\n        upload_status_response = await put_file_multipart_complete(\n            upload_id=self._upload_id,\n            endpoint=self._syn.fileHandleEndpoint,\n            synapse_client=self._syn,\n        )\n\n        upload_state = upload_status_response.get(\"state\")\n        if upload_state != \"COMPLETED\":\n            # at this point we think successfully uploaded all the parts\n            # but the upload status isn't complete, we'll throw an error\n            # and let a subsequent attempt try to reconcile\n            raise SynapseUploadFailedException(\n                f\"Upload status has an unexpected state {upload_state}\"\n            )\n\n        return upload_status_response\n\n    def _handle_part(\n        self, part_number: int, otel_context: Union[Context, None]\n    ) -&gt; HandlePartResult:\n        \"\"\"Take an individual part number and upload it to the pre-signed URL.\n\n        Arguments:\n            part_number: The part number to upload.\n            otel_context: The OpenTelemetry context to use for tracing.\n\n        Returns:\n            The result of the part upload.\n\n        Raises:\n            SynapseUploadAbortedException: If the upload has been aborted.\n            ValueError: If the part body is None.\n        \"\"\"\n        if otel_context:\n            context.attach(otel_context)\n        with self._thread_lock:\n            if self._aborted:\n                # this upload attempt has already been aborted\n                # so we short circuit the attempt to upload this part\n                raise SynapseUploadAbortedException(\n                    f\"Upload aborted, skipping part {part_number}\"\n                )\n\n            part_url, signed_headers = self._pre_signed_part_urls.get(part_number)\n\n        session: httpx.Client = self._syn._requests_session_storage\n\n        # obtain the body (i.e. the upload bytes) for the given part number.\n        body = (\n            self._part_request_body_provider_fn(part_number)\n            if self._part_request_body_provider_fn\n            else None\n        )\n        part_size = len(body) if body else 0\n        self._syn.logger.debug(f\"Uploading part {part_number} of size {part_size}\")\n        if not self._is_copy() and body is None:\n            raise ValueError(f\"No body for part {part_number}\")\n\n        response = self._put_part_with_retry(\n            session=session,\n            body=body,\n            part_url=part_url,\n            signed_headers=signed_headers,\n            part_number=part_number,\n        )\n\n        md5_hex = self._md5_fn(body, response)\n        del response\n        del body\n\n        # # remove so future batch pre_signed url fetches will exclude this part\n        with self._thread_lock:\n            del self._pre_signed_part_urls[part_number]\n\n        return HandlePartResult(part_number, part_size, md5_hex)\n\n    def _put_part_with_retry(\n        self,\n        session: httpx.Client,\n        body: bytes,\n        part_url: str,\n        signed_headers: Dict[str, str],\n        part_number: int,\n    ) -&gt; Union[httpx.Response, None]:\n        \"\"\"Put a part to the storage provider with retries.\n\n        Arguments:\n            session: The requests session to use for the put.\n            body: The body of the part to put.\n            part_url: The URL to put the part to.\n            signed_headers: The signed headers to use for the put.\n            part_number: The part number being put.\n\n        Returns:\n            The response from the put.\n\n        Raises:\n            SynapseHTTPError: If the put fails.\n        \"\"\"\n        response = None\n        for retry in range(2):\n            try:\n                # use our backoff mechanism here, we have encountered 500s on puts to AWS signed urls\n\n                response = with_retry_time_based(\n                    lambda part_url=part_url, signed_headers=signed_headers: session.put(\n                        url=part_url,\n                        content=body,  # noqa: F821\n                        headers=signed_headers,\n                    ),\n                    retry_exceptions=[requests.exceptions.ConnectionError],\n                )\n\n                _raise_for_status_httpx(response=response, logger=self._syn.logger)\n\n                # completed upload part to s3 successfully\n                break\n\n            except SynapseHTTPError as ex:\n                if ex.response.status_code == 403 and retry &lt; 1:\n                    # we interpret this to mean our pre_signed url expired.\n                    self._syn.logger.debug(\n                        f\"The pre-signed upload URL for part {part_number} has expired. \"\n                        \"Refreshing urls and retrying.\\n\"\n                    )\n\n                    # we refresh all the urls and obtain this part's\n                    # specific url for the retry\n                    (\n                        part_url,\n                        signed_headers,\n                    ) = self._refresh_pre_signed_part_urls(\n                        part_number,\n                        part_url,\n                    )\n\n                else:\n                    raise\n        return response\n</code></pre>"},{"location":"reference/core/#synapseclient.core.upload.multipart_upload_async-functions","title":"Functions","text":""},{"location":"reference/core/#synapseclient.core.upload.multipart_upload_async.shared_progress_bar","title":"<code>shared_progress_bar(progress_bar)</code>","text":"<p>An outside process that will eventually trigger an upload through this module can configure a shared Progress Bar by running its code within this context manager.</p> Source code in <code>synapseclient/core/upload/multipart_upload_async.py</code> <pre><code>@contextmanager\ndef shared_progress_bar(progress_bar):\n    \"\"\"An outside process that will eventually trigger an upload through this module\n    can configure a shared Progress Bar by running its code within this context manager.\n    \"\"\"\n    _thread_local.progress_bar = progress_bar\n    try:\n        yield\n    finally:\n        _thread_local.progress_bar.close()\n        _thread_local.progress_bar.refresh()\n        del _thread_local.progress_bar\n</code></pre>"},{"location":"reference/core/#synapseclient.core.upload.multipart_upload_async.multipart_upload_file_async","title":"<code>multipart_upload_file_async(syn, file_path, dest_file_name=None, content_type=None, part_size=None, storage_location_id=None, preview=True, force_restart=False, md5=None, storage_str=None)</code>  <code>async</code>","text":"<p>Upload a file to a Synapse upload destination in chunks.</p> PARAMETER DESCRIPTION <code>syn</code> <p>a Synapse object</p> <p> TYPE: <code>Synapse</code> </p> <code>file_path</code> <p>the file to upload</p> <p> TYPE: <code>str</code> </p> <code>dest_file_name</code> <p>upload as a different filename</p> <p> TYPE: <code>str</code> DEFAULT: <code>None</code> </p> <code>content_type</code> <p>Refers to the Content-Type of the API request.</p> <p> TYPE: <code>str</code> DEFAULT: <code>None</code> </p> <code>part_size</code> <p>Number of bytes per part. Minimum is 5MiB (5 * 1024 * 1024 bytes).</p> <p> TYPE: <code>int</code> DEFAULT: <code>None</code> </p> <code>storage_location_id</code> <p>an id indicating where the file should be                  stored. Retrieved from Synapse's UploadDestination</p> <p> TYPE: <code>str</code> DEFAULT: <code>None</code> </p> <code>preview</code> <p>True to generate a preview</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> <code>force_restart</code> <p>True to restart a previously initiated upload            from scratch, False to try to resume</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>md5</code> <p>The MD5 of the file. If not provided, it will be calculated.</p> <p> TYPE: <code>str</code> DEFAULT: <code>None</code> </p> <code>storage_str</code> <p>Optional string to append to the upload message</p> <p> TYPE: <code>str</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>str</code> <p>a File Handle ID</p> <p>Keyword arguments are passed down to _multipart_upload().</p> Source code in <code>synapseclient/core/upload/multipart_upload_async.py</code> <pre><code>async def multipart_upload_file_async(\n    syn: \"Synapse\",\n    file_path: str,\n    dest_file_name: str = None,\n    content_type: str = None,\n    part_size: int = None,\n    storage_location_id: str = None,\n    preview: bool = True,\n    force_restart: bool = False,\n    md5: str = None,\n    storage_str: str = None,\n) -&gt; str:\n    \"\"\"Upload a file to a Synapse upload destination in chunks.\n\n    Arguments:\n        syn: a Synapse object\n        file_path: the file to upload\n        dest_file_name: upload as a different filename\n        content_type: Refers to the Content-Type of the API request.\n        part_size: Number of bytes per part. Minimum is 5MiB (5 * 1024 * 1024 bytes).\n        storage_location_id: an id indicating where the file should be\n                             stored. Retrieved from Synapse's UploadDestination\n        preview: True to generate a preview\n        force_restart: True to restart a previously initiated upload\n                       from scratch, False to try to resume\n        md5: The MD5 of the file. If not provided, it will be calculated.\n        storage_str: Optional string to append to the upload message\n\n    Returns:\n        a File Handle ID\n\n    Keyword arguments are passed down to\n    [_multipart_upload()][synapseclient.core.upload.multipart_upload._multipart_upload].\n\n    \"\"\"\n    trace.get_current_span().set_attributes(\n        {\n            \"synapse.storage_location_id\": (\n                storage_location_id if storage_location_id is not None else \"\"\n            )\n        }\n    )\n\n    if not os.path.exists(file_path):\n        raise IOError(f'File \"{file_path}\" not found.')\n    if os.path.isdir(file_path):\n        raise IOError(f'File \"{file_path}\" is a directory.')\n\n    file_size = os.path.getsize(file_path)\n    if not dest_file_name:\n        dest_file_name = os.path.basename(file_path)\n\n    if content_type is None:\n        mime_type, _ = mimetypes.guess_type(file_path, strict=False)\n        content_type = mime_type or \"application/octet-stream\"\n\n    md5_hex = md5 or (\n        await md5_for_file_multiprocessing(\n            filename=file_path,\n            process_pool_executor=syn._get_process_pool_executor(\n                asyncio_event_loop=asyncio.get_running_loop()\n            ),\n            md5_semaphore=syn._get_md5_semaphore(\n                asyncio_event_loop=asyncio.get_running_loop()\n            ),\n        )\n    )\n\n    part_size = get_part_size(\n        part_size or DEFAULT_PART_SIZE,\n        file_size,\n        MIN_PART_SIZE,\n        MAX_NUMBER_OF_PARTS,\n    )\n\n    upload_request = {\n        \"concreteType\": concrete_types.MULTIPART_UPLOAD_REQUEST,\n        \"contentType\": content_type,\n        \"contentMD5Hex\": md5_hex,\n        \"fileName\": dest_file_name,\n        \"fileSizeBytes\": file_size,\n        \"generatePreview\": preview,\n        \"partSizeBytes\": part_size,\n        \"storageLocationId\": storage_location_id,\n    }\n\n    def part_fn(part_number: int) -&gt; bytes:\n        \"\"\"Return the nth chunk of a file.\"\"\"\n        return get_file_chunk(file_path, part_number, part_size)\n\n    return await _multipart_upload_async(\n        syn,\n        dest_file_name,\n        upload_request,\n        part_fn,\n        md5_fn_util,\n        force_restart=force_restart,\n        storage_str=storage_str,\n    )\n</code></pre>"},{"location":"reference/core/#synapseclient.core.upload.multipart_upload_async.multipart_upload_string_async","title":"<code>multipart_upload_string_async(syn, text, dest_file_name=None, part_size=None, content_type=None, storage_location_id=None, preview=True, force_restart=False)</code>  <code>async</code>","text":"<p>Upload a file to a Synapse upload destination in chunks.</p> PARAMETER DESCRIPTION <code>syn</code> <p>a Synapse object</p> <p> TYPE: <code>Synapse</code> </p> <code>text</code> <p>a string to upload as a file.</p> <p> TYPE: <code>str</code> </p> <code>dest_file_name</code> <p>upload as a different filename</p> <p> TYPE: <code>str</code> DEFAULT: <code>None</code> </p> <code>content_type</code> <p>Refers to the Content-Type of the API request.</p> <p> TYPE: <code>str</code> DEFAULT: <code>None</code> </p> <code>part_size</code> <p>number of bytes per part. Minimum 5MB.</p> <p> TYPE: <code>int</code> DEFAULT: <code>None</code> </p> <code>storage_location_id</code> <p>an id indicating where the file should be                  stored. Retrieved from Synapse's UploadDestination</p> <p> TYPE: <code>str</code> DEFAULT: <code>None</code> </p> <code>preview</code> <p>True to generate a preview</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> <code>force_restart</code> <p>True to restart a previously initiated upload            from scratch, False to try to resume</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> RETURNS DESCRIPTION <code>str</code> <p>a File Handle ID</p> <p>Keyword arguments are passed down to _multipart_upload().</p> Source code in <code>synapseclient/core/upload/multipart_upload_async.py</code> <pre><code>async def multipart_upload_string_async(\n    syn: \"Synapse\",\n    text: str,\n    dest_file_name: str = None,\n    part_size: int = None,\n    content_type: str = None,\n    storage_location_id: str = None,\n    preview: bool = True,\n    force_restart: bool = False,\n) -&gt; str:\n    \"\"\"Upload a file to a Synapse upload destination in chunks.\n\n    Arguments:\n        syn: a Synapse object\n        text: a string to upload as a file.\n        dest_file_name: upload as a different filename\n        content_type: Refers to the Content-Type of the API request.\n        part_size: number of bytes per part. Minimum 5MB.\n        storage_location_id: an id indicating where the file should be\n                             stored. Retrieved from Synapse's UploadDestination\n        preview: True to generate a preview\n        force_restart: True to restart a previously initiated upload\n                       from scratch, False to try to resume\n\n    Returns:\n        a File Handle ID\n\n    Keyword arguments are passed down to\n    [_multipart_upload()][synapseclient.core.upload.multipart_upload._multipart_upload].\n\n    \"\"\"\n    data = text.encode(\"utf-8\")\n    file_size = len(data)\n    md5_hex = md5_fn_util(data, None)\n\n    if not dest_file_name:\n        dest_file_name = \"message.txt\"\n\n    if not content_type:\n        content_type = \"text/plain; charset=utf-8\"\n\n    part_size = get_part_size(\n        part_size or DEFAULT_PART_SIZE, file_size, MIN_PART_SIZE, MAX_NUMBER_OF_PARTS\n    )\n\n    upload_request = {\n        \"concreteType\": concrete_types.MULTIPART_UPLOAD_REQUEST,\n        \"contentType\": content_type,\n        \"contentMD5Hex\": md5_hex,\n        \"fileName\": dest_file_name,\n        \"fileSizeBytes\": file_size,\n        \"generatePreview\": preview,\n        \"partSizeBytes\": part_size,\n        \"storageLocationId\": storage_location_id,\n    }\n\n    def part_fn(part_number: int) -&gt; bytes:\n        \"\"\"Get the nth chunk of a buffer.\"\"\"\n        return get_data_chunk(data, part_number, part_size)\n\n    part_size = get_part_size(\n        part_size or DEFAULT_PART_SIZE, file_size, MIN_PART_SIZE, MAX_NUMBER_OF_PARTS\n    )\n    return await _multipart_upload_async(\n        syn,\n        dest_file_name,\n        upload_request,\n        part_fn,\n        md5_fn_util,\n        force_restart=force_restart,\n    )\n</code></pre>"},{"location":"reference/core/#synapseclient.core.upload.multipart_upload_async.multipart_copy_async","title":"<code>multipart_copy_async(syn, source_file_handle_association, dest_file_name=None, part_size=None, storage_location_id=None, preview=True, force_restart=False)</code>  <code>async</code>","text":"<p>Makes a Multipart Upload Copy Request. This request performs a copy of an existing file handle without data transfer from the client.</p> PARAMETER DESCRIPTION <code>syn</code> <p>A Synapse object</p> <p> TYPE: <code>Synapse</code> </p> <code>source_file_handle_association</code> <p>Describes an association of a FileHandle with another object.</p> <p> TYPE: <code>Dict[str, str]</code> </p> <code>dest_file_name</code> <p>The name of the file to be uploaded.</p> <p> TYPE: <code>str</code> DEFAULT: <code>None</code> </p> <code>part_size</code> <p>The size that each part will be (in bytes).</p> <p> TYPE: <code>int</code> DEFAULT: <code>None</code> </p> <code>storage_location_id</code> <p>The identifier of the storage location where this file should be copied to.                  The user must be the owner of the storage location.</p> <p> TYPE: <code>str</code> DEFAULT: <code>None</code> </p> <code>preview</code> <p>True to generate a preview of the data.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> <code>force_restart</code> <p>True to restart a previously initiated upload from scratch, False to try to resume.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> RETURNS DESCRIPTION <code>str</code> <p>a File Handle ID</p> <p>Keyword arguments are passed down to _multipart_upload().</p> Source code in <code>synapseclient/core/upload/multipart_upload_async.py</code> <pre><code>async def multipart_copy_async(\n    syn: \"Synapse\",\n    source_file_handle_association: Dict[str, str],\n    dest_file_name: str = None,\n    part_size: int = None,\n    storage_location_id: str = None,\n    preview: bool = True,\n    force_restart: bool = False,\n) -&gt; str:\n    \"\"\"Makes a\n    [Multipart Upload Copy Request](https://rest-docs.synapse.org/rest/org/sagebionetworks/repo/model/file/MultipartUploadCopyRequest.html).\n    This request performs a copy of an existing file handle without data transfer from the client.\n\n    Arguments:\n        syn: A Synapse object\n        source_file_handle_association: Describes an association of a FileHandle with another object.\n        dest_file_name: The name of the file to be uploaded.\n        part_size: The size that each part will be (in bytes).\n        storage_location_id: The identifier of the storage location where this file should be copied to.\n                             The user must be the owner of the storage location.\n        preview: True to generate a preview of the data.\n        force_restart: True to restart a previously initiated upload from scratch, False to try to resume.\n\n    Returns:\n        a File Handle ID\n\n    Keyword arguments are passed down to\n    [_multipart_upload()][synapseclient.core.upload.multipart_upload._multipart_upload].\n\n    \"\"\"\n    part_size = part_size or DEFAULT_PART_SIZE\n\n    upload_request = {\n        \"concreteType\": concrete_types.MULTIPART_UPLOAD_COPY_REQUEST,\n        \"fileName\": dest_file_name,\n        \"generatePreview\": preview,\n        \"partSizeBytes\": part_size,\n        \"sourceFileHandleAssociation\": source_file_handle_association,\n        \"storageLocationId\": storage_location_id,\n    }\n\n    return await _multipart_upload_async(\n        syn,\n        dest_file_name,\n        upload_request,\n        copy_part_request_body_provider_fn,\n        copy_md5_fn,\n        force_restart=force_restart,\n    )\n</code></pre>"},{"location":"reference/core/#multithreaded-downloading","title":"Multithreaded Downloading","text":""},{"location":"reference/core/#synapseclient.core.multithread_download","title":"<code>synapseclient.core.multithread_download</code>","text":""},{"location":"reference/core/#synapseclient.core.multithread_download-classes","title":"Classes","text":""},{"location":"reference/core/#synapseclient.core.multithread_download.DownloadRequest","title":"<code>DownloadRequest</code>","text":"<p>               Bases: <code>NamedTuple</code></p> <p>A request to download a file from Synapse</p> ATTRIBUTE DESCRIPTION <code>file_handle_id</code> <p>The file handle ID to download.</p> <p> </p> <code>object_id</code> <p>The Synapse object this file associated to.</p> <p> </p> <code>object_type</code> <p>The type of the associated Synapse object.</p> <p> </p> <code>path</code> <p>The local path to download the file to. This path can be either an absolute path or a relative path from where the code is executed to the download location.</p> <p> </p> <code>debug</code> <p>A boolean to specify if debug mode is on.</p> <p> TYPE: <code>bool</code> </p> Source code in <code>synapseclient/core/multithread_download/download_threads.py</code> <pre><code>@deprecated(\n    version=\"4.4.0\",\n    reason=\"To be removed in 5.0.0. \"\n    \"Moved to synapseclient/core/download/download_async.py\",\n)\nclass DownloadRequest(NamedTuple):\n    \"\"\"\n    A request to download a file from Synapse\n\n    Attributes:\n        file_handle_id : The file handle ID to download.\n        object_id : The Synapse object this file associated to.\n        object_type : The type of the associated Synapse object.\n        path : The local path to download the file to.\n            This path can be either an absolute path or\n            a relative path from where the code is executed to the download location.\n        debug: A boolean to specify if debug mode is on.\n    \"\"\"\n\n    file_handle_id: int\n    object_id: str\n    object_type: str\n    path: str\n    debug: bool = False\n</code></pre>"},{"location":"reference/core/#synapseclient.core.multithread_download-functions","title":"Functions","text":""},{"location":"reference/core/#synapseclient.core.multithread_download.download_file","title":"<code>download_file(client, download_request, *, max_concurrent_parts=None)</code>","text":"<p>Main driver for the multi-threaded download. Users an ExecutorService, either set externally onto a thread local by an outside process, or creating one as needed otherwise.</p> PARAMETER DESCRIPTION <code>client</code> <p>A synapseclient</p> <p> </p> <code>download_request</code> <p>A batch of DownloadRequest objects specifying what                 Synapse files to download</p> <p> TYPE: <code>DownloadRequest</code> </p> <code>max_concurrent_parts</code> <p>The maximum concurrent number parts to download                     at once when downloading this file</p> <p> TYPE: <code>int</code> DEFAULT: <code>None</code> </p> Source code in <code>synapseclient/core/multithread_download/download_threads.py</code> <pre><code>@deprecated(\n    version=\"4.4.0\",\n    reason=\"To be removed in 5.0.0. \"\n    \"Moved to synapseclient/core/download/download_async.py\",\n)\ndef download_file(\n    client,\n    download_request: DownloadRequest,\n    *,\n    max_concurrent_parts: int = None,\n):\n    \"\"\"\n    Main driver for the multi-threaded download. Users an ExecutorService,\n    either set externally onto a thread local by an outside process,\n    or creating one as needed otherwise.\n\n    Arguments:\n        client: A synapseclient\n        download_request: A batch of DownloadRequest objects specifying what\n                            Synapse files to download\n        max_concurrent_parts: The maximum concurrent number parts to download\n                                at once when downloading this file\n    \"\"\"\n\n    # we obtain an executor from a thread local if we are in the context of a Synapse sync\n    # and wan't to re-use the same threadpool as was created for that\n    executor = getattr(_thread_local, \"executor\", None)\n    shutdown_after = False\n    if not executor:\n        shutdown_after = True\n        executor = get_executor(client.max_threads)\n\n    max_concurrent_parts = max_concurrent_parts or client.max_threads\n    try:\n        downloader = _MultithreadedDownloader(client, executor, max_concurrent_parts)\n        downloader.download_file(download_request)\n    finally:\n        # if we created the Executor for the purposes of processing this download we also\n        # shut it down. if it was passed in from the outside then it's managed by the caller\n        if shutdown_after:\n            executor.shutdown()\n</code></pre>"},{"location":"reference/core/#synapseclient.core.multithread_download.shared_executor","title":"<code>shared_executor(executor)</code>","text":"<p>An outside process that will eventually trigger a download through the this module can configure a shared Executor by running its code within this context manager.</p> Source code in <code>synapseclient/core/multithread_download/download_threads.py</code> <pre><code>@contextmanager\n@deprecated(\n    version=\"4.4.0\",\n    reason=\"To be removed in 5.0.0. \"\n    \"Moved to synapseclient/core/download/download_async.py\",\n)\ndef shared_executor(executor):\n    \"\"\"An outside process that will eventually trigger a download through the this module\n    can configure a shared Executor by running its code within this context manager.\"\"\"\n    _thread_local.executor = executor\n    try:\n        yield\n    finally:\n        del _thread_local.executor\n</code></pre>"},{"location":"reference/core/#download-functions","title":"Download Functions","text":""},{"location":"reference/core/#synapseclient.core.download.download_functions","title":"<code>synapseclient.core.download.download_functions</code>","text":"<p>This module handles the various ways that a user can download a file to Synapse.</p>"},{"location":"reference/core/#synapseclient.core.download.download_functions-classes","title":"Classes","text":""},{"location":"reference/core/#synapseclient.core.download.download_functions-functions","title":"Functions","text":""},{"location":"reference/core/#synapseclient.core.download.download_functions.download_file_entity","title":"<code>download_file_entity(download_location, entity, if_collision, submission, *, synapse_client=None)</code>  <code>async</code>","text":"<p>Download file entity</p> PARAMETER DESCRIPTION <code>download_location</code> <p>The location on disk where the entity will be downloaded. If there is a matching file at the location, the download collision will be handled according to the <code>if_collision</code> argument.</p> <p> TYPE: <code>str</code> </p> <code>entity</code> <p>The Synapse Entity object</p> <p> TYPE: <code>Entity</code> </p> <code>if_collision</code> <p>Determines how to handle file collisions.                 May be</p> <ul> <li><code>overwrite.local</code></li> <li><code>keep.local</code></li> <li><code>keep.both</code></li> </ul> <p> TYPE: <code>str</code> </p> <code>submission</code> <p>Access associated files through a submission rather than through an entity.</p> <p> TYPE: <code>str</code> </p> <code>synapse_client</code> <p>If not passed in or None this will use the last client from the <code>.login()</code> method.</p> <p> TYPE: <code>Optional[Synapse]</code> DEFAULT: <code>None</code> </p> Source code in <code>synapseclient/core/download/download_functions.py</code> <pre><code>async def download_file_entity(\n    download_location: str,\n    entity: \"Entity\",\n    if_collision: str,\n    submission: str,\n    *,\n    synapse_client: Optional[\"Synapse\"] = None,\n) -&gt; None:\n    \"\"\"\n    Download file entity\n\n    Arguments:\n        download_location: The location on disk where the entity will be downloaded. If\n            there is a matching file at the location, the download collision will be\n            handled according to the `if_collision` argument.\n        entity:           The Synapse Entity object\n        if_collision:      Determines how to handle file collisions.\n                            May be\n\n            - `overwrite.local`\n            - `keep.local`\n            - `keep.both`\n\n        submission:       Access associated files through a submission rather than through an entity.\n        synapse_client: If not passed in or None this will use the last client from\n            the `.login()` method.\n    \"\"\"\n    from synapseclient import Synapse\n\n    client = Synapse.get_client(synapse_client=synapse_client)\n    # set the initial local state\n    entity.path = None\n    entity.files = []\n    entity.cacheDir = None\n\n    # check to see if an UNMODIFIED version of the file (since it was last downloaded) already exists\n    # this location could be either in .synapseCache or a user specified location to which the user previously\n    # downloaded the file\n    cached_file_path = client.cache.get(\n        file_handle_id=entity.dataFileHandleId, path=download_location\n    )\n\n    # location in .synapseCache where the file would be corresponding to its FileHandleId\n    synapse_cache_location = client.cache.get_cache_dir(\n        file_handle_id=entity.dataFileHandleId\n    )\n\n    file_name = (\n        entity._file_handle.fileName\n        if cached_file_path is None\n        else os.path.basename(cached_file_path)\n    )\n\n    # Decide the best download location for the file\n    if download_location is not None:\n        # Make sure the specified download location is a fully resolved directory\n        download_location = ensure_download_location_is_directory(download_location)\n    elif cached_file_path is not None:\n        # file already cached so use that as the download location\n        download_location = os.path.dirname(cached_file_path)\n    else:\n        # file not cached and no user-specified location so default to .synapseCache\n        download_location = synapse_cache_location\n\n    # resolve file path collisions by either overwriting, renaming, or not downloading, depending on the\n    # ifcollision value\n    download_path = resolve_download_path_collisions(\n        download_location=download_location,\n        file_name=file_name,\n        if_collision=if_collision,\n        synapse_cache_location=synapse_cache_location,\n        cached_file_path=cached_file_path,\n    )\n    if download_path is None:\n        return\n\n    if cached_file_path is not None:  # copy from cache\n        if download_path != cached_file_path:\n            # create the foider if it does not exist already\n            if not os.path.exists(download_location):\n                os.makedirs(download_location)\n            client.logger.info(\n                f\"Copying existing file from {cached_file_path} to {download_path}\"\n            )\n            shutil.copy(cached_file_path, download_path)\n\n    else:  # download the file from URL (could be a local file)\n        object_type = \"FileEntity\" if submission is None else \"SubmissionAttachment\"\n        object_id = entity[\"id\"] if submission is None else submission\n\n        # reassign downloadPath because if url points to local file (e.g. file://~/someLocalFile.txt)\n        # it won't be \"downloaded\" and, instead, downloadPath will just point to '~/someLocalFile.txt'\n        # _downloadFileHandle may also return None to indicate that the download failed\n        with logging_redirect_tqdm(loggers=[client.logger]):\n            download_path = await download_by_file_handle(\n                file_handle_id=entity.dataFileHandleId,\n                synapse_id=object_id,\n                entity_type=object_type,\n                destination=download_path,\n            )\n\n        if download_path is None or not os.path.exists(download_path):\n            return\n\n    # converts the path format from forward slashes back to backward slashes on Windows\n    entity.path = os.path.normpath(download_path)\n    entity.files = [os.path.basename(download_path)]\n    entity.cacheDir = os.path.dirname(download_path)\n</code></pre>"},{"location":"reference/core/#synapseclient.core.download.download_functions.download_file_entity_model","title":"<code>download_file_entity_model(download_location, file, if_collision, submission, *, synapse_client=None)</code>  <code>async</code>","text":"<p>Download file entity</p> PARAMETER DESCRIPTION <code>download_location</code> <p>The location on disk where the entity will be downloaded. If there is a matching file at the location, the download collision will be handled according to the <code>if_collision</code> argument.</p> <p> TYPE: <code>Union[str, None]</code> </p> <code>entity</code> <p>The File object</p> <p> </p> <code>if_collision</code> <p>Determines how to handle file collisions.                 May be</p> <ul> <li><code>overwrite.local</code></li> <li><code>keep.local</code></li> <li><code>keep.both</code></li> </ul> <p> TYPE: <code>str</code> </p> <code>submission</code> <p>Access associated files through a submission rather than through an entity.</p> <p> TYPE: <code>str</code> </p> <code>synapse_client</code> <p>If not passed in or None this will use the last client from the <code>.login()</code> method.</p> <p> TYPE: <code>Optional[Synapse]</code> DEFAULT: <code>None</code> </p> Source code in <code>synapseclient/core/download/download_functions.py</code> <pre><code>async def download_file_entity_model(\n    download_location: Union[str, None],\n    file: \"File\",\n    if_collision: str,\n    submission: str,\n    *,\n    synapse_client: Optional[\"Synapse\"] = None,\n) -&gt; None:\n    \"\"\"\n    Download file entity\n\n    Arguments:\n        download_location: The location on disk where the entity will be downloaded. If\n            there is a matching file at the location, the download collision will be\n            handled according to the `if_collision` argument.\n        entity:           The File object\n        if_collision:      Determines how to handle file collisions.\n                            May be\n\n            - `overwrite.local`\n            - `keep.local`\n            - `keep.both`\n\n        submission:       Access associated files through a submission rather than through an entity.\n        synapse_client: If not passed in or None this will use the last client from\n            the `.login()` method.\n    \"\"\"\n    from synapseclient import Synapse\n\n    client = Synapse.get_client(synapse_client=synapse_client)\n    # set the initial local state\n    file.path = None\n\n    # check to see if an UNMODIFIED version of the file (since it was last downloaded) already exists\n    # this location could be either in .synapseCache or a user specified location to which the user previously\n    # downloaded the file\n    cached_file_path = client.cache.get(\n        file_handle_id=file.data_file_handle_id, path=download_location\n    )\n\n    # location in .synapseCache where the file would be corresponding to its FileHandleId\n    synapse_cache_location = client.cache.get_cache_dir(\n        file_handle_id=file.data_file_handle_id\n    )\n\n    file_name = (\n        file.file_handle.file_name\n        if cached_file_path is None\n        else os.path.basename(cached_file_path)\n    )\n\n    # Decide the best download location for the file\n    if download_location is not None:\n        # Make sure the specified download location is a fully resolved directory\n        download_location = ensure_download_location_is_directory(download_location)\n    elif cached_file_path is not None:\n        # file already cached so use that as the download location\n        download_location = os.path.dirname(cached_file_path)\n    else:\n        # file not cached and no user-specified location so default to .synapseCache\n        download_location = synapse_cache_location\n\n    # resolve file path collisions by either overwriting, renaming, or not downloading, depending on the\n    # ifcollision value\n    download_path = resolve_download_path_collisions(\n        download_location=download_location,\n        file_name=file_name,\n        if_collision=if_collision,\n        synapse_cache_location=synapse_cache_location,\n        cached_file_path=cached_file_path,\n    )\n    if download_path is None:\n        return\n\n    if cached_file_path is not None:  # copy from cache\n        if download_path != cached_file_path:\n            # create the foider if it does not exist already\n            if not os.path.exists(download_location):\n                os.makedirs(download_location)\n            client.logger.info(\n                f\"Copying existing file from {cached_file_path} to {download_path}\"\n            )\n            shutil.copy(cached_file_path, download_path)\n\n    else:  # download the file from URL (could be a local file)\n        object_type = \"FileEntity\" if submission is None else \"SubmissionAttachment\"\n        object_id = file.id if submission is None else submission\n\n        # reassign downloadPath because if url points to local file (e.g. file://~/someLocalFile.txt)\n        # it won't be \"downloaded\" and, instead, downloadPath will just point to '~/someLocalFile.txt'\n        # _downloadFileHandle may also return None to indicate that the download failed\n        with logging_redirect_tqdm(loggers=[client.logger]):\n            download_path = await download_by_file_handle(\n                file_handle_id=file.data_file_handle_id,\n                synapse_id=object_id,\n                entity_type=object_type,\n                destination=download_path,\n            )\n\n        if download_path is None or not os.path.exists(download_path):\n            return\n\n    # converts the path format from forward slashes back to backward slashes on Windows\n    file.path = os.path.normpath(download_path)\n</code></pre>"},{"location":"reference/core/#synapseclient.core.download.download_functions.download_by_file_handle","title":"<code>download_by_file_handle(file_handle_id, synapse_id, entity_type, destination, retries=5, *, synapse_client=None)</code>  <code>async</code>","text":"<p>Download a file from the given URL to the local file system.</p> PARAMETER DESCRIPTION <code>file_handle_id</code> <p>The id of the FileHandle to download</p> <p> TYPE: <code>str</code> </p> <code>synapse_id</code> <p>The id of the Synapse object that uses the FileHandle e.g. \"syn123\"</p> <p> TYPE: <code>str</code> </p> <code>entity_type</code> <p>The type of the Synapse object that uses the FileHandle e.g. \"FileEntity\"</p> <p> TYPE: <code>str</code> </p> <code>destination</code> <p>The destination on local file system</p> <p> TYPE: <code>str</code> </p> <code>retries</code> <p>The Number of download retries attempted before throwing an exception.</p> <p> TYPE: <code>int</code> DEFAULT: <code>5</code> </p> <code>synapse_client</code> <p>If not passed in or None this will use the last client from the <code>.login()</code> method.</p> <p> TYPE: <code>Optional[Synapse]</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>str</code> <p>The path to downloaded file</p> <pre><code>sequenceDiagram\n    title Multi-Threaded Download Process with Retry Mechanism\n\n    actor Client as Client\n    participant download_functions as download_functions\n    participant download_async as download_async\n    participant download_execution as download_execution\n    participant multi_threaded_download as multi_threaded_download\n    participant remote_storage_server as remote_storage_server\n    participant file as file\n\n    activate Client\n    Client -&gt;&gt; download_functions: download_by_file_handle\n    activate download_functions\n\n    loop retryable\n\n        alt Download type = multi_threaded\n            note over download_functions: download_from_url_multi_threaded\n\n            download_functions -&gt;&gt; download_async: download_file\n            activate download_async\n\n            download_async -&gt;&gt; download_async: _generate_stream_and_write_chunk_tasks\n\n\n            loop for each download task\n                download_async -&gt;&gt; download_execution: _execute_download_tasks\n                activate download_execution\n\n                par MULTI-THREADED: Run in thread executor\n                    download_execution -&gt;&gt; multi_threaded_download: _stream_and_write_chunk\n                    activate multi_threaded_download\n\n                    loop stream chunk into memory\n                        multi_threaded_download -&gt;&gt; remote_storage_server: stream chunk from remote server\n                        remote_storage_server --&gt;&gt; multi_threaded_download: Return partial range\n                    end\n\n                    note over multi_threaded_download: Chunk loaded into memory\n\n                    alt obtain thread lock [Failed]\n                        note over multi_threaded_download: Wait to obtain lock\n                    else obtain thread lock [Success]\n                        multi_threaded_download -&gt;&gt; file: write chunk to file\n                        file --&gt;&gt; multi_threaded_download: .\n                        note over multi_threaded_download: Update progress bar\n                        note over multi_threaded_download: Release lock\n                    end\n                    multi_threaded_download --&gt;&gt; download_execution: .\n                end\n                download_execution --&gt;&gt; download_async: .\n                note over download_async: Run garbage collection every 100 iterations\n                deactivate multi_threaded_download\n                deactivate download_execution\n            end\n\n            download_async --&gt;&gt; download_functions: .\n            deactivate download_async\n\n            download_functions -&gt;&gt; download_functions: md5_for_file\n            download_functions --&gt;&gt; Client: File downloaded\n            deactivate download_functions\n        else Download type = non multi_threaded\n            note over download_functions: Execute `download_from_url`\n        else Download type = external s3 object store\n            note over download_functions: Execute `S3ClientWrapper.download_file`\n        else Download type = aws s3 sts storage\n            note over download_functions: Execute `S3ClientWrapper.download_file` with with_boto_sts_credentials\n        end\n    end\n\n    deactivate Client</code></pre> Source code in <code>synapseclient/core/download/download_functions.py</code> <pre><code>async def download_by_file_handle(\n    file_handle_id: str,\n    synapse_id: str,\n    entity_type: str,\n    destination: str,\n    retries: int = 5,\n    *,\n    synapse_client: Optional[\"Synapse\"] = None,\n) -&gt; str:\n    \"\"\"\n    Download a file from the given URL to the local file system.\n\n    Arguments:\n        file_handle_id: The id of the FileHandle to download\n        synapse_id: The id of the Synapse object that uses the FileHandle e.g. \"syn123\"\n        entity_type: The type of the Synapse object that uses the FileHandle e.g. \"FileEntity\"\n        destination: The destination on local file system\n        retries: The Number of download retries attempted before throwing an exception.\n        synapse_client: If not passed in or None this will use the last client from\n            the `.login()` method.\n\n    Returns:\n        The path to downloaded file\n\n\n    ```mermaid\n    sequenceDiagram\n        title Multi-Threaded Download Process with Retry Mechanism\n\n        actor Client as Client\n        participant download_functions as download_functions\n        participant download_async as download_async\n        participant download_execution as download_execution\n        participant multi_threaded_download as multi_threaded_download\n        participant remote_storage_server as remote_storage_server\n        participant file as file\n\n        activate Client\n        Client -&gt;&gt; download_functions: download_by_file_handle\n        activate download_functions\n\n        loop retryable\n\n            alt Download type = multi_threaded\n                note over download_functions: download_from_url_multi_threaded\n\n                download_functions -&gt;&gt; download_async: download_file\n                activate download_async\n\n                download_async -&gt;&gt; download_async: _generate_stream_and_write_chunk_tasks\n\n\n                loop for each download task\n                    download_async -&gt;&gt; download_execution: _execute_download_tasks\n                    activate download_execution\n\n                    par MULTI-THREADED: Run in thread executor\n                        download_execution -&gt;&gt; multi_threaded_download: _stream_and_write_chunk\n                        activate multi_threaded_download\n\n                        loop stream chunk into memory\n                            multi_threaded_download -&gt;&gt; remote_storage_server: stream chunk from remote server\n                            remote_storage_server --&gt;&gt; multi_threaded_download: Return partial range\n                        end\n\n                        note over multi_threaded_download: Chunk loaded into memory\n\n                        alt obtain thread lock [Failed]\n                            note over multi_threaded_download: Wait to obtain lock\n                        else obtain thread lock [Success]\n                            multi_threaded_download -&gt;&gt; file: write chunk to file\n                            file --&gt;&gt; multi_threaded_download: .\n                            note over multi_threaded_download: Update progress bar\n                            note over multi_threaded_download: Release lock\n                        end\n                        multi_threaded_download --&gt;&gt; download_execution: .\n                    end\n                    download_execution --&gt;&gt; download_async: .\n                    note over download_async: Run garbage collection every 100 iterations\n                    deactivate multi_threaded_download\n                    deactivate download_execution\n                end\n\n                download_async --&gt;&gt; download_functions: .\n                deactivate download_async\n\n                download_functions -&gt;&gt; download_functions: md5_for_file\n                download_functions --&gt;&gt; Client: File downloaded\n                deactivate download_functions\n            else Download type = non multi_threaded\n                note over download_functions: Execute `download_from_url`\n            else Download type = external s3 object store\n                note over download_functions: Execute `S3ClientWrapper.download_file`\n            else Download type = aws s3 sts storage\n                note over download_functions: Execute `S3ClientWrapper.download_file` with with_boto_sts_credentials\n            end\n        end\n\n        deactivate Client\n    ```\n    \"\"\"\n    from synapseclient import Synapse\n\n    syn = Synapse.get_client(synapse_client=synapse_client)\n    os.makedirs(os.path.dirname(destination), exist_ok=True)\n\n    while retries &gt; 0:\n        try:\n            file_handle_result: Dict[\n                str, str\n            ] = await get_file_handle_for_download_async(\n                file_handle_id=file_handle_id,\n                synapse_id=synapse_id,\n                entity_type=entity_type,\n                synapse_client=syn,\n            )\n            file_handle = file_handle_result[\"fileHandle\"]\n            concrete_type = file_handle[\"concreteType\"]\n            storage_location_id = file_handle.get(\"storageLocationId\")\n\n            if concrete_type == concrete_types.EXTERNAL_OBJECT_STORE_FILE_HANDLE:\n                profile = get_client_authenticated_s3_profile(\n                    endpoint=file_handle[\"endpointUrl\"],\n                    bucket=file_handle[\"bucket\"],\n                    config_path=syn.configPath,\n                )\n\n                progress_bar = get_or_create_download_progress_bar(\n                    file_size=1, postfix=synapse_id\n                )\n                loop = asyncio.get_running_loop()\n                downloaded_path = await loop.run_in_executor(\n                    syn._get_thread_pool_executor(asyncio_event_loop=loop),\n                    lambda: S3ClientWrapper.download_file(\n                        bucket=file_handle[\"bucket\"],\n                        endpoint_url=file_handle[\"endpointUrl\"],\n                        remote_file_key=file_handle[\"fileKey\"],\n                        download_file_path=destination,\n                        profile_name=profile,\n                        credentials=_get_aws_credentials(),\n                        progress_bar=progress_bar,\n                    ),\n                )\n\n            elif (\n                sts_transfer.is_boto_sts_transfer_enabled(syn=syn)\n                and await sts_transfer.is_storage_location_sts_enabled_async(\n                    syn=syn, entity_id=synapse_id, location=storage_location_id\n                )\n                and concrete_type == concrete_types.S3_FILE_HANDLE\n            ):\n                progress_bar = get_or_create_download_progress_bar(\n                    file_size=1, postfix=synapse_id\n                )\n\n                def download_fn(\n                    credentials: Dict[str, str],\n                    file_handle: Dict[str, str] = file_handle,\n                ) -&gt; str:\n                    \"\"\"Use the STS credentials to download the file from S3.\n\n                    Arguments:\n                        credentials: The STS credentials\n\n                    Returns:\n                        The path to the downloaded file\n                    \"\"\"\n                    return S3ClientWrapper.download_file(\n                        bucket=file_handle[\"bucketName\"],\n                        endpoint_url=None,\n                        remote_file_key=file_handle[\"key\"],\n                        download_file_path=destination,\n                        credentials=credentials,\n                        progress_bar=progress_bar,\n                        # pass through our synapse threading config to boto s3\n                        transfer_config_kwargs={\"max_concurrency\": syn.max_threads},\n                    )\n\n                loop = asyncio.get_running_loop()\n                downloaded_path = await loop.run_in_executor(\n                    syn._get_thread_pool_executor(asyncio_event_loop=loop),\n                    lambda: sts_transfer.with_boto_sts_credentials(\n                        download_fn, syn, synapse_id, \"read_only\"\n                    ),\n                )\n\n            elif (\n                syn.multi_threaded\n                and concrete_type == concrete_types.S3_FILE_HANDLE\n                and file_handle.get(\"contentSize\", 0)\n                &gt; SYNAPSE_DEFAULT_DOWNLOAD_PART_SIZE\n            ):\n                # run the download multi threaded if the file supports it, we're configured to do so,\n                # and the file is large enough that it would be broken into parts to take advantage of\n                # multiple downloading threads. otherwise it's more efficient to run the download as a simple\n                # single threaded URL download.\n                downloaded_path = await download_from_url_multi_threaded(\n                    file_handle_id=file_handle_id,\n                    object_id=synapse_id,\n                    object_type=entity_type,\n                    destination=destination,\n                    expected_md5=file_handle.get(\"contentMd5\"),\n                    synapse_client=syn,\n                )\n\n            else:\n                loop = asyncio.get_running_loop()\n                progress_bar = get_or_create_download_progress_bar(\n                    file_size=1, postfix=synapse_id\n                )\n                downloaded_path = await loop.run_in_executor(\n                    syn._get_thread_pool_executor(asyncio_event_loop=loop),\n                    lambda: download_from_url(\n                        url=file_handle_result[\"preSignedURL\"],\n                        destination=destination,\n                        file_handle_id=file_handle[\"id\"],\n                        expected_md5=file_handle.get(\"contentMd5\"),\n                        progress_bar=progress_bar,\n                        synapse_client=syn,\n                    ),\n                )\n\n            syn.logger.info(f\"Downloaded {synapse_id} to {downloaded_path}\")\n            syn.cache.add(\n                file_handle[\"id\"], downloaded_path, file_handle.get(\"contentMd5\", None)\n            )\n            close_download_progress_bar()\n            return downloaded_path\n\n        except Exception as ex:\n            if not is_retryable_download_error(ex):\n                close_download_progress_bar()\n                raise\n\n            exc_info = sys.exc_info()\n            ex.progress = 0 if not hasattr(ex, \"progress\") else ex.progress\n            syn.logger.debug(\n                f\"\\nRetrying download on error: [{exc_info[0]}] after progressing {ex.progress} bytes\",\n                exc_info=True,\n            )  # this will include stack trace\n            if ex.progress == 0:  # No progress was made reduce remaining retries.\n                retries -= 1\n            if retries &lt;= 0:\n                close_download_progress_bar()\n                # Re-raise exception\n                raise\n\n    close_download_progress_bar()\n    raise RuntimeError(\"should not reach this line\")\n</code></pre>"},{"location":"reference/core/#synapseclient.core.download.download_functions.download_from_url_multi_threaded","title":"<code>download_from_url_multi_threaded(file_handle_id, object_id, object_type, destination, *, expected_md5=None, synapse_client=None)</code>  <code>async</code>","text":"<p>Download a file from the given URL using multiple threads.</p> PARAMETER DESCRIPTION <code>file_handle_id</code> <p>The id of the FileHandle to download</p> <p> TYPE: <code>str</code> </p> <code>object_id</code> <p>The id of the Synapse object that uses the FileHandle e.g. \"syn123\"</p> <p> TYPE: <code>str</code> </p> <code>object_type</code> <p>The type of the Synapse object that uses the FileHandle e.g. \"FileEntity\". Any of https://rest-docs.synapse.org/rest/org/sagebionetworks/repo/model/file/FileHandleAssociateType.html</p> <p> TYPE: <code>str</code> </p> <code>destination</code> <p>The destination on local file system</p> <p> TYPE: <code>str</code> </p> <code>expected_md5</code> <p>The expected MD5</p> <p> TYPE: <code>str</code> DEFAULT: <code>None</code> </p> <code>content_size</code> <p>The size of the content</p> <p> </p> <code>synapse_client</code> <p>If not passed in or None this will use the last client from the <code>.login()</code> method.</p> <p> TYPE: <code>Optional[Synapse]</code> DEFAULT: <code>None</code> </p> <p>Raises:     SynapseMd5MismatchError: If the actual MD5 does not match expected MD5.</p> RETURNS DESCRIPTION <code>str</code> <p>The path to downloaded file</p> Source code in <code>synapseclient/core/download/download_functions.py</code> <pre><code>async def download_from_url_multi_threaded(\n    file_handle_id: str,\n    object_id: str,\n    object_type: str,\n    destination: str,\n    *,\n    expected_md5: str = None,\n    synapse_client: Optional[\"Synapse\"] = None,\n) -&gt; str:\n    \"\"\"\n    Download a file from the given URL using multiple threads.\n\n    Arguments:\n        file_handle_id: The id of the FileHandle to download\n        object_id:      The id of the Synapse object that uses the FileHandle\n            e.g. \"syn123\"\n        object_type:    The type of the Synapse object that uses the\n            FileHandle e.g. \"FileEntity\". Any of\n            &lt;https://rest-docs.synapse.org/rest/org/sagebionetworks/repo/model/file/FileHandleAssociateType.html&gt;\n        destination:    The destination on local file system\n        expected_md5:   The expected MD5\n        content_size:   The size of the content\n        synapse_client: If not passed in or None this will use the last client from\n            the `.login()` method.\n    Raises:\n        SynapseMd5MismatchError: If the actual MD5 does not match expected MD5.\n\n    Returns:\n        The path to downloaded file\n    \"\"\"\n    from synapseclient import Synapse\n\n    client = Synapse.get_client(synapse_client=synapse_client)\n    destination = os.path.abspath(destination)\n    temp_destination = utils.temp_download_filename(\n        destination=destination, file_handle_id=file_handle_id\n    )\n\n    request = DownloadRequest(\n        file_handle_id=int(file_handle_id),\n        object_id=object_id,\n        object_type=object_type,\n        path=temp_destination,\n        debug=client.debug,\n    )\n\n    await download_file(client=client, download_request=request)\n\n    if expected_md5:  # if md5 not set (should be the case for all except http download)\n        actual_md5 = utils.md5_for_file_hex(filename=temp_destination)\n        # check md5 if given\n        if actual_md5 != expected_md5:\n            try:\n                os.remove(temp_destination)\n            except FileNotFoundError:\n                # file already does not exist. nothing to do\n                pass\n            raise SynapseMd5MismatchError(\n                f\"Downloaded file {temp_destination}'s md5 {actual_md5} does not match expected MD5 of {expected_md5}\"\n            )\n    # once download completed, rename to desired destination\n    shutil.move(temp_destination, destination)\n\n    return destination\n</code></pre>"},{"location":"reference/core/#synapseclient.core.download.download_functions.download_from_url","title":"<code>download_from_url(url, destination, file_handle_id=None, expected_md5=None, progress_bar=None, *, synapse_client=None)</code>","text":"<p>Download a file from the given URL to the local file system.</p> PARAMETER DESCRIPTION <code>url</code> <p>The source of download</p> <p> TYPE: <code>str</code> </p> <code>destination</code> <p>The destination on local file system</p> <p> TYPE: <code>str</code> </p> <code>file_handle_id</code> <p>Optional. If given, the file will be given a temporary name that includes the file                     handle id which allows resuming partial downloads of the same file from previous                     sessions</p> <p> TYPE: <code>Optional[str]</code> DEFAULT: <code>None</code> </p> <code>expected_md5</code> <p>Optional. If given, check that the MD5 of the downloaded file matches the expected MD5</p> <p> TYPE: <code>Optional[str]</code> DEFAULT: <code>None</code> </p> <code>synapse_client</code> <p>If not passed in or None this will use the last client from the <code>.login()</code> method.</p> <p> TYPE: <code>Optional[Synapse]</code> DEFAULT: <code>None</code> </p> RAISES DESCRIPTION <code>IOError</code> <p>If the local file does not exist.</p> <code>SynapseError</code> <p>If fail to download the file.</p> <code>SynapseHTTPError</code> <p>If there are too many redirects.</p> <code>SynapseMd5MismatchError</code> <p>If the actual MD5 does not match expected MD5.</p> RETURNS DESCRIPTION <code>Union[str, None]</code> <p>The path to downloaded file or None if the download failed</p> Source code in <code>synapseclient/core/download/download_functions.py</code> <pre><code>def download_from_url(\n    url: str,\n    destination: str,\n    file_handle_id: Optional[str] = None,\n    expected_md5: Optional[str] = None,\n    progress_bar: Optional[tqdm] = None,\n    *,\n    synapse_client: Optional[\"Synapse\"] = None,\n) -&gt; Union[str, None]:\n    \"\"\"\n    Download a file from the given URL to the local file system.\n\n    Arguments:\n        url:           The source of download\n        destination:   The destination on local file system\n        file_handle_id:  Optional. If given, the file will be given a temporary name that includes the file\n                                handle id which allows resuming partial downloads of the same file from previous\n                                sessions\n        expected_md5:  Optional. If given, check that the MD5 of the downloaded file matches the expected MD5\n        synapse_client: If not passed in or None this will use the last client from\n            the `.login()` method.\n\n    Raises:\n        IOError:                 If the local file does not exist.\n        SynapseError:            If fail to download the file.\n        SynapseHTTPError:        If there are too many redirects.\n        SynapseMd5MismatchError: If the actual MD5 does not match expected MD5.\n\n    Returns:\n        The path to downloaded file or None if the download failed\n    \"\"\"\n    from synapseclient import Synapse\n\n    client = Synapse.get_client(synapse_client=synapse_client)\n\n    destination = os.path.abspath(destination)\n    actual_md5 = None\n    redirect_count = 0\n    delete_on_md5_mismatch = True\n    client.logger.debug(f\"Downloading from {url} to {destination}\")\n    while redirect_count &lt; REDIRECT_LIMIT:\n        redirect_count += 1\n        scheme = urllib_urlparse.urlparse(url).scheme\n        if scheme == \"file\":\n            delete_on_md5_mismatch = False\n            destination = utils.file_url_to_path(url, verify_exists=True)\n            if destination is None:\n                raise IOError(f\"Local file ({url}) does not exist.\")\n            if progress_bar is not None:\n                file_size = os.path.getsize(destination)\n                increment_progress_bar_total(total=file_size, progress_bar=progress_bar)\n                increment_progress_bar(n=progress_bar.total, progress_bar=progress_bar)\n            break\n        elif scheme == \"sftp\":\n            username, password = client._getUserCredentials(url)\n            destination = SFTPWrapper.download_file(\n                url=url,\n                localFilepath=destination,\n                username=username,\n                password=password,\n                progress_bar=progress_bar,\n            )\n            break\n        elif scheme == \"ftp\":\n            updated_progress_bar_with_total = False\n\n            def _ftp_report_hook(\n                _: int,\n                read_size: int,\n                total_size: int,\n            ) -&gt; None:\n                \"\"\"Report hook for urllib.request.urlretrieve to show download progress.\n\n                Arguments:\n                    _: The number of blocks transferred so far\n                    read_size: The size of each block\n                    total_size: The total size of the file\n\n                Returns:\n                    None\n                \"\"\"\n                nonlocal updated_progress_bar_with_total\n                if progress_bar is not None:\n                    if not updated_progress_bar_with_total:\n                        updated_progress_bar_with_total = True\n                        increment_progress_bar_total(\n                            total=total_size, progress_bar=progress_bar\n                        )\n                    increment_progress_bar(n=read_size, progress_bar=progress_bar)\n\n            urllib_request.urlretrieve(\n                url=url, filename=destination, reporthook=_ftp_report_hook\n            )\n            break\n        elif scheme in [\"http\", \"https\"]:\n            # if a partial download exists with the temporary name,\n            temp_destination = utils.temp_download_filename(\n                destination=destination, file_handle_id=file_handle_id\n            )\n            range_header = (\n                {\"Range\": f\"bytes={os.path.getsize(filename=temp_destination)}-\"}\n                if os.path.exists(temp_destination)\n                else {}\n            )\n\n            # pass along synapse auth credentials only if downloading directly from synapse\n            auth = (\n                client.credentials\n                if is_synapse_uri(uri=url, synapse_client=client)\n                else None\n            )\n\n            response = with_retry(\n                lambda url=url, range_header=range_header, auth=auth: client._requests_session.get(\n                    url=url,\n                    headers=client._generate_headers(range_header),\n                    stream=True,\n                    allow_redirects=False,\n                    auth=auth,\n                ),\n                verbose=client.debug,\n                **STANDARD_RETRY_PARAMS,\n            )\n            try:\n                exceptions._raise_for_status(response, verbose=client.debug)\n            except SynapseHTTPError as err:\n                if err.response.status_code == 404:\n                    raise SynapseError(f\"Could not download the file at {url}\") from err\n                elif (\n                    err.response.status_code == 416\n                ):  # Requested Range Not Statisfiable\n                    # this is a weird error when the client already finished downloading but the loop continues\n                    # When this exception occurs, the range we request is guaranteed to be &gt;= file size so we\n                    # assume that the file has been fully downloaded, rename it to destination file\n                    # and break out of the loop to perform the MD5 check.\n                    # If it fails the user can retry with another download.\n                    shutil.move(temp_destination, destination)\n                    break\n                raise\n\n            # handle redirects\n            if response.status_code in [301, 302, 303, 307, 308]:\n                url = response.headers[\"location\"]\n                # don't break, loop again\n            else:\n                # get filename from content-disposition, if we don't have it already\n                if os.path.isdir(destination):\n                    filename = utils.extract_filename(\n                        content_disposition_header=response.headers.get(\n                            \"content-disposition\", None\n                        ),\n                        default_filename=utils.guess_file_name(url),\n                    )\n                    destination = os.path.join(destination, filename)\n                # Stream the file to disk\n                if \"content-length\" in response.headers:\n                    to_be_transferred = float(response.headers[\"content-length\"])\n                else:\n                    to_be_transferred = -1\n                transferred = 0\n\n                # Servers that respect the Range header return 206 Partial Content\n                if response.status_code == 206:\n                    mode = \"ab\"\n                    previously_transferred = os.path.getsize(filename=temp_destination)\n                    to_be_transferred += previously_transferred\n                    transferred += previously_transferred\n                    increment_progress_bar_total(\n                        total=to_be_transferred, progress_bar=progress_bar\n                    )\n                    increment_progress_bar(n=transferred, progress_bar=progress_bar)\n                    client.logger.debug(\n                        f\"Resuming partial download to {temp_destination}. \"\n                        f\"{previously_transferred}/{to_be_transferred} bytes already \"\n                        \"transferred.\"\n                    )\n                    sig = utils.md5_for_file(filename=temp_destination)\n                else:\n                    mode = \"wb\"\n                    previously_transferred = 0\n                    increment_progress_bar_total(\n                        total=to_be_transferred, progress_bar=progress_bar\n                    )\n                    sig = hashlib.new(\"md5\", usedforsecurity=False)  # nosec\n\n                try:\n                    with open(temp_destination, mode) as fd:\n                        for _, chunk in enumerate(\n                            response.iter_content(FILE_BUFFER_SIZE)\n                        ):\n                            fd.write(chunk)\n                            sig.update(chunk)\n\n                            # the 'content-length' header gives the total number of bytes that will be transferred\n                            # to us len(chunk) cannot be used to track progress because iter_content automatically\n                            # decodes the chunks if the response body is encoded so the len(chunk) could be\n                            # different from the total number of bytes we've read read from the response body\n                            # response.raw.tell() is the total number of response body bytes transferred over the\n                            # wire so far\n                            transferred = response.raw.tell() + previously_transferred\n                            increment_progress_bar(\n                                n=len(chunk), progress_bar=progress_bar\n                            )\n                except (\n                    Exception\n                ) as ex:  # We will add a progress parameter then push it back to retry.\n                    ex.progress = transferred - previously_transferred\n                    raise\n\n                # verify that the file was completely downloaded and retry if it is not complete\n                if to_be_transferred &gt; 0 and transferred &lt; to_be_transferred:\n                    client.logger.warning(\n                        \"\\nRetrying download because the connection ended early.\\n\"\n                    )\n                    continue\n\n                actual_md5 = sig.hexdigest()\n                # rename to final destination\n                shutil.move(temp_destination, destination)\n                break\n        else:\n            client.logger.error(f\"Unable to download URLs of type {scheme}\")\n            return None\n\n    else:  # didn't break out of loop\n        raise SynapseHTTPError(\"Too many redirects\")\n\n    if (\n        actual_md5 is None\n    ):  # if md5 not set (should be the case for all except http download)\n        actual_md5 = utils.md5_for_file_hex(filename=destination)\n\n    # check md5 if given\n    if expected_md5 and actual_md5 != expected_md5:\n        if delete_on_md5_mismatch and os.path.exists(destination):\n            os.remove(destination)\n        raise SynapseMd5MismatchError(\n            f\"Downloaded file {destination}'s md5 {actual_md5} does not match expected MD5 of {expected_md5}\"\n        )\n\n    return destination\n</code></pre>"},{"location":"reference/core/#synapseclient.core.download.download_functions.is_retryable_download_error","title":"<code>is_retryable_download_error(ex)</code>","text":"<p>Check if the download error is retryable</p> PARAMETER DESCRIPTION <code>ex</code> <p>An exception</p> <p> TYPE: <code>Exception</code> </p> RETURNS DESCRIPTION <code>bool</code> <p>Boolean value indicating whether the download error is retryable</p> Source code in <code>synapseclient/core/download/download_functions.py</code> <pre><code>def is_retryable_download_error(ex: Exception) -&gt; bool:\n    \"\"\"\n    Check if the download error is retryable\n\n    Arguments:\n        ex: An exception\n\n    Returns:\n        Boolean value indicating whether the download error is retryable\n    \"\"\"\n    # some exceptions caught during download indicate non-recoverable situations that\n    # will not be remedied by a repeated download attempt.\n    return not (\n        (isinstance(ex, OSError) and ex.errno == errno.ENOSPC)\n        or isinstance(ex, SynapseMd5MismatchError)  # out of disk space\n    )\n</code></pre>"},{"location":"reference/core/#synapseclient.core.download.download_functions.resolve_download_path_collisions","title":"<code>resolve_download_path_collisions(download_location, file_name, if_collision, synapse_cache_location, cached_file_path, *, synapse_client=None)</code>","text":"<p>Resolve file path collisions</p> PARAMETER DESCRIPTION <code>download_location</code> <p>The location on disk where the entity will be downloaded. If there is a matching file at the location, the download collision will be handled according to the <code>if_collision</code> argument.</p> <p> TYPE: <code>str</code> </p> <code>file_name</code> <p>The file name</p> <p> TYPE: <code>str</code> </p> <code>if_collision</code> <p>Determines how to handle file collisions.                     May be \"overwrite.local\", \"keep.local\", or \"keep.both\".</p> <p> TYPE: <code>str</code> </p> <code>synapse_cache_location</code> <p>The location in .synapseCache where the file would be                     corresponding to its FileHandleId.</p> <p> TYPE: <code>str</code> </p> <code>cached_file_path</code> <p>The file path of the cached copy</p> <p> TYPE: <code>str</code> </p> RAISES DESCRIPTION <code>ValueError</code> <p>Invalid ifcollision. Should be \"overwrite.local\", \"keep.local\", or \"keep.both\".</p> RETURNS DESCRIPTION <code>Union[str, None]</code> <p>The download file path with collisions resolved or None if the file should</p> <code>Union[str, None]</code> <p>not be downloaded</p> Source code in <code>synapseclient/core/download/download_functions.py</code> <pre><code>def resolve_download_path_collisions(\n    download_location: str,\n    file_name: str,\n    if_collision: str,\n    synapse_cache_location: str,\n    cached_file_path: str,\n    *,\n    synapse_client: Optional[\"Synapse\"] = None,\n) -&gt; Union[str, None]:\n    \"\"\"\n    Resolve file path collisions\n\n    Arguments:\n        download_location: The location on disk where the entity will be downloaded. If\n            there is a matching file at the location, the download collision will be\n            handled according to the `if_collision` argument.\n        file_name:             The file name\n        if_collision:           Determines how to handle file collisions.\n                                May be \"overwrite.local\", \"keep.local\", or \"keep.both\".\n        synapse_cache_location: The location in .synapseCache where the file would be\n                                corresponding to its FileHandleId.\n        cached_file_path:      The file path of the cached copy\n\n    Raises:\n        ValueError: Invalid ifcollision. Should be \"overwrite.local\", \"keep.local\", or \"keep.both\".\n\n    Returns:\n        The download file path with collisions resolved or None if the file should\n        not be downloaded\n    \"\"\"\n    from synapseclient import Synapse\n\n    client = Synapse.get_client(synapse_client=synapse_client)\n\n    # always overwrite if we are downloading to .synapseCache\n    if utils.normalize_path(download_location) == synapse_cache_location:\n        if if_collision is not None and if_collision != COLLISION_OVERWRITE_LOCAL:\n            client.logger.warning(\n                \"\\n\"\n                + \"!\" * 50\n                + f\"\\nifcollision={if_collision} \"\n                + \"is being IGNORED because the download destination is synapse's cache.\"\n                f' Instead, the behavior is \"{COLLISION_OVERWRITE_LOCAL}\". \\n'\n                + \"!\" * 50\n                + \"\\n\"\n            )\n        if_collision = COLLISION_OVERWRITE_LOCAL\n    # if ifcollision not specified, keep.local\n    if_collision = if_collision or COLLISION_KEEP_BOTH\n\n    download_path = utils.normalize_path(os.path.join(download_location, file_name))\n    # resolve collision\n    if os.path.exists(path=download_path):\n        if if_collision == COLLISION_OVERWRITE_LOCAL:\n            pass  # Let the download proceed and overwrite the local file.\n        elif if_collision == COLLISION_KEEP_LOCAL:\n            client.logger.info(\n                f\"Found existing file at {download_path}, skipping download.\"\n            )\n\n            # Don't want to overwrite the local file.\n            download_path = None\n        elif if_collision == COLLISION_KEEP_BOTH:\n            if download_path != cached_file_path:\n                download_path = utils.unique_filename(download_path)\n        else:\n            raise ValueError(\n                f'Invalid parameter: \"{if_collision}\" is not a valid value for \"ifcollision\"'\n            )\n    return download_path\n</code></pre>"},{"location":"reference/core/#synapseclient.core.download.download_functions.ensure_download_location_is_directory","title":"<code>ensure_download_location_is_directory(download_location)</code>","text":"<p>Check if the download location is a directory</p> PARAMETER DESCRIPTION <code>download_location</code> <p>The location on disk where the entity will be downloaded.</p> <p> TYPE: <code>str</code> </p> RAISES DESCRIPTION <code>ValueError</code> <p>If the download_location is not a directory</p> RETURNS DESCRIPTION <code>str</code> <p>The download location</p> Source code in <code>synapseclient/core/download/download_functions.py</code> <pre><code>def ensure_download_location_is_directory(download_location: str) -&gt; str:\n    \"\"\"\n    Check if the download location is a directory\n\n    Arguments:\n        download_location: The location on disk where the entity will be downloaded.\n\n    Raises:\n        ValueError: If the download_location is not a directory\n\n    Returns:\n        The download location\n    \"\"\"\n    download_dir = os.path.expandvars(os.path.expanduser(download_location))\n    if os.path.isfile(download_dir):\n        raise ValueError(\n            \"Parameter 'download_location' should be a directory, not a file.\"\n        )\n    return download_dir\n</code></pre>"},{"location":"reference/core/#synapseclient.core.download.download_functions.is_synapse_uri","title":"<code>is_synapse_uri(uri, *, synapse_client=None)</code>","text":"<p>Check whether the given uri is hosted at the configured Synapse repo endpoint</p> PARAMETER DESCRIPTION <code>uri</code> <p>A given uri</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>bool</code> <p>A boolean value indicating whether the given uri is hosted at the configured Synapse repo endpoint</p> Source code in <code>synapseclient/core/download/download_functions.py</code> <pre><code>def is_synapse_uri(\n    uri: str,\n    *,\n    synapse_client: Optional[\"Synapse\"] = None,\n) -&gt; bool:\n    \"\"\"\n    Check whether the given uri is hosted at the configured Synapse repo endpoint\n\n    Arguments:\n        uri: A given uri\n\n    Returns:\n        A boolean value indicating whether the given uri is hosted at the configured Synapse repo endpoint\n    \"\"\"\n    from synapseclient import Synapse\n\n    client = Synapse.get_client(synapse_client=synapse_client)\n\n    uri_domain = urllib_urlparse.urlparse(uri).netloc\n    synapse_repo_domain = urllib_urlparse.urlparse(client.repoEndpoint).netloc\n    return uri_domain.lower() == synapse_repo_domain.lower()\n</code></pre>"},{"location":"reference/core/#async-managed-multithreaded-downloads","title":"Async managed Multithreaded Downloads","text":""},{"location":"reference/core/#synapseclient.core.download.download_async","title":"<code>synapseclient.core.download.download_async</code>","text":"<p>Logic required for the actual transferring of files.</p>"},{"location":"reference/core/#synapseclient.core.download.download_async-classes","title":"Classes","text":""},{"location":"reference/core/#synapseclient.core.download.download_async.DownloadRequest","title":"<code>DownloadRequest</code>","text":"<p>               Bases: <code>NamedTuple</code></p> <p>A request to download a file from Synapse</p> ATTRIBUTE DESCRIPTION <code>file_handle_id</code> <p>The file handle ID to download.</p> <p> </p> <code>object_id</code> <p>The Synapse object this file associated to.</p> <p> </p> <code>object_type</code> <p>The type of the associated Synapse object. Any of https://rest-docs.synapse.org/rest/org/sagebionetworks/repo/model/file/FileHandleAssociateType.html</p> <p> </p> <code>path</code> <p>The local path to download the file to. This path can be either an absolute path or a relative path from where the code is executed to the download location.</p> <p> </p> <code>debug</code> <p>A boolean to specify if debug mode is on.</p> <p> TYPE: <code>bool</code> </p> Source code in <code>synapseclient/core/download/download_async.py</code> <pre><code>class DownloadRequest(NamedTuple):\n    \"\"\"\n    A request to download a file from Synapse\n\n    Attributes:\n        file_handle_id : The file handle ID to download.\n        object_id : The Synapse object this file associated to.\n        object_type : The type of the associated Synapse object. Any of\n            &lt;https://rest-docs.synapse.org/rest/org/sagebionetworks/repo/model/file/FileHandleAssociateType.html&gt;\n        path : The local path to download the file to.\n            This path can be either an absolute path or\n            a relative path from where the code is executed to the download location.\n        debug: A boolean to specify if debug mode is on.\n    \"\"\"\n\n    file_handle_id: int\n    object_id: str\n    object_type: str\n    path: str\n    debug: bool = False\n</code></pre>"},{"location":"reference/core/#synapseclient.core.download.download_async.PresignedUrlInfo","title":"<code>PresignedUrlInfo</code>","text":"<p>               Bases: <code>NamedTuple</code></p> <p>Information about a retrieved presigned-url</p> ATTRIBUTE DESCRIPTION <code>file_name</code> <p>Name of the file for the presigned url</p> <p> TYPE: <code>str</code> </p> <code>url</code> <p>The actual presigned url</p> <p> TYPE: <code>str</code> </p> <code>expiration_utc</code> <p>datetime in UTC at which the url will expire</p> <p> TYPE: <code>datetime</code> </p> Source code in <code>synapseclient/core/download/download_async.py</code> <pre><code>class PresignedUrlInfo(NamedTuple):\n    \"\"\"\n    Information about a retrieved presigned-url\n\n    Attributes:\n        file_name: Name of the file for the presigned url\n        url: The actual presigned url\n        expiration_utc: datetime in UTC at which the url will expire\n    \"\"\"\n\n    file_name: str\n    url: str\n    expiration_utc: datetime.datetime\n</code></pre>"},{"location":"reference/core/#synapseclient.core.download.download_async.PresignedUrlProvider","title":"<code>PresignedUrlProvider</code>  <code>dataclass</code>","text":"<p>Provides an un-exipired pre-signed url to download a file</p> Source code in <code>synapseclient/core/download/download_async.py</code> <pre><code>@dataclass\nclass PresignedUrlProvider:\n    \"\"\"\n    Provides an un-exipired pre-signed url to download a file\n    \"\"\"\n\n    client: \"Synapse\"\n    request: DownloadRequest\n    _lock: _threading.Lock = _threading.Lock()\n    _cached_info: Optional[PresignedUrlInfo] = None\n\n    # offset parameter used to buffer url expiration checks, time in seconds\n    _TIME_BUFFER: datetime.timedelta = datetime.timedelta(seconds=5)\n\n    async def get_info_async(self) -&gt; PresignedUrlInfo:\n        \"\"\"\n        Using async, returns the cached info if it's not expired, otherwise\n        retrieves a new pre-signed url and returns that.\n\n        Returns:\n            Information about a retrieved presigned-url from either the cache or a\n            new request\n        \"\"\"\n        if not self._cached_info or (\n            datetime.datetime.now(tz=datetime.timezone.utc)\n            + PresignedUrlProvider._TIME_BUFFER\n            &gt;= self._cached_info.expiration_utc\n        ):\n            self._cached_info = await self._get_pre_signed_info_async()\n\n        return self._cached_info\n\n    def get_info(self) -&gt; PresignedUrlInfo:\n        \"\"\"\n        Using a thread lock, returns the cached info if it's not expired, otherwise\n        retrieves a new pre-signed url and returns that.\n\n        Returns:\n            Information about a retrieved presigned-url from either the cache or a\n            new request\n        \"\"\"\n        with self._lock:\n            if not self._cached_info or (\n                datetime.datetime.now(tz=datetime.timezone.utc)\n                + PresignedUrlProvider._TIME_BUFFER\n                &gt;= self._cached_info.expiration_utc\n            ):\n                self._cached_info = self._get_pre_signed_info()\n\n            return self._cached_info\n\n    def _get_pre_signed_info(self) -&gt; PresignedUrlInfo:\n        \"\"\"\n        Make an HTTP request to get a pre-signed url to download a file.\n\n        Returns:\n            Information about a retrieved presigned-url from a new request.\n        \"\"\"\n        response = get_file_handle_for_download(\n            file_handle_id=self.request.file_handle_id,\n            synapse_id=self.request.object_id,\n            entity_type=self.request.object_type,\n            synapse_client=self.client,\n        )\n        file_name = response[\"fileHandle\"][\"fileName\"]\n        pre_signed_url = response[\"preSignedURL\"]\n        return PresignedUrlInfo(\n            file_name=file_name,\n            url=pre_signed_url,\n            expiration_utc=_pre_signed_url_expiration_time(pre_signed_url),\n        )\n\n    async def _get_pre_signed_info_async(self) -&gt; PresignedUrlInfo:\n        \"\"\"\n        Make an HTTP request to get a pre-signed url to download a file.\n\n        Returns:\n            Information about a retrieved presigned-url from a new request.\n        \"\"\"\n        response = await get_file_handle_for_download_async(\n            file_handle_id=self.request.file_handle_id,\n            synapse_id=self.request.object_id,\n            entity_type=self.request.object_type,\n            synapse_client=self.client,\n        )\n        file_name = response[\"fileHandle\"][\"fileName\"]\n        pre_signed_url = response[\"preSignedURL\"]\n        return PresignedUrlInfo(\n            file_name=file_name,\n            url=pre_signed_url,\n            expiration_utc=_pre_signed_url_expiration_time(pre_signed_url),\n        )\n</code></pre>"},{"location":"reference/core/#synapseclient.core.download.download_async.PresignedUrlProvider-functions","title":"Functions","text":""},{"location":"reference/core/#synapseclient.core.download.download_async.PresignedUrlProvider.get_info_async","title":"<code>get_info_async()</code>  <code>async</code>","text":"<p>Using async, returns the cached info if it's not expired, otherwise retrieves a new pre-signed url and returns that.</p> RETURNS DESCRIPTION <code>PresignedUrlInfo</code> <p>Information about a retrieved presigned-url from either the cache or a</p> <code>PresignedUrlInfo</code> <p>new request</p> Source code in <code>synapseclient/core/download/download_async.py</code> <pre><code>async def get_info_async(self) -&gt; PresignedUrlInfo:\n    \"\"\"\n    Using async, returns the cached info if it's not expired, otherwise\n    retrieves a new pre-signed url and returns that.\n\n    Returns:\n        Information about a retrieved presigned-url from either the cache or a\n        new request\n    \"\"\"\n    if not self._cached_info or (\n        datetime.datetime.now(tz=datetime.timezone.utc)\n        + PresignedUrlProvider._TIME_BUFFER\n        &gt;= self._cached_info.expiration_utc\n    ):\n        self._cached_info = await self._get_pre_signed_info_async()\n\n    return self._cached_info\n</code></pre>"},{"location":"reference/core/#synapseclient.core.download.download_async.PresignedUrlProvider.get_info","title":"<code>get_info()</code>","text":"<p>Using a thread lock, returns the cached info if it's not expired, otherwise retrieves a new pre-signed url and returns that.</p> RETURNS DESCRIPTION <code>PresignedUrlInfo</code> <p>Information about a retrieved presigned-url from either the cache or a</p> <code>PresignedUrlInfo</code> <p>new request</p> Source code in <code>synapseclient/core/download/download_async.py</code> <pre><code>def get_info(self) -&gt; PresignedUrlInfo:\n    \"\"\"\n    Using a thread lock, returns the cached info if it's not expired, otherwise\n    retrieves a new pre-signed url and returns that.\n\n    Returns:\n        Information about a retrieved presigned-url from either the cache or a\n        new request\n    \"\"\"\n    with self._lock:\n        if not self._cached_info or (\n            datetime.datetime.now(tz=datetime.timezone.utc)\n            + PresignedUrlProvider._TIME_BUFFER\n            &gt;= self._cached_info.expiration_utc\n        ):\n            self._cached_info = self._get_pre_signed_info()\n\n        return self._cached_info\n</code></pre>"},{"location":"reference/core/#synapseclient.core.download.download_async-functions","title":"Functions","text":""},{"location":"reference/core/#synapseclient.core.download.download_async.download_file","title":"<code>download_file(client, download_request)</code>  <code>async</code>","text":"<p>Main driver for the multi-threaded download. Users an ExecutorService, either set externally onto a thread local by an outside process, or creating one as needed otherwise.</p> PARAMETER DESCRIPTION <code>client</code> <p>A synapseclient</p> <p> TYPE: <code>Synapse</code> </p> <code>download_request</code> <p>A batch of DownloadRequest objects specifying what                 Synapse files to download</p> <p> TYPE: <code>DownloadRequest</code> </p> Source code in <code>synapseclient/core/download/download_async.py</code> <pre><code>async def download_file(\n    client: \"Synapse\",\n    download_request: DownloadRequest,\n) -&gt; None:\n    \"\"\"\n    Main driver for the multi-threaded download. Users an ExecutorService,\n    either set externally onto a thread local by an outside process,\n    or creating one as needed otherwise.\n\n    Arguments:\n        client: A synapseclient\n        download_request: A batch of DownloadRequest objects specifying what\n                            Synapse files to download\n    \"\"\"\n    downloader = _MultithreadedDownloader(syn=client, download_request=download_request)\n    await downloader.download_file()\n</code></pre>"},{"location":"reference/core/#cache","title":"Cache","text":""},{"location":"reference/core/#synapseclient.core.cache","title":"<code>synapseclient.core.cache</code>","text":"<p>File Caching</p> <p>Implements a cache on local disk for Synapse file entities and other objects with a FileHandle. This is part of the internal implementation of the client and should not be accessed directly by users of the client.</p>"},{"location":"reference/core/#synapseclient.core.cache-classes","title":"Classes","text":""},{"location":"reference/core/#synapseclient.core.cache.Cache","title":"<code>Cache</code>","text":"<p>Represent a cache in which files are accessed by file handle ID.</p> Source code in <code>synapseclient/core/cache.py</code> <pre><code>class Cache:\n    \"\"\"\n    Represent a cache in which files are accessed by file handle ID.\n    \"\"\"\n\n    def __setattr__(self, key, value):\n        # expand out home shortcut ('~') and environment variables when setting cache_root_dir\n        if key == \"cache_root_dir\":\n            value = os.path.expandvars(os.path.expanduser(value))\n            # create the cache_root_dir if it does not already exist\n            if not os.path.exists(value):\n                os.makedirs(value, exist_ok=True)\n        self.__dict__[key] = value\n\n    def __init__(self, cache_root_dir=CACHE_ROOT_DIR, fanout=1000):\n        # set root dir of cache in which meta data will be stored and files\n        # will be stored here by default, but other locations can be specified\n        self.cache_root_dir = cache_root_dir\n        self.fanout = fanout\n        self.cache_map_file_name = \".cacheMap\"\n\n    def get_cache_dir(\n        self, file_handle_id: typing.Union[collections.abc.Mapping, str]\n    ) -&gt; str:\n        if isinstance(file_handle_id, collections.abc.Mapping):\n            if \"dataFileHandleId\" in file_handle_id:\n                file_handle_id = file_handle_id[\"dataFileHandleId\"]\n            elif (\n                \"concreteType\" in file_handle_id\n                and \"id\" in file_handle_id\n                and file_handle_id[\"concreteType\"].startswith(\n                    \"org.sagebionetworks.repo.model.file\"\n                )\n            ):\n                file_handle_id = file_handle_id[\"id\"]\n        return os.path.join(\n            self.cache_root_dir,\n            str(int(file_handle_id) % self.fanout),\n            str(file_handle_id),\n        )\n\n    def _read_cache_map(self, cache_dir: str) -&gt; dict:\n        cache_map_file = os.path.join(cache_dir, self.cache_map_file_name)\n\n        if not os.path.exists(cache_map_file):\n            return {}\n\n        with open(cache_map_file, \"r\") as f:\n            try:\n                cache_map = json.load(f)\n            except json.decoder.JSONDecodeError:\n                # a corrupt cache map file that is not parseable as JSON is treated\n                # as if it does not exist at all (will be overwritten).\n                return {}\n\n        return cache_map\n\n    def _write_cache_map(self, cache_dir: str, cache_map: dict) -&gt; None:\n        if not os.path.exists(cache_dir):\n            os.makedirs(cache_dir)\n\n        cache_map_file = os.path.join(cache_dir, self.cache_map_file_name)\n\n        with open(cache_map_file, \"w\") as f:\n            json.dump(cache_map, f)\n            f.write(\"\\n\")  # For compatibility with R's JSON parser\n\n    def _get_cache_modified_time(\n        self, cache_map_entry: typing.Union[str, dict, None]\n    ) -&gt; typing.Union[str, None]:\n        \"\"\"\n        Retrieve the `modified_time` from the `cache_map_entry`. This needed to be\n        backwards-compatible any cache entries that do not have the new JSON structure\n        for data. That means that if the cache_map_entry has a `modified_time` key,\n        then it is a new entry and we can return the value. If it does not, then it\n        is an old entry and we should return the `cache_map_entry` itself.\n\n        The caveat is that `cache_map_entry` needs to be a string to return the value\n        otherwise it will return None.\n\n        Arguments:\n            cache_map_entry: The entry from the cache map\n\n        Returns:\n            The modified time if it exists, otherwise the cache_map_entry\n        \"\"\"\n        if cache_map_entry is not None and \"modified_time\" in cache_map_entry:\n            return cache_map_entry.get(\"modified_time\", None)\n        elif cache_map_entry is not None and isinstance(cache_map_entry, str):\n            return cache_map_entry\n        return None\n\n    def _get_cache_content_md5(\n        self, cache_map_entry: typing.Union[str, dict, None]\n    ) -&gt; typing.Union[str, None]:\n        \"\"\"\n        Retrieve the `content_md5` from the cache_map_entry.\n\n        Arguments:\n            cache_map_entry: The entry from the cache map\n\n        Returns:\n            The content md5 if it exists, otherwise None\n        \"\"\"\n        if cache_map_entry is not None and \"content_md5\" in cache_map_entry:\n            return cache_map_entry.get(\"content_md5\", None)\n        else:\n            return None\n\n    def _cache_item_unmodified(\n        self, cache_map_entry: typing.Union[str, dict], path: str\n    ) -&gt; bool:\n        \"\"\"\n        Determine if the cache_map_entry is unmodified by comparing the modified_time\n        and content_md5 to the file at the given path.\n\n        Arguments:\n            cache_map_entry: The entry from the cache map\n            path:            The path to the file to compare to\n\n        Returns:\n            True if the cache_map_entry is unmodified, otherwise False\n        \"\"\"\n        cached_time = self._get_cache_modified_time(cache_map_entry)\n        cached_md5 = self._get_cache_content_md5(cache_map_entry)\n\n        # compare_timestamps has an implicit check for whether the path exists\n        return compare_timestamps(_get_modified_time(path), cached_time) and (\n            cached_md5 is None or cached_md5 == utils.md5_for_file(path).hexdigest()\n        )\n\n    def contains(\n        self, file_handle_id: typing.Union[collections.abc.Mapping, str], path: str\n    ) -&gt; bool:\n        \"\"\"\n        Given a file and file_handle_id, return True if an unmodified cached\n        copy of the file exists at the exact path given or False otherwise.\n\n        Arguments:\n            file_handle_id: The ID of the fileHandle\n            path:           The file path at which to look for a cached copy\n        \"\"\"\n        cache_dir = self.get_cache_dir(file_handle_id)\n        if not os.path.exists(cache_dir):\n            return False\n\n        with Lock(self.cache_map_file_name, dir=cache_dir):\n            cache_map = self._read_cache_map(cache_dir)\n\n            path = utils.normalize_path(path)\n\n            cached_time = self._get_cache_modified_time(cache_map.get(path, None))\n\n            if cached_time:\n                return compare_timestamps(_get_modified_time(path), cached_time)\n        return False\n\n    @tracer.start_as_current_span(\"cache::get\")\n    def get(\n        self,\n        file_handle_id: typing.Union[collections.abc.Mapping, str],\n        path: str = None,\n    ) -&gt; typing.Union[str, None]:\n        \"\"\"\n        Retrieve a file with the given file handle from the cache.\n\n        Arguments:\n            file_handle_id: The ID of the fileHandle\n            path:           If the given path is None, look for a cached copy of the\n                            file in the cache directory. If the path is a directory,\n                            look there for a cached copy. If a full file-path is\n                            given, only check whether that exact file exists and is\n                            unmodified since it was cached.\n\n        Returns:\n            Either a file path, if an unmodified cached copy of the file\n            exists in the specified location or None if it does not\n        \"\"\"\n        cache_dir = self.get_cache_dir(file_handle_id)\n        trace.get_current_span().set_attributes(\n            {\n                \"synapse.cache.dir\": cache_dir,\n                \"synapse.cache.file_handle_id\": file_handle_id,\n            }\n        )\n        if not os.path.exists(cache_dir):\n            trace.get_current_span().set_attributes({\"synapse.cache.hit\": False})\n            return None\n\n        with Lock(self.cache_map_file_name, dir=cache_dir):\n            cache_map = self._read_cache_map(cache_dir)\n\n            path = utils.normalize_path(path)\n\n            # If the caller specifies a path and that path exists in the cache\n            # but has been modified, we need to indicate no match by returning\n            # None. The logic for updating a synapse entity depends on this to\n            # determine the need to upload a new file.\n\n            if path is not None:\n                # If we're given a path to a directory, look for a cached file in that directory\n                if os.path.isdir(path):\n                    matching_unmodified_directory = None\n                    removed_entry_from_cache = (\n                        False  # determines if cache_map needs to be rewritten to disk\n                    )\n\n                    # iterate a copy of cache_map to allow modifying original cache_map\n                    for cached_file_path, cache_map_entry in dict(cache_map).items():\n                        if path == os.path.dirname(cached_file_path):\n                            if self._cache_item_unmodified(\n                                cache_map_entry, cached_file_path\n                            ):\n                                # \"break\" instead of \"return\" to write removed invalid entries to disk if necessary\n                                matching_unmodified_directory = cached_file_path\n                                break\n                            else:\n                                # remove invalid cache entries pointing to files that that no longer exist\n                                # or have been modified\n                                del cache_map[cached_file_path]\n                                removed_entry_from_cache = True\n\n                    if removed_entry_from_cache:\n                        # write cache_map with non-existent entries removed\n                        self._write_cache_map(cache_dir, cache_map)\n\n                    if matching_unmodified_directory is not None:\n                        trace.get_current_span().set_attributes(\n                            {\"synapse.cache.hit\": True}\n                        )\n                        return matching_unmodified_directory\n\n                # if we're given a full file path, look up a matching file in the cache\n                else:\n                    cache_map_entry = cache_map.get(path, None)\n                    if cache_map_entry:\n                        matching_file_path = (\n                            path\n                            if self._cache_item_unmodified(cache_map_entry, path)\n                            else None\n                        )\n                        trace.get_current_span().set_attributes(\n                            {\"synapse.cache.hit\": matching_file_path is not None}\n                        )\n                        return matching_file_path\n\n            # return most recently cached and unmodified file OR\n            # None if there are no unmodified files\n            for cached_file_path, cache_map_entry in sorted(\n                cache_map.items(),\n                key=lambda item: (\n                    item[1][\"modified_time\"] if isinstance(item[1], dict) else item[1]\n                ),\n                reverse=True,\n            ):\n                if self._cache_item_unmodified(cache_map_entry, cached_file_path):\n                    trace.get_current_span().set_attributes({\"synapse.cache.hit\": True})\n                    return cached_file_path\n\n            trace.get_current_span().set_attributes({\"synapse.cache.hit\": False})\n            return None\n\n    def add(\n        self,\n        file_handle_id: typing.Union[collections.abc.Mapping, str],\n        path: str,\n        md5: str = None,\n    ) -&gt; dict:\n        \"\"\"\n        Add a file to the cache\n        \"\"\"\n        if not path or not os.path.exists(path):\n            raise ValueError('Can\\'t find file \"%s\"' % path)\n\n        cache_dir = self.get_cache_dir(file_handle_id)\n        content_md5 = md5 or utils.md5_for_file(path).hexdigest()\n        with Lock(self.cache_map_file_name, dir=cache_dir):\n            cache_map = self._read_cache_map(cache_dir)\n\n            path = utils.normalize_path(path)\n            # write .000 milliseconds for backward compatibility\n            cache_map[path] = {\n                \"modified_time\": epoch_time_to_iso(\n                    math.floor(_get_modified_time(path))\n                ),\n                \"content_md5\": content_md5,\n            }\n            self._write_cache_map(cache_dir, cache_map)\n\n        return cache_map\n\n    def remove(\n        self,\n        file_handle_id: typing.Union[collections.abc.Mapping, str],\n        path: str = None,\n        delete: bool = None,\n    ) -&gt; typing.List[str]:\n        \"\"\"\n        Remove a file from the cache.\n\n        Arguments:\n            file_handle_id: Will also extract file handle id from either a File or file handle\n            path:           If the given path is None, remove (and potentially delete)\n                            all cached copies. If the path is that of a file in the\n                            .cacheMap file, remove it.\n            delete:         If True, delete the file from disk as well as removing it from the cache\n\n        Returns:\n            A list of files removed\n        \"\"\"\n        removed = []\n        cache_dir = self.get_cache_dir(file_handle_id)\n\n        # if we've passed an entity and not a path, get path from entity\n        if (\n            path is None\n            and isinstance(file_handle_id, collections.abc.Mapping)\n            and \"path\" in file_handle_id\n        ):\n            path = file_handle_id[\"path\"]\n\n        with Lock(self.cache_map_file_name, dir=cache_dir):\n            cache_map = self._read_cache_map(cache_dir)\n\n            if path is None:\n                for path in cache_map:\n                    if delete is True and os.path.exists(path):\n                        os.remove(path)\n                    removed.append(path)\n                cache_map = {}\n            else:\n                path = utils.normalize_path(path)\n                if path in cache_map:\n                    if delete is True and os.path.exists(path):\n                        os.remove(path)\n                    del cache_map[path]\n                    removed.append(path)\n\n            self._write_cache_map(cache_dir, cache_map)\n\n        return removed\n\n    def _cache_dirs(self):\n        \"\"\"\n        Generate a list of all cache dirs, directories of the form:\n        [cache.cache_root_dir]/949/59949\n        \"\"\"\n        for item1 in os.listdir(self.cache_root_dir):\n            path1 = os.path.join(self.cache_root_dir, item1)\n            if os.path.isdir(path1) and re.match(\"\\\\d+\", item1):\n                for item2 in os.listdir(path1):\n                    path2 = os.path.join(path1, item2)\n                    if os.path.isdir(path2) and re.match(\"\\\\d+\", item2):\n                        yield path2\n\n    def purge(\n        self,\n        before_date: typing.Union[datetime.datetime, int] = None,\n        after_date: typing.Union[datetime.datetime, int] = None,\n        dry_run: bool = False,\n    ) -&gt; int:\n        \"\"\"\n        Purge the cache. Use with caution. Deletes files whose cache maps were last updated in a specified period.\n\n        Deletes .cacheMap files and files stored in the cache.cache_root_dir, but does not delete files stored outside\n        the cache.\n\n        Arguments:\n            before_date: If specified, all files before this date will be removed\n            after_date:  If specified, all files after this date will be removed\n            dry_run:     If dry_run is True, then the selected files are printed rather than removed\n\n        Returns:\n            The number of files selected for removal\n\n        Example: Using this function\n            Either the before_date or after_date must be specified. If both are passed, files between the two dates are\n            selected for removal. Dates must either be a timezone naive Python datetime.datetime instance or the number\n            of seconds since the unix epoch. For example to delete all the files modified in January 2021, either of the\n            following can be used::\n\n            using offset naive datetime objects\n\n                cache.purge(after_date=datetime.datetime(2021, 1, 1), before_date=datetime.datetime(2021, 2, 1))\n\n            using seconds since the unix epoch\n\n                cache.purge(after_date=1609459200, before_date=1612137600)\n        \"\"\"\n        if before_date is None and after_date is None:\n            raise ValueError(\"Either before date or after date should be provided\")\n\n        if isinstance(before_date, datetime.datetime):\n            before_date = utils.to_unix_epoch_time_secs(before_date)\n        if isinstance(after_date, datetime.datetime):\n            after_date = utils.to_unix_epoch_time_secs(after_date)\n\n        if before_date and after_date and before_date &lt; after_date:\n            raise ValueError(\"Before date should be larger than after date\")\n\n        count = 0\n        for cache_dir in self._cache_dirs():\n            # _get_modified_time returns None if the cache map file doesn't\n            # exist and n &gt; None evaluates to True in python 2.7(wtf?). I'm guessing it's\n            # OK to purge directories in the cache that have no .cacheMap file\n\n            last_modified_time = _get_modified_time(\n                os.path.join(cache_dir, self.cache_map_file_name)\n            )\n            if last_modified_time is None or (\n                (not before_date or before_date &gt; last_modified_time)\n                and (not after_date or after_date &lt; last_modified_time)\n            ):\n                if dry_run:\n                    print(cache_dir)\n                else:\n                    shutil.rmtree(cache_dir)\n                count += 1\n        return count\n</code></pre>"},{"location":"reference/core/#synapseclient.core.cache.Cache-functions","title":"Functions","text":""},{"location":"reference/core/#synapseclient.core.cache.Cache.contains","title":"<code>contains(file_handle_id, path)</code>","text":"<p>Given a file and file_handle_id, return True if an unmodified cached copy of the file exists at the exact path given or False otherwise.</p> PARAMETER DESCRIPTION <code>file_handle_id</code> <p>The ID of the fileHandle</p> <p> TYPE: <code>Union[Mapping, str]</code> </p> <code>path</code> <p>The file path at which to look for a cached copy</p> <p> TYPE: <code>str</code> </p> Source code in <code>synapseclient/core/cache.py</code> <pre><code>def contains(\n    self, file_handle_id: typing.Union[collections.abc.Mapping, str], path: str\n) -&gt; bool:\n    \"\"\"\n    Given a file and file_handle_id, return True if an unmodified cached\n    copy of the file exists at the exact path given or False otherwise.\n\n    Arguments:\n        file_handle_id: The ID of the fileHandle\n        path:           The file path at which to look for a cached copy\n    \"\"\"\n    cache_dir = self.get_cache_dir(file_handle_id)\n    if not os.path.exists(cache_dir):\n        return False\n\n    with Lock(self.cache_map_file_name, dir=cache_dir):\n        cache_map = self._read_cache_map(cache_dir)\n\n        path = utils.normalize_path(path)\n\n        cached_time = self._get_cache_modified_time(cache_map.get(path, None))\n\n        if cached_time:\n            return compare_timestamps(_get_modified_time(path), cached_time)\n    return False\n</code></pre>"},{"location":"reference/core/#synapseclient.core.cache.Cache.get","title":"<code>get(file_handle_id, path=None)</code>","text":"<p>Retrieve a file with the given file handle from the cache.</p> PARAMETER DESCRIPTION <code>file_handle_id</code> <p>The ID of the fileHandle</p> <p> TYPE: <code>Union[Mapping, str]</code> </p> <code>path</code> <p>If the given path is None, look for a cached copy of the             file in the cache directory. If the path is a directory,             look there for a cached copy. If a full file-path is             given, only check whether that exact file exists and is             unmodified since it was cached.</p> <p> TYPE: <code>str</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>Union[str, None]</code> <p>Either a file path, if an unmodified cached copy of the file</p> <code>Union[str, None]</code> <p>exists in the specified location or None if it does not</p> Source code in <code>synapseclient/core/cache.py</code> <pre><code>@tracer.start_as_current_span(\"cache::get\")\ndef get(\n    self,\n    file_handle_id: typing.Union[collections.abc.Mapping, str],\n    path: str = None,\n) -&gt; typing.Union[str, None]:\n    \"\"\"\n    Retrieve a file with the given file handle from the cache.\n\n    Arguments:\n        file_handle_id: The ID of the fileHandle\n        path:           If the given path is None, look for a cached copy of the\n                        file in the cache directory. If the path is a directory,\n                        look there for a cached copy. If a full file-path is\n                        given, only check whether that exact file exists and is\n                        unmodified since it was cached.\n\n    Returns:\n        Either a file path, if an unmodified cached copy of the file\n        exists in the specified location or None if it does not\n    \"\"\"\n    cache_dir = self.get_cache_dir(file_handle_id)\n    trace.get_current_span().set_attributes(\n        {\n            \"synapse.cache.dir\": cache_dir,\n            \"synapse.cache.file_handle_id\": file_handle_id,\n        }\n    )\n    if not os.path.exists(cache_dir):\n        trace.get_current_span().set_attributes({\"synapse.cache.hit\": False})\n        return None\n\n    with Lock(self.cache_map_file_name, dir=cache_dir):\n        cache_map = self._read_cache_map(cache_dir)\n\n        path = utils.normalize_path(path)\n\n        # If the caller specifies a path and that path exists in the cache\n        # but has been modified, we need to indicate no match by returning\n        # None. The logic for updating a synapse entity depends on this to\n        # determine the need to upload a new file.\n\n        if path is not None:\n            # If we're given a path to a directory, look for a cached file in that directory\n            if os.path.isdir(path):\n                matching_unmodified_directory = None\n                removed_entry_from_cache = (\n                    False  # determines if cache_map needs to be rewritten to disk\n                )\n\n                # iterate a copy of cache_map to allow modifying original cache_map\n                for cached_file_path, cache_map_entry in dict(cache_map).items():\n                    if path == os.path.dirname(cached_file_path):\n                        if self._cache_item_unmodified(\n                            cache_map_entry, cached_file_path\n                        ):\n                            # \"break\" instead of \"return\" to write removed invalid entries to disk if necessary\n                            matching_unmodified_directory = cached_file_path\n                            break\n                        else:\n                            # remove invalid cache entries pointing to files that that no longer exist\n                            # or have been modified\n                            del cache_map[cached_file_path]\n                            removed_entry_from_cache = True\n\n                if removed_entry_from_cache:\n                    # write cache_map with non-existent entries removed\n                    self._write_cache_map(cache_dir, cache_map)\n\n                if matching_unmodified_directory is not None:\n                    trace.get_current_span().set_attributes(\n                        {\"synapse.cache.hit\": True}\n                    )\n                    return matching_unmodified_directory\n\n            # if we're given a full file path, look up a matching file in the cache\n            else:\n                cache_map_entry = cache_map.get(path, None)\n                if cache_map_entry:\n                    matching_file_path = (\n                        path\n                        if self._cache_item_unmodified(cache_map_entry, path)\n                        else None\n                    )\n                    trace.get_current_span().set_attributes(\n                        {\"synapse.cache.hit\": matching_file_path is not None}\n                    )\n                    return matching_file_path\n\n        # return most recently cached and unmodified file OR\n        # None if there are no unmodified files\n        for cached_file_path, cache_map_entry in sorted(\n            cache_map.items(),\n            key=lambda item: (\n                item[1][\"modified_time\"] if isinstance(item[1], dict) else item[1]\n            ),\n            reverse=True,\n        ):\n            if self._cache_item_unmodified(cache_map_entry, cached_file_path):\n                trace.get_current_span().set_attributes({\"synapse.cache.hit\": True})\n                return cached_file_path\n\n        trace.get_current_span().set_attributes({\"synapse.cache.hit\": False})\n        return None\n</code></pre>"},{"location":"reference/core/#synapseclient.core.cache.Cache.add","title":"<code>add(file_handle_id, path, md5=None)</code>","text":"<p>Add a file to the cache</p> Source code in <code>synapseclient/core/cache.py</code> <pre><code>def add(\n    self,\n    file_handle_id: typing.Union[collections.abc.Mapping, str],\n    path: str,\n    md5: str = None,\n) -&gt; dict:\n    \"\"\"\n    Add a file to the cache\n    \"\"\"\n    if not path or not os.path.exists(path):\n        raise ValueError('Can\\'t find file \"%s\"' % path)\n\n    cache_dir = self.get_cache_dir(file_handle_id)\n    content_md5 = md5 or utils.md5_for_file(path).hexdigest()\n    with Lock(self.cache_map_file_name, dir=cache_dir):\n        cache_map = self._read_cache_map(cache_dir)\n\n        path = utils.normalize_path(path)\n        # write .000 milliseconds for backward compatibility\n        cache_map[path] = {\n            \"modified_time\": epoch_time_to_iso(\n                math.floor(_get_modified_time(path))\n            ),\n            \"content_md5\": content_md5,\n        }\n        self._write_cache_map(cache_dir, cache_map)\n\n    return cache_map\n</code></pre>"},{"location":"reference/core/#synapseclient.core.cache.Cache.remove","title":"<code>remove(file_handle_id, path=None, delete=None)</code>","text":"<p>Remove a file from the cache.</p> PARAMETER DESCRIPTION <code>file_handle_id</code> <p>Will also extract file handle id from either a File or file handle</p> <p> TYPE: <code>Union[Mapping, str]</code> </p> <code>path</code> <p>If the given path is None, remove (and potentially delete)             all cached copies. If the path is that of a file in the             .cacheMap file, remove it.</p> <p> TYPE: <code>str</code> DEFAULT: <code>None</code> </p> <code>delete</code> <p>If True, delete the file from disk as well as removing it from the cache</p> <p> TYPE: <code>bool</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>List[str]</code> <p>A list of files removed</p> Source code in <code>synapseclient/core/cache.py</code> <pre><code>def remove(\n    self,\n    file_handle_id: typing.Union[collections.abc.Mapping, str],\n    path: str = None,\n    delete: bool = None,\n) -&gt; typing.List[str]:\n    \"\"\"\n    Remove a file from the cache.\n\n    Arguments:\n        file_handle_id: Will also extract file handle id from either a File or file handle\n        path:           If the given path is None, remove (and potentially delete)\n                        all cached copies. If the path is that of a file in the\n                        .cacheMap file, remove it.\n        delete:         If True, delete the file from disk as well as removing it from the cache\n\n    Returns:\n        A list of files removed\n    \"\"\"\n    removed = []\n    cache_dir = self.get_cache_dir(file_handle_id)\n\n    # if we've passed an entity and not a path, get path from entity\n    if (\n        path is None\n        and isinstance(file_handle_id, collections.abc.Mapping)\n        and \"path\" in file_handle_id\n    ):\n        path = file_handle_id[\"path\"]\n\n    with Lock(self.cache_map_file_name, dir=cache_dir):\n        cache_map = self._read_cache_map(cache_dir)\n\n        if path is None:\n            for path in cache_map:\n                if delete is True and os.path.exists(path):\n                    os.remove(path)\n                removed.append(path)\n            cache_map = {}\n        else:\n            path = utils.normalize_path(path)\n            if path in cache_map:\n                if delete is True and os.path.exists(path):\n                    os.remove(path)\n                del cache_map[path]\n                removed.append(path)\n\n        self._write_cache_map(cache_dir, cache_map)\n\n    return removed\n</code></pre>"},{"location":"reference/core/#synapseclient.core.cache.Cache.purge","title":"<code>purge(before_date=None, after_date=None, dry_run=False)</code>","text":"<p>Purge the cache. Use with caution. Deletes files whose cache maps were last updated in a specified period.</p> <p>Deletes .cacheMap files and files stored in the cache.cache_root_dir, but does not delete files stored outside the cache.</p> PARAMETER DESCRIPTION <code>before_date</code> <p>If specified, all files before this date will be removed</p> <p> TYPE: <code>Union[datetime, int]</code> DEFAULT: <code>None</code> </p> <code>after_date</code> <p>If specified, all files after this date will be removed</p> <p> TYPE: <code>Union[datetime, int]</code> DEFAULT: <code>None</code> </p> <code>dry_run</code> <p>If dry_run is True, then the selected files are printed rather than removed</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> RETURNS DESCRIPTION <code>int</code> <p>The number of files selected for removal</p> Using this function <p>Either the before_date or after_date must be specified. If both are passed, files between the two dates are selected for removal. Dates must either be a timezone naive Python datetime.datetime instance or the number of seconds since the unix epoch. For example to delete all the files modified in January 2021, either of the following can be used::</p> <p>using offset naive datetime objects</p> <pre><code>cache.purge(after_date=datetime.datetime(2021, 1, 1), before_date=datetime.datetime(2021, 2, 1))\n</code></pre> <p>using seconds since the unix epoch</p> <pre><code>cache.purge(after_date=1609459200, before_date=1612137600)\n</code></pre> Source code in <code>synapseclient/core/cache.py</code> <pre><code>def purge(\n    self,\n    before_date: typing.Union[datetime.datetime, int] = None,\n    after_date: typing.Union[datetime.datetime, int] = None,\n    dry_run: bool = False,\n) -&gt; int:\n    \"\"\"\n    Purge the cache. Use with caution. Deletes files whose cache maps were last updated in a specified period.\n\n    Deletes .cacheMap files and files stored in the cache.cache_root_dir, but does not delete files stored outside\n    the cache.\n\n    Arguments:\n        before_date: If specified, all files before this date will be removed\n        after_date:  If specified, all files after this date will be removed\n        dry_run:     If dry_run is True, then the selected files are printed rather than removed\n\n    Returns:\n        The number of files selected for removal\n\n    Example: Using this function\n        Either the before_date or after_date must be specified. If both are passed, files between the two dates are\n        selected for removal. Dates must either be a timezone naive Python datetime.datetime instance or the number\n        of seconds since the unix epoch. For example to delete all the files modified in January 2021, either of the\n        following can be used::\n\n        using offset naive datetime objects\n\n            cache.purge(after_date=datetime.datetime(2021, 1, 1), before_date=datetime.datetime(2021, 2, 1))\n\n        using seconds since the unix epoch\n\n            cache.purge(after_date=1609459200, before_date=1612137600)\n    \"\"\"\n    if before_date is None and after_date is None:\n        raise ValueError(\"Either before date or after date should be provided\")\n\n    if isinstance(before_date, datetime.datetime):\n        before_date = utils.to_unix_epoch_time_secs(before_date)\n    if isinstance(after_date, datetime.datetime):\n        after_date = utils.to_unix_epoch_time_secs(after_date)\n\n    if before_date and after_date and before_date &lt; after_date:\n        raise ValueError(\"Before date should be larger than after date\")\n\n    count = 0\n    for cache_dir in self._cache_dirs():\n        # _get_modified_time returns None if the cache map file doesn't\n        # exist and n &gt; None evaluates to True in python 2.7(wtf?). I'm guessing it's\n        # OK to purge directories in the cache that have no .cacheMap file\n\n        last_modified_time = _get_modified_time(\n            os.path.join(cache_dir, self.cache_map_file_name)\n        )\n        if last_modified_time is None or (\n            (not before_date or before_date &gt; last_modified_time)\n            and (not after_date or after_date &lt; last_modified_time)\n        ):\n            if dry_run:\n                print(cache_dir)\n            else:\n                shutil.rmtree(cache_dir)\n            count += 1\n    return count\n</code></pre>"},{"location":"reference/core/#synapseclient.core.cache-functions","title":"Functions","text":""},{"location":"reference/core/#synapseclient.core.cache.epoch_time_to_iso","title":"<code>epoch_time_to_iso(epoch_time)</code>","text":"<p>Convert seconds since unix epoch to a string in ISO format</p> Source code in <code>synapseclient/core/cache.py</code> <pre><code>def epoch_time_to_iso(epoch_time):\n    \"\"\"\n    Convert seconds since unix epoch to a string in ISO format\n    \"\"\"\n    return (\n        None\n        if epoch_time is None\n        else utils.datetime_to_iso(utils.from_unix_epoch_time_secs(epoch_time))\n    )\n</code></pre>"},{"location":"reference/core/#synapseclient.core.cache.iso_time_to_epoch","title":"<code>iso_time_to_epoch(iso_time)</code>","text":"<p>Convert an ISO formatted time into seconds since unix epoch</p> Source code in <code>synapseclient/core/cache.py</code> <pre><code>def iso_time_to_epoch(iso_time):\n    \"\"\"\n    Convert an ISO formatted time into seconds since unix epoch\n    \"\"\"\n    return (\n        None\n        if iso_time is None\n        else utils.to_unix_epoch_time_secs(utils.iso_to_datetime(iso_time))\n    )\n</code></pre>"},{"location":"reference/core/#synapseclient.core.cache.compare_timestamps","title":"<code>compare_timestamps(modified_time, cached_time)</code>","text":"<p>Compare two ISO formatted timestamps, with a special case when cached_time ends in .000Z.</p> <p>For backward compatibility, we always write .000 for milliseconds into the cache. We then match a cached time ending in .000Z, meaning zero milliseconds with a modified time with any number of milliseconds.</p> PARAMETER DESCRIPTION <code>modified_time</code> <p>The float representing seconds since unix epoch</p> <p> </p> <code>cached_time</code> <p>The string holding a ISO formatted time</p> <p> </p> Source code in <code>synapseclient/core/cache.py</code> <pre><code>def compare_timestamps(modified_time, cached_time):\n    \"\"\"\n    Compare two ISO formatted timestamps, with a special case when cached_time ends in .000Z.\n\n    For backward compatibility, we always write .000 for milliseconds into the cache.\n    We then match a cached time ending in .000Z, meaning zero milliseconds with a modified time with any number of\n    milliseconds.\n\n    Arguments:\n        modified_time: The float representing seconds since unix epoch\n        cached_time:   The string holding a ISO formatted time\n    \"\"\"\n    if cached_time is None or modified_time is None:\n        return False\n    if cached_time.endswith(\".000Z\"):\n        return cached_time == epoch_time_to_iso(math.floor(modified_time))\n    else:\n        return cached_time == epoch_time_to_iso(modified_time)\n</code></pre>"},{"location":"reference/core/#credentials","title":"Credentials","text":""},{"location":"reference/core/#synapseclient.core.credentials.cred_data.SynapseCredentials","title":"<code>synapseclient.core.credentials.cred_data.SynapseCredentials</code>","text":"<p>               Bases: <code>AuthBase</code>, <code>ABC</code></p> Source code in <code>synapseclient/core/credentials/cred_data.py</code> <pre><code>class SynapseCredentials(requests.auth.AuthBase, abc.ABC):\n    @property\n    @abc.abstractmethod\n    def username(self) -&gt; None:\n        \"\"\"The username associated with these credentials.\"\"\"\n\n    @property\n    @abc.abstractmethod\n    def secret(self) -&gt; None:\n        \"\"\"The secret associated with these credentials.\"\"\"\n</code></pre>"},{"location":"reference/core/#synapseclient.core.credentials.cred_data.SynapseCredentials-attributes","title":"Attributes","text":""},{"location":"reference/core/#synapseclient.core.credentials.cred_data.SynapseCredentials.username","title":"<code>username: None</code>  <code>abstractmethod</code> <code>property</code>","text":"<p>The username associated with these credentials.</p>"},{"location":"reference/core/#synapseclient.core.credentials.cred_data.SynapseCredentials.secret","title":"<code>secret: None</code>  <code>abstractmethod</code> <code>property</code>","text":"<p>The secret associated with these credentials.</p>"},{"location":"reference/core/#synapseclient.core.credentials.cred_data.SynapseAuthTokenCredentials","title":"<code>synapseclient.core.credentials.cred_data.SynapseAuthTokenCredentials</code>","text":"<p>               Bases: <code>SynapseCredentials</code></p> Source code in <code>synapseclient/core/credentials/cred_data.py</code> <pre><code>class SynapseAuthTokenCredentials(SynapseCredentials):\n    @classmethod\n    def get_keyring_service_name(\n        cls,\n    ) -&gt; typing.Literal[\"SYNAPSE.ORG_CLIENT_AUTH_TOKEN\"]:\n        return \"SYNAPSE.ORG_CLIENT_AUTH_TOKEN\"\n\n    @classmethod\n    def _validate_token(cls, token):\n        # decode the token to ensure it minimally has view scope.\n        # if it doesn't raise an error, the client will not be useful without it.\n\n        # if for any reason we are not able to decode the token and check its scopes\n        # we do NOT raise an error. this is to accommodate the possibility of a changed\n        # token format some day that this version of the client may still be able to\n        # pass as a bearer token.\n        try:\n            token_body = json.loads(\n                str(\n                    base64.urlsafe_b64decode(\n                        # we add padding to ensure that lack of padding won't prevent a decode error.\n                        # the python base64 implementation will truncate extra padding so we can overpad\n                        # rather than compute exactly how much padding we might need.\n                        # https://stackoverflow.com/a/49459036\n                        token.split(\".\")[1]\n                        + \"===\"\n                    ),\n                    \"utf-8\",\n                )\n            )\n            scopes = token_body.get(\"access\", {}).get(\"scope\")\n            if scopes is not None and \"view\" not in scopes:\n                raise SynapseAuthenticationError(\"A view scoped token is required\")\n\n        except (IndexError, ValueError):\n            # possible errors if token is not encoded as expected:\n            # IndexError if the token is not a '.' delimited base64 string with a header and body\n            # ValueError if the split string is not base64 encoded or if the decoded base64 is not json\n            pass\n\n    def __init__(self, token, username=None):\n        self._validate_token(token)\n\n        self._token = token\n        self.username = username\n\n    @property\n    def username(self) -&gt; str:\n        \"\"\"The username associated with this token.\"\"\"\n        return self._username\n\n    @username.setter\n    def username(self, username: str) -&gt; None:\n        self._username = username\n\n    @property\n    def secret(self) -&gt; str:\n        \"\"\"The bearer token.\"\"\"\n        return self._token\n\n    def __call__(self, r):\n        r.headers.update({\"Authorization\": f\"Bearer {self.secret}\"})\n        return r\n\n    def __repr__(self):\n        return f\"SynapseAuthTokenCredentials(username='{self.username}', token='{self.secret}')\"\n</code></pre>"},{"location":"reference/core/#synapseclient.core.credentials.cred_data.SynapseAuthTokenCredentials-attributes","title":"Attributes","text":""},{"location":"reference/core/#synapseclient.core.credentials.cred_data.SynapseAuthTokenCredentials.username","title":"<code>username: str</code>  <code>property</code> <code>writable</code>","text":"<p>The username associated with this token.</p>"},{"location":"reference/core/#synapseclient.core.credentials.cred_data.SynapseAuthTokenCredentials.secret","title":"<code>secret: str</code>  <code>property</code>","text":"<p>The bearer token.</p>"},{"location":"reference/core/#synapseclient.core.credentials.credential_provider","title":"<code>synapseclient.core.credentials.credential_provider</code>","text":"<p>This module contains classes that are responsible for retrieving synapse authentication information (e.g. authToken) from a source (e.g. login args, config file).</p>"},{"location":"reference/core/#synapseclient.core.credentials.credential_provider-classes","title":"Classes","text":""},{"location":"reference/core/#synapseclient.core.credentials.credential_provider.SynapseCredentialsProvider","title":"<code>SynapseCredentialsProvider</code>","text":"<p>A credential provider is responsible for retrieving synapse authentication information (e.g. authToken) from a source (e.g. login args, config file), and use them to return a SynapseCredentials instance.</p> Source code in <code>synapseclient/core/credentials/credential_provider.py</code> <pre><code>class SynapseCredentialsProvider(metaclass=abc.ABCMeta):\n    \"\"\"\n    A credential provider is responsible for retrieving synapse authentication\n    information (e.g. authToken) from a source (e.g. login args, config file),\n    and use them to return a\n    [SynapseCredentials][synapseclient.core.credentials.cred_data.SynapseCredentials]\n    instance.\n    \"\"\"\n\n    @abc.abstractmethod\n    def _get_auth_info(\n        self, syn: \"Synapse\", user_login_args: Dict[str, str]\n    ) -&gt; Tuple[None, None]:\n        \"\"\"\n        Subclasses must implement this to decide how to obtain an authentication token.\n        For any of these values, return None if it is not possible to get that value.\n\n        Not all implementations will need to make use of the user_login_args parameter\n        or syn. These parameters provide context about the Synapse client's configuration\n        and login() arguments.\n\n        Arguments:\n            syn: Synapse client instance\n            user_login_args: subset of arguments passed during syn.login()\n\n        Returns:\n            Tuple of (username, bearer authentication token e.g. a personal access token),\n            any of these values could None if it is not available.\n        \"\"\"\n        return None, None\n\n    def get_synapse_credentials(\n        self, syn: \"Synapse\", user_login_args: Dict[str, str]\n    ) -&gt; Union[SynapseCredentials, None]:\n        \"\"\"\n        Returns\n        [SynapseCredentials][synapseclient.core.credentials.cred_data.SynapseCredentials]\n        if this provider is able to get valid credentials, returns None otherwise.\n\n        Arguments:\n            syn: Synapse client instance\n            user_login_args: subset of arguments passed during syn.login()\n\n        Returns:\n            [SynapseCredentials][synapseclient.core.credentials.cred_data.SynapseCredentials]\n                if valid credentials can be found by this provider, None otherwise.\n        \"\"\"\n        return self._create_synapse_credential(\n            syn, *self._get_auth_info(syn=syn, user_login_args=user_login_args)\n        )\n\n    def _create_synapse_credential(\n        self, syn: \"Synapse\", username: str, auth_token: str\n    ) -&gt; Union[SynapseCredentials, None]:\n        if auth_token is not None:\n            credentials = SynapseAuthTokenCredentials(auth_token)\n            profile = syn.restGET(\"/userProfile\", auth=credentials)\n            profile_username = profile.get(\"userName\")\n            profile_emails = profile.get(\"emails\", [])\n\n            if username and (\n                username != profile_username and username not in profile_emails\n            ):\n                # a username/email is not required when logging in with an auth token\n                # however if both are provided raise an error if they do not correspond\n                # to avoid any ambiguity about what profile was logged in\n                raise SynapseAuthenticationError(\n                    \"username/email and auth_token both provided but username does not \"\n                    \"match token profile\"\n                )\n\n            credentials.username = profile_username\n            return credentials\n\n        return None\n</code></pre>"},{"location":"reference/core/#synapseclient.core.credentials.credential_provider.SynapseCredentialsProvider-functions","title":"Functions","text":""},{"location":"reference/core/#synapseclient.core.credentials.credential_provider.SynapseCredentialsProvider.get_synapse_credentials","title":"<code>get_synapse_credentials(syn, user_login_args)</code>","text":"<p>Returns SynapseCredentials if this provider is able to get valid credentials, returns None otherwise.</p> PARAMETER DESCRIPTION <code>syn</code> <p>Synapse client instance</p> <p> TYPE: <code>Synapse</code> </p> <code>user_login_args</code> <p>subset of arguments passed during syn.login()</p> <p> TYPE: <code>Dict[str, str]</code> </p> RETURNS DESCRIPTION <code>Union[SynapseCredentials, None]</code> <p>SynapseCredentials if valid credentials can be found by this provider, None otherwise.</p> Source code in <code>synapseclient/core/credentials/credential_provider.py</code> <pre><code>def get_synapse_credentials(\n    self, syn: \"Synapse\", user_login_args: Dict[str, str]\n) -&gt; Union[SynapseCredentials, None]:\n    \"\"\"\n    Returns\n    [SynapseCredentials][synapseclient.core.credentials.cred_data.SynapseCredentials]\n    if this provider is able to get valid credentials, returns None otherwise.\n\n    Arguments:\n        syn: Synapse client instance\n        user_login_args: subset of arguments passed during syn.login()\n\n    Returns:\n        [SynapseCredentials][synapseclient.core.credentials.cred_data.SynapseCredentials]\n            if valid credentials can be found by this provider, None otherwise.\n    \"\"\"\n    return self._create_synapse_credential(\n        syn, *self._get_auth_info(syn=syn, user_login_args=user_login_args)\n    )\n</code></pre>"},{"location":"reference/core/#synapseclient.core.credentials.credential_provider.UserArgsCredentialsProvider","title":"<code>UserArgsCredentialsProvider</code>","text":"<p>               Bases: <code>SynapseCredentialsProvider</code></p> <p>Retrieves auth info from user_login_args during a CLI session.</p> Source code in <code>synapseclient/core/credentials/credential_provider.py</code> <pre><code>class UserArgsCredentialsProvider(SynapseCredentialsProvider):\n    \"\"\"\n    Retrieves auth info from user_login_args during a CLI session.\n    \"\"\"\n\n    def _get_auth_info(\n        self, syn: \"Synapse\", user_login_args: Dict[str, str]\n    ) -&gt; Tuple[str, str]:\n        return (\n            user_login_args.username,\n            user_login_args.auth_token,\n        )\n</code></pre>"},{"location":"reference/core/#synapseclient.core.credentials.credential_provider.ConfigFileCredentialsProvider","title":"<code>ConfigFileCredentialsProvider</code>","text":"<p>               Bases: <code>SynapseCredentialsProvider</code></p> <p>Retrieves auth info from the <code>~/.synapseConfig</code> file</p> Source code in <code>synapseclient/core/credentials/credential_provider.py</code> <pre><code>class ConfigFileCredentialsProvider(SynapseCredentialsProvider):\n    \"\"\"\n    Retrieves auth info from the `~/.synapseConfig` file\n    \"\"\"\n\n    def _get_auth_info(\n        self, syn: \"Synapse\", user_login_args: Dict[str, str]\n    ) -&gt; Tuple[Union[str, None], Union[str, None]]:\n        config_dict = get_config_authentication(config_path=syn.configPath)\n        # check to make sure we didn't accidentally provide the wrong user\n\n        username = config_dict.get(\"username\")\n        token = config_dict.get(\"authtoken\")\n\n        if user_login_args.username and username != user_login_args.username:\n            # if the username is provided and there is a config file username but they\n            # don't match then we don't use any of the values from the config\n            # to prevent ambiguity\n            username = None\n            token = None\n            syn.logger.warning(\n                f\"{user_login_args.username} was defined in the user login \"\n                \"arguments, however, it is also defined in the `~/.synapseConfig` \"\n                \"file. Becuase they do not match we will not use the `authtoken` \"\n                \"in the `~/.synapseConfig` file.\",\n            )\n\n        return username, token\n</code></pre>"},{"location":"reference/core/#synapseclient.core.credentials.credential_provider.AWSParameterStoreCredentialsProvider","title":"<code>AWSParameterStoreCredentialsProvider</code>","text":"<p>               Bases: <code>SynapseCredentialsProvider</code></p> <p>Retrieves user's authentication token from AWS SSM Parameter store</p> Source code in <code>synapseclient/core/credentials/credential_provider.py</code> <pre><code>class AWSParameterStoreCredentialsProvider(SynapseCredentialsProvider):\n    \"\"\"\n    Retrieves user's authentication token from AWS SSM Parameter store\n    \"\"\"\n\n    ENVIRONMENT_VAR_NAME = \"SYNAPSE_TOKEN_AWS_SSM_PARAMETER_NAME\"\n\n    def _get_auth_info(\n        self, syn: \"Synapse\", user_login_args: Dict[str, str]\n    ) -&gt; Tuple[Union[str, None], Union[str, None]]:\n        ssm_param_name = os.environ.get(self.ENVIRONMENT_VAR_NAME)\n        token = None\n        if ssm_param_name:\n            try:\n                import boto3\n                import botocore\n\n                ssm_client = boto3.client(\"ssm\")\n                result = ssm_client.get_parameter(\n                    Name=ssm_param_name,\n                    WithDecryption=True,\n                )\n                token = result[\"Parameter\"][\"Value\"]\n            except ImportError:\n                syn.logger.warning(\n                    f\"{self.ENVIRONMENT_VAR_NAME} was defined as {ssm_param_name}, \"\n                    'but \"boto3\" could not be imported. The Synapse client uses \"boto3\" '\n                    \"in order to access Systems Manager Parameter Storage. Please ensure \"\n                    'that you have installed \"boto3\" to enable this feature.'\n                )\n            # this except block must be defined after the ImportError except block\n            # otherwise, there's no guarantee \"botocore\" is already imported and defined\n            except botocore.exceptions.ClientError:\n                syn.logger.warning(\n                    f\"{self.ENVIRONMENT_VAR_NAME} was defined as {ssm_param_name}, \"\n                    \"but the matching parameter name could not be found in AWS Parameter \"\n                    \"Store. Caused by AWS error:\\n\",\n                    exc_info=True,\n                )\n\n        # if username is included in user's arguments, return it so that\n        # it may be validated against the username authenticated by the token\n        return user_login_args.username, token\n</code></pre>"},{"location":"reference/core/#synapseclient.core.credentials.credential_provider.EnvironmentVariableCredentialsProvider","title":"<code>EnvironmentVariableCredentialsProvider</code>","text":"<p>               Bases: <code>SynapseCredentialsProvider</code></p> <p>Retrieves the user's authentication token from an environment variable</p> Source code in <code>synapseclient/core/credentials/credential_provider.py</code> <pre><code>class EnvironmentVariableCredentialsProvider(SynapseCredentialsProvider):\n    \"\"\"\n    Retrieves the user's authentication token from an environment variable\n    \"\"\"\n\n    ENVIRONMENT_VAR_NAME = \"SYNAPSE_AUTH_TOKEN\"\n\n    def _get_auth_info(\n        self, syn: \"Synapse\", user_login_args: Dict[str, str]\n    ) -&gt; Tuple[Union[str, None], Union[str, None]]:\n        return (\n            user_login_args.username,\n            os.environ.get(self.ENVIRONMENT_VAR_NAME),\n        )\n</code></pre>"},{"location":"reference/core/#synapseclient.core.credentials.credential_provider.SynapseCredentialsProviderChain","title":"<code>SynapseCredentialsProviderChain</code>","text":"<p>               Bases: <code>object</code></p> <p>Class that has a list of SynapseCredentialsProvider from which this class attempts to retrieve SynapseCredentials.</p> <p>By default this class uses the following providers in this order:</p> <ol> <li>UserArgsCredentialsProvider</li> <li>ConfigFileCredentialsProvider</li> <li>EnvironmentVariableCredentialsProvider</li> <li>AWSParameterStoreCredentialsProvider</li> </ol> ATTRIBUTE DESCRIPTION <code>cred_providers</code> <p>list of (SynapseCredentialsProvider) credential providers</p> <p> </p> Source code in <code>synapseclient/core/credentials/credential_provider.py</code> <pre><code>class SynapseCredentialsProviderChain(object):\n    \"\"\"\n    Class that has a list of\n    [SynapseCredentialsProvider][synapseclient.core.credentials.credential_provider.SynapseCredentialsProvider]\n    from which this class attempts to retrieve\n    [SynapseCredentials][synapseclient.core.credentials.cred_data.SynapseCredentials].\n\n\n    By default this class uses the following providers in this order:\n\n    1. [UserArgsCredentialsProvider][synapseclient.core.credentials.credential_provider.UserArgsCredentialsProvider]\n    2. [ConfigFileCredentialsProvider][synapseclient.core.credentials.credential_provider.ConfigFileCredentialsProvider]\n    3. [EnvironmentVariableCredentialsProvider][synapseclient.core.credentials.credential_provider.EnvironmentVariableCredentialsProvider]\n    4. [AWSParameterStoreCredentialsProvider][synapseclient.core.credentials.credential_provider.AWSParameterStoreCredentialsProvider]\n\n    Attributes:\n        cred_providers: list of\n            ([SynapseCredentialsProvider][synapseclient.core.credentials.credential_provider.SynapseCredentialsProvider])\n            credential providers\n    \"\"\"\n\n    def __init__(self, cred_providers) -&gt; None:\n        self.cred_providers = list(cred_providers)\n\n    def get_credentials(\n        self, syn: \"Synapse\", user_login_args: Dict[str, str]\n    ) -&gt; Union[SynapseCredentials, None]:\n        \"\"\"\n        Iterates its list of\n        [SynapseCredentialsProvider][synapseclient.core.credentials.credential_provider.SynapseCredentialsProvider]\n        and returns the first non-None\n        [SynapseCredentials][synapseclient.core.credentials.cred_data.SynapseCredentials]\n        returned by a provider. If no provider is able to provide a\n        [SynapseCredentials][synapseclient.core.credentials.cred_data.SynapseCredentials],\n        returns None.\n\n        Arguments:\n            syn: Synapse client instance\n            user_login_args: subset of arguments passed during syn.login()\n\n        Returns:\n            [SynapseCredentials][synapseclient.core.credentials.cred_data.SynapseCredentials]\n                returned by the first non-None provider in its list, None otherwise\n        \"\"\"\n        for provider in self.cred_providers:\n            creds = provider.get_synapse_credentials(syn, user_login_args)\n            if creds is not None:\n                return creds\n        return None\n</code></pre>"},{"location":"reference/core/#synapseclient.core.credentials.credential_provider.SynapseCredentialsProviderChain-functions","title":"Functions","text":""},{"location":"reference/core/#synapseclient.core.credentials.credential_provider.SynapseCredentialsProviderChain.get_credentials","title":"<code>get_credentials(syn, user_login_args)</code>","text":"<p>Iterates its list of SynapseCredentialsProvider and returns the first non-None SynapseCredentials returned by a provider. If no provider is able to provide a SynapseCredentials, returns None.</p> PARAMETER DESCRIPTION <code>syn</code> <p>Synapse client instance</p> <p> TYPE: <code>Synapse</code> </p> <code>user_login_args</code> <p>subset of arguments passed during syn.login()</p> <p> TYPE: <code>Dict[str, str]</code> </p> RETURNS DESCRIPTION <code>Union[SynapseCredentials, None]</code> <p>SynapseCredentials returned by the first non-None provider in its list, None otherwise</p> Source code in <code>synapseclient/core/credentials/credential_provider.py</code> <pre><code>def get_credentials(\n    self, syn: \"Synapse\", user_login_args: Dict[str, str]\n) -&gt; Union[SynapseCredentials, None]:\n    \"\"\"\n    Iterates its list of\n    [SynapseCredentialsProvider][synapseclient.core.credentials.credential_provider.SynapseCredentialsProvider]\n    and returns the first non-None\n    [SynapseCredentials][synapseclient.core.credentials.cred_data.SynapseCredentials]\n    returned by a provider. If no provider is able to provide a\n    [SynapseCredentials][synapseclient.core.credentials.cred_data.SynapseCredentials],\n    returns None.\n\n    Arguments:\n        syn: Synapse client instance\n        user_login_args: subset of arguments passed during syn.login()\n\n    Returns:\n        [SynapseCredentials][synapseclient.core.credentials.cred_data.SynapseCredentials]\n            returned by the first non-None provider in its list, None otherwise\n    \"\"\"\n    for provider in self.cred_providers:\n        creds = provider.get_synapse_credentials(syn, user_login_args)\n        if creds is not None:\n            return creds\n    return None\n</code></pre>"},{"location":"reference/core/#synapseclient.core.credentials.credential_provider-functions","title":"Functions","text":""},{"location":"reference/core/#synapseclient.core.credentials.credential_provider.get_default_credential_chain","title":"<code>get_default_credential_chain()</code>","text":"<p>Creates and uses a default credential chain to retrieve SynapseCredentials. The order this is returned is the order in which the credential providers are attempted.</p> RETURNS DESCRIPTION <code>SynapseCredentialsProviderChain</code> <p>credential chain</p> Source code in <code>synapseclient/core/credentials/credential_provider.py</code> <pre><code>def get_default_credential_chain() -&gt; SynapseCredentialsProviderChain:\n    \"\"\"\n    Creates and uses a default credential chain to retrieve\n    [SynapseCredentials][synapseclient.core.credentials.cred_data.SynapseCredentials].\n    The order this is returned is the order in which the credential providers\n    are attempted.\n\n    Returns:\n        credential chain\n    \"\"\"\n    return DEFAULT_CREDENTIAL_PROVIDER_CHAIN\n</code></pre>"},{"location":"reference/core/#remote-file-storage-wrappers","title":"Remote File Storage Wrappers","text":""},{"location":"reference/core/#synapseclient.core.remote_file_storage_wrappers","title":"<code>synapseclient.core.remote_file_storage_wrappers</code>","text":"<p>Wrappers for remote file storage clients like S3 and SFTP.</p>"},{"location":"reference/core/#synapseclient.core.remote_file_storage_wrappers-classes","title":"Classes","text":""},{"location":"reference/core/#synapseclient.core.remote_file_storage_wrappers.S3ClientWrapper","title":"<code>S3ClientWrapper</code>","text":"<p>Wrapper class for S3 client.</p> Source code in <code>synapseclient/core/remote_file_storage_wrappers.py</code> <pre><code>class S3ClientWrapper:\n    \"\"\"\n    Wrapper class for S3 client.\n    \"\"\"\n\n    # These methods are static because in our use case, we always have the bucket and\n    # endpoint and usually only call the download/upload once so there is no need to instantiate multiple objects\n\n    @staticmethod\n    def _attempt_import_boto3():\n        \"\"\"\n        Check if boto3 installed and give instructions if not.\n\n        Returns:\n            The boto3 module or instructions to install it if unavailable\n        \"\"\"\n        return attempt_import(\n            \"boto3\",\n            \"\\n\\nLibraries required for client authenticated S3 access are not installed!\\n\"\n            \"The Synapse client uses boto3 in order to access S3-like storage \"\n            \"locations.\\n\",\n        )\n\n    @staticmethod\n    def _create_progress_callback_func(\n        progress_bar: tqdm,\n    ) -&gt; callable:\n        \"\"\"\n        Creates a progress callback function for tracking the progress of a file transfer.\n\n        Arguments:\n            file_size: The total size of the file being transferred.\n            filename: The name of the file being transferred.\n            prefix: A prefix to display before the progress bar. Defaults to None.\n\n        Returns:\n            progress_callback: The progress callback function.\n        \"\"\"\n\n        def progress_callback(transferred_bytes: int) -&gt; None:\n            \"\"\"\n            Update the progress of a transfer.\n\n            Arguments:\n                bytes: The number of bytes transferred.\n            \"\"\"\n            increment_progress_bar(n=transferred_bytes, progress_bar=progress_bar)\n\n        return progress_callback\n\n    @staticmethod\n    def download_file(\n        bucket: str,\n        endpoint_url: Union[str, None],\n        remote_file_key: str,\n        download_file_path: str,\n        *,\n        profile_name: str = None,\n        credentials: typing.Dict[str, str] = None,\n        progress_bar: Union[tqdm, None] = None,\n        transfer_config_kwargs: dict = None,\n    ) -&gt; str:\n        \"\"\"\n        Download a file from s3 using boto3.\n\n        Arguments:\n            bucket: name of bucket to upload to\n            endpoint_url: a boto3 compatible endpoint url\n            remote_file_key: object key to upload the file to\n            download_file_path: local path to save the file to\n            profile_name: AWS profile name from local aws config, **mutually exclusive with credentials**\n            credentials: a dictionary of AWS credentials to use, **mutually exclusive with profile_name**\n\n                Expected items:\n\n                - `aws_access_key_id`\n                - `aws_secret_access_key`\n                - `aws_session_token`\n            progress_bar: The progress bar to update. Defaults to None.\n            transfer_config_kwargs: boto S3 transfer configuration (see boto3.s3.transfer.TransferConfig)\n\n        Returns:\n            download_file_path: S3 path of the file\n\n        Raises:\n            ValueError: If the key does not exist in the bucket.\n            botocore.exceptions.ClientError: If there is an error with the S3 client.\n        \"\"\"\n\n        S3ClientWrapper._attempt_import_boto3()\n\n        import boto3.s3.transfer\n        import botocore\n\n        transfer_config = boto3.s3.transfer.TransferConfig(\n            **(transfer_config_kwargs or {})\n        )\n\n        session_args = credentials if credentials else {\"profile_name\": profile_name}\n        boto_session = boto3.session.Session(**session_args)\n        s3 = boto_session.resource(\"s3\", endpoint_url=endpoint_url)\n\n        try:\n            s3_obj = s3.Object(bucket, remote_file_key)\n\n            progress_callback = None\n\n            if progress_bar is not None:\n                s3_obj.load()\n                file_size = s3_obj.content_length\n                increment_progress_bar_total(total=file_size, progress_bar=progress_bar)\n                progress_callback = S3ClientWrapper._create_progress_callback_func(\n                    progress_bar\n                )\n\n            s3_obj.download_file(\n                download_file_path,\n                Callback=progress_callback,\n                Config=transfer_config,\n            )\n\n            return download_file_path\n\n        except botocore.exceptions.ClientError as e:\n            if e.response[\"Error\"][\"Code\"] == \"404\":\n                raise ValueError(\n                    \"The key:%s does not exist in bucket:%s.\", remote_file_key, bucket\n                )\n            else:\n                raise\n\n    @staticmethod\n    def upload_file(\n        bucket: str,\n        endpoint_url: typing.Optional[str],\n        remote_file_key: str,\n        upload_file_path: str,\n        *,\n        profile_name: str = None,\n        credentials: typing.Dict[str, str] = None,\n        show_progress: bool = True,\n        transfer_config_kwargs: dict = None,\n        storage_str: str = None,\n    ) -&gt; str:\n        \"\"\"\n        Upload a file to s3 using boto3.\n\n        Arguments:\n            bucket: name of bucket to upload to\n            endpoint_url: a boto3 compatible endpoint url\n            remote_file_key: object key to upload the file to\n            upload_file_path: local path of the file to upload\n            profile_name: AWS profile name from local aws config, **mutually exclusive with credentials**\n            credentials: a dictionary of AWS credentials to use, **mutually exclusive with profile_name**\n\n                Expected items:\n\n                - `aws_access_key_id`\n                - `aws_secret_access_key`\n                - `aws_session_token`\n            show_progress: whether to print progress indicator to console\n            transfer_config_kwargs: boto S3 transfer configuration (see boto3.s3.transfer.TransferConfig)\n\n        Returns:\n            upload_file_path: S3 path of the file\n\n        Raises:\n            ValueError: If the path does not exist or is not a file\n            botocore.exceptions.ClientError: If there is an error with the S3 client.\n        \"\"\"\n\n        if not os.path.isfile(upload_file_path):\n            raise ValueError(\n                \"The path: [%s] does not exist or is not a file\", upload_file_path\n            )\n\n        S3ClientWrapper._attempt_import_boto3()\n        import boto3.s3.transfer\n\n        transfer_config = boto3.s3.transfer.TransferConfig(\n            **(transfer_config_kwargs or {})\n        )\n\n        session_args = credentials if credentials else {\"profile_name\": profile_name}\n        boto_session = boto3.session.Session(**session_args)\n        s3 = boto_session.resource(\"s3\", endpoint_url=endpoint_url)\n\n        progress_callback = None\n        progress_bar = None\n        if show_progress:\n            file_size = os.stat(upload_file_path).st_size\n            filename = os.path.basename(upload_file_path)\n            progress_bar = tqdm(\n                total=file_size,\n                desc=storage_str,\n                unit=\"B\",\n                unit_scale=True,\n                postfix=filename,\n                smoothing=0,\n            )\n            progress_callback = S3ClientWrapper._create_progress_callback_func(\n                progress_bar\n            )\n\n        # automatically determines whether to perform multi-part upload\n        s3.Bucket(bucket).upload_file(\n            upload_file_path,\n            remote_file_key,\n            Callback=progress_callback,\n            Config=transfer_config,\n            ExtraArgs={\"ACL\": \"bucket-owner-full-control\"},\n        )\n        if progress_bar is not None:\n            progress_bar.close()\n        return upload_file_path\n</code></pre>"},{"location":"reference/core/#synapseclient.core.remote_file_storage_wrappers.S3ClientWrapper-functions","title":"Functions","text":""},{"location":"reference/core/#synapseclient.core.remote_file_storage_wrappers.S3ClientWrapper.download_file","title":"<code>download_file(bucket, endpoint_url, remote_file_key, download_file_path, *, profile_name=None, credentials=None, progress_bar=None, transfer_config_kwargs=None)</code>  <code>staticmethod</code>","text":"<p>Download a file from s3 using boto3.</p> PARAMETER DESCRIPTION <code>bucket</code> <p>name of bucket to upload to</p> <p> TYPE: <code>str</code> </p> <code>endpoint_url</code> <p>a boto3 compatible endpoint url</p> <p> TYPE: <code>Union[str, None]</code> </p> <code>remote_file_key</code> <p>object key to upload the file to</p> <p> TYPE: <code>str</code> </p> <code>download_file_path</code> <p>local path to save the file to</p> <p> TYPE: <code>str</code> </p> <code>profile_name</code> <p>AWS profile name from local aws config, mutually exclusive with credentials</p> <p> TYPE: <code>str</code> DEFAULT: <code>None</code> </p> <code>credentials</code> <p>a dictionary of AWS credentials to use, mutually exclusive with profile_name</p> <p>Expected items:</p> <ul> <li><code>aws_access_key_id</code></li> <li><code>aws_secret_access_key</code></li> <li><code>aws_session_token</code></li> </ul> <p> TYPE: <code>Dict[str, str]</code> DEFAULT: <code>None</code> </p> <code>progress_bar</code> <p>The progress bar to update. Defaults to None.</p> <p> TYPE: <code>Union[tqdm, None]</code> DEFAULT: <code>None</code> </p> <code>transfer_config_kwargs</code> <p>boto S3 transfer configuration (see boto3.s3.transfer.TransferConfig)</p> <p> TYPE: <code>dict</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>download_file_path</code> <p>S3 path of the file</p> <p> TYPE: <code>str</code> </p> RAISES DESCRIPTION <code>ValueError</code> <p>If the key does not exist in the bucket.</p> <code>ClientError</code> <p>If there is an error with the S3 client.</p> Source code in <code>synapseclient/core/remote_file_storage_wrappers.py</code> <pre><code>@staticmethod\ndef download_file(\n    bucket: str,\n    endpoint_url: Union[str, None],\n    remote_file_key: str,\n    download_file_path: str,\n    *,\n    profile_name: str = None,\n    credentials: typing.Dict[str, str] = None,\n    progress_bar: Union[tqdm, None] = None,\n    transfer_config_kwargs: dict = None,\n) -&gt; str:\n    \"\"\"\n    Download a file from s3 using boto3.\n\n    Arguments:\n        bucket: name of bucket to upload to\n        endpoint_url: a boto3 compatible endpoint url\n        remote_file_key: object key to upload the file to\n        download_file_path: local path to save the file to\n        profile_name: AWS profile name from local aws config, **mutually exclusive with credentials**\n        credentials: a dictionary of AWS credentials to use, **mutually exclusive with profile_name**\n\n            Expected items:\n\n            - `aws_access_key_id`\n            - `aws_secret_access_key`\n            - `aws_session_token`\n        progress_bar: The progress bar to update. Defaults to None.\n        transfer_config_kwargs: boto S3 transfer configuration (see boto3.s3.transfer.TransferConfig)\n\n    Returns:\n        download_file_path: S3 path of the file\n\n    Raises:\n        ValueError: If the key does not exist in the bucket.\n        botocore.exceptions.ClientError: If there is an error with the S3 client.\n    \"\"\"\n\n    S3ClientWrapper._attempt_import_boto3()\n\n    import boto3.s3.transfer\n    import botocore\n\n    transfer_config = boto3.s3.transfer.TransferConfig(\n        **(transfer_config_kwargs or {})\n    )\n\n    session_args = credentials if credentials else {\"profile_name\": profile_name}\n    boto_session = boto3.session.Session(**session_args)\n    s3 = boto_session.resource(\"s3\", endpoint_url=endpoint_url)\n\n    try:\n        s3_obj = s3.Object(bucket, remote_file_key)\n\n        progress_callback = None\n\n        if progress_bar is not None:\n            s3_obj.load()\n            file_size = s3_obj.content_length\n            increment_progress_bar_total(total=file_size, progress_bar=progress_bar)\n            progress_callback = S3ClientWrapper._create_progress_callback_func(\n                progress_bar\n            )\n\n        s3_obj.download_file(\n            download_file_path,\n            Callback=progress_callback,\n            Config=transfer_config,\n        )\n\n        return download_file_path\n\n    except botocore.exceptions.ClientError as e:\n        if e.response[\"Error\"][\"Code\"] == \"404\":\n            raise ValueError(\n                \"The key:%s does not exist in bucket:%s.\", remote_file_key, bucket\n            )\n        else:\n            raise\n</code></pre>"},{"location":"reference/core/#synapseclient.core.remote_file_storage_wrappers.S3ClientWrapper.upload_file","title":"<code>upload_file(bucket, endpoint_url, remote_file_key, upload_file_path, *, profile_name=None, credentials=None, show_progress=True, transfer_config_kwargs=None, storage_str=None)</code>  <code>staticmethod</code>","text":"<p>Upload a file to s3 using boto3.</p> PARAMETER DESCRIPTION <code>bucket</code> <p>name of bucket to upload to</p> <p> TYPE: <code>str</code> </p> <code>endpoint_url</code> <p>a boto3 compatible endpoint url</p> <p> TYPE: <code>Optional[str]</code> </p> <code>remote_file_key</code> <p>object key to upload the file to</p> <p> TYPE: <code>str</code> </p> <code>upload_file_path</code> <p>local path of the file to upload</p> <p> TYPE: <code>str</code> </p> <code>profile_name</code> <p>AWS profile name from local aws config, mutually exclusive with credentials</p> <p> TYPE: <code>str</code> DEFAULT: <code>None</code> </p> <code>credentials</code> <p>a dictionary of AWS credentials to use, mutually exclusive with profile_name</p> <p>Expected items:</p> <ul> <li><code>aws_access_key_id</code></li> <li><code>aws_secret_access_key</code></li> <li><code>aws_session_token</code></li> </ul> <p> TYPE: <code>Dict[str, str]</code> DEFAULT: <code>None</code> </p> <code>show_progress</code> <p>whether to print progress indicator to console</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> <code>transfer_config_kwargs</code> <p>boto S3 transfer configuration (see boto3.s3.transfer.TransferConfig)</p> <p> TYPE: <code>dict</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>upload_file_path</code> <p>S3 path of the file</p> <p> TYPE: <code>str</code> </p> RAISES DESCRIPTION <code>ValueError</code> <p>If the path does not exist or is not a file</p> <code>ClientError</code> <p>If there is an error with the S3 client.</p> Source code in <code>synapseclient/core/remote_file_storage_wrappers.py</code> <pre><code>@staticmethod\ndef upload_file(\n    bucket: str,\n    endpoint_url: typing.Optional[str],\n    remote_file_key: str,\n    upload_file_path: str,\n    *,\n    profile_name: str = None,\n    credentials: typing.Dict[str, str] = None,\n    show_progress: bool = True,\n    transfer_config_kwargs: dict = None,\n    storage_str: str = None,\n) -&gt; str:\n    \"\"\"\n    Upload a file to s3 using boto3.\n\n    Arguments:\n        bucket: name of bucket to upload to\n        endpoint_url: a boto3 compatible endpoint url\n        remote_file_key: object key to upload the file to\n        upload_file_path: local path of the file to upload\n        profile_name: AWS profile name from local aws config, **mutually exclusive with credentials**\n        credentials: a dictionary of AWS credentials to use, **mutually exclusive with profile_name**\n\n            Expected items:\n\n            - `aws_access_key_id`\n            - `aws_secret_access_key`\n            - `aws_session_token`\n        show_progress: whether to print progress indicator to console\n        transfer_config_kwargs: boto S3 transfer configuration (see boto3.s3.transfer.TransferConfig)\n\n    Returns:\n        upload_file_path: S3 path of the file\n\n    Raises:\n        ValueError: If the path does not exist or is not a file\n        botocore.exceptions.ClientError: If there is an error with the S3 client.\n    \"\"\"\n\n    if not os.path.isfile(upload_file_path):\n        raise ValueError(\n            \"The path: [%s] does not exist or is not a file\", upload_file_path\n        )\n\n    S3ClientWrapper._attempt_import_boto3()\n    import boto3.s3.transfer\n\n    transfer_config = boto3.s3.transfer.TransferConfig(\n        **(transfer_config_kwargs or {})\n    )\n\n    session_args = credentials if credentials else {\"profile_name\": profile_name}\n    boto_session = boto3.session.Session(**session_args)\n    s3 = boto_session.resource(\"s3\", endpoint_url=endpoint_url)\n\n    progress_callback = None\n    progress_bar = None\n    if show_progress:\n        file_size = os.stat(upload_file_path).st_size\n        filename = os.path.basename(upload_file_path)\n        progress_bar = tqdm(\n            total=file_size,\n            desc=storage_str,\n            unit=\"B\",\n            unit_scale=True,\n            postfix=filename,\n            smoothing=0,\n        )\n        progress_callback = S3ClientWrapper._create_progress_callback_func(\n            progress_bar\n        )\n\n    # automatically determines whether to perform multi-part upload\n    s3.Bucket(bucket).upload_file(\n        upload_file_path,\n        remote_file_key,\n        Callback=progress_callback,\n        Config=transfer_config,\n        ExtraArgs={\"ACL\": \"bucket-owner-full-control\"},\n    )\n    if progress_bar is not None:\n        progress_bar.close()\n    return upload_file_path\n</code></pre>"},{"location":"reference/core/#synapseclient.core.remote_file_storage_wrappers.SFTPWrapper","title":"<code>SFTPWrapper</code>","text":"Source code in <code>synapseclient/core/remote_file_storage_wrappers.py</code> <pre><code>class SFTPWrapper:\n    @staticmethod\n    def _attempt_import_sftp():\n        \"\"\"\n        Check if pysftp is installed and give instructions if not.\n\n        Returns:\n            The pysftp module if available\n        \"\"\"\n        return attempt_import(\n            \"pysftp\",\n            \"\\n\\nLibraries required for SFTP are not installed!\\n\"\n            \"The Synapse client uses pysftp in order to access SFTP storage locations. \"\n            \"This library in turn depends on pycrypto.\\n\"\n            \"For Windows systems without a C/C++ compiler, install the appropriate binary \"\n            \"distribution of pycrypto from:\\n\"\n            \"http://www.voidspace.org.uk/python/modules.shtml#pycrypto\\n\\n\"\n            \"For more information, see: http://python-docs.synapse.org/build/html/sftp.html\",\n        )\n\n    @staticmethod\n    def _parse_for_sftp(url):\n        parsedURL = urllib_parse.urlparse(url)\n        if parsedURL.scheme != \"sftp\":\n            raise (\n                NotImplementedError(\n                    \"This method only supports sftp URLs of the form sftp://...\"\n                )\n            )\n        return parsedURL\n\n    @staticmethod\n    def upload_file(\n        filepath: str,\n        url: str,\n        username: str = None,\n        password: str = None,\n        storage_str: str = None,\n    ) -&gt; str:\n        \"\"\"\n        Performs upload of a local file to an sftp server.\n\n        Arguments:\n            filepath: The path to the file to be uploaded.\n            url: URL where file will be deposited. Should include path and protocol. e.g.\n                        sftp://sftp.example.com/path/to/file/store\n            username: The username for authentication. Defaults to None.\n            password: The password for authentication. Defaults to None.\n\n        Returns:\n            The URL of the uploaded file.\n        \"\"\"\n        progress_bar = tqdm(\n            desc=storage_str,\n            unit=\"B\",\n            unit_scale=True,\n            smoothing=0,\n            postfix=filepath,\n        )\n\n        def progress_callback(*args, **kwargs) -&gt; None:\n            if not progress_bar.total:\n                progress_bar.total = args[1]\n            progress_bar.update(args[0] - progress_bar.n)\n\n        parsedURL = SFTPWrapper._parse_for_sftp(url)\n        with _retry_pysftp_connection(\n            parsedURL.hostname, username=username, password=password\n        ) as sftp:\n            sftp.makedirs(parsedURL.path)\n            with sftp.cd(parsedURL.path):\n                sftp.put(filepath, preserve_mtime=True, callback=progress_callback)\n        progress_bar.close()\n        path = urllib_parse.quote(parsedURL.path + \"/\" + os.path.split(filepath)[-1])\n        parsedURL = parsedURL._replace(path=path)\n        return urllib_parse.urlunparse(parsedURL)\n\n    @staticmethod\n    def download_file(\n        url: str,\n        localFilepath: str = None,\n        username: str = None,\n        password: str = None,\n        progress_bar: Union[tqdm, None] = None,\n    ) -&gt; str:\n        \"\"\"\n        Performs download of a file from an sftp server.\n\n        Arguments:\n            url: URL where file will be deposited.  Path will be chopped out.\n            localFilepath: location where to store file\n            username: username on server\n            password: password for authentication on  server\n            progress_bar: The progress bar to update. Defaults to None.\n\n        Returns:\n            The local filepath where the file was saved.\n        \"\"\"\n        updated_progress_bar_with_total = False\n        last_transfer_checkpoint = 0\n\n        def progress_callback(\n            *args,\n            **kwargs,\n        ) -&gt; None:\n            nonlocal updated_progress_bar_with_total\n            nonlocal last_transfer_checkpoint\n            if not updated_progress_bar_with_total:\n                updated_progress_bar_with_total = True\n                increment_progress_bar_total(args[1], progress_bar)\n            increment_progress_bar(\n                n=args[0] - last_transfer_checkpoint, progress_bar=progress_bar\n            )\n            last_transfer_checkpoint = args[0]\n\n        parsed_url = SFTPWrapper._parse_for_sftp(url)\n\n        # Create the local file path if it doesn't exist\n        path = urllib_parse.unquote(parsed_url.path)\n        if localFilepath is None:\n            localFilepath = os.getcwd()\n        if os.path.isdir(localFilepath):\n            localFilepath = os.path.join(localFilepath, path.split(\"/\")[-1])\n        # Check and create the directory\n        download_directory = os.path.dirname(localFilepath)\n        if not os.path.exists(download_directory):\n            os.makedirs(download_directory)\n\n        # Download file\n        with _retry_pysftp_connection(\n            parsed_url.hostname, username=username, password=password\n        ) as sftp:\n            sftp.get(\n                path,\n                localFilepath,\n                preserve_mtime=True,\n                callback=(progress_callback if progress_bar is not None else None),\n            )\n        return localFilepath\n</code></pre>"},{"location":"reference/core/#synapseclient.core.remote_file_storage_wrappers.SFTPWrapper-functions","title":"Functions","text":""},{"location":"reference/core/#synapseclient.core.remote_file_storage_wrappers.SFTPWrapper.upload_file","title":"<code>upload_file(filepath, url, username=None, password=None, storage_str=None)</code>  <code>staticmethod</code>","text":"<p>Performs upload of a local file to an sftp server.</p> PARAMETER DESCRIPTION <code>filepath</code> <p>The path to the file to be uploaded.</p> <p> TYPE: <code>str</code> </p> <code>url</code> <p>URL where file will be deposited. Should include path and protocol. e.g.         sftp://sftp.example.com/path/to/file/store</p> <p> TYPE: <code>str</code> </p> <code>username</code> <p>The username for authentication. Defaults to None.</p> <p> TYPE: <code>str</code> DEFAULT: <code>None</code> </p> <code>password</code> <p>The password for authentication. Defaults to None.</p> <p> TYPE: <code>str</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>str</code> <p>The URL of the uploaded file.</p> Source code in <code>synapseclient/core/remote_file_storage_wrappers.py</code> <pre><code>@staticmethod\ndef upload_file(\n    filepath: str,\n    url: str,\n    username: str = None,\n    password: str = None,\n    storage_str: str = None,\n) -&gt; str:\n    \"\"\"\n    Performs upload of a local file to an sftp server.\n\n    Arguments:\n        filepath: The path to the file to be uploaded.\n        url: URL where file will be deposited. Should include path and protocol. e.g.\n                    sftp://sftp.example.com/path/to/file/store\n        username: The username for authentication. Defaults to None.\n        password: The password for authentication. Defaults to None.\n\n    Returns:\n        The URL of the uploaded file.\n    \"\"\"\n    progress_bar = tqdm(\n        desc=storage_str,\n        unit=\"B\",\n        unit_scale=True,\n        smoothing=0,\n        postfix=filepath,\n    )\n\n    def progress_callback(*args, **kwargs) -&gt; None:\n        if not progress_bar.total:\n            progress_bar.total = args[1]\n        progress_bar.update(args[0] - progress_bar.n)\n\n    parsedURL = SFTPWrapper._parse_for_sftp(url)\n    with _retry_pysftp_connection(\n        parsedURL.hostname, username=username, password=password\n    ) as sftp:\n        sftp.makedirs(parsedURL.path)\n        with sftp.cd(parsedURL.path):\n            sftp.put(filepath, preserve_mtime=True, callback=progress_callback)\n    progress_bar.close()\n    path = urllib_parse.quote(parsedURL.path + \"/\" + os.path.split(filepath)[-1])\n    parsedURL = parsedURL._replace(path=path)\n    return urllib_parse.urlunparse(parsedURL)\n</code></pre>"},{"location":"reference/core/#synapseclient.core.remote_file_storage_wrappers.SFTPWrapper.download_file","title":"<code>download_file(url, localFilepath=None, username=None, password=None, progress_bar=None)</code>  <code>staticmethod</code>","text":"<p>Performs download of a file from an sftp server.</p> PARAMETER DESCRIPTION <code>url</code> <p>URL where file will be deposited.  Path will be chopped out.</p> <p> TYPE: <code>str</code> </p> <code>localFilepath</code> <p>location where to store file</p> <p> TYPE: <code>str</code> DEFAULT: <code>None</code> </p> <code>username</code> <p>username on server</p> <p> TYPE: <code>str</code> DEFAULT: <code>None</code> </p> <code>password</code> <p>password for authentication on  server</p> <p> TYPE: <code>str</code> DEFAULT: <code>None</code> </p> <code>progress_bar</code> <p>The progress bar to update. Defaults to None.</p> <p> TYPE: <code>Union[tqdm, None]</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>str</code> <p>The local filepath where the file was saved.</p> Source code in <code>synapseclient/core/remote_file_storage_wrappers.py</code> <pre><code>@staticmethod\ndef download_file(\n    url: str,\n    localFilepath: str = None,\n    username: str = None,\n    password: str = None,\n    progress_bar: Union[tqdm, None] = None,\n) -&gt; str:\n    \"\"\"\n    Performs download of a file from an sftp server.\n\n    Arguments:\n        url: URL where file will be deposited.  Path will be chopped out.\n        localFilepath: location where to store file\n        username: username on server\n        password: password for authentication on  server\n        progress_bar: The progress bar to update. Defaults to None.\n\n    Returns:\n        The local filepath where the file was saved.\n    \"\"\"\n    updated_progress_bar_with_total = False\n    last_transfer_checkpoint = 0\n\n    def progress_callback(\n        *args,\n        **kwargs,\n    ) -&gt; None:\n        nonlocal updated_progress_bar_with_total\n        nonlocal last_transfer_checkpoint\n        if not updated_progress_bar_with_total:\n            updated_progress_bar_with_total = True\n            increment_progress_bar_total(args[1], progress_bar)\n        increment_progress_bar(\n            n=args[0] - last_transfer_checkpoint, progress_bar=progress_bar\n        )\n        last_transfer_checkpoint = args[0]\n\n    parsed_url = SFTPWrapper._parse_for_sftp(url)\n\n    # Create the local file path if it doesn't exist\n    path = urllib_parse.unquote(parsed_url.path)\n    if localFilepath is None:\n        localFilepath = os.getcwd()\n    if os.path.isdir(localFilepath):\n        localFilepath = os.path.join(localFilepath, path.split(\"/\")[-1])\n    # Check and create the directory\n    download_directory = os.path.dirname(localFilepath)\n    if not os.path.exists(download_directory):\n        os.makedirs(download_directory)\n\n    # Download file\n    with _retry_pysftp_connection(\n        parsed_url.hostname, username=username, password=password\n    ) as sftp:\n        sftp.get(\n            path,\n            localFilepath,\n            preserve_mtime=True,\n            callback=(progress_callback if progress_bar is not None else None),\n        )\n    return localFilepath\n</code></pre>"},{"location":"reference/core/#synapseclient.core.remote_file_storage_wrappers-functions","title":"Functions","text":""},{"location":"reference/core/#retry","title":"Retry","text":""},{"location":"reference/core/#synapseclient.core.retry","title":"<code>synapseclient.core.retry</code>","text":"<p>A helper tool that allows the Python client to make more than one attempt at connecting to the server if initially met with an error. These retry attempts can be made under certain conditions, i.e. for certain status codes, connection errors, and/or connection exceptions.</p>"},{"location":"reference/core/#synapseclient.core.retry-functions","title":"Functions","text":""},{"location":"reference/core/#synapseclient.core.retry.with_retry","title":"<code>with_retry(function, verbose=False, retry_status_codes=[429, 500, 502, 503, 504], expected_status_codes=[], retry_errors=[], retry_exceptions=[], retries=DEFAULT_RETRIES, wait=DEFAULT_WAIT, back_off=DEFAULT_BACK_OFF, max_wait=DEFAULT_MAX_WAIT)</code>","text":"<p>Retries the given function under certain conditions.</p> PARAMETER DESCRIPTION <code>function</code> <p>A function with no arguments.  If arguments are needed, use a lambda (see example).</p> <p> </p> <code>retry_status_codes</code> <p>What status codes to retry upon in the case of a SynapseHTTPError.</p> <p> DEFAULT: <code>[429, 500, 502, 503, 504]</code> </p> <code>expected_status_codes</code> <p>If specified responses with any other status codes result in a retry.</p> <p> DEFAULT: <code>[]</code> </p> <code>retry_errors</code> <p>What reasons to retry upon, if function().response.json()['reason'] exists.</p> <p> DEFAULT: <code>[]</code> </p> <code>retry_exceptions</code> <p>What types of exceptions, specified as strings or Exception classes, to retry upon.</p> <p> DEFAULT: <code>[]</code> </p> <code>retries</code> <p>How many times to retry maximum.</p> <p> DEFAULT: <code>DEFAULT_RETRIES</code> </p> <code>wait</code> <p>How many seconds to wait between retries.</p> <p> DEFAULT: <code>DEFAULT_WAIT</code> </p> <code>back_off</code> <p>Exponential constant to increase wait for between progressive failures.</p> <p> DEFAULT: <code>DEFAULT_BACK_OFF</code> </p> <code>max_wait</code> <p>back_off between requests will not exceed this value</p> <p> DEFAULT: <code>DEFAULT_MAX_WAIT</code> </p> RETURNS DESCRIPTION <p>function()</p> Using with_retry <p>Using <code>with_retry</code> to consolidate inputs into a list.</p> <pre><code>from synapseclient.core.retry import with_retry\n\ndef foo(a, b, c): return [a, b, c]\nresult = with_retry(lambda: foo(\"1\", \"2\", \"3\"), **STANDARD_RETRY_PARAMS)\n</code></pre> Source code in <code>synapseclient/core/retry.py</code> <pre><code>def with_retry(\n    function,\n    verbose=False,\n    retry_status_codes=[429, 500, 502, 503, 504],\n    expected_status_codes=[],\n    retry_errors=[],\n    retry_exceptions=[],\n    retries=DEFAULT_RETRIES,\n    wait=DEFAULT_WAIT,\n    back_off=DEFAULT_BACK_OFF,\n    max_wait=DEFAULT_MAX_WAIT,\n):\n    \"\"\"\n    Retries the given function under certain conditions.\n\n    Arguments:\n        function: A function with no arguments.  If arguments are needed, use a lambda (see example).\n        retry_status_codes: What status codes to retry upon in the case of a SynapseHTTPError.\n        expected_status_codes: If specified responses with any other status codes result in a retry.\n        retry_errors: What reasons to retry upon, if function().response.json()['reason'] exists.\n        retry_exceptions: What types of exceptions, specified as strings or Exception classes, to retry upon.\n        retries: How many times to retry maximum.\n        wait: How many seconds to wait between retries.\n        back_off: Exponential constant to increase wait for between progressive failures.\n        max_wait: back_off between requests will not exceed this value\n\n    Returns:\n        function()\n\n    Example: Using with_retry\n        Using ``with_retry`` to consolidate inputs into a list.\n\n            from synapseclient.core.retry import with_retry\n\n            def foo(a, b, c): return [a, b, c]\n            result = with_retry(lambda: foo(\"1\", \"2\", \"3\"), **STANDARD_RETRY_PARAMS)\n    \"\"\"\n\n    if verbose:\n        logger = logging.getLogger(DEBUG_LOGGER_NAME)\n    else:\n        logger = logging.getLogger(DEFAULT_LOGGER_NAME)\n\n    # Retry until we succeed or run out of tries\n    total_wait = 0\n    while True:\n        # Start with a clean slate\n        exc = None\n        exc_info = None\n        retry = False\n        response = None\n\n        # Try making the call\n        try:\n            response = function()\n        except Exception as ex:\n            exc = ex\n            exc_info = sys.exc_info()\n            logger.debug(DEBUG_EXCEPTION, function, exc_info=True)\n            if hasattr(ex, \"response\"):\n                response = ex.response\n\n        # Check if we got a retry-able error\n        if response is not None and hasattr(response, \"status_code\"):\n            if (\n                expected_status_codes\n                and response.status_code not in expected_status_codes\n            ) or (retry_status_codes and response.status_code in retry_status_codes):\n                response_message = _get_message(response)\n                retry = True\n                logger.debug(\"retrying on status code: %s\" % str(response.status_code))\n                # TODO: this was originally printed regardless of 'verbose' was that behavior correct?\n                logger.debug(str(response_message))\n                if (response.status_code == 429) and (wait &gt; 10):\n                    logger.warning(\"%s...\\n\" % response_message)\n                    logger.warning(\"Retrying in %i seconds\" % wait)\n\n            elif response.status_code not in range(200, 299):\n                # For all other non 200 messages look for retryable errors in the body or reason field\n                response_message = _get_message(response)\n                if any(\n                    [msg.lower() in response_message.lower() for msg in retry_errors]\n                ):\n                    retry = True\n                    logger.debug(\"retrying %s\" % response_message)\n                # special case for message throttling\n                elif (\n                    \"Please slow down.  You may send a maximum of 10 message\"\n                    in response\n                ):\n                    retry = True\n                    wait = 16\n                    logger.debug(\"retrying \" + response_message)\n\n        # Check if we got a retry-able exception\n        if exc is not None:\n            if (\n                exc.__class__.__name__ in retry_exceptions\n                or exc.__class__ in retry_exceptions\n                or any(\n                    [msg.lower() in str(exc_info[1]).lower() for msg in retry_errors]\n                )\n            ):\n                retry = True\n                logger.debug(\"retrying exception: \" + str(exc))\n\n        # Wait then retry\n        retries -= 1\n        if retries &gt;= 0 and retry:\n            randomized_wait = wait * random.uniform(0.5, 1.5)\n            logger.debug(\n                \"total wait time {total_wait:5.0f} seconds\\n \"\n                \"... Retrying in {wait:5.1f} seconds...\".format(\n                    total_wait=total_wait, wait=randomized_wait\n                )\n            )\n            total_wait += randomized_wait\n            doze(randomized_wait)\n            wait = min(max_wait, wait * back_off)\n            continue\n\n        # Out of retries, re-raise the exception or return the response\n        if exc_info is not None and exc_info[0] is not None:\n            logger.debug(\n                \"retries have run out. re-raising the exception\", exc_info=True\n            )\n            raise exc\n        return response\n</code></pre>"},{"location":"reference/core/#synapseclient.core.retry.calculate_exponential_backoff","title":"<code>calculate_exponential_backoff(retries, base_wait, wait_random_lower, wait_random_upper, back_off_factor, max_back_off)</code>","text":"<p>Handle calculating the exponential backoff.</p> PARAMETER DESCRIPTION <code>retries</code> <p>The number of retries that have been attempted</p> <p> TYPE: <code>int</code> </p> <code>base_wait</code> <p>The base wait time</p> <p> TYPE: <code>float</code> </p> <code>wait_random_lower</code> <p>The lower bound of the random wait time</p> <p> TYPE: <code>float</code> </p> <code>wait_random_upper</code> <p>The upper bound of the random wait time</p> <p> TYPE: <code>float</code> </p> <code>back_off_factor</code> <p>The factor to increase the wait time by for each retry</p> <p> TYPE: <code>float</code> </p> <code>max_back_off</code> <p>The maximum wait time</p> <p> TYPE: <code>float</code> </p> RETURNS DESCRIPTION <code>float</code> <p>The total wait time</p> Source code in <code>synapseclient/core/retry.py</code> <pre><code>def calculate_exponential_backoff(\n    retries: int,\n    base_wait: float,\n    wait_random_lower: float,\n    wait_random_upper: float,\n    back_off_factor: float,\n    max_back_off: float,\n) -&gt; float:\n    \"\"\"\n    Handle calculating the exponential backoff.\n\n    Arguments:\n        retries: The number of retries that have been attempted\n        base_wait: The base wait time\n        wait_random_lower: The lower bound of the random wait time\n        wait_random_upper: The upper bound of the random wait time\n        back_off_factor: The factor to increase the wait time by for each retry\n        max_back_off: The maximum wait time\n\n    Returns:\n        The total wait time\n    \"\"\"\n    random_jitter = random.uniform(wait_random_lower, wait_random_upper)\n    time_to_wait = min(\n        (base_wait * (back_off_factor**retries)) + random_jitter,\n        max_back_off,\n    )\n    return time_to_wait\n</code></pre>"},{"location":"reference/core/#synapseclient.core.retry.with_retry_time_based_async","title":"<code>with_retry_time_based_async(function, verbose=False, retry_status_codes=None, expected_status_codes=None, retry_errors=None, retry_exceptions=None, retry_base_wait=DEFAULT_BASE_WAIT_ASYNC, retry_wait_random_lower=DEFAULT_WAIT_RANDOM_LOWER_ASYNC, retry_wait_random_upper=DEFAULT_WAIT_RANDOM_UPPER_ASYNC, retry_back_off_factor=DEFAULT_BACK_OFF_FACTOR_ASYNC, retry_max_back_off=DEFAULT_MAX_BACK_OFF_ASYNC, retry_max_wait_before_failure=DEFAULT_MAX_WAIT_BEFORE_FAIL_ASYNC)</code>  <code>async</code>","text":"<p>Retries the given function under certain conditions. This is created such that it will retry an unbounded number of times until the maximum wait time is reached. The backoff is calculated using an exponential backoff algorithm with a random jitter. The maximum backoff inbetween retries is capped at <code>retry_max_back_off</code>.</p> PARAMETER DESCRIPTION <code>verbose</code> <p>Whether to log debug messages</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>function</code> <p>A function with no arguments. If arguments are needed, use a lambda (see example).</p> <p> TYPE: <code>Coroutine[Any, Any, Any]</code> </p> <code>retry_status_codes</code> <p>What status codes to retry upon in the case of a SynapseHTTPError.</p> <p> TYPE: <code>List[int]</code> DEFAULT: <code>None</code> </p> <code>expected_status_codes</code> <p>If specified responses with any other status codes result in a retry.</p> <p> TYPE: <code>List[int]</code> DEFAULT: <code>None</code> </p> <code>retry_errors</code> <p>What reasons to retry upon, if <code>function().response.json()['reason']</code> exists.</p> <p> TYPE: <code>List[str]</code> DEFAULT: <code>None</code> </p> <code>retry_exceptions</code> <p>What types of exceptions, specified as strings or Exception classes, to retry upon.</p> <p> TYPE: <code>List[Union[Exception, str]]</code> DEFAULT: <code>None</code> </p> <code>retry_base_wait</code> <p>The base wait time inbetween retries.</p> <p> TYPE: <code>float</code> DEFAULT: <code>DEFAULT_BASE_WAIT_ASYNC</code> </p> <code>retry_wait_random_lower</code> <p>The lower bound of the random wait time.</p> <p> TYPE: <code>float</code> DEFAULT: <code>DEFAULT_WAIT_RANDOM_LOWER_ASYNC</code> </p> <code>retry_wait_random_upper</code> <p>The upper bound of the random wait time.</p> <p> TYPE: <code>float</code> DEFAULT: <code>DEFAULT_WAIT_RANDOM_UPPER_ASYNC</code> </p> <code>retry_back_off_factor</code> <p>The factor to increase the wait time by for each retry.</p> <p> TYPE: <code>float</code> DEFAULT: <code>DEFAULT_BACK_OFF_FACTOR_ASYNC</code> </p> <code>retry_max_back_off</code> <p>The maximum wait time.</p> <p> TYPE: <code>float</code> DEFAULT: <code>DEFAULT_MAX_BACK_OFF_ASYNC</code> </p> <code>retry_max_wait_before_failure</code> <p>The maximum wait time before failure.</p> <p> TYPE: <code>float</code> DEFAULT: <code>DEFAULT_MAX_WAIT_BEFORE_FAIL_ASYNC</code> </p> Using with_retry <p>Using <code>with_retry_time_based_async</code> to consolidate inputs into a list.</p> <pre><code>from synapseclient.core.retry import with_retry_time_based_async\n\nasync def foo(a, b, c): return [a, b, c]\nresult = await with_retry_time_based_async(lambda: foo(\"1\", \"2\", \"3\"))\n</code></pre> Source code in <code>synapseclient/core/retry.py</code> <pre><code>async def with_retry_time_based_async(\n    function: Coroutine[Any, Any, Any],\n    verbose: bool = False,\n    retry_status_codes: List[int] = None,\n    expected_status_codes: List[int] = None,\n    retry_errors: List[str] = None,\n    retry_exceptions: List[Union[Exception, str]] = None,\n    retry_base_wait: float = DEFAULT_BASE_WAIT_ASYNC,\n    retry_wait_random_lower: float = DEFAULT_WAIT_RANDOM_LOWER_ASYNC,\n    retry_wait_random_upper: float = DEFAULT_WAIT_RANDOM_UPPER_ASYNC,\n    retry_back_off_factor: float = DEFAULT_BACK_OFF_FACTOR_ASYNC,\n    retry_max_back_off: float = DEFAULT_MAX_BACK_OFF_ASYNC,\n    retry_max_wait_before_failure: float = DEFAULT_MAX_WAIT_BEFORE_FAIL_ASYNC,\n) -&gt; Union[Exception, httpx.Response, Any, None]:\n    \"\"\"\n    Retries the given function under certain conditions. This is created such that it\n    will retry an unbounded number of times until the maximum wait time is reached. The\n    backoff is calculated using an exponential backoff algorithm with a random jitter.\n    The maximum backoff inbetween retries is capped at `retry_max_back_off`.\n\n    Arguments:\n        verbose: Whether to log debug messages\n        function: A function with no arguments. If arguments are needed, use a lambda\n            (see example).\n        retry_status_codes: What status codes to retry upon in the case of a\n            SynapseHTTPError.\n        expected_status_codes: If specified responses with any other status codes result\n            in a retry.\n        retry_errors: What reasons to retry upon, if\n            `function().response.json()['reason']` exists.\n        retry_exceptions: What types of exceptions, specified as strings or Exception\n            classes, to retry upon.\n        retry_base_wait: The base wait time inbetween retries.\n        retry_wait_random_lower: The lower bound of the random wait time.\n        retry_wait_random_upper: The upper bound of the random wait time.\n        retry_back_off_factor: The factor to increase the wait time by for each retry.\n        retry_max_back_off: The maximum wait time.\n        retry_max_wait_before_failure: The maximum wait time before failure.\n\n    Example: Using with_retry\n        Using ``with_retry_time_based_async`` to consolidate inputs into a list.\n\n            from synapseclient.core.retry import with_retry_time_based_async\n\n            async def foo(a, b, c): return [a, b, c]\n            result = await with_retry_time_based_async(lambda: foo(\"1\", \"2\", \"3\"))\n    \"\"\"\n    (\n        retry_status_codes,\n        expected_status_codes,\n        retry_errors,\n        retry_exceptions,\n        logger,\n    ) = _assign_default_values(\n        retry_status_codes=retry_status_codes,\n        expected_status_codes=expected_status_codes,\n        retry_errors=retry_errors,\n        retry_exceptions=retry_exceptions,\n        verbose=verbose,\n    )\n\n    # Retry until we succeed or run past the maximum wait time\n    total_wait = 0\n    retries = -1\n    while True:\n        caught_exception = None\n        caught_exception_info = None\n        response = None\n        current_span = trace.get_current_span()\n        current_span.set_attribute(\"synapse.retries\", str(retries + 1))\n\n        try:\n            response = await function()\n        except Exception as ex:\n            caught_exception = ex\n            caught_exception_info = sys.exc_info()\n            logger.debug(DEBUG_EXCEPTION, function, exc_info=True)\n            if hasattr(ex, \"response\"):\n                response = ex.response\n\n        retry = _is_retryable(\n            response=response,\n            caught_exception=caught_exception,\n            caught_exception_info=caught_exception_info,\n            expected_status_codes=expected_status_codes,\n            retry_status_codes=retry_status_codes,\n            retry_exceptions=retry_exceptions,\n            retry_errors=retry_errors,\n        )\n\n        # Wait then retry\n        retries += 1\n        if total_wait &lt; retry_max_wait_before_failure and retry:\n            _log_for_retry(\n                logger=logger, response=response, caught_exception=caught_exception\n            )\n\n            backoff_wait = calculate_exponential_backoff(\n                retries=retries,\n                base_wait=retry_base_wait,\n                wait_random_lower=retry_wait_random_lower,\n                wait_random_upper=retry_wait_random_upper,\n                back_off_factor=retry_back_off_factor,\n                max_back_off=retry_max_back_off,\n            )\n            total_wait += backoff_wait\n            await asyncio.sleep(backoff_wait)\n            continue\n\n        # Out of retries, re-raise the exception or return the response\n        if caught_exception_info is not None and caught_exception_info[0] is not None:\n            logger.debug(\n                (\n                    \"Retries have run out. re-raising the exception: %s\"\n                    if retry\n                    else \"Raising the exception: %s\"\n                ),\n                str(caught_exception_info[0]),\n            )\n            raise caught_exception\n        return response\n</code></pre>"},{"location":"reference/core/#synapseclient.core.retry.with_retry_time_based","title":"<code>with_retry_time_based(function, verbose=False, retry_status_codes=None, expected_status_codes=None, retry_errors=None, retry_exceptions=None, retry_base_wait=DEFAULT_BASE_WAIT_ASYNC, retry_wait_random_lower=DEFAULT_WAIT_RANDOM_LOWER_ASYNC, retry_wait_random_upper=DEFAULT_WAIT_RANDOM_UPPER_ASYNC, retry_back_off_factor=DEFAULT_BACK_OFF_FACTOR_ASYNC, retry_max_back_off=DEFAULT_MAX_BACK_OFF_ASYNC, retry_max_wait_before_failure=DEFAULT_MAX_WAIT_BEFORE_FAIL_ASYNC)</code>","text":"<p>Retries the given function under certain conditions. This is created such that it will retry an unbounded number of times until the maximum wait time is reached. The backoff is calculated using an exponential backoff algorithm with a random jitter. The maximum backoff inbetween retries is capped at <code>retry_max_back_off</code>.</p> PARAMETER DESCRIPTION <code>verbose</code> <p>Whether to log debug messages</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>function</code> <p>A function with no arguments. If arguments are needed, use a lambda (see example).</p> <p> </p> <code>retry_status_codes</code> <p>What status codes to retry upon in the case of a SynapseHTTPError.</p> <p> TYPE: <code>List[int]</code> DEFAULT: <code>None</code> </p> <code>expected_status_codes</code> <p>If specified responses with any other status codes result in a retry.</p> <p> TYPE: <code>List[int]</code> DEFAULT: <code>None</code> </p> <code>retry_errors</code> <p>What reasons to retry upon, if <code>function().response.json()['reason']</code> exists.</p> <p> TYPE: <code>List[str]</code> DEFAULT: <code>None</code> </p> <code>retry_exceptions</code> <p>What types of exceptions, specified as strings or Exception classes, to retry upon.</p> <p> TYPE: <code>List[Union[Exception, str]]</code> DEFAULT: <code>None</code> </p> <code>retry_base_wait</code> <p>The base wait time inbetween retries.</p> <p> TYPE: <code>float</code> DEFAULT: <code>DEFAULT_BASE_WAIT_ASYNC</code> </p> <code>retry_wait_random_lower</code> <p>The lower bound of the random wait time.</p> <p> TYPE: <code>float</code> DEFAULT: <code>DEFAULT_WAIT_RANDOM_LOWER_ASYNC</code> </p> <code>retry_wait_random_upper</code> <p>The upper bound of the random wait time.</p> <p> TYPE: <code>float</code> DEFAULT: <code>DEFAULT_WAIT_RANDOM_UPPER_ASYNC</code> </p> <code>retry_back_off_factor</code> <p>The factor to increase the wait time by for each retry.</p> <p> TYPE: <code>float</code> DEFAULT: <code>DEFAULT_BACK_OFF_FACTOR_ASYNC</code> </p> <code>retry_max_back_off</code> <p>The maximum wait time.</p> <p> TYPE: <code>float</code> DEFAULT: <code>DEFAULT_MAX_BACK_OFF_ASYNC</code> </p> <code>retry_max_wait_before_failure</code> <p>The maximum wait time before failure.</p> <p> TYPE: <code>float</code> DEFAULT: <code>DEFAULT_MAX_WAIT_BEFORE_FAIL_ASYNC</code> </p> Using with_retry <p>Using <code>with_retry_time_based</code> to consolidate inputs into a list.</p> <pre><code>from synapseclient.core.retry import with_retry_time_based\n\nasync def foo(a, b, c): return [a, b, c]\nresult = with_retry_time_based(lambda: foo(\"1\", \"2\", \"3\"))\n</code></pre> Source code in <code>synapseclient/core/retry.py</code> <pre><code>def with_retry_time_based(\n    function,\n    verbose: bool = False,\n    retry_status_codes: List[int] = None,\n    expected_status_codes: List[int] = None,\n    retry_errors: List[str] = None,\n    retry_exceptions: List[Union[Exception, str]] = None,\n    retry_base_wait: float = DEFAULT_BASE_WAIT_ASYNC,\n    retry_wait_random_lower: float = DEFAULT_WAIT_RANDOM_LOWER_ASYNC,\n    retry_wait_random_upper: float = DEFAULT_WAIT_RANDOM_UPPER_ASYNC,\n    retry_back_off_factor: float = DEFAULT_BACK_OFF_FACTOR_ASYNC,\n    retry_max_back_off: float = DEFAULT_MAX_BACK_OFF_ASYNC,\n    retry_max_wait_before_failure: float = DEFAULT_MAX_WAIT_BEFORE_FAIL_ASYNC,\n) -&gt; Union[Exception, httpx.Response, Any, None]:\n    \"\"\"\n    Retries the given function under certain conditions. This is created such that it\n    will retry an unbounded number of times until the maximum wait time is reached. The\n    backoff is calculated using an exponential backoff algorithm with a random jitter.\n    The maximum backoff inbetween retries is capped at `retry_max_back_off`.\n\n    Arguments:\n        verbose: Whether to log debug messages\n        function: A function with no arguments. If arguments are needed, use a lambda\n            (see example).\n        retry_status_codes: What status codes to retry upon in the case of a\n            SynapseHTTPError.\n        expected_status_codes: If specified responses with any other status codes result\n            in a retry.\n        retry_errors: What reasons to retry upon, if\n            `function().response.json()['reason']` exists.\n        retry_exceptions: What types of exceptions, specified as strings or Exception\n            classes, to retry upon.\n        retry_base_wait: The base wait time inbetween retries.\n        retry_wait_random_lower: The lower bound of the random wait time.\n        retry_wait_random_upper: The upper bound of the random wait time.\n        retry_back_off_factor: The factor to increase the wait time by for each retry.\n        retry_max_back_off: The maximum wait time.\n        retry_max_wait_before_failure: The maximum wait time before failure.\n\n    Example: Using with_retry\n        Using ``with_retry_time_based`` to consolidate inputs into a list.\n\n            from synapseclient.core.retry import with_retry_time_based\n\n            async def foo(a, b, c): return [a, b, c]\n            result = with_retry_time_based(lambda: foo(\"1\", \"2\", \"3\"))\n    \"\"\"\n    (\n        retry_status_codes,\n        expected_status_codes,\n        retry_errors,\n        retry_exceptions,\n        logger,\n    ) = _assign_default_values(\n        retry_status_codes=retry_status_codes,\n        expected_status_codes=expected_status_codes,\n        retry_errors=retry_errors,\n        retry_exceptions=retry_exceptions,\n        verbose=verbose,\n    )\n\n    # Retry until we succeed or run past the maximum wait time\n    total_wait = 0\n    retries = -1\n    while True:\n        caught_exception = None\n        caught_exception_info = None\n        response = None\n        current_span = trace.get_current_span()\n        current_span.set_attribute(\"synapse.retries\", str(retries + 1))\n\n        try:\n            response = function()\n        except Exception as ex:\n            caught_exception = ex\n            caught_exception_info = sys.exc_info()\n            logger.debug(DEBUG_EXCEPTION, function, exc_info=True)\n            if hasattr(ex, \"response\"):\n                response = ex.response\n\n        retry = _is_retryable(\n            response=response,\n            caught_exception=caught_exception,\n            caught_exception_info=caught_exception_info,\n            expected_status_codes=expected_status_codes,\n            retry_status_codes=retry_status_codes,\n            retry_exceptions=retry_exceptions,\n            retry_errors=retry_errors,\n        )\n\n        # Wait then retry\n        retries += 1\n        if total_wait &lt; retry_max_wait_before_failure and retry:\n            _log_for_retry(\n                logger=logger, response=response, caught_exception=caught_exception\n            )\n\n            backoff_wait = calculate_exponential_backoff(\n                retries=retries,\n                base_wait=retry_base_wait,\n                wait_random_lower=retry_wait_random_lower,\n                wait_random_upper=retry_wait_random_upper,\n                back_off_factor=retry_back_off_factor,\n                max_back_off=retry_max_back_off,\n            )\n            total_wait += backoff_wait\n            time.sleep(backoff_wait)\n            continue\n\n        # Out of retries, re-raise the exception or return the response\n        if caught_exception_info is not None and caught_exception_info[0] is not None:\n            logger.debug(\n                (\n                    \"Retries have run out. re-raising the exception: %s\"\n                    if retry\n                    else \"Raising the exception: %s\"\n                ),\n                str(caught_exception_info[0]),\n            )\n            raise caught_exception\n        return response\n</code></pre>"},{"location":"reference/core/#utils","title":"Utils","text":""},{"location":"reference/core/#synapseclient.core.utils","title":"<code>synapseclient.core.utils</code>","text":"<p>Utility functions useful in the implementation and testing of the Synapse client.</p>"},{"location":"reference/core/#synapseclient.core.utils-classes","title":"Classes","text":""},{"location":"reference/core/#synapseclient.core.utils.threadsafe_iter","title":"<code>threadsafe_iter</code>","text":"<p>Takes an iterator/generator and makes it thread-safe by serializing call to the <code>next</code> method of given iterator/generator. See: http://anandology.com/blog/using-iterators-and-generators/</p> Source code in <code>synapseclient/core/utils.py</code> <pre><code>class threadsafe_iter:\n    \"\"\"Takes an iterator/generator and makes it thread-safe by serializing call to the\n    `next` method of given iterator/generator.\n    See: &lt;http://anandology.com/blog/using-iterators-and-generators/&gt;\n    \"\"\"\n\n    def __init__(self, it):\n        self.it = it\n        self.lock = threading.Lock()\n\n    def __iter__(self):\n        return self\n\n    def __next__(self):\n        with self.lock:\n            return next(self.it)\n</code></pre>"},{"location":"reference/core/#synapseclient.core.utils.deprecated_keyword_param","title":"<code>deprecated_keyword_param</code>","text":"<p>A decorator to use to warn when a keyword parameter from a function has been deprecated and is intended for future removal. Will emit a warning such a keyword is passed.</p> Source code in <code>synapseclient/core/utils.py</code> <pre><code>class deprecated_keyword_param:\n    \"\"\"A decorator to use to warn when a keyword parameter from a function has been deprecated\n    and is intended for future removal. Will emit a warning such a keyword is passed.\"\"\"\n\n    def __init__(self, keywords, version, reason):\n        self.keywords = set(keywords)\n        self.version = version\n        self.reason = reason\n\n    def __call__(self, fn):\n        def wrapper(*args, **kwargs):\n            found = self.keywords.intersection(kwargs)\n            if found:\n                warnings.warn(\n                    \"Parameter(s) {} deprecated since version {}; {}\".format(\n                        sorted(list(found)), self.version, self.reason\n                    ),\n                    category=DeprecationWarning,\n                    stacklevel=2,\n                )\n\n            return fn(*args, **kwargs)\n\n        return wrapper\n</code></pre>"},{"location":"reference/core/#synapseclient.core.utils-functions","title":"Functions","text":""},{"location":"reference/core/#synapseclient.core.utils.md5_for_file","title":"<code>md5_for_file(filename, block_size=2 * MB, callback=None)</code>","text":"<p>Calculates the MD5 of the given file. See source http://stackoverflow.com/questions/1131220/get-md5-hash-of-a-files-without-open-it-in-python.</p> PARAMETER DESCRIPTION <code>filename</code> <p>The file to read in</p> <p> TYPE: <code>str</code> </p> <code>block_size</code> <p>How much of the file to read in at once (bytes).         Defaults to 2 MB</p> <p> TYPE: <code>int</code> DEFAULT: <code>2 * MB</code> </p> <code>callback</code> <p>The callback function that help us show loading spinner on terminal.         Defaults to None</p> <p> TYPE: <code>Callable</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <p>The MD5 Checksum</p> Source code in <code>synapseclient/core/utils.py</code> <pre><code>def md5_for_file(\n    filename: str, block_size: int = 2 * MB, callback: typing.Callable = None\n):\n    \"\"\"\n    Calculates the MD5 of the given file.\n    See source &lt;http://stackoverflow.com/questions/1131220/get-md5-hash-of-a-files-without-open-it-in-python&gt;.\n\n    Arguments:\n        filename: The file to read in\n        block_size: How much of the file to read in at once (bytes).\n                    Defaults to 2 MB\n        callback: The callback function that help us show loading spinner on terminal.\n                    Defaults to None\n\n    Returns:\n        The MD5 Checksum\n    \"\"\"\n    loop_iteration = 0\n    md5 = hashlib.new(\"md5\", usedforsecurity=False)  # nosec\n    with open(filename, \"rb\") as f:\n        while True:\n            loop_iteration += 1\n            if callback:\n                callback()\n            data = f.read(block_size)\n            if not data:\n                break\n            md5.update(data)\n            del data\n            # Garbage collect every 100 iterations\n            if loop_iteration % 100 == 0:\n                gc.collect()\n    return md5\n</code></pre>"},{"location":"reference/core/#synapseclient.core.utils.md5_for_file_hex","title":"<code>md5_for_file_hex(filename, block_size=2 * MB, callback=None)</code>","text":"<p>Calculates the MD5 of the given file. See source http://stackoverflow.com/questions/1131220/get-md5-hash-of-a-files-without-open-it-in-python.</p> PARAMETER DESCRIPTION <code>filename</code> <p>The file to read in</p> <p> TYPE: <code>str</code> </p> <code>block_size</code> <p>How much of the file to read in at once (bytes).         Defaults to 2 MB</p> <p> TYPE: <code>int</code> DEFAULT: <code>2 * MB</code> </p> <code>callback</code> <p>The callback function that help us show loading spinner on terminal.         Defaults to None</p> <p> TYPE: <code>Callable</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>str</code> <p>The MD5 Checksum</p> Source code in <code>synapseclient/core/utils.py</code> <pre><code>def md5_for_file_hex(\n    filename: str, block_size: int = 2 * MB, callback: typing.Callable = None\n) -&gt; str:\n    \"\"\"\n    Calculates the MD5 of the given file.\n    See source &lt;http://stackoverflow.com/questions/1131220/get-md5-hash-of-a-files-without-open-it-in-python&gt;.\n\n    Arguments:\n        filename: The file to read in\n        block_size: How much of the file to read in at once (bytes).\n                    Defaults to 2 MB\n        callback: The callback function that help us show loading spinner on terminal.\n                    Defaults to None\n\n    Returns:\n        The MD5 Checksum\n    \"\"\"\n\n    return md5_for_file(filename, block_size, callback).hexdigest()\n</code></pre>"},{"location":"reference/core/#synapseclient.core.utils.md5_for_file_multiprocessing","title":"<code>md5_for_file_multiprocessing(filename, process_pool_executor, md5_semaphore, block_size=2 * MB)</code>  <code>async</code>","text":"<p>Calculates the MD5 of the given file. See source http://stackoverflow.com/questions/1131220/get-md5-hash-of-a-files-without-open-it-in-python.</p> PARAMETER DESCRIPTION <code>filename</code> <p>The file to read in</p> <p> TYPE: <code>str</code> </p> <code>process_pool_executor</code> <p>The process pool executor to use for the calculation.</p> <p> </p> <code>md5_semaphore</code> <p>The semaphore to use for waiting to calculate.</p> <p> TYPE: <code>Semaphore</code> </p> <code>block_size</code> <p>How much of the file to read in at once (bytes).         Defaults to 2 MB.</p> <p> TYPE: <code>int</code> DEFAULT: <code>2 * MB</code> </p> RETURNS DESCRIPTION <code>str</code> <p>The MD5 Checksum</p> Source code in <code>synapseclient/core/utils.py</code> <pre><code>async def md5_for_file_multiprocessing(\n    filename: str,\n    process_pool_executor,\n    md5_semaphore: asyncio.Semaphore,\n    block_size: int = 2 * MB,\n) -&gt; str:\n    \"\"\"\n    Calculates the MD5 of the given file.\n    See source &lt;http://stackoverflow.com/questions/1131220/get-md5-hash-of-a-files-without-open-it-in-python&gt;.\n\n    Arguments:\n        filename: The file to read in\n        process_pool_executor: The process pool executor to use for the calculation.\n        md5_semaphore: The semaphore to use for waiting to calculate.\n        block_size: How much of the file to read in at once (bytes).\n                    Defaults to 2 MB.\n\n    Returns:\n        The MD5 Checksum\n    \"\"\"\n    async with md5_semaphore:\n        with tracer.start_as_current_span(\"Utils::md5_for_file_multiprocessing\"):\n            future = process_pool_executor.submit(\n                md5_for_file_hex, filename, block_size\n            )\n            while not future.done():\n                await asyncio.sleep(0)\n            result = future.result()\n            return result\n</code></pre>"},{"location":"reference/core/#synapseclient.core.utils.md5_fn","title":"<code>md5_fn(part, _)</code>","text":"<p>Calculate the MD5 of a file-like object.</p> PARAMETER DESCRIPTION <code>part</code> <p>A file-like object to read from.</p> <p> </p> RETURNS DESCRIPTION <code>str</code> <p>The MD5 Checksum</p> Source code in <code>synapseclient/core/utils.py</code> <pre><code>@tracer.start_as_current_span(\"Utils::md5_fn\")\ndef md5_fn(part, _) -&gt; str:\n    \"\"\"Calculate the MD5 of a file-like object.\n\n    Arguments:\n        part: A file-like object to read from.\n\n    Returns:\n        The MD5 Checksum\n    \"\"\"\n    md5 = hashlib.new(\"md5\", usedforsecurity=False)  # nosec\n    md5.update(part)\n    return md5.hexdigest()\n</code></pre>"},{"location":"reference/core/#synapseclient.core.utils.download_file","title":"<code>download_file(url, localFilepath=None)</code>","text":"<p>Downloads a remote file.</p> PARAMETER DESCRIPTION <code>localFilePath</code> <p>May be None, in which case a temporary file is created</p> <p> </p> RETURNS DESCRIPTION <code>localFilePath</code> <p>The path to the downloaded file</p> <p> TYPE: <code>str</code> </p> Source code in <code>synapseclient/core/utils.py</code> <pre><code>def download_file(url: str, localFilepath: str = None) -&gt; str:\n    \"\"\"\n    Downloads a remote file.\n\n    Arguments:\n        localFilePath: May be None, in which case a temporary file is created\n\n    Returns:\n        localFilePath: The path to the downloaded file\n    \"\"\"\n\n    f = None\n    try:\n        if localFilepath:\n            dir = os.path.dirname(localFilepath)\n            if not os.path.exists(dir):\n                os.makedirs(dir)\n            f = open(localFilepath, \"wb\")\n        else:\n            f = tempfile.NamedTemporaryFile(delete=False)\n            localFilepath = f.name\n\n        r = requests.get(url, stream=True)\n        toBeTransferred = float(r.headers[\"content-length\"])\n        for nChunks, chunk in enumerate(r.iter_content(chunk_size=1024 * 10)):\n            if chunk:\n                f.write(chunk)\n                printTransferProgress(nChunks * 1024 * 10, toBeTransferred)\n    finally:\n        if f:\n            f.close()\n            printTransferProgress(toBeTransferred, toBeTransferred)\n\n    return localFilepath\n</code></pre>"},{"location":"reference/core/#synapseclient.core.utils.extract_filename","title":"<code>extract_filename(content_disposition_header, default_filename=None)</code>","text":"<p>Extract a filename from an HTTP content-disposition header field.</p> <p>See this memo and this package for cryptic details.</p> Source code in <code>synapseclient/core/utils.py</code> <pre><code>def extract_filename(content_disposition_header, default_filename=None):\n    \"\"\"\n    Extract a filename from an HTTP content-disposition header field.\n\n    See [this memo](http://tools.ietf.org/html/rfc6266) and\n    [this package](http://pypi.python.org/pypi/rfc6266)\n    for cryptic details.\n    \"\"\"\n\n    if not content_disposition_header:\n        return default_filename\n    value, params = cgi.parse_header(content_disposition_header)\n    return params.get(\"filename\", default_filename)\n</code></pre>"},{"location":"reference/core/#synapseclient.core.utils.extract_user_name","title":"<code>extract_user_name(profile)</code>","text":"<p>Extract a displayable user name from a user's profile</p> Source code in <code>synapseclient/core/utils.py</code> <pre><code>def extract_user_name(profile):\n    \"\"\"\n    Extract a displayable user name from a user's profile\n    \"\"\"\n    if \"userName\" in profile and profile[\"userName\"]:\n        return profile[\"userName\"]\n    elif \"displayName\" in profile and profile[\"displayName\"]:\n        return profile[\"displayName\"]\n    else:\n        if (\n            \"firstName\" in profile\n            and profile[\"firstName\"]\n            and \"lastName\" in profile\n            and profile[\"lastName\"]\n        ):\n            return profile[\"firstName\"] + \" \" + profile[\"lastName\"]\n        elif \"lastName\" in profile and profile[\"lastName\"]:\n            return profile[\"lastName\"]\n        elif \"firstName\" in profile and profile[\"firstName\"]:\n            return profile[\"firstName\"]\n        else:\n            return str(profile.get(\"id\", \"Unknown-user\"))\n</code></pre>"},{"location":"reference/core/#synapseclient.core.utils.id_of","title":"<code>id_of(obj)</code>","text":"<p>Try to figure out the Synapse ID of the given object.</p> PARAMETER DESCRIPTION <code>obj</code> <p>May be a string, Entity object, or dictionary</p> <p> TYPE: <code>Union[str, Mapping, Number]</code> </p> RETURNS DESCRIPTION <code>str</code> <p>The ID</p> RAISES DESCRIPTION <code>ValueError</code> <p>if the object doesn't have an ID</p> Source code in <code>synapseclient/core/utils.py</code> <pre><code>def id_of(obj: typing.Union[str, collections.abc.Mapping, numbers.Number]) -&gt; str:\n    \"\"\"\n    Try to figure out the Synapse ID of the given object.\n\n    Arguments:\n        obj: May be a string, Entity object, or dictionary\n\n    Returns:\n        The ID\n\n    Raises:\n        ValueError: if the object doesn't have an ID\n    \"\"\"\n    if isinstance(obj, str):\n        return str(obj)\n    if isinstance(obj, numbers.Number):\n        return str(obj)\n\n    id_attr_names = [\n        \"id\",\n        \"ownerId\",\n        \"tableId\",\n    ]  # possible attribute names for a synapse Id\n    for attribute_name in id_attr_names:\n        syn_id = _get_from_members_items_or_properties(obj, attribute_name)\n        if syn_id is not None:\n            return str(syn_id)\n\n    raise ValueError(\"Invalid parameters: couldn't find id of \" + str(obj))\n</code></pre>"},{"location":"reference/core/#synapseclient.core.utils.concrete_type_of","title":"<code>concrete_type_of(obj)</code>","text":"<p>Return the concrete type of an object representing a Synapse entity. This is meant to operate either against an actual Entity object, or the lighter weight dictionary returned by Synapse#getChildren, both of which are Mappings.</p> Source code in <code>synapseclient/core/utils.py</code> <pre><code>def concrete_type_of(obj: collections.abc.Mapping):\n    \"\"\"\n    Return the concrete type of an object representing a Synapse entity.\n    This is meant to operate either against an actual Entity object, or the lighter\n    weight dictionary returned by Synapse#getChildren, both of which are Mappings.\n    \"\"\"\n    concrete_type = None\n    if isinstance(obj, collections.abc.Mapping):\n        for key in (\"concreteType\", \"type\"):\n            concrete_type = obj.get(key)\n            if concrete_type:\n                break\n\n    if not isinstance(concrete_type, str) or not concrete_type.startswith(\n        \"org.sagebionetworks.repo.model\"\n    ):\n        raise ValueError(\"Unable to determine concreteType\")\n\n    return concrete_type\n</code></pre>"},{"location":"reference/core/#synapseclient.core.utils.is_in_path","title":"<code>is_in_path(id, path)</code>","text":"<p>Determines whether id is in the path as returned from /entity/{id}/path</p> PARAMETER DESCRIPTION <code>id</code> <p>synapse id string</p> <p> TYPE: <code>str</code> </p> <code>path</code> <p>object as returned from '/entity/{id}/path'</p> <p> TYPE: <code>Mapping</code> </p> RETURNS DESCRIPTION <code>bool</code> <p>True or False</p> Source code in <code>synapseclient/core/utils.py</code> <pre><code>def is_in_path(id: str, path: collections.abc.Mapping) -&gt; bool:\n    \"\"\"Determines whether id is in the path as returned from /entity/{id}/path\n\n    Arguments:\n        id: synapse id string\n        path: object as returned from '/entity/{id}/path'\n\n    Returns:\n        True or False\n    \"\"\"\n    return id in [item[\"id\"] for item in path[\"path\"]]\n</code></pre>"},{"location":"reference/core/#synapseclient.core.utils.get_properties","title":"<code>get_properties(entity)</code>","text":"<p>Returns the dictionary of properties of the given Entity.</p> Source code in <code>synapseclient/core/utils.py</code> <pre><code>def get_properties(entity):\n    \"\"\"Returns the dictionary of properties of the given Entity.\"\"\"\n\n    return entity.properties if hasattr(entity, \"properties\") else entity\n</code></pre>"},{"location":"reference/core/#synapseclient.core.utils.is_url","title":"<code>is_url(s)</code>","text":"<p>Return True if the string appears to be a valid URL.</p> Source code in <code>synapseclient/core/utils.py</code> <pre><code>def is_url(s):\n    \"\"\"Return True if the string appears to be a valid URL.\"\"\"\n    if isinstance(s, str):\n        try:\n            url_parts = urllib_parse.urlsplit(s)\n            # looks like a Windows drive letter?\n            if len(url_parts.scheme) == 1 and url_parts.scheme.isalpha():\n                return False\n            if url_parts.scheme == \"file\" and bool(url_parts.path):\n                return True\n            return bool(url_parts.scheme) and bool(url_parts.netloc)\n        except Exception:\n            return False\n    return False\n</code></pre>"},{"location":"reference/core/#synapseclient.core.utils.as_url","title":"<code>as_url(s)</code>","text":"<p>Tries to convert the input into a proper URL.</p> Source code in <code>synapseclient/core/utils.py</code> <pre><code>def as_url(s):\n    \"\"\"Tries to convert the input into a proper URL.\"\"\"\n    url_parts = urllib_parse.urlsplit(s)\n    # Windows drive letter?\n    if len(url_parts.scheme) == 1 and url_parts.scheme.isalpha():\n        return \"file:///%s\" % str(s).replace(\"\\\\\", \"/\")\n    if url_parts.scheme:\n        return url_parts.geturl()\n    else:\n        return \"file://%s\" % str(s)\n</code></pre>"},{"location":"reference/core/#synapseclient.core.utils.guess_file_name","title":"<code>guess_file_name(string)</code>","text":"<p>Tries to derive a filename from an arbitrary string.</p> Source code in <code>synapseclient/core/utils.py</code> <pre><code>def guess_file_name(string):\n    \"\"\"Tries to derive a filename from an arbitrary string.\"\"\"\n    path = normalize_path(urllib_parse.urlparse(string).path)\n    tokens = [x for x in path.split(\"/\") if x != \"\"]\n    if len(tokens) &gt; 0:\n        return tokens[-1]\n\n    # Try scrubbing the path of illegal characters\n    if len(path) &gt; 0:\n        path = re.sub(r\"[^a-zA-Z0-9_.+() -]\", \"\", path)\n    if len(path) &gt; 0:\n        return path\n    raise ValueError(\"Could not derive a name from %s\" % string)\n</code></pre>"},{"location":"reference/core/#synapseclient.core.utils.normalize_path","title":"<code>normalize_path(path)</code>","text":"<p>Transforms a path into an absolute path with forward slashes only.</p> Source code in <code>synapseclient/core/utils.py</code> <pre><code>def normalize_path(path):\n    \"\"\"Transforms a path into an absolute path with forward slashes only.\"\"\"\n    if path is None:\n        return None\n    return re.sub(r\"\\\\\", \"/\", os.path.normcase(os.path.abspath(path)))\n</code></pre>"},{"location":"reference/core/#synapseclient.core.utils.equal_paths","title":"<code>equal_paths(path1, path2)</code>","text":"<p>Compare file paths in a platform neutral way</p> Source code in <code>synapseclient/core/utils.py</code> <pre><code>def equal_paths(path1, path2):\n    \"\"\"\n    Compare file paths in a platform neutral way\n    \"\"\"\n    return normalize_path(path1) == normalize_path(path2)\n</code></pre>"},{"location":"reference/core/#synapseclient.core.utils.file_url_to_path","title":"<code>file_url_to_path(url, verify_exists=False)</code>","text":"<p>Convert a file URL to a path, handling some odd cases around Windows paths.</p> PARAMETER DESCRIPTION <code>url</code> <p>a file URL</p> <p> TYPE: <code>str</code> </p> <code>verify_exists</code> <p>If true, return an populated dict only if the resulting file             path exists on the local file system.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> RETURNS DESCRIPTION <code>Union[str, None]</code> <p>a path or None if the URL is not a file URL.</p> Source code in <code>synapseclient/core/utils.py</code> <pre><code>def file_url_to_path(url: str, verify_exists: bool = False) -&gt; typing.Union[str, None]:\n    \"\"\"\n    Convert a file URL to a path, handling some odd cases around Windows paths.\n\n    Arguments:\n        url: a file URL\n        verify_exists: If true, return an populated dict only if the resulting file\n                        path exists on the local file system.\n\n    Returns:\n        a path or None if the URL is not a file URL.\n    \"\"\"\n    parts = urllib_parse.urlsplit(url)\n    if parts.scheme == \"file\" or parts.scheme == \"\":\n        path = parts.path\n        # A windows file URL, for example file:///c:/WINDOWS/asdf.txt\n        # will get back a path of: /c:/WINDOWS/asdf.txt, which we need to fix by\n        # lopping off the leading slash character. Apparently, the Python developers\n        # think this is not a bug: http://bugs.python.org/issue7965\n        if SLASH_PREFIX_REGEX.match(path):\n            path = path[1:]\n        if os.path.exists(path) or not verify_exists:\n            return path\n    return None\n</code></pre>"},{"location":"reference/core/#synapseclient.core.utils.is_same_base_url","title":"<code>is_same_base_url(url1, url2)</code>","text":"<p>Compares two urls to see if they are the same excluding up to the base path</p> PARAMETER DESCRIPTION <code>url1</code> <p>a URL</p> <p> TYPE: <code>str</code> </p> <code>url2</code> <p>a second URL</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>bool</code> <p>A Boolean</p> Source code in <code>synapseclient/core/utils.py</code> <pre><code>def is_same_base_url(url1: str, url2: str) -&gt; bool:\n    \"\"\"Compares two urls to see if they are the same excluding up to the base path\n\n    Arguments:\n        url1: a URL\n        url2: a second URL\n\n    Returns:\n        A Boolean\n    \"\"\"\n    url1 = urllib_parse.urlsplit(url1)\n    url2 = urllib_parse.urlsplit(url2)\n    return url1.scheme == url2.scheme and url1.hostname == url2.hostname\n</code></pre>"},{"location":"reference/core/#synapseclient.core.utils.is_synapse_id_str","title":"<code>is_synapse_id_str(obj)</code>","text":"<p>If the input is a Synapse ID return it, otherwise return None</p> Source code in <code>synapseclient/core/utils.py</code> <pre><code>def is_synapse_id_str(obj: str) -&gt; typing.Union[str, None]:\n    \"\"\"If the input is a Synapse ID return it, otherwise return None\"\"\"\n    if isinstance(obj, str):\n        m = re.match(r\"(syn\\d+(\\.\\d+)?$)\", obj)\n        if m:\n            return m.group(1)\n    return None\n</code></pre>"},{"location":"reference/core/#synapseclient.core.utils.get_synid_and_version","title":"<code>get_synid_and_version(obj)</code>","text":"<p>Extract the Synapse ID and version number from input entity</p> PARAMETER DESCRIPTION <code>obj</code> <p>May be a string, Entity object, or dictionary.</p> <p> TYPE: <code>Union[str, Mapping]</code> </p> RETURNS DESCRIPTION <code>Tuple[str, Union[int, None]]</code> <p>A tuple containing the synapse ID and version number, where the version number may be an integer or None if the input object does not contain a versonNumber or .version notation (if string).</p> Get synID and version from string object <p>Extract the synID and version number of the entity string ID</p> <pre><code>from synapseclient.core import utils\nutils.get_synid_and_version(\"syn123.4\")\n</code></pre> <p>The call above will return the following tuple:</p> <pre><code>('syn123', 4)\n</code></pre> Source code in <code>synapseclient/core/utils.py</code> <pre><code>def get_synid_and_version(\n    obj: typing.Union[str, collections.abc.Mapping]\n) -&gt; typing.Tuple[str, typing.Union[int, None]]:\n    \"\"\"Extract the Synapse ID and version number from input entity\n\n    Arguments:\n            obj: May be a string, Entity object, or dictionary.\n\n    Returns:\n        A tuple containing the synapse ID and version number,\n            where the version number may be an integer or None if\n            the input object does not contain a versonNumber or\n            .version notation (if string).\n\n    Example: Get synID and version from string object\n        Extract the synID and version number of the entity string ID\n\n            from synapseclient.core import utils\n            utils.get_synid_and_version(\"syn123.4\")\n\n        The call above will return the following tuple:\n\n            ('syn123', 4)\n    \"\"\"\n\n    if isinstance(obj, str):\n        synapse_id_and_version = is_synapse_id_str(obj)\n        if not synapse_id_and_version:\n            raise ValueError(\"The input string was not determined to be a syn ID.\")\n        m = re.match(r\"(syn\\d+)(?:\\.(\\d+))?\", synapse_id_and_version)\n        id = m.group(1)\n        version = int(m.group(2)) if m.group(2) is not None else m.group(2)\n\n        return id, version\n\n    id = id_of(obj)\n    version = None\n    if \"versionNumber\" in obj:\n        version = obj[\"versionNumber\"]\n\n    return id, version\n</code></pre>"},{"location":"reference/core/#synapseclient.core.utils.bool_or_none","title":"<code>bool_or_none(input_value)</code>","text":"<p>Attempts to convert a string to a bool. Returns None if it fails.</p> PARAMETER DESCRIPTION <code>input_value</code> <p>The string to convert to a bool</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>Union[bool, None]</code> <p>The bool or None if the conversion fails</p> Source code in <code>synapseclient/core/utils.py</code> <pre><code>def bool_or_none(input_value: str) -&gt; typing.Union[bool, None]:\n    \"\"\"\n    Attempts to convert a string to a bool. Returns None if it fails.\n\n    Arguments:\n        input_value: The string to convert to a bool\n\n    Returns:\n        The bool or None if the conversion fails\n    \"\"\"\n    if input_value is None or input_value == \"\":\n        return None\n\n    return_value = None\n\n    if input_value.lower() == \"true\":\n        return_value = True\n    elif input_value.lower() == \"false\":\n        return_value = False\n\n    return return_value\n</code></pre>"},{"location":"reference/core/#synapseclient.core.utils.datetime_or_none","title":"<code>datetime_or_none(datetime_str)</code>","text":"<p>Attempts to convert a string to a datetime object. Returns None if it fails.</p> <p>Some of the expected formats of datetime_str are:</p> <ul> <li>2023-12-04T07:00:00Z</li> <li>2001-01-01 15:00:00+07:00</li> <li>2001-01-01 15:00:00-07:00</li> <li>2023-12-04 07:00:00+00:00</li> <li>2019-01-01</li> </ul> PARAMETER DESCRIPTION <code>datetime_str</code> <p>The string to convert to a datetime object</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>Union[datetime, None]</code> <p>The datetime object or None if the conversion fails</p> Source code in <code>synapseclient/core/utils.py</code> <pre><code>def datetime_or_none(datetime_str: str) -&gt; typing.Union[datetime.datetime, None]:\n    \"\"\"Attempts to convert a string to a datetime object. Returns None if it fails.\n\n    Some of the expected formats of datetime_str are:\n\n    - 2023-12-04T07:00:00Z\n    - 2001-01-01 15:00:00+07:00\n    - 2001-01-01 15:00:00-07:00\n    - 2023-12-04 07:00:00+00:00\n    - 2019-01-01\n\n    Arguments:\n        datetime_str: The string to convert to a datetime object\n\n    Returns:\n        The datetime object or None if the conversion fails\n    \"\"\"\n    try:\n        return datetime.datetime.fromisoformat(datetime_str.replace(\"Z\", \"+00:00\"))\n    except Exception:\n        return None\n</code></pre>"},{"location":"reference/core/#synapseclient.core.utils.is_date","title":"<code>is_date(dt)</code>","text":"<p>Objects of class datetime.date and datetime.datetime will be recognized as dates</p> Source code in <code>synapseclient/core/utils.py</code> <pre><code>def is_date(dt):\n    \"\"\"Objects of class datetime.date and datetime.datetime will be recognized as dates\"\"\"\n    return isinstance(dt, datetime.date) or isinstance(dt, datetime.datetime)\n</code></pre>"},{"location":"reference/core/#synapseclient.core.utils.to_list","title":"<code>to_list(value)</code>","text":"<p>Convert the value (an iterable or a scalar value) to a list.</p> Source code in <code>synapseclient/core/utils.py</code> <pre><code>def to_list(value):\n    \"\"\"Convert the value (an iterable or a scalar value) to a list.\"\"\"\n    if isinstance(value, collections.abc.Iterable) and not isinstance(value, str):\n        values = []\n        for val in value:\n            possible_datetime = None\n            if isinstance(val, str):\n                possible_datetime = datetime_or_none(value)\n            values.append(val if possible_datetime is None else possible_datetime)\n        return values\n    else:\n        possible_datetime = None\n        if isinstance(value, str):\n            possible_datetime = datetime_or_none(value)\n        return [value if possible_datetime is None else possible_datetime]\n</code></pre>"},{"location":"reference/core/#synapseclient.core.utils.make_bogus_uuid_file","title":"<code>make_bogus_uuid_file()</code>","text":"<p>Makes a bogus test file with a uuid4 string for testing. It is the caller's responsibility to clean up the file when finished.</p> RETURNS DESCRIPTION <code>str</code> <p>The name of the file</p> Source code in <code>synapseclient/core/utils.py</code> <pre><code>def make_bogus_uuid_file() -&gt; str:\n    \"\"\"\n    Makes a bogus test file with a uuid4 string for testing. It is the caller's\n    responsibility to clean up the file when finished.\n\n    Returns:\n        The name of the file\n    \"\"\"\n\n    data = uuid.uuid4()\n\n    f = tempfile.NamedTemporaryFile(mode=\"w\", suffix=\".txt\", delete=False)\n    try:\n        f.write(str(data))\n        f.write(\"\\n\")\n    finally:\n        f.close()\n\n    return normalize_path(f.name)\n</code></pre>"},{"location":"reference/core/#synapseclient.core.utils.make_bogus_data_file","title":"<code>make_bogus_data_file(n=100, seed=None)</code>","text":"<p>Makes a bogus data file for testing. It is the caller's responsibility to clean up the file when finished.</p> PARAMETER DESCRIPTION <code>n</code> <p>How many random floating point numbers to be written into the file, separated by commas</p> <p> TYPE: <code>int</code> DEFAULT: <code>100</code> </p> <code>seed</code> <p>Random seed for the random numbers</p> <p> TYPE: <code>int</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>str</code> <p>The name of the file</p> Source code in <code>synapseclient/core/utils.py</code> <pre><code>def make_bogus_data_file(n: int = 100, seed: int = None) -&gt; str:\n    \"\"\"\n    Makes a bogus data file for testing. It is the caller's responsibility\n    to clean up the file when finished.\n\n    Arguments:\n        n: How many random floating point numbers to be written into the file,\n            separated by commas\n        seed: Random seed for the random numbers\n\n    Returns:\n        The name of the file\n    \"\"\"\n\n    if seed is not None:\n        random.seed(seed)\n    data = [random.gauss(mu=0.0, sigma=1.0) for i in range(n)]\n\n    f = tempfile.NamedTemporaryFile(mode=\"w\", suffix=\".txt\", delete=False)\n    try:\n        f.write(\", \".join(str(n) for n in data))\n        f.write(\"\\n\")\n    finally:\n        f.close()\n\n    return normalize_path(f.name)\n</code></pre>"},{"location":"reference/core/#synapseclient.core.utils.make_bogus_binary_file","title":"<code>make_bogus_binary_file(n=1 * KB, filepath=None, printprogress=False)</code>","text":"<p>Makes a bogus binary data file for testing. It is the caller's responsibility to clean up the file when finished.</p> PARAMETER DESCRIPTION <code>n</code> <p>How many bytes to write</p> <p> TYPE: <code>int</code> DEFAULT: <code>1 * KB</code> </p> <code>filepath</code> <p>Where to write the data</p> <p> TYPE: <code>str</code> DEFAULT: <code>None</code> </p> <code>printprogress</code> <p>Toggle printing of progress</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> RETURNS DESCRIPTION <code>str</code> <p>The name of the file</p> Source code in <code>synapseclient/core/utils.py</code> <pre><code>def make_bogus_binary_file(\n    n: int = 1 * KB, filepath: str = None, printprogress: bool = False\n) -&gt; str:\n    \"\"\"\n    Makes a bogus binary data file for testing. It is the caller's responsibility\n    to clean up the file when finished.\n\n    Arguments:\n        n: How many bytes to write\n        filepath: Where to write the data\n        printprogress: Toggle printing of progress\n\n    Returns:\n        The name of the file\n    \"\"\"\n\n    with (\n        open(filepath, \"wb\")\n        if filepath\n        else tempfile.NamedTemporaryFile(mode=\"wb\", suffix=\".dat\", delete=False)\n    ) as f:\n        if not filepath:\n            filepath = f.name\n        progress = 0\n        remaining = n\n        while remaining &gt; 0:\n            buff_size = int(min(remaining, 1 * KB))\n            f.write(os.urandom(buff_size))\n            remaining -= buff_size\n            if printprogress:\n                progress += buff_size\n                printTransferProgress(progress, n, \"Generated \", filepath)\n        return normalize_path(filepath)\n</code></pre>"},{"location":"reference/core/#synapseclient.core.utils.to_unix_epoch_time","title":"<code>to_unix_epoch_time(dt)</code>","text":"<p>Convert either datetime.date or datetime.datetime objects to UNIX time.</p> Source code in <code>synapseclient/core/utils.py</code> <pre><code>def to_unix_epoch_time(dt: typing.Union[datetime.date, datetime.datetime, str]) -&gt; int:\n    \"\"\"\n    Convert either [datetime.date or datetime.datetime objects](http://docs.python.org/2/library/datetime.html) to UNIX time.\n    \"\"\"\n    if type(dt) == str:\n        dt = datetime.datetime.fromisoformat(dt.replace(\"Z\", \"+00:00\"))\n    if type(dt) == datetime.date:\n        current_timezone = datetime.datetime.now().astimezone().tzinfo\n        datetime_utc = datetime.datetime.combine(dt, datetime.time(0, 0, 0, 0)).replace(\n            tzinfo=current_timezone\n        )\n    else:\n        # If the datetime is not timezone aware, assume it is in the local timezone.\n        # This is required in order for windows to work with the `astimezone` method.\n        if dt.tzinfo is None:\n            current_timezone = datetime.datetime.now().astimezone().tzinfo\n            dt = dt.replace(tzinfo=current_timezone)\n        datetime_utc = dt.astimezone(datetime.timezone.utc)\n    return int((datetime_utc - UNIX_EPOCH).total_seconds() * 1000)\n</code></pre>"},{"location":"reference/core/#synapseclient.core.utils.to_unix_epoch_time_secs","title":"<code>to_unix_epoch_time_secs(dt)</code>","text":"<p>Convert either datetime.date or datetime.datetime objects to UNIX time.</p> Source code in <code>synapseclient/core/utils.py</code> <pre><code>def to_unix_epoch_time_secs(\n    dt: typing.Union[datetime.date, datetime.datetime]\n) -&gt; float:\n    \"\"\"\n    Convert either [datetime.date or datetime.datetime objects](http://docs.python.org/2/library/datetime.html) to UNIX time.\n    \"\"\"\n    if type(dt) == datetime.date:\n        current_timezone = datetime.datetime.now().astimezone().tzinfo\n        datetime_utc = datetime.datetime.combine(dt, datetime.time(0, 0, 0, 0)).replace(\n            tzinfo=current_timezone\n        )\n    else:\n        # If the datetime is not timezone aware, assume it is in the local timezone.\n        # This is required in order for windows to work with the `astimezone` method.\n        if dt.tzinfo is None:\n            current_timezone = datetime.datetime.now().astimezone().tzinfo\n            dt = dt.replace(tzinfo=current_timezone)\n        datetime_utc = dt.astimezone(datetime.timezone.utc)\n    return (datetime_utc - UNIX_EPOCH).total_seconds()\n</code></pre>"},{"location":"reference/core/#synapseclient.core.utils.from_unix_epoch_time_secs","title":"<code>from_unix_epoch_time_secs(secs)</code>","text":"<p>Returns a Datetime object given milliseconds since midnight Jan 1, 1970.</p> Source code in <code>synapseclient/core/utils.py</code> <pre><code>def from_unix_epoch_time_secs(secs):\n    \"\"\"Returns a Datetime object given milliseconds since midnight Jan 1, 1970.\"\"\"\n    if isinstance(secs, str):\n        secs = float(secs)\n\n    # utcfromtimestamp() fails for negative values (dates before 1970-1-1) on Windows\n    # so, here's a hack that enables ancient events, such as Chris's birthday to be\n    # converted from milliseconds since the UNIX epoch to higher level Datetime objects. Ha!\n    if platform.system() == \"Windows\" and secs &lt; 0:\n        mirror_date = datetime.datetime.utcfromtimestamp(abs(secs)).replace(\n            tzinfo=datetime.timezone.utc\n        )\n\n        result = (UNIX_EPOCH - (mirror_date - UNIX_EPOCH)).replace(\n            tzinfo=datetime.timezone.utc\n        )\n\n        return result\n    datetime_instance = datetime.datetime.utcfromtimestamp(secs).replace(\n        tzinfo=datetime.timezone.utc\n    )\n\n    return datetime_instance\n</code></pre>"},{"location":"reference/core/#synapseclient.core.utils.from_unix_epoch_time","title":"<code>from_unix_epoch_time(ms)</code>","text":"<p>Returns a Datetime object given milliseconds since midnight Jan 1, 1970.</p> Source code in <code>synapseclient/core/utils.py</code> <pre><code>def from_unix_epoch_time(ms) -&gt; datetime.datetime:\n    \"\"\"Returns a Datetime object given milliseconds since midnight Jan 1, 1970.\"\"\"\n\n    if isinstance(ms, str):\n        ms = float(ms)\n    return from_unix_epoch_time_secs(ms / 1000.0)\n</code></pre>"},{"location":"reference/core/#synapseclient.core.utils.datetime_to_iso","title":"<code>datetime_to_iso(dt, sep='T', include_milliseconds_if_zero=True)</code>","text":"<p>Round microseconds to milliseconds (as expected by older clients) and add back the \"Z\" at the end. See: http://stackoverflow.com/questions/30266188/how-to-convert-date-string-to-iso8601-standard</p> PARAMETER DESCRIPTION <code>dt</code> <p>The datetime to convert</p> <p> TYPE: <code>datetime</code> </p> <code>sep</code> <p>Seperator character to use.</p> <p> TYPE: <code>str</code> DEFAULT: <code>'T'</code> </p> <code>include_milliseconds_if_zero</code> <p>Whether or not to include millseconds in this result                             if the number of millseconds is 0.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> RETURNS DESCRIPTION <code>str</code> <p>The formatted string.</p> Source code in <code>synapseclient/core/utils.py</code> <pre><code>def datetime_to_iso(\n    dt: datetime.datetime, sep: str = \"T\", include_milliseconds_if_zero: bool = True\n) -&gt; str:\n    \"\"\"\n    Round microseconds to milliseconds (as expected by older clients) and add back\n    the \"Z\" at the end.\n    See: http://stackoverflow.com/questions/30266188/how-to-convert-date-string-to-iso8601-standard\n\n    Arguments:\n        dt: The datetime to convert\n        sep: Seperator character to use.\n        include_milliseconds_if_zero: Whether or not to include millseconds in this result\n                                        if the number of millseconds is 0.\n\n    Returns:\n        The formatted string.\n    \"\"\"\n    fmt = (\n        \"{time.year:04}-{time.month:02}-{time.day:02}\"\n        \"{sep}{time.hour:02}:{time.minute:02}:{time.second:02}.{millisecond:03}{tz}\"\n    )\n    fmt_no_mills = (\n        \"{time.year:04}-{time.month:02}-{time.day:02}\"\n        \"{sep}{time.hour:02}:{time.minute:02}:{time.second:02}{tz}\"\n    )\n    if dt.microsecond &gt;= 999500:\n        dt -= datetime.timedelta(microseconds=dt.microsecond)\n        dt += datetime.timedelta(seconds=1)\n    rounded_microseconds = int(round(dt.microsecond / 1000.0))\n    if include_milliseconds_if_zero or rounded_microseconds:\n        return fmt.format(time=dt, millisecond=rounded_microseconds, tz=\"Z\", sep=sep)\n    else:\n        return fmt_no_mills.format(\n            time=dt, millisecond=rounded_microseconds, tz=\"Z\", sep=sep\n        )\n</code></pre>"},{"location":"reference/core/#synapseclient.core.utils.format_time_interval","title":"<code>format_time_interval(seconds)</code>","text":"<p>Format a time interval given in seconds to a readable value, e.g. \"5 minutes, 37 seconds\".</p> Source code in <code>synapseclient/core/utils.py</code> <pre><code>def format_time_interval(seconds):\n    \"\"\"\n    Format a time interval given in seconds to a readable value,\n    e.g. \\\"5 minutes, 37 seconds\\\".\n    \"\"\"\n\n    periods = (\n        (\"year\", 60 * 60 * 24 * 365),\n        (\"month\", 60 * 60 * 24 * 30),\n        (\"day\", 60 * 60 * 24),\n        (\"hour\", 60 * 60),\n        (\"minute\", 60),\n        (\"second\", 1),\n    )\n\n    result = []\n    for period_name, period_seconds in periods:\n        if seconds &gt; period_seconds or period_name == \"second\":\n            period_value, seconds = divmod(seconds, period_seconds)\n            if period_value &gt; 0 or period_name == \"second\":\n                if period_value == 1:\n                    result.append(\"%d %s\" % (period_value, period_name))\n                else:\n                    result.append(\"%d %ss\" % (period_value, period_name))\n    return \", \".join(result)\n</code></pre>"},{"location":"reference/core/#synapseclient.core.utils.itersubclasses","title":"<code>itersubclasses(cls, _seen=None)</code>","text":"<p>http://code.activestate.com/recipes/576949/ (r3)</p> <p>itersubclasses(cls)</p> <p>Generator over all subclasses of a given class, in depth first order.</p> <pre><code>&gt;&gt;&gt; list(itersubclasses(int)) == [bool]\nTrue\n&gt;&gt;&gt; class A(object): pass\n&gt;&gt;&gt; class B(A): pass\n&gt;&gt;&gt; class C(A): pass\n&gt;&gt;&gt; class D(B,C): pass\n&gt;&gt;&gt; class E(D): pass\n&gt;&gt;&gt;\n&gt;&gt;&gt; for cls in itersubclasses(A):\n...     print(cls.__name__)\nB\nD\nE\nC\n&gt;&gt;&gt; # get ALL (new-style) classes currently defined\n&gt;&gt;&gt; [cls.__name__ for cls in itersubclasses(object)] #doctest: +ELLIPSIS\n['type', ...'tuple', ...]\n</code></pre> Source code in <code>synapseclient/core/utils.py</code> <pre><code>def itersubclasses(cls, _seen=None):\n    \"\"\"\n    &lt;http://code.activestate.com/recipes/576949/&gt; (r3)\n\n    itersubclasses(cls)\n\n    Generator over all subclasses of a given class, in depth first order.\n\n        &gt;&gt;&gt; list(itersubclasses(int)) == [bool]\n        True\n        &gt;&gt;&gt; class A(object): pass\n        &gt;&gt;&gt; class B(A): pass\n        &gt;&gt;&gt; class C(A): pass\n        &gt;&gt;&gt; class D(B,C): pass\n        &gt;&gt;&gt; class E(D): pass\n        &gt;&gt;&gt;\n        &gt;&gt;&gt; for cls in itersubclasses(A):\n        ...     print(cls.__name__)\n        B\n        D\n        E\n        C\n        &gt;&gt;&gt; # get ALL (new-style) classes currently defined\n        &gt;&gt;&gt; [cls.__name__ for cls in itersubclasses(object)] #doctest: +ELLIPSIS\n        ['type', ...'tuple', ...]\n    \"\"\"\n\n    if not isinstance(cls, type):\n        raise TypeError(\n            \"itersubclasses must be called with \" \"new-style classes, not %.100r\" % cls\n        )\n    if _seen is None:\n        _seen = set()\n    try:\n        subs = cls.__subclasses__()\n    except TypeError:  # fails only when cls is type\n        subs = cls.__subclasses__(cls)\n    for sub in subs:\n        if sub not in _seen:\n            _seen.add(sub)\n            yield sub\n            for inner_sub in itersubclasses(sub, _seen):\n                yield inner_sub\n</code></pre>"},{"location":"reference/core/#synapseclient.core.utils.normalize_whitespace","title":"<code>normalize_whitespace(s)</code>","text":"<p>Strips the string and replace all whitespace sequences and other non-printable characters with a single space.</p> Source code in <code>synapseclient/core/utils.py</code> <pre><code>def normalize_whitespace(s):\n    \"\"\"\n    Strips the string and replace all whitespace sequences and other\n    non-printable characters with a single space.\n    \"\"\"\n    assert isinstance(s, str)\n    return re.sub(r\"[\\x00-\\x20\\s]+\", \" \", s.strip())\n</code></pre>"},{"location":"reference/core/#synapseclient.core.utils.query_limit_and_offset","title":"<code>query_limit_and_offset(query, hard_limit=1000)</code>","text":"<p>Extract limit and offset from the end of a query string.</p> RETURNS DESCRIPTION <code>str</code> <p>A tuple containing the query with limit and offset removed,</p> <code>int</code> <p>the limit at most equal to the hard_limit,</p> <code>int</code> <p>and the offset which defaults to 1</p> Source code in <code>synapseclient/core/utils.py</code> <pre><code>def query_limit_and_offset(\n    query: str, hard_limit: int = 1000\n) -&gt; typing.Tuple[str, int, int]:\n    \"\"\"\n    Extract limit and offset from the end of a query string.\n\n    Returns:\n        A tuple containing the query with limit and offset removed,\n        the limit at most equal to the hard_limit,\n        and the offset which defaults to 1\n    \"\"\"\n    # Regex a lower-case string to simplify matching\n    tempQueryStr = query.lower()\n    regex = r\"\\A(.*\\s)(offset|limit)\\s*(\\d*\\s*)\\Z\"\n\n    # Continue to strip off and save the last limit/offset\n    match = re.search(regex, tempQueryStr)\n    options = {}\n    while match is not None:\n        options[match.group(2)] = int(match.group(3))\n        tempQueryStr = match.group(1)\n        match = re.search(regex, tempQueryStr)\n\n    # Get a truncated version of the original query string (not in lower-case)\n    query = query[: len(tempQueryStr)].strip()\n\n    # Continue querying until the entire query has been fetched (or crash out)\n    limit = min(options.get(\"limit\", hard_limit), hard_limit)\n    offset = options.get(\"offset\", 1)\n\n    return query, limit, offset\n</code></pre>"},{"location":"reference/core/#synapseclient.core.utils.extract_synapse_id_from_query","title":"<code>extract_synapse_id_from_query(query)</code>","text":"<p>An unfortunate hack to pull the synapse ID out of a table query of the form \"select column1, column2 from syn12345 where....\" needed to build URLs for table services.</p> Source code in <code>synapseclient/core/utils.py</code> <pre><code>def extract_synapse_id_from_query(query):\n    \"\"\"\n    An unfortunate hack to pull the synapse ID out of a table query of the form\n    \"select column1, column2 from syn12345 where....\"\n    needed to build URLs for table services.\n    \"\"\"\n    m = re.search(r\"from\\s+(syn\\d+)\", query, re.IGNORECASE)\n    if m:\n        return m.group(1)\n    else:\n        raise ValueError('Couldn\\'t extract synapse ID from query: \"%s\"' % query)\n</code></pre>"},{"location":"reference/core/#synapseclient.core.utils.printTransferProgress","title":"<code>printTransferProgress(transferred, toBeTransferred, prefix='', postfix='', isBytes=True, dt=None, previouslyTransferred=0)</code>","text":"<p>Prints a progress bar</p> PARAMETER DESCRIPTION <code>transferred</code> <p>a number of items/bytes completed</p> <p> TYPE: <code>int</code> </p> <code>toBeTransferred</code> <p>total number of items/bytes when completed</p> <p> TYPE: <code>int</code> </p> <code>prefix</code> <p>String printed before progress bar</p> <p> TYPE: <code>str</code> DEFAULT: <code>''</code> </p> <code>postfix</code> <p>String printed after progress bar</p> <p> TYPE: <code>str</code> DEFAULT: <code>''</code> </p> <code>isBytes</code> <p>A boolean indicating whether to convert bytes to kB, MB, GB etc.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> <code>dt</code> <p>The time in seconds that has passed since transfer started is used to calculate rate</p> <p> TYPE: <code>float</code> DEFAULT: <code>None</code> </p> <code>previouslyTransferred</code> <p>the number of bytes that were already transferred before this                     transfer began (e.g. someone ctrl+c'd out of an upload and                     restarted it later)</p> <p> TYPE: <code>int</code> DEFAULT: <code>0</code> </p> Source code in <code>synapseclient/core/utils.py</code> <pre><code>def printTransferProgress(\n    transferred: int,\n    toBeTransferred: int,\n    prefix: str = \"\",\n    postfix: str = \"\",\n    isBytes: bool = True,\n    dt: float = None,\n    previouslyTransferred: int = 0,\n):\n    \"\"\"Prints a progress bar\n\n    Arguments:\n        transferred: a number of items/bytes completed\n        toBeTransferred: total number of items/bytes when completed\n        prefix: String printed before progress bar\n        postfix: String printed after progress bar\n        isBytes: A boolean indicating whether to convert bytes to kB, MB, GB etc.\n        dt: The time in seconds that has passed since transfer started is used to calculate rate\n        previouslyTransferred: the number of bytes that were already transferred before this\n                                transfer began (e.g. someone ctrl+c'd out of an upload and\n                                restarted it later)\n    \"\"\"\n    if not sys.stdout.isatty():\n        return\n    barLength = 20  # Modify this to change the length of the progress bar\n    status = \"\"\n    rate = \"\"\n    if dt is not None and dt != 0:\n        rate = (transferred - previouslyTransferred) / float(dt)\n        rate = \"(%s/s)\" % humanizeBytes(rate) if isBytes else rate\n    if toBeTransferred &lt; 0:\n        defaultToBeTransferred = barLength * 1 * MB\n        if transferred &gt; defaultToBeTransferred:\n            progress = (\n                float(transferred % defaultToBeTransferred) / defaultToBeTransferred\n            )\n        else:\n            progress = float(transferred) / defaultToBeTransferred\n    elif toBeTransferred == 0:  # There is nothing to be transferred\n        progress = 1\n        status = \"Done...\\n\"\n    else:\n        progress = float(transferred) / toBeTransferred\n        if progress &gt;= 1:\n            progress = 1\n            status = \"Done...\\n\"\n    block = int(round(barLength * progress))\n    nbytes = humanizeBytes(transferred) if isBytes else transferred\n    if toBeTransferred &gt; 0:\n        outOf = \"/%s\" % (humanizeBytes(toBeTransferred) if isBytes else toBeTransferred)\n        percentage = \"%4.2f%%\" % (progress * 100)\n    else:\n        outOf = \"\"\n        percentage = \"\"\n    text = \"\\r%s [%s]%s   %s%s %s %s %s    \\n\" % (\n        prefix,\n        \"#\" * block + \"-\" * (barLength - block),\n        percentage,\n        nbytes,\n        outOf,\n        rate,\n        postfix,\n        status,\n    )\n    sys.stdout.write(text)\n    sys.stdout.flush()\n</code></pre>"},{"location":"reference/core/#synapseclient.core.utils.touch","title":"<code>touch(path, times=None)</code>","text":"<p>Make sure a file exists. Update its access and modified times.</p> Source code in <code>synapseclient/core/utils.py</code> <pre><code>def touch(path, times=None):\n    \"\"\"\n    Make sure a file exists. Update its access and modified times.\n    \"\"\"\n    basedir = os.path.dirname(path)\n    if not os.path.exists(basedir):\n        try:\n            os.makedirs(basedir)\n        except OSError as err:\n            # alternate processes might be creating these at the same time\n            if err.errno != errno.EEXIST:\n                raise\n\n    with open(path, \"a\"):\n        os.utime(path, times)\n    return path\n</code></pre>"},{"location":"reference/core/#synapseclient.core.utils.is_json","title":"<code>is_json(content_type)</code>","text":"<p>detect if a content-type is JSON</p> Source code in <code>synapseclient/core/utils.py</code> <pre><code>def is_json(content_type):\n    \"\"\"detect if a content-type is JSON\"\"\"\n    # The value of Content-Type defined here:\n    # http://www.w3.org/Protocols/rfc2616/rfc2616-sec3.html#sec3.7\n    return (\n        content_type.lower().strip().startswith(\"application/json\")\n        if content_type\n        else False\n    )\n</code></pre>"},{"location":"reference/core/#synapseclient.core.utils.find_data_file_handle","title":"<code>find_data_file_handle(bundle)</code>","text":"<p>Return the fileHandle whose ID matches the dataFileHandleId in an entity bundle</p> Source code in <code>synapseclient/core/utils.py</code> <pre><code>def find_data_file_handle(bundle):\n    \"\"\"Return the fileHandle whose ID matches the dataFileHandleId in an entity bundle\"\"\"\n    for fileHandle in bundle[\"fileHandles\"]:\n        if fileHandle[\"id\"] == bundle[\"entity\"][\"dataFileHandleId\"]:\n            return fileHandle\n    return None\n</code></pre>"},{"location":"reference/core/#synapseclient.core.utils.unique_filename","title":"<code>unique_filename(path)</code>","text":"<p>Returns a unique path by appending (n) for some number n to the end of the filename.</p> Source code in <code>synapseclient/core/utils.py</code> <pre><code>def unique_filename(path):\n    \"\"\"Returns a unique path by appending (n) for some number n to the end of the filename.\"\"\"\n\n    base, ext = os.path.splitext(path)\n    counter = 0\n    while os.path.exists(path):\n        counter += 1\n        path = base + (\"(%d)\" % counter) + ext\n\n    return path\n</code></pre>"},{"location":"reference/core/#synapseclient.core.utils.threadsafe_generator","title":"<code>threadsafe_generator(f)</code>","text":"<p>A decorator that takes a generator function and makes it thread-safe. See: http://anandology.com/blog/using-iterators-and-generators/</p> Source code in <code>synapseclient/core/utils.py</code> <pre><code>def threadsafe_generator(f):\n    \"\"\"A decorator that takes a generator function and makes it thread-safe.\n    See: &lt;http://anandology.com/blog/using-iterators-and-generators/&gt;\n    \"\"\"\n\n    def g(*a, **kw):\n        return threadsafe_iter(f(*a, **kw))\n\n    return g\n</code></pre>"},{"location":"reference/core/#synapseclient.core.utils.extract_prefix","title":"<code>extract_prefix(keys)</code>","text":"<p>Takes a list of strings and extracts a common prefix delimited by a dot, for example::</p> <pre><code>extract_prefix([\"entity.bang\", \"entity.bar\", \"entity.bat\"])\n# returns \"entity\"\n</code></pre> Source code in <code>synapseclient/core/utils.py</code> <pre><code>def extract_prefix(keys):\n    \"\"\"\n    Takes a list of strings and extracts a common prefix delimited by a dot,\n    for example::\n\n        extract_prefix([\"entity.bang\", \"entity.bar\", \"entity.bat\"])\n        # returns \"entity\"\n\n    \"\"\"\n    prefixes = set()\n    for key in keys:\n        parts = key.split(\".\")\n        if len(parts) &gt; 1:\n            prefixes.add(parts[0])\n        else:\n            return \"\"\n    if len(prefixes) == 1:\n        return prefixes.pop() + \".\"\n    return \"\"\n</code></pre>"},{"location":"reference/core/#synapseclient.core.utils.extract_zip_file_to_directory","title":"<code>extract_zip_file_to_directory(zip_file, zip_entry_name, target_dir)</code>","text":"<p>Extracts a specified file in a zip to the specified directory</p> PARAMETER DESCRIPTION <code>zip_file</code> <p>an opened zip file. e.g. \"with zipfile.ZipFile(zipfilepath) as zip_file:\"</p> <p> TYPE: <code>ZipFile</code> </p> <code>zip_entry_name</code> <p>the name of the file to be extracted from the zip             e.g. folderInsideZipIfAny/fileName.txt</p> <p> TYPE: <code>str</code> </p> <code>target_dir</code> <p>the directory to which the file will be extracted</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>str</code> <p>full path to the extracted file</p> Source code in <code>synapseclient/core/utils.py</code> <pre><code>def extract_zip_file_to_directory(\n    zip_file: zipfile.ZipFile, zip_entry_name: str, target_dir: str\n) -&gt; str:\n    \"\"\"\n    Extracts a specified file in a zip to the specified directory\n\n    Arguments:\n        zip_file: an opened zip file. e.g. \"with zipfile.ZipFile(zipfilepath) as zip_file:\"\n        zip_entry_name: the name of the file to be extracted from the zip\n                        e.g. folderInsideZipIfAny/fileName.txt\n        target_dir: the directory to which the file will be extracted\n\n    Returns:\n        full path to the extracted file\n    \"\"\"\n    file_base_name = os.path.basename(zip_entry_name)  # base name of the file\n    filepath = os.path.join(\n        target_dir, file_base_name\n    )  # file path to the cached file to write\n\n    # Create the cache directory if it does not exist\n    if not os.path.exists(target_dir):\n        os.makedirs(target_dir)\n\n    # write the file from the zip into the cache\n    with open(filepath, \"wb\") as cache_file:\n        cache_file.write(zip_file.read(zip_entry_name))\n\n    return filepath\n</code></pre>"},{"location":"reference/core/#synapseclient.core.utils.topolgical_sort","title":"<code>topolgical_sort(graph)</code>","text":"<p>Given a graph in the form of a dictionary returns a sorted list Adapted from: http://blog.jupo.org/2012/04/06/topological-sorting-acyclic-directed-graphs/</p> PARAMETER DESCRIPTION <code>graph</code> <p>a dictionary with values containing lists of keys</p> <p> TYPE: <code>Dict[str, List[str]]</code> </p> RETURNS DESCRIPTION <code>list</code> <p>A sorted list of items</p> Source code in <code>synapseclient/core/utils.py</code> <pre><code>def topolgical_sort(graph: typing.Dict[str, typing.List[str]]) -&gt; list:\n    \"\"\"Given a graph in the form of a dictionary returns a sorted list\n    Adapted from:\n    &lt;http://blog.jupo.org/2012/04/06/topological-sorting-acyclic-directed-graphs/&gt;\n\n    Arguments:\n        graph: a dictionary with values containing lists of keys\n        referencing back into the dictionary\n\n    Returns:\n        A sorted list of items\n    \"\"\"\n    graph_unsorted = graph.copy()\n    graph_sorted = []\n    # Convert the unsorted graph into a hash table. This gives us\n    # constant-time lookup for checking if edges are unresolved\n\n    # Run until the unsorted graph is empty.\n    while graph_unsorted:\n        # Go through each of the node/edges pairs in the unsorted\n        # graph. If a set of edges doesn't contain any nodes that\n        # haven't been resolved, that is, that are still in the\n        # unsorted graph, remove the pair from the unsorted graph,\n        # and append it to the sorted graph. Note here that by using\n        # using the items() method for iterating, a copy of the\n        # unsorted graph is used, allowing us to modify the unsorted\n        # graph as we move through it. We also keep a flag for\n        # checking that that graph is acyclic, which is true if any\n        # nodes are resolved during each pass through the graph. If\n        # not, we need to bail out as the graph therefore can't be\n        # sorted.\n        acyclic = False\n        for node, edges in list(graph_unsorted.items()):\n            for edge in edges:\n                if edge in graph_unsorted:\n                    break\n            else:\n                acyclic = True\n                del graph_unsorted[node]\n                graph_sorted.append((node, edges))\n\n        if not acyclic:\n            # We've passed through all the unsorted nodes and\n            # weren't able to resolve any of them, which means there\n            # are nodes with cyclic edges that will never be resolved,\n            # so we bail out with an error.\n            raise RuntimeError(\n                \"A cyclic dependency occurred.\"\n                \" Some files in provenance reference each other circularly.\"\n            )\n    return graph_sorted\n</code></pre>"},{"location":"reference/core/#synapseclient.core.utils.caller_module_name","title":"<code>caller_module_name(current_frame)</code>","text":"<p>Returns the name of the module in which the calling function resides.</p> PARAMETER DESCRIPTION <code>current_frame</code> <p>use inspect.currentframe().</p> <p> </p> RETURNS DESCRIPTION <p>the name of the module calling the function, foo(),</p> <p>in which this calling_module() is invoked.</p> <p>Ignores callers that belong in the same module as foo()</p> Source code in <code>synapseclient/core/utils.py</code> <pre><code>def caller_module_name(current_frame):\n    \"\"\"\n    Returns the name of the module in which the calling function resides.\n\n    Arguments:\n        current_frame: use inspect.currentframe().\n\n    Returns:\n        the name of the module calling the function, foo(),\n        in which this calling_module() is invoked.\n        Ignores callers that belong in the same module as foo()\n    \"\"\"\n\n    current_frame_filename = (\n        current_frame.f_code.co_filename\n    )  # filename in which foo() resides\n\n    # go back a frame takes us to the frame calling foo()\n    caller_frame = current_frame.f_back\n    caller_filename = caller_frame.f_code.co_filename\n\n    # find the first frame that does not have the same filename.\n    # this ensures that we don't consider functions within\n    # the same module as foo() that use foo() as a helper function\n    while caller_filename == current_frame_filename:\n        caller_frame = caller_frame.f_back\n        caller_filename = caller_frame.f_code.co_filename\n\n    return inspect.getmodulename(caller_filename)\n</code></pre>"},{"location":"reference/core/#synapseclient.core.utils.attempt_import","title":"<code>attempt_import(module_name, fail_message)</code>","text":"<p>Attempt to import a module by name and return the imported module if successful.</p> PARAMETER DESCRIPTION <code>module_name</code> <p>The name of the module to import.</p> <p> TYPE: <code>str</code> </p> <code>fail_message</code> <p>The error message to display if the import fails.</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <p>The imported module.</p> RAISES DESCRIPTION <code>ImportError</code> <p>If the module cannot be imported.</p> Source code in <code>synapseclient/core/utils.py</code> <pre><code>def attempt_import(module_name: str, fail_message: str):\n    \"\"\"\n    Attempt to import a module by name and return the imported module if successful.\n\n    Arguments:\n        module_name: The name of the module to import.\n        fail_message: The error message to display if the import fails.\n\n    Returns:\n        The imported module.\n\n    Raises:\n        ImportError: If the module cannot be imported.\n\n    \"\"\"\n    try:\n        return importlib.import_module(module_name)\n    except ImportError:\n        sys.stderr.write(\n            (\n                fail_message\n                + \"To install this library on Mac or Linux distributions:\\n\"\n                \"    (sudo) pip install %s\\n\\n\"\n                \"On Windows, right click the Command Prompt(cmd.exe) and select 'Run as administrator' then:\\n\"\n                \"    pip install %s\\n\\n\"\n                \"\\n\\n\\n\" % (module_name, module_name)\n            )\n        )\n        raise\n</code></pre>"},{"location":"reference/core/#synapseclient.core.utils.snake_case","title":"<code>snake_case(string)</code>","text":"<p>Convert the given string from CamelCase to snake_case</p> Source code in <code>synapseclient/core/utils.py</code> <pre><code>def snake_case(string):\n    \"\"\"Convert the given string from CamelCase to snake_case\"\"\"\n    # https://stackoverflow.com/a/1176023\n    return re.sub(r\"(?&lt;!^)(?=[A-Z])\", \"_\", string).lower()\n</code></pre>"},{"location":"reference/core/#synapseclient.core.utils.is_base64_encoded","title":"<code>is_base64_encoded(input_string)</code>","text":"<p>Return whether the given input string appears to be base64 encoded</p> Source code in <code>synapseclient/core/utils.py</code> <pre><code>def is_base64_encoded(input_string):\n    \"\"\"Return whether the given input string appears to be base64 encoded\"\"\"\n    if not input_string:\n        # None, empty string are not considered encoded\n        return False\n    try:\n        # see if we can decode it and then reencode it back to the input\n        byte_string = (\n            input_string\n            if isinstance(input_string, bytes)\n            else str.encode(input_string)\n        )\n        return base64.b64encode(base64.b64decode(byte_string)) == byte_string\n    except Exception:\n        return False\n</code></pre>"},{"location":"reference/core/#synapseclient.core.utils.run_and_attach_otel_context","title":"<code>run_and_attach_otel_context(callable_function, current_context)</code>","text":"<p>This is a generic function that will run a callable function and attach the passed in OpenTelemetry context to the thread or context that the function is running on.</p> <p>This is a hack to get around AsyncIO <code>run_in_executor</code> not propagating the context to the code it's executing. When we are directly calling async functions after SYNPY-1411 we will be able to remove this function.</p> Adding this to a <code>run_in_executor</code> call <p>Note the 2 lambdas that are required:</p> <pre><code>import asyncio\nfrom opentelemetry import context\nfrom synapseclient import Synapse\n\nloop = asyncio.get_event_loop()\ncurrent_context = context.get_current()\nawait loop.run_in_executor(\n    None,\n    lambda: run_and_attach_otel_context(\n        lambda: Synapse.get_client(synapse_client=synapse_client).delete(\n            obj=\"syn123\",\n        ),\n        current_context,\n    ),\n)\n</code></pre> Source code in <code>synapseclient/core/utils.py</code> <pre><code>def run_and_attach_otel_context(\n    callable_function: Callable[..., R], current_context: Context\n) -&gt; R:\n    \"\"\"\n    This is a generic function that will run a callable function and attach the passed in\n    OpenTelemetry context to the thread or context that the function is running on.\n\n    This is a hack to get around AsyncIO `run_in_executor` not propagating the context\n    to the code it's executing. When we are directly calling async functions after\n    SYNPY-1411 we will be able to remove this function.\n\n    Example: Adding this to a `run_in_executor` call\n        Note the 2 lambdas that are required:\n\n            import asyncio\n            from opentelemetry import context\n            from synapseclient import Synapse\n\n            loop = asyncio.get_event_loop()\n            current_context = context.get_current()\n            await loop.run_in_executor(\n                None,\n                lambda: run_and_attach_otel_context(\n                    lambda: Synapse.get_client(synapse_client=synapse_client).delete(\n                        obj=\"syn123\",\n                    ),\n                    current_context,\n                ),\n            )\n    \"\"\"\n    context.attach(current_context)\n    return callable_function()\n</code></pre>"},{"location":"reference/core/#synapseclient.core.utils.delete_none_keys","title":"<code>delete_none_keys(incoming_object)</code>","text":"<p>Clean up the incoming object by removing any keys with None values.</p> Source code in <code>synapseclient/core/utils.py</code> <pre><code>def delete_none_keys(incoming_object: typing.Dict) -&gt; None:\n    \"\"\"Clean up the incoming object by removing any keys with None values.\"\"\"\n    if incoming_object:\n        for key in list(incoming_object.keys()):\n            if incoming_object[key] is None:\n                del incoming_object[key]\n</code></pre>"},{"location":"reference/core/#synapseclient.core.utils.merge_dataclass_entities","title":"<code>merge_dataclass_entities(source, destination, fields_to_ignore=None)</code>","text":"<p>Utility function to merge two dataclass entities together. This is used when we are upserting an entity from the Synapse service with the requested changes.</p> PARAMETER DESCRIPTION <code>source</code> <p>The source entity to merge from.</p> <p> TYPE: <code>Union[Project, Folder, File]</code> </p> <code>destination</code> <p>The destination entity to merge into.</p> <p> TYPE: <code>Union[Project, Folder, File]</code> </p> <code>fields_to_ignore</code> <p>A list of fields to ignore when merging.</p> <p> TYPE: <code>List[str]</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>Union[Project, Folder, File]</code> <p>The destination entity with the merged values.</p> Source code in <code>synapseclient/core/utils.py</code> <pre><code>def merge_dataclass_entities(\n    source: typing.Union[\"Project\", \"Folder\", \"File\"],\n    destination: typing.Union[\"Project\", \"Folder\", \"File\"],\n    fields_to_ignore: typing.List[str] = None,\n) -&gt; typing.Union[\"Project\", \"Folder\", \"File\"]:\n    \"\"\"\n    Utility function to merge two dataclass entities together. This is used when we are\n    upserting an entity from the Synapse service with the requested changes.\n\n    Arguments:\n        source: The source entity to merge from.\n        destination: The destination entity to merge into.\n        fields_to_ignore: A list of fields to ignore when merging.\n\n    Returns:\n        The destination entity with the merged values.\n    \"\"\"\n    # Convert dataclasses to dictionaries\n    destination_dict = asdict(destination)\n    source_dict = asdict(source)\n    modified_items = {}\n\n    # Update destination_dict with source_dict, keeping destination's values in case of conflicts\n    for key, value in source_dict.items():\n        if fields_to_ignore is not None and key in fields_to_ignore:\n            continue\n        if is_dataclass(getattr(source, key)):\n            if hasattr(destination, key):\n                setattr(destination, key, getattr(source, key))\n            else:\n                modified_items[key] = merge_dataclass_entities(\n                    getattr(source, key), destination=getattr(destination, key)\n                )\n        elif key not in destination_dict or destination_dict[key] is None:\n            modified_items[key] = value\n        elif key == \"annotations\":\n            modified_items[key] = {\n                **(value or {}),\n                **destination_dict[key],\n            }\n\n    # Update destination's fields with the merged dictionary\n    for key, value in modified_items.items():\n        setattr(destination, key, value)\n\n    return destination\n</code></pre>"},{"location":"reference/core/#async-utils","title":"Async Utils","text":""},{"location":"reference/core/#synapseclient.core.async_utils","title":"<code>synapseclient.core.async_utils</code>","text":"<p>This utility class is to hold any utilities that are needed for async operations.</p>"},{"location":"reference/core/#synapseclient.core.async_utils-classes","title":"Classes","text":""},{"location":"reference/core/#synapseclient.core.async_utils.ClassOrInstance","title":"<code>ClassOrInstance</code>","text":"<p>Helper class to allow a method to be called as a class method or instance method.</p> Source code in <code>synapseclient/core/async_utils.py</code> <pre><code>class ClassOrInstance:\n    \"\"\"Helper class to allow a method to be called as a class method or instance method.\"\"\"\n\n    def __init__(self, fn):\n        self.fn = fn\n\n    def __get__(self, obj, cls):\n        def f(*args, **kwds):\n            if obj is not None:\n                return self.fn(obj, *args, **kwds)\n            else:\n                return self.fn(cls, *args, **kwds)\n\n        functools.update_wrapper(f, self.fn)\n        return f\n</code></pre>"},{"location":"reference/core/#synapseclient.core.async_utils-functions","title":"Functions","text":""},{"location":"reference/core/#synapseclient.core.async_utils.otel_trace_method","title":"<code>otel_trace_method(method_to_trace_name=None)</code>","text":"<p>Decorator to trace a method with OpenTelemetry in an async environment. This function is specifically written to be used on a method within a class.</p> <p>This will pass the class instance as the first argument to the method. This allows you to modify the name of the trace to include information about the class instance.</p> Decorating a method within a class that will be traced with OpenTelemetry. <p>Setting the trace name:</p> <pre><code>@otel_trace_method(method_to_trace_name=lambda self, **kwargs: f\"Project_Store: {self.name}\")\nasync def store(self):\n</code></pre> PARAMETER DESCRIPTION <code>method_to_trace_name</code> <p>A callable that takes the class instance as the first argument and returns a string to be used as the trace name. If this is not provided, the trace name will be set to the method name.</p> <p> TYPE: <code>Union[Callable[..., str], None]</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <p>A callable decorator that will trace the method with OpenTelemetry.</p> Source code in <code>synapseclient/core/async_utils.py</code> <pre><code>def otel_trace_method(method_to_trace_name: Union[Callable[..., str], None] = None):\n    \"\"\"\n    Decorator to trace a method with OpenTelemetry in an async environment. This function\n    is specifically written to be used on a method within a class.\n\n    This will pass the class instance as the first argument to the method. This allows\n    you to modify the name of the trace to include information about the class instance.\n\n    Example: Decorating a method within a class that will be traced with OpenTelemetry.\n        Setting the trace name:\n\n            @otel_trace_method(method_to_trace_name=lambda self, **kwargs: f\"Project_Store: {self.name}\")\n            async def store(self):\n\n    Arguments:\n        method_to_trace_name: A callable that takes the class instance as the first argument\n            and returns a string to be used as the trace name. If this is not provided,\n            the trace name will be set to the method name.\n\n    Returns:\n        A callable decorator that will trace the method with OpenTelemetry.\n    \"\"\"\n\n    def decorator(func):\n        \"\"\"Function decorator.\"\"\"\n\n        async def otel_trace_method_wrapper(self, *arg, **kwargs) -&gt; None:\n            \"\"\"Wrapper for the function to be traced.\"\"\"\n            trace_name = (\n                method_to_trace_name(self, *arg, **kwargs)\n                if method_to_trace_name\n                else None\n            )\n            current_span = trace.get_current_span()\n            if current_span.is_recording():\n                with tracer.start_as_current_span(\n                    trace_name or f\"Synaspse::{func.__name__}\"\n                ):\n                    return await func(self, *arg, **kwargs)\n            else:\n                return await func(self, *arg, **kwargs)\n\n        return otel_trace_method_wrapper\n\n    return decorator\n</code></pre>"},{"location":"reference/core/#synapseclient.core.async_utils.wrap_async_to_sync","title":"<code>wrap_async_to_sync(coroutine, syn)</code>","text":"<p>Wrap an async function to be called in a sync context.</p> Source code in <code>synapseclient/core/async_utils.py</code> <pre><code>def wrap_async_to_sync(coroutine: Coroutine[Any, Any, Any], syn: \"Synapse\") -&gt; Any:\n    \"\"\"Wrap an async function to be called in a sync context.\"\"\"\n    loop = None\n    try:\n        try:\n            loop = asyncio.get_running_loop()\n        except RuntimeError:\n            pass\n\n        if loop:\n            nest_asyncio.apply(loop=loop)\n            return loop.run_until_complete(coroutine)\n        else:\n            return asyncio.run(coroutine)\n\n    except Exception as ex:\n        syn.logger.exception(\n            f\"Error occurred while running {coroutine} in a sync context.\"\n        )\n        raise ex\n</code></pre>"},{"location":"reference/core/#synapseclient.core.async_utils.async_to_sync","title":"<code>async_to_sync(cls)</code>","text":"<p>Convert all name_of_thing_async methods to name_of_thing methods</p> <p>(see http://stackoverflow.com/questions/18048341/add-methods-to-a-class-generated-from-other-methods for help understanding)</p> Source code in <code>synapseclient/core/async_utils.py</code> <pre><code>def async_to_sync(cls):\n    \"\"\"\n    Convert all name_of_thing_async methods to name_of_thing methods\n\n    (see\n    http://stackoverflow.com/questions/18048341/add-methods-to-a-class-generated-from-other-methods\n    for help understanding)\n    \"\"\"\n\n    def create_method(async_method_name: str):\n        \"\"\"Creates a replacement method for the async method.\"\"\"\n\n        @ClassOrInstance\n        def newmethod(self, *args, **kwargs):\n            \"\"\"The new method that will replace the non-async method.\"\"\"\n\n            async def wrapper(*args, **kwargs):\n                \"\"\"Wrapper for the function to be called in an async context.\"\"\"\n                return await getattr(self, async_method_name)(*args, **kwargs)\n\n            loop = None\n            try:\n                try:\n                    loop = asyncio.get_running_loop()\n                except RuntimeError:\n                    pass\n\n                if loop:\n                    nest_asyncio.apply(loop=loop)\n                    return loop.run_until_complete(wrapper(*args, **kwargs))\n                else:\n                    return asyncio.run(wrapper(*args, **kwargs))\n\n            except Exception as ex:\n                from synapseclient import Synapse\n\n                synapse_client = Synapse.get_client(\n                    getattr(kwargs, \"synapse_client\", None)\n                )\n                synapse_client.logger.exception(\n                    f\"Error occurred while running {async_method_name} on {self.__class__}.\"\n                )\n                raise ex\n\n        return newmethod\n\n    methods = cls.__dict__.keys()\n\n    methods_to_update = []\n    for k in methods:\n        if \"async\" in k and (new_method_name := k.replace(\"_async\", \"\")) not in methods:\n            new_method = create_method(k)\n\n            new_method.fn.__name__ = new_method_name\n            new_method.__name__ = new_method_name\n\n            functools.update_wrapper(new_method, new_method.fn)\n            methods_to_update.append(\n                {\n                    \"new_method_name\": new_method_name,\n                    \"new_method\": new_method,\n                }\n            )\n    for method_to_update in methods_to_update:\n        setattr(\n            cls, method_to_update[\"new_method_name\"], method_to_update[\"new_method\"]\n        )\n\n    return cls\n</code></pre>"},{"location":"reference/core/#versions","title":"Versions","text":""},{"location":"reference/core/#synapseclient.core.version_check","title":"<code>synapseclient.core.version_check</code>","text":""},{"location":"reference/core/#synapseclient.core.version_check--version-functions","title":"Version Functions","text":"<p>Check for latest version and recommend upgrade:</p> <pre><code>synapseclient.check_for_updates()\n</code></pre> <p>Print release notes for installed version of client:</p> <pre><code>synapseclient.release_notes()\n</code></pre>"},{"location":"reference/core/#synapseclient.core.version_check-functions","title":"Functions","text":""},{"location":"reference/core/#synapseclient.core.version_check.version_check","title":"<code>version_check(current_version=None, version_url=_VERSION_URL, check_for_point_releases=False)</code>","text":"<p>Gets the latest version information from version_url and check against the current version. Recommends upgrade, if a newer version exists.</p> PARAMETER DESCRIPTION <code>current_version</code> <p>The current version of the entity</p> <p> DEFAULT: <code>None</code> </p> <code>version_url</code> <p>The URL of the entity version</p> <p> DEFAULT: <code>_VERSION_URL</code> </p> <code>check_for_point_releases</code> <p>Bool.</p> <p> DEFAULT: <code>False</code> </p> RETURNS DESCRIPTION <p>True if current version is the latest release (or higher) version, otherwise False.</p> Source code in <code>synapseclient/core/version_check.py</code> <pre><code>def version_check(\n    current_version=None, version_url=_VERSION_URL, check_for_point_releases=False\n):\n    \"\"\"\n    Gets the latest version information from version_url and check against the current version.\n    Recommends upgrade, if a newer version exists.\n\n    Arguments:\n        current_version: The current version of the entity\n        version_url: The URL of the entity version\n        check_for_point_releases: Bool.\n\n    Returns:\n        True if current version is the latest release (or higher) version, otherwise False.\n    \"\"\"\n\n    try:\n        if not current_version:\n            current_version = synapseclient.__version__\n\n        version_info = _get_version_info(version_url)\n\n        current_base_version = _strip_dev_suffix(current_version)\n\n        # Check blacklist\n        if (\n            current_base_version in version_info[\"blacklist\"]\n            or current_version in version_info[\"blacklist\"]\n        ):\n            msg = (\n                \"\\nPLEASE UPGRADE YOUR CLIENT\\n\\nUpgrading your SynapseClient is\"\n                \" required. Please upgrade your client by typing:\\n    pip install\"\n                \" --upgrade synapseclient\\n\\n\"\n            )\n            raise SystemExit(msg)\n\n        if \"message\" in version_info:\n            sys.stderr.write(version_info[\"message\"] + \"\\n\")\n\n        levels = 3 if check_for_point_releases else 2\n\n        # Compare with latest version\n        if _version_tuple(current_version, levels=levels) &lt; _version_tuple(\n            version_info[\"latestVersion\"], levels=levels\n        ):\n            sys.stderr.write(\n                \"\\nUPGRADE AVAILABLE\\n\\nA more recent version of the Synapse Client\"\n                \" (%s) is available. Your version (%s) can be upgraded by typing:\\n   \"\n                \" pip install --upgrade synapseclient\\n\\n\"\n                % (\n                    version_info[\"latestVersion\"],\n                    current_version,\n                )\n            )\n            if \"releaseNotes\" in version_info:\n                sys.stderr.write(\n                    \"Python Synapse Client version %s release notes\\n\\n\"\n                    % version_info[\"latestVersion\"]\n                )\n                sys.stderr.write(version_info[\"releaseNotes\"] + \"\\n\\n\")\n            return False\n\n    except Exception as e:\n        # Don't prevent the client from running if something goes wrong\n        sys.stderr.write(\"Exception in version check: %s\\n\" % (str(e),))\n        return False\n\n    return True\n</code></pre>"},{"location":"reference/core/#synapseclient.core.version_check.check_for_updates","title":"<code>check_for_updates()</code>","text":"<p>Check for the existence of newer versions of the client, reporting both current release version and development version.</p> <p>For help installing development versions of the client, see the README.md.</p> Source code in <code>synapseclient/core/version_check.py</code> <pre><code>def check_for_updates():\n    \"\"\"\n    Check for the existence of newer versions of the client, reporting both current release version and development\n    version.\n\n    For help installing development versions of the client,\n    see the [README.md](https://github.com/Sage-Bionetworks/synapsePythonClient#installation).\n    \"\"\"\n    sys.stderr.write(\"Python Synapse Client\\n\")\n    sys.stderr.write(\"currently running version:  %s\\n\" % synapseclient.__version__)\n\n    release_version_info = _get_version_info(_VERSION_URL)\n    sys.stderr.write(\n        \"latest release version:     %s\\n\" % release_version_info[\"latestVersion\"]\n    )\n\n    if _version_tuple(synapseclient.__version__, levels=3) &lt; _version_tuple(\n        release_version_info[\"latestVersion\"], levels=3\n    ):\n        print(\n            \"\\nUPGRADE AVAILABLE\\n\\nA more recent version of the Synapse Client (%s) is\"\n            \" available. Your version (%s) can be upgraded by typing:\\n    pip install\"\n            \" --upgrade synapseclient\\n\\n\"\n            % (\n                release_version_info[\"latestVersion\"],\n                synapseclient.__version__,\n            )\n        )\n    else:\n        sys.stderr.write(\"\\nYour Synapse client is up to date!\\n\")\n</code></pre>"},{"location":"reference/core/#synapseclient.core.version_check.release_notes","title":"<code>release_notes(version_url=None)</code>","text":"<p>Print release notes for the installed version of the client or latest release or development version if version_url is supplied.</p> Defaults to None, meaning release notes for the installed version. Alternatives are: <ul> <li>synapseclient.version_check._VERSION_URL</li> <li>synapseclient.version_check._DEV_VERSION_URL</li> </ul> Source code in <code>synapseclient/core/version_check.py</code> <pre><code>def release_notes(version_url=None):\n    \"\"\"\n    Print release notes for the installed version of the client or latest release or development version if version_url\n    is supplied.\n\n    version_url: Defaults to None, meaning release notes for the installed version. Alternatives are:\n                        - synapseclient.version_check._VERSION_URL\n                        - synapseclient.version_check._DEV_VERSION_URL\n\n    \"\"\"\n    version_info = _get_version_info(version_url)\n    sys.stderr.write(\n        \"Python Synapse Client version %s release notes\\n\\n\"\n        % version_info[\"latestVersion\"]\n    )\n    if \"releaseNotes\" in version_info:\n        sys.stderr.write(version_info[\"releaseNotes\"] + \"\\n\")\n</code></pre>"},{"location":"reference/core/#sts-transfer","title":"STS Transfer","text":""},{"location":"reference/core/#synapseclient.core.sts_transfer","title":"<code>synapseclient.core.sts_transfer</code>","text":""},{"location":"reference/core/#synapseclient.core.sts_transfer-classes","title":"Classes","text":""},{"location":"reference/core/#synapseclient.core.sts_transfer.StsTokenStore","title":"<code>StsTokenStore</code>","text":"<p>Cache STS tokens in memory for observed entity ids. An optimization for long lived Synapse objects that will interact with the same Synapse storage locations over and over again so they don't have to do a remote call to fetch a new token for every entity, which for e.g. small files can amount to non trivial overhead.</p> Source code in <code>synapseclient/core/sts_transfer.py</code> <pre><code>class StsTokenStore:\n    \"\"\"\n    Cache STS tokens in memory for observed entity ids.\n    An optimization for long lived Synapse objects that will interact with the same\n    Synapse storage locations over and over again so they don't have to do a remote call\n    to fetch a new token for every entity, which for e.g. small files can amount to\n    non trivial overhead.\n    \"\"\"\n\n    # each token is &lt; 1k but given we don't know how long Python process will be running\n    # (could be very long in a programmatic environment) we impose a limit on the maximum\n    # number of tokens we will store in memory to prevent this optimization from becoming\n    # a memory leak.\n    DEFAULT_TOKEN_CACHE_SIZE = 5000\n\n    def __init__(self, max_token_cache_size=DEFAULT_TOKEN_CACHE_SIZE):\n        self._tokens = {p: _TokenCache(max_token_cache_size) for p in STS_PERMISSIONS}\n        self._lock = threading.Lock()\n\n    def get_token(\n        self, syn, entity_id, permission, min_remaining_life: datetime.timedelta\n    ):\n        with self._lock:\n            utcnow = datetime.datetime.utcnow()\n            token_cache = self._tokens.get(permission)\n            if token_cache is None:\n                raise ValueError(f\"Invalid STS permission {permission}\")\n\n            token = token_cache.get(entity_id)\n            if (\n                not token\n                or (iso_to_datetime(token[\"expiration\"]) - utcnow) &lt; min_remaining_life\n            ):\n                # either there is no cached token or the remaining life on the token isn't enough so fetch new\n                token = token_cache[entity_id] = self._fetch_token(\n                    syn, entity_id, permission\n                )\n\n        return token\n\n    @staticmethod\n    def _fetch_token(syn, entity_id, permission):\n        return syn.restGET(f\"/entity/{entity_id}/sts?permission={permission}\")\n</code></pre>"},{"location":"reference/core/#synapseclient.core.sts_transfer-functions","title":"Functions","text":""},{"location":"reference/core/#synapseclient.core.sts_transfer.get_sts_credentials","title":"<code>get_sts_credentials(syn, entity_id, permission, *, output_format='json', min_remaining_life=None)</code>","text":"<p>See Synapse.get_sts_storage_token</p> Source code in <code>synapseclient/core/sts_transfer.py</code> <pre><code>def get_sts_credentials(\n    syn, entity_id, permission, *, output_format=\"json\", min_remaining_life=None\n):\n    \"\"\"See Synapse.get_sts_storage_token\"\"\"\n    min_remaining_life = min_remaining_life or DEFAULT_MIN_LIFE\n\n    value = syn._sts_token_store.get_token(\n        syn, entity_id, permission, min_remaining_life\n    )\n\n    if output_format == \"boto\":\n        # the Synapse STS API returns camel cased keys that we need to convert to use with boto.\n        # prefix with \"aws_\", convert to snake case, and exclude any other key/value pairs in the value\n        # e.g. expiration\n        return {\n            \"aws_{}\".format(snake_case(k)): value[k]\n            for k in (\"accessKeyId\", \"secretAccessKey\", \"sessionToken\")\n        }\n    elif output_format == \"json\":\n        # pass through what server sent\n        return value\n\n    elif output_format == \"shell\":\n        # for \"shell\" we try to detect what is best for the system\n        # assume bourne compatible output outside of windows\n        if platform.system() == \"Windows\" and \"bash\" not in os.environ.get(\"SHELL\", \"\"):\n            if len(os.getenv(\"PSModulePath\", \"\").split(os.pathsep)) &gt;= 3:\n                # https://stackoverflow.com/a/55598796\n                output_format = \"powershell\"\n            else:\n                output_format = \"cmd\"\n        else:\n            output_format = \"bash\"\n\n    template_string = EXPORT_TEMPLATE_STRINGS.get(output_format)\n    if not template_string:\n        raise ValueError(f\"Unrecognized output_format {output_format}\")\n\n    return _format_export_template_string(syn, entity_id, value, template_string)\n</code></pre>"},{"location":"reference/core/#synapseclient.core.sts_transfer.with_boto_sts_credentials","title":"<code>with_boto_sts_credentials(fn, syn, entity_id, permission)</code>","text":"<p>A wrapper around a function that will get sts credentials and try to use them on the given function which should take a dictionary with the <code>aws_access_key_id</code>, <code>aws_secret_access_key</code>, and <code>aws_session_token</code> as keys. If the given function returns a boto error that looks like the token has expired it will retry once after fetching fresh credentials.</p> <p>The purpose is to be able to use potentially cached credentials in long running tasks while reducing worry that they will expire in the middle of running and cause an unrecoverable error. The alternative of fetching a fresh STS token for every request might be okay for a few large files but would greatly slow down transferring many small files.</p> Source code in <code>synapseclient/core/sts_transfer.py</code> <pre><code>def with_boto_sts_credentials(fn, syn, entity_id, permission):\n    \"\"\"\n    A wrapper around a function that will get sts credentials and try to use them on the given\n    function which should take a dictionary with the `aws_access_key_id`, `aws_secret_access_key`, and `aws_session_token`\n    as keys. If the given function returns a boto error that looks like the token has expired\n    it will retry once after fetching fresh credentials.\n\n    The purpose is to be able to use potentially cached credentials in long running tasks while reducing\n    worry that they will expire in the middle of running and cause an unrecoverable error.\n    The alternative of fetching a fresh STS token for every request might be okay for a few large files\n    but would greatly slow down transferring many small files.\n    \"\"\"\n\n    for attempt in range(2):\n        credentials = get_sts_credentials(\n            syn, entity_id, permission, output_format=\"boto\"\n        )\n        try:\n            response = fn(credentials)\n        except boto3.exceptions.Boto3Error as ex:\n            if \"ExpiredToken\" in str(ex) and attempt == 0:\n                continue\n            else:\n                raise\n\n        return response\n</code></pre>"},{"location":"reference/core/#synapseclient.core.sts_transfer.is_boto_sts_transfer_enabled","title":"<code>is_boto_sts_transfer_enabled(syn)</code>","text":"<p>Check if the boto/STS transfers are enabled in the Synapse configuration. If enabled then synapseclient will attempt to automatically use boto to upload and download from supported storage locations that are sts enabled.</p> PARAMETER DESCRIPTION <code>syn</code> <p>A Synapse object</p> <p> </p> RETURNS DESCRIPTION <p>True if STS if enabled, False otherwise</p> Source code in <code>synapseclient/core/sts_transfer.py</code> <pre><code>def is_boto_sts_transfer_enabled(syn):\n    \"\"\"\n    Check if the boto/STS transfers are enabled in the Synapse configuration.\n    If enabled then synapseclient will attempt to automatically use boto to upload\n    and download from supported storage locations that are sts enabled.\n\n    Arguments:\n        syn: A [Synapse][synapseclient.Synapse] object\n\n    Returns:\n        True if STS if enabled, False otherwise\n    \"\"\"\n    return bool(boto3 and syn.use_boto_sts_transfers)\n</code></pre>"},{"location":"reference/core/#synapseclient.core.sts_transfer.is_storage_location_sts_enabled","title":"<code>is_storage_location_sts_enabled(syn, entity_id, location)</code>","text":"<p>Returns whether the given storage location is enabled for STS.</p> PARAMETER DESCRIPTION <code>syn</code> <p>A Synapse object</p> <p> </p> <code>entity_id</code> <p>The ID of synapse entity whose storage location we want to check for sts access</p> <p> </p> <code>location</code> <p>A storage location ID or a dictionary representing the location UploadDestination</p> <p> </p> RETURNS DESCRIPTION <p>True if STS is enabled for the location, False otherwise</p> Source code in <code>synapseclient/core/sts_transfer.py</code> <pre><code>def is_storage_location_sts_enabled(syn, entity_id, location):\n    \"\"\"\n    Returns whether the given storage location is enabled for STS.\n\n    Arguments:\n        syn:       A [Synapse][synapseclient.Synapse] object\n        entity_id: The ID of synapse entity whose storage location we want to check for sts access\n        location:  A storage location ID or a dictionary representing the location UploadDestination\n\n    Returns:\n        True if STS is enabled for the location, False otherwise\n    \"\"\"\n    if not location:\n        return False\n\n    if isinstance(location, collections.abc.Mapping):\n        # looks like this is already an upload destination dict\n        destination = location\n\n    else:\n        # otherwise treat it as a storage location id,\n        destination = syn.restGET(\n            f\"/entity/{entity_id}/uploadDestination/{location}\",\n            endpoint=syn.fileHandleEndpoint,\n        )\n\n    return destination.get(\"stsEnabled\", False)\n</code></pre>"},{"location":"reference/core/#synapseclient.core.sts_transfer.is_storage_location_sts_enabled_async","title":"<code>is_storage_location_sts_enabled_async(syn, entity_id, location)</code>  <code>async</code>","text":"<p>Returns whether the given storage location is enabled for STS.</p> PARAMETER DESCRIPTION <code>syn</code> <p>A Synapse object</p> <p> TYPE: <code>Synapse</code> </p> <code>entity_id</code> <p>The ID of synapse entity whose storage location we want to check for sts access</p> <p> TYPE: <code>str</code> </p> <code>location</code> <p>A storage location ID or a dictionary representing the location UploadDestination</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>bool</code> <p>True if STS is enabled for the location, False otherwise</p> Source code in <code>synapseclient/core/sts_transfer.py</code> <pre><code>async def is_storage_location_sts_enabled_async(\n    syn: \"Synapse\", entity_id: str, location: str\n) -&gt; bool:\n    \"\"\"\n    Returns whether the given storage location is enabled for STS.\n\n    Arguments:\n        syn:       A [Synapse][synapseclient.Synapse] object\n        entity_id: The ID of synapse entity whose storage location we want to check for sts access\n        location:  A storage location ID or a dictionary representing the location UploadDestination\n\n    Returns:\n        True if STS is enabled for the location, False otherwise\n    \"\"\"\n    if not location:\n        return False\n\n    if isinstance(location, collections.abc.Mapping):\n        # looks like this is already an upload destination dict\n        destination = location\n\n    else:\n        # Lazy import to avoid circular imports\n        from synapseclient.api.entity_services import get_upload_destination_location\n\n        # otherwise treat it as a storage location id,\n        destination = await get_upload_destination_location(\n            entity_id=entity_id, location=location, synapse_client=syn\n        )\n\n    return destination.get(\"stsEnabled\", False)\n</code></pre>"},{"location":"reference/docker_repository/","title":"DockerRepository","text":""},{"location":"reference/docker_repository/#synapseclient.entity.DockerRepository","title":"<code>synapseclient.entity.DockerRepository</code>","text":"<p>               Bases: <code>Entity</code></p> <p>A Docker repository is a lightweight virtual machine image.</p> <p>NOTE: store()-ing a DockerRepository created in the Python client will always result in it being treated as a reference to an external Docker repository that is not managed by synapse. To upload a docker image that is managed by Synapse please use the official Docker client and read https://help.synapse.org/docs/Synapse-Docker-Registry.2011037752.html for instructions on uploading a Docker Image to Synapse</p> ATTRIBUTE DESCRIPTION <code>repositoryName</code> <p>The name of the Docker Repository. Usually in the format: [host[:port]/]path.             If host is not set, it will default to that of DockerHub.             port can only be specified if the host is also specified.</p> <p> </p> <code>parent</code> <p>The parent project or folder</p> <p> </p> <code>properties</code> <p>A map of Synapse properties</p> <p> </p> <code>annotations</code> <p>A map of user defined annotations</p> <p> </p> <code>local_state</code> <p>Internal use only</p> <p> </p> Source code in <code>synapseclient/entity.py</code> <pre><code>class DockerRepository(Entity):\n    \"\"\"\n    A Docker repository is a lightweight virtual machine image.\n\n    NOTE: [store()][synapseclient.Synapse.store]-ing a DockerRepository created in the Python client will always result\n    in it being treated as a reference to an external Docker repository that is not\n    managed by synapse. To upload a docker image that is managed by Synapse please use the official\n    Docker client and read &lt;https://help.synapse.org/docs/Synapse-Docker-Registry.2011037752.html&gt;\n    for instructions on uploading a Docker Image to Synapse\n\n    Attributes:\n        repositoryName: The name of the Docker Repository. Usually in the format: [host[:port]/]path.\n                        If host is not set, it will default to that of DockerHub.\n                        port can only be specified if the host is also specified.\n        parent: The parent project or folder\n        properties: A map of Synapse properties\n        annotations: A map of user defined annotations\n        local_state: Internal use only\n    \"\"\"\n\n    _synapse_entity_type = \"org.sagebionetworks.repo.model.docker.DockerRepository\"\n\n    _property_keys = Entity._property_keys + [\"repositoryName\"]\n\n    def __init__(\n        self,\n        repositoryName=None,\n        parent=None,\n        properties=None,\n        annotations=None,\n        local_state=None,\n        **kwargs,\n    ):\n        if repositoryName:\n            kwargs[\"repositoryName\"] = repositoryName\n        super(DockerRepository, self).__init__(\n            properties=properties,\n            annotations=annotations,\n            local_state=local_state,\n            parent=parent,\n            **kwargs,\n        )\n        if \"repositoryName\" not in self:\n            raise SynapseMalformedEntityError(\n                \"DockerRepository must have a repositoryName.\"\n            )\n</code></pre>"},{"location":"reference/entity/","title":"Entity","text":"<p>The Entity class is the base class for all entities, including Project, Folder, File, and Link.</p> <p>Entities are dictionary-like objects in which both object and dictionary notation (<code>entity.foo</code> or <code>entity['foo']</code>) can be used interchangeably.</p>"},{"location":"reference/entity/#synapseclient.entity.Entity","title":"<code>synapseclient.entity.Entity</code>","text":"<p>               Bases: <code>MutableMapping</code></p> <p>A Synapse entity is an object that has metadata, access control, and potentially a file. It can represent data, source code, or a folder that contains other entities.</p> <p>Entities should typically be created using the constructors for specific subclasses such as synapseclient.Project, synapseclient.Folder or synapseclient.File.</p> ATTRIBUTE DESCRIPTION <code>id</code> <p>The unique immutable ID for this entity. A new ID will be generated for new Entities. Once issued, this ID is guaranteed to never change or be re-issued</p> <p> </p> <code>name</code> <p>The name of this entity. Must be 256 characters or less. Names may only     contain: letters, numbers, spaces, underscores, hyphens, periods, plus     signs, apostrophes, and parentheses</p> <p> </p> <code>description</code> <p>The description of this entity. Must be 1000 characters or less.</p> <p> </p> <code>parentId</code> <p>The ID of the Entity that is the parent of this Entity.</p> <p> </p> <code>entityType</code> <p>The type of this entity.</p> <p> </p> <code>concreteType</code> <p>Indicates which implementation of Entity this object represents.             The value is the fully qualified class name, e.g.             org.sagebionetworks.repo.model.FileEntity.</p> <p> </p> <code>etag</code> <p>Synapse employs an Optimistic Concurrency Control (OCC) scheme to handle     concurrent updates. Since the E-Tag changes every time an entity is     updated it is used to detect when a client's current representation of     an entity is out-of-date.</p> <p> </p> <code>annotations</code> <p>The dict of annotations for this entity.</p> <p> </p> <code>accessControlList</code> <p>The access control list for this entity.</p> <p> </p> <code>createdOn</code> <p>The date this entity was created.</p> <p> </p> <code>createdBy</code> <p>The ID of the user that created this entity.</p> <p> </p> <code>modifiedOn</code> <p>The date this entity was last modified.</p> <p> </p> <code>modifiedBy</code> <p>The ID of the user that last modified this entity.</p> <p> </p> Source code in <code>synapseclient/entity.py</code> <pre><code>class Entity(collections.abc.MutableMapping):\n    \"\"\"\n    A Synapse entity is an object that has metadata, access control, and potentially a file. It can represent data,\n    source code, or a folder that contains other entities.\n\n    Entities should typically be created using the constructors for specific subclasses\n    such as [synapseclient.Project][], [synapseclient.Folder][] or [synapseclient.File][].\n\n    Attributes:\n        id: The unique immutable ID for this entity. A new ID will be generated for new\n            Entities. Once issued, this ID is guaranteed to never change or be re-issued\n        name: The name of this entity. Must be 256 characters or less. Names may only\n                contain: letters, numbers, spaces, underscores, hyphens, periods, plus\n                signs, apostrophes, and parentheses\n        description: The description of this entity. Must be 1000 characters or less.\n        parentId: The ID of the Entity that is the parent of this Entity.\n        entityType: The type of this entity.\n        concreteType: Indicates which implementation of Entity this object represents.\n                        The value is the fully qualified class name, e.g.\n                        org.sagebionetworks.repo.model.FileEntity.\n        etag: Synapse employs an Optimistic Concurrency Control (OCC) scheme to handle\n                concurrent updates. Since the E-Tag changes every time an entity is\n                updated it is used to detect when a client's current representation of\n                an entity is out-of-date.\n        annotations: The dict of annotations for this entity.\n        accessControlList: The access control list for this entity.\n        createdOn: The date this entity was created.\n        createdBy: The ID of the user that created this entity.\n        modifiedOn: The date this entity was last modified.\n        modifiedBy: The ID of the user that last modified this entity.\n    \"\"\"\n\n    _synapse_entity_type = \"org.sagebionetworks.repo.model.Entity\"\n    _property_keys = [\n        \"id\",\n        \"name\",\n        \"description\",\n        \"parentId\",\n        \"entityType\",\n        \"concreteType\",\n        \"uri\",\n        \"etag\",\n        \"annotations\",\n        \"accessControlList\",\n        \"createdOn\",\n        \"createdBy\",\n        \"modifiedOn\",\n        \"modifiedBy\",\n    ]\n    _local_keys = []\n\n    @classmethod\n    def create(cls, properties=None, annotations=None, local_state=None):\n        \"\"\"\n        Create an Entity or a subclass given dictionaries of properties and annotations, as might be received from the\n        Synapse Repository.\n\n        Arguments:\n            properties:  A map of Synapse properties\n\n                - If 'concreteType' is defined in properties, we create the proper subclass of Entity. If not, give back the\n                type whose constructor was called.\n                - If passed an Entity as input, create a new Entity using the input entity as a prototype.\n            annotations: A map of user defined annotations\n            local_state: Internal use only\n        \"\"\"\n\n        # Create a new Entity using an existing Entity as a prototype\n        if isinstance(properties, Entity):\n            if annotations is None:\n                annotations = {}\n            if local_state is None:\n                local_state = {}\n            annotations.update(properties.annotations)\n            local_state.update(properties.local_state())\n            properties = properties.properties\n            if \"id\" in properties:\n                del properties[\"id\"]\n\n        if (\n            cls == Entity\n            and \"concreteType\" in properties\n            and properties[\"concreteType\"] in entity_type_to_class\n        ):\n            cls = entity_type_to_class[properties[\"concreteType\"]]\n        return cls(\n            properties=properties, annotations=annotations, local_state=local_state\n        )\n\n    @classmethod\n    def getURI(cls, id):\n        return \"/entity/%s\" % id\n\n    def __new__(cls, *args, **kwargs):\n        obj = object.__new__(cls)\n\n        # Make really sure that properties and annotations exist before\n        # any object methods get invoked. This is important because the\n        # dot operator magic methods have been overridden and depend on\n        # properties and annotations existing.\n        obj.__dict__[\"properties\"] = DictObject()\n        obj.__dict__[\"annotations\"] = DictObject()\n        return obj\n\n    def __init__(\n        self, properties=None, annotations=None, local_state=None, parent=None, **kwargs\n    ):\n        if properties:\n            if isinstance(properties, collections.abc.Mapping):\n                if \"annotations\" in properties and isinstance(\n                    properties[\"annotations\"], collections.abc.Mapping\n                ):\n                    annotations.update(properties[\"annotations\"])\n                    del properties[\"annotations\"]\n\n                # Re-map `items` to `datasetItems` to avoid namespace conflicts\n                # between Dataset schema and the items() builtin method.\n                if \"items\" in properties:\n                    properties[\"datasetItems\"] = properties[\"items\"]\n                    del properties[\"items\"]\n                self.__dict__[\"properties\"].update(properties)\n            else:\n                raise SynapseMalformedEntityError(\n                    \"Unknown argument type: properties is a %s\" % str(type(properties))\n                )\n\n        if annotations:\n            if isinstance(annotations, collections.abc.Mapping):\n                self.__dict__[\"annotations\"].update(annotations)\n            elif isinstance(annotations, str):\n                self.properties[\"annotations\"] = annotations\n            else:\n                raise SynapseMalformedEntityError(\n                    \"Unknown argument type: annotations is a %s\"\n                    % str(type(annotations))\n                )\n\n        if local_state:\n            if isinstance(local_state, collections.abc.Mapping):\n                self.local_state(local_state)\n            else:\n                raise SynapseMalformedEntityError(\n                    \"Unknown argument type: local_state is a %s\"\n                    % str(type(local_state))\n                )\n\n        for key in self.__class__._local_keys:\n            if key not in self.__dict__:\n                self.__dict__[key] = None\n\n        # Extract parentId from parent\n        if \"parentId\" not in kwargs:\n            if parent:\n                try:\n                    kwargs[\"parentId\"] = id_of(parent)\n                except Exception:\n                    if isinstance(parent, Entity) and \"id\" not in parent:\n                        raise SynapseMalformedEntityError(\n                            \"Couldn't find 'id' of parent.\"\n                            \" Has it been stored in Synapse?\"\n                        )\n                    else:\n                        raise SynapseMalformedEntityError(\n                            \"Couldn't find 'id' of parent.\"\n                        )\n\n        # Note: that this will work properly if derived classes declare their internal state variable *before* invoking\n        # super(...).__init__(...)\n        for key, value in kwargs.items():\n            self.__setitem__(key, value)\n\n        if \"concreteType\" not in self:\n            self[\"concreteType\"] = self.__class__._synapse_entity_type\n\n        # Only project can be top-level. All other entity types require parentId don't enforce this for generic Entity\n        if (\n            \"parentId\" not in self\n            and not isinstance(self, Project)\n            and not type(self) == Entity\n        ) and \"id\" not in self:\n            raise SynapseMalformedEntityError(\n                \"Entities of type %s must have a parentId.\" % type(self)\n            )\n\n    def postURI(self):\n        return \"/entity\"\n\n    def putURI(self):\n        return \"/entity/%s\" % self.id\n\n    def deleteURI(self, versionNumber=None):\n        if versionNumber:\n            return \"/entity/%s/version/%s\" % (self.id, versionNumber)\n        else:\n            return \"/entity/%s\" % self.id\n\n    def local_state(self, state: dict = None) -&gt; dict:\n        \"\"\"\n        Set or get the object's internal state, excluding properties, or annotations.\n\n        Arguments:\n            state: A dictionary containing the object's internal state.\n\n        Returns:\n            result: The object's internal state, excluding properties, or annotations.\n        \"\"\"\n        if state:\n            for key, value in state.items():\n                if key not in [\"annotations\", \"properties\"]:\n                    self.__dict__[key] = value\n        result = {}\n        for key, value in self.__dict__.items():\n            if key not in [\"annotations\", \"properties\"] and not key.startswith(\"__\"):\n                result[key] = value\n        return result\n\n    def __setattr__(self, key, value):\n        return self.__setitem__(key, value)\n\n    def __setitem__(self, key, value):\n        if key in self.__dict__ or key in self.__class__._local_keys:\n            # If we assign like so:\n            #   entity.annotations = {'foo';123, 'bar':'bat'}\n            # Wrap the dictionary in a DictObject so we can\n            # later do:\n            #   entity.annotations.foo = 'bar'\n            if (key == \"annotations\" or key == \"properties\") and not isinstance(\n                value, DictObject\n            ):\n                value = DictObject(value)\n            self.__dict__[key] = value\n        elif key in self.__class__._property_keys:\n            self.properties[key] = value\n        else:\n            self.annotations[key] = value\n\n    # TODO: def __delattr__\n\n    def __getattr__(self, key):\n        # Note: that __getattr__ is only called after an attempt to\n        # look the key up in the object's dictionary has failed.\n        try:\n            return self.__getitem__(key)\n        except KeyError:\n            # Note that hasattr in Python2 is more permissive than Python3\n            # about what exceptions it catches. In Python3, hasattr catches\n            # only AttributeError\n            raise AttributeError(key)\n\n    def __getitem__(self, key):\n        if key in self.__dict__:\n            return self.__dict__[key]\n        elif key in self.properties:\n            return self.properties[key]\n        elif key in self.annotations:\n            return self.annotations[key]\n        else:\n            raise KeyError(key)\n\n    def __delitem__(self, key):\n        if key in self.properties:\n            del self.properties[key]\n        elif key in self.annotations:\n            del self.annotations[key]\n\n    def __iter__(self):\n        return iter(self.keys())\n\n    def __len__(self):\n        return len(self.keys())\n\n    # TODO shouldn't these include local_state as well? -jcb\n    def keys(self):\n        \"\"\"\n        Returns:\n            A set of property and annotation keys\n        \"\"\"\n        return set(self.properties.keys()) | set(self.annotations.keys())\n\n    def has_key(self, key):\n        \"\"\"Is the given key a property or annotation?\"\"\"\n\n        return key in self.properties or key in self.annotations\n\n    def _write_kvps(\n        self,\n        f: io.StringIO,\n        dictionary: dict,\n        key_filter: callable = None,\n        key_aliases: dict = None,\n    ) -&gt; None:\n        \"\"\"\n        Writes key-value pairs from a dictionary to a file.\n\n        Arguments:\n            f: The file object to write to.\n            dictionary: The dictionary containing the key-value pairs.\n            key_filter: A function that filters the keys.\n                        Only keys that pass the filter will be written to the file.\n                        Defaults to None.\n            key_aliases: A dictionary mapping keys to their alias names.\n                         If provided, the alias names will be used instead\n                         of the original keys when writing to the file.\n                         Defaults to None.\n        \"\"\"\n        for key in sorted(dictionary.keys()):\n            if (not key_filter) or key_filter(key):\n                f.write(\"  \")\n                f.write(str(key) if not key_aliases else key_aliases[key])\n                f.write(\"=\")\n                f.write(str(dictionary[key]))\n                f.write(\"\\n\")\n\n    def __str__(self):\n        \"\"\"Returns a string representation of the object.\n\n        Returns:\n            str: A string representation of the object, including the class name,\n                name property, id property (if available), properties, and annotations.\n        \"\"\"\n        f = io.StringIO()\n\n        f.write(\n            \"%s: %s (%s)\\n\"\n            % (\n                self.__class__.__name__,\n                self.properties.get(\"name\", \"None\"),\n                self[\"id\"] if \"id\" in self else \"-\",\n            )\n        )\n\n        self._str_localstate(f)\n\n        f.write(\"properties:\\n\")\n        self._write_kvps(f, self.properties)\n\n        f.write(\"annotations:\\n\")\n        self._write_kvps(f, self.annotations)\n\n        return f.getvalue()\n\n    def _str_localstate(self, f: io.StringIO) -&gt; None:\n        \"\"\"\n        Helper method for writing the string representation\n        of the local state to a StringIO object\n\n        Arguments:\n            f: a StringIO object to which the local state string will be written\n        \"\"\"\n        self._write_kvps(\n            f,\n            self.__dict__,\n            lambda key: not (\n                key in [\"properties\", \"annotations\"] or key.startswith(\"__\")\n            ),\n        )\n\n    def __repr__(self):\n        \"\"\"Returns an eval-able representation of the Entity.\"\"\"\n\n        f = io.StringIO()\n        f.write(self.__class__.__name__)\n        f.write(\"(\")\n        f.write(\n            \", \".join(\n                {\n                    \"%s=%s\"\n                    % (\n                        str(key),\n                        value.__repr__(),\n                    )\n                    for key, value in itertools.chain(\n                        list(\n                            [\n                                k_v\n                                for k_v in self.__dict__.items()\n                                if not (\n                                    k_v[0] in [\"properties\", \"annotations\"]\n                                    or k_v[0].startswith(\"__\")\n                                )\n                            ]\n                        ),\n                        self.properties.items(),\n                        self.annotations.items(),\n                    )\n                }\n            )\n        )\n        f.write(\")\")\n        return f.getvalue()\n</code></pre>"},{"location":"reference/entity/#synapseclient.entity.Entity-functions","title":"Functions","text":""},{"location":"reference/entity/#synapseclient.entity.Entity.create","title":"<code>create(properties=None, annotations=None, local_state=None)</code>  <code>classmethod</code>","text":"<p>Create an Entity or a subclass given dictionaries of properties and annotations, as might be received from the Synapse Repository.</p> PARAMETER DESCRIPTION <code>properties</code> <p>A map of Synapse properties</p> <ul> <li>If 'concreteType' is defined in properties, we create the proper subclass of Entity. If not, give back the type whose constructor was called.</li> <li>If passed an Entity as input, create a new Entity using the input entity as a prototype.</li> </ul> <p> DEFAULT: <code>None</code> </p> <code>annotations</code> <p>A map of user defined annotations</p> <p> DEFAULT: <code>None</code> </p> <code>local_state</code> <p>Internal use only</p> <p> DEFAULT: <code>None</code> </p> Source code in <code>synapseclient/entity.py</code> <pre><code>@classmethod\ndef create(cls, properties=None, annotations=None, local_state=None):\n    \"\"\"\n    Create an Entity or a subclass given dictionaries of properties and annotations, as might be received from the\n    Synapse Repository.\n\n    Arguments:\n        properties:  A map of Synapse properties\n\n            - If 'concreteType' is defined in properties, we create the proper subclass of Entity. If not, give back the\n            type whose constructor was called.\n            - If passed an Entity as input, create a new Entity using the input entity as a prototype.\n        annotations: A map of user defined annotations\n        local_state: Internal use only\n    \"\"\"\n\n    # Create a new Entity using an existing Entity as a prototype\n    if isinstance(properties, Entity):\n        if annotations is None:\n            annotations = {}\n        if local_state is None:\n            local_state = {}\n        annotations.update(properties.annotations)\n        local_state.update(properties.local_state())\n        properties = properties.properties\n        if \"id\" in properties:\n            del properties[\"id\"]\n\n    if (\n        cls == Entity\n        and \"concreteType\" in properties\n        and properties[\"concreteType\"] in entity_type_to_class\n    ):\n        cls = entity_type_to_class[properties[\"concreteType\"]]\n    return cls(\n        properties=properties, annotations=annotations, local_state=local_state\n    )\n</code></pre>"},{"location":"reference/entity/#synapseclient.entity.Entity.local_state","title":"<code>local_state(state=None)</code>","text":"<p>Set or get the object's internal state, excluding properties, or annotations.</p> PARAMETER DESCRIPTION <code>state</code> <p>A dictionary containing the object's internal state.</p> <p> TYPE: <code>dict</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>result</code> <p>The object's internal state, excluding properties, or annotations.</p> <p> TYPE: <code>dict</code> </p> Source code in <code>synapseclient/entity.py</code> <pre><code>def local_state(self, state: dict = None) -&gt; dict:\n    \"\"\"\n    Set or get the object's internal state, excluding properties, or annotations.\n\n    Arguments:\n        state: A dictionary containing the object's internal state.\n\n    Returns:\n        result: The object's internal state, excluding properties, or annotations.\n    \"\"\"\n    if state:\n        for key, value in state.items():\n            if key not in [\"annotations\", \"properties\"]:\n                self.__dict__[key] = value\n    result = {}\n    for key, value in self.__dict__.items():\n        if key not in [\"annotations\", \"properties\"] and not key.startswith(\"__\"):\n            result[key] = value\n    return result\n</code></pre>"},{"location":"reference/entity/#synapseclient.entity.Entity.keys","title":"<code>keys()</code>","text":"RETURNS DESCRIPTION <p>A set of property and annotation keys</p> Source code in <code>synapseclient/entity.py</code> <pre><code>def keys(self):\n    \"\"\"\n    Returns:\n        A set of property and annotation keys\n    \"\"\"\n    return set(self.properties.keys()) | set(self.annotations.keys())\n</code></pre>"},{"location":"reference/entity/#synapseclient.entity.Entity.has_key","title":"<code>has_key(key)</code>","text":"<p>Is the given key a property or annotation?</p> Source code in <code>synapseclient/entity.py</code> <pre><code>def has_key(self, key):\n    \"\"\"Is the given key a property or annotation?\"\"\"\n\n    return key in self.properties or key in self.annotations\n</code></pre>"},{"location":"reference/entity/#synapseclient.entity.Versionable","title":"<code>synapseclient.entity.Versionable</code>","text":"<p>               Bases: <code>object</code></p> <p>An entity for which Synapse will store a version history.</p> ATTRIBUTE DESCRIPTION <code>versionNumber</code> <p>The version number issued to this version on the object.</p> <p> </p> <code>versionLabel</code> <p>The version label for this entity</p> <p> </p> <code>versionComment</code> <p>The version comment for this entity</p> <p> </p> <code>versionUrl</code> <p>The URL for this version</p> <p> </p> <code>versions</code> <p>A list of all versions</p> <p> </p> Source code in <code>synapseclient/entity.py</code> <pre><code>class Versionable(object):\n    \"\"\"An entity for which Synapse will store a version history.\n\n    Attributes:\n        versionNumber: The version number issued to this version on the object.\n        versionLabel:  \tThe version label for this entity\n        versionComment: The version comment for this entity\n        versionUrl:     The URL for this version\n        versions:       A list of all versions\n\n    \"\"\"\n\n    _synapse_entity_type = \"org.sagebionetworks.repo.model.Versionable\"\n    _property_keys = [\n        \"versionNumber\",\n        \"versionLabel\",\n        \"versionComment\",\n        \"versionUrl\",\n        \"versions\",\n    ]\n</code></pre>"},{"location":"reference/evaluation/","title":"Evaluation","text":""},{"location":"reference/evaluation/#synapseclient.evaluation","title":"<code>synapseclient.evaluation</code>","text":""},{"location":"reference/evaluation/#synapseclient.evaluation--evaluations","title":"Evaluations","text":"<p>An Evaluation object represents a collection of Synapse Entities that will be processed in a particular way. This could mean scoring Entries in a challenge or executing a processing pipeline.</p> <p>Imports and authentication:</p> <pre><code>from synapseclient import Evaluation, Submission, SubmissionStatus, Synapse\n\nsyn = Synapse()\nsyn.login()\n</code></pre> <p>Evaluations can be retrieved by ID:</p> <pre><code>evaluation = syn.getEvaluation(1901877)\n</code></pre> <p>Like entities, evaluations are access controlled via ACLs. The synapseclient.Synapse.getPermissions and synapseclient.Synapse.setPermissions methods work for evaluations:</p> <pre><code>access = syn.getPermissions(evaluation, user_id)\n</code></pre> <p>The synapseclient.Synapse.submit method returns a Submission object:</p> <pre><code>entity = syn.get(synapse_id)\nsubmission = syn.submit(evaluation, entity, name='My Data', team='My Team')\n</code></pre> <p>The getSubmissionStatus function can then be used to check the SubmissionStatus of the submission:</p> <pre><code>status = syn.getSubmissionStatus(submission)\n</code></pre> The status of a submission may be <ul> <li>INVALID the submitted entity is in the wrong format</li> <li>SCORED in the context of a challenge or competition</li> <li>OPEN indicating processing has not completed</li> <li>CLOSED indicating processing has completed</li> </ul> <p>SubmissionStatus objects can be updated, usually by changing the status and score fields, and stored back to Synapse using synapseclient.Synapse.store:</p> <pre><code>status.score = 0.99\nstatus.status = 'SCORED'\nstatus = syn.store(status)\n</code></pre> <p>See:</p> <ul> <li>synapseclient.Synapse.getEvaluation</li> <li>synapseclient.Synapse.getEvaluationByContentSource</li> <li>synapseclient.Synapse.getEvaluationByName</li> <li>synapseclient.Synapse.submit</li> <li>synapseclient.Synapse.getSubmissions</li> <li>synapseclient.Synapse.getSubmission</li> <li>synapseclient.Synapse.getSubmissionStatus</li> <li>synapseclient.Synapse.getPermissions</li> <li>synapseclient.Synapse.setPermissions</li> </ul>"},{"location":"reference/evaluation/#synapseclient.evaluation-classes","title":"Classes","text":""},{"location":"reference/evaluation/#synapseclient.evaluation.Evaluation","title":"<code>Evaluation</code>","text":"<p>               Bases: <code>DictObject</code></p> <p>An Evaluation Submission queue, allowing submissions, retrieval and scoring.</p> PARAMETER DESCRIPTION <code>name</code> <p>Name of the evaluation</p> <p> </p> <code>description</code> <p>A short description of the evaluation</p> <p> </p> <code>contentSource</code> <p>Synapse Project associated with the evaluation</p> <p> </p> <code>submissionReceiptMessage</code> <p>Message to display to users upon submission</p> <p> </p> <code>submissionInstructionsMessage</code> <p>Message to display to users detailing acceptable formatting for submissions.</p> <p> </p> Create and store an Evaluation <p>To create an Evaluation and store it in Synapse:</p> <pre><code>import synapseclient\nfrom synapseclient import Evaluation\n\n## Initialize a Synapse object &amp; authenticate\nsyn = synapseclient.Synapse()\nsyn.login()\n\nevaluation = syn.store(Evaluation(\n    name=\"Q1 Final\",\n    description=\"Predict progression of MMSE scores for final scoring\",\n    contentSource=\"syn2290704\"))\n</code></pre> <p>The contentSource field links the evaluation to its Project (or, really, any synapse ID, but sticking to projects is a good idea).</p> <p>Evaluations can be retrieved from Synapse by ID:</p> <pre><code>evaluation = syn.getEvaluation(1901877)\n</code></pre> <p>...by the Synapse ID of the content source (associated entity):</p> <pre><code>evaluation = syn.getEvaluationByContentSource('syn12345')\n</code></pre> <p>...or by the name of the evaluation:</p> <pre><code>evaluation = syn.getEvaluationByName('Foo Challenge Question 1')\n</code></pre> Source code in <code>synapseclient/evaluation.py</code> <pre><code>class Evaluation(DictObject):\n    \"\"\"\n    An Evaluation Submission queue, allowing submissions, retrieval and scoring.\n\n    Arguments:\n        name: Name of the evaluation\n        description: A short description of the evaluation\n        contentSource: Synapse Project associated with the evaluation\n        submissionReceiptMessage: Message to display to users upon submission\n        submissionInstructionsMessage: Message to display to users detailing acceptable formatting for submissions.\n\n    Example: Create and store an Evaluation\n        To create an [Evaluation](https://rest-docs.synapse.org/rest/org/sagebionetworks/evaluation/model/Evaluation.html)\n        and store it in Synapse:\n\n            import synapseclient\n            from synapseclient import Evaluation\n\n            ## Initialize a Synapse object &amp; authenticate\n            syn = synapseclient.Synapse()\n            syn.login()\n\n            evaluation = syn.store(Evaluation(\n                name=\"Q1 Final\",\n                description=\"Predict progression of MMSE scores for final scoring\",\n                contentSource=\"syn2290704\"))\n\n    The *contentSource* field links the evaluation to its [Project][synapseclient.entity.Project]\n    (or, really, any synapse ID, but sticking to projects is a good idea).\n\n    [Evaluations](https://rest-docs.synapse.org/rest/org/sagebionetworks/evaluation/model/Evaluation.html)\n    can be retrieved from Synapse by ID:\n\n        evaluation = syn.getEvaluation(1901877)\n\n    ...by the Synapse ID of the content source (associated entity):\n\n        evaluation = syn.getEvaluationByContentSource('syn12345')\n\n    ...or by the name of the evaluation:\n\n        evaluation = syn.getEvaluationByName('Foo Challenge Question 1')\n\n    \"\"\"\n\n    @classmethod\n    def getByNameURI(cls, name: str):\n        quoted_name = urllib_urlparse.quote(name)\n        return f\"/evaluation/name/{quoted_name}\"\n\n    @classmethod\n    def getURI(cls, id: Union[str, int]):\n        return f\"/evaluation/{id}\"\n\n    def __init__(self, **kwargs):\n        kwargs[\"contentSource\"] = kwargs.get(\"contentSource\", \"\")\n        if not kwargs[\"contentSource\"].startswith(\n            \"syn\"\n        ):  # Verify that synapse Id given\n            raise ValueError(\n                'The \"contentSource\" parameter must be specified as a Synapse'\n                \" Entity when creating an Evaluation\"\n            )\n        super(Evaluation, self).__init__(kwargs)\n\n    def postURI(self):\n        return \"/evaluation\"\n\n    def putURI(self):\n        return f\"/evaluation/{self.id}\"\n\n    def deleteURI(self):\n        return f\"/evaluation/{self.id}\"\n\n    def getACLURI(self):\n        return f\"/evaluation/{self.id}/acl\"\n\n    def putACLURI(self):\n        return \"/evaluation/acl\"\n</code></pre>"},{"location":"reference/evaluation/#synapseclient.evaluation.Submission","title":"<code>Submission</code>","text":"<p>               Bases: <code>DictObject</code></p> <p>Builds a Synapse submission object.</p> PARAMETER DESCRIPTION <code>name</code> <p>Name of submission</p> <p> </p> <code>entityId</code> <p>Synapse ID of the Entity to submit</p> <p> </p> <code>evaluationId</code> <p>ID of the Evaluation to which the Entity is to be submitted</p> <p> </p> <code>versionNumber</code> <p>Version number of the submitted Entity</p> <p> </p> <code>submitterAlias</code> <p>A pseudonym or team name for a challenge entry</p> <p> </p> Source code in <code>synapseclient/evaluation.py</code> <pre><code>class Submission(DictObject):\n    \"\"\"\n    Builds a Synapse submission object.\n\n    Arguments:\n        name: Name of submission\n        entityId: Synapse ID of the Entity to submit\n        evaluationId: ID of the Evaluation to which the Entity is to be submitted\n        versionNumber: Version number of the submitted Entity\n        submitterAlias: A pseudonym or team name for a challenge entry\n    \"\"\"\n\n    @classmethod\n    def getURI(cls, id: Union[str, int]):\n        return f\"/evaluation/submission/{id}\"\n\n    def __init__(self, **kwargs):\n        if not (\n            \"evaluationId\" in kwargs\n            and \"entityId\" in kwargs\n            and \"versionNumber\" in kwargs\n        ):\n            raise KeyError\n\n        super().__init__(kwargs)\n\n    def postURI(self):\n        return f\"/evaluation/submission?etag={self.etag}\"\n\n    def putURI(self):\n        return f\"/evaluation/submission/{self.id}\"\n\n    def deleteURI(self):\n        return f\"/evaluation/submission/{self.id}\"\n</code></pre>"},{"location":"reference/evaluation/#synapseclient.evaluation.SubmissionStatus","title":"<code>SubmissionStatus</code>","text":"<p>               Bases: <code>DictObject</code></p> <p>Builds an Synapse submission status object. https://rest-docs.synapse.org/rest/org/sagebionetworks/evaluation/model/SubmissionStatus.html</p> PARAMETER DESCRIPTION <code>id</code> <p>Unique immutable Synapse Id of the Submission</p> <p> TYPE: <code>Union[str, int]</code> </p> <code>status</code> <p>Status can be one of        https://rest-docs.synapse.org/rest/org/sagebionetworks/evaluation/model/SubmissionStatusEnum.html.</p> <p> </p> <code>submissionAnnotations</code> <p>synapseclient.Annotations to store annotations of submission</p> <p> </p> <code>canCancel</code> <p>Can this submission be cancelled?</p> <p> </p> <code>cancelRequested</code> <p>Has user requested to cancel this submission?</p> <p> </p> Source code in <code>synapseclient/evaluation.py</code> <pre><code>class SubmissionStatus(DictObject):\n    \"\"\"\n    Builds an Synapse submission status object.\n    &lt;https://rest-docs.synapse.org/rest/org/sagebionetworks/evaluation/model/SubmissionStatus.html&gt;\n\n    Arguments:\n        id: Unique immutable Synapse Id of the Submission\n        status: Status can be one of\n                   &lt;https://rest-docs.synapse.org/rest/org/sagebionetworks/evaluation/model/SubmissionStatusEnum.html&gt;.\n        submissionAnnotations: synapseclient.Annotations to store annotations of submission\n        canCancel: Can this submission be cancelled?\n        cancelRequested: Has user requested to cancel this submission?\n    \"\"\"\n\n    @classmethod\n    def getURI(cls, id: Union[str, int]):\n        return f\"/evaluation/submission/{id}/status\"\n\n    def __init__(self, id: Union[str, int], etag: str, **kwargs):\n        annotations = kwargs.pop(\"submissionAnnotations\", {})\n        # If it is synapse annotations, turn into a format\n        # that can be worked with otherwise, create\n        # synapseclient.Annotations\n        submission_annotations = _convert_to_annotation_cls(\n            id=id, etag=etag, values=annotations\n        )\n        # In Python 3, the super(SubmissionStatus, self) call is equivalent to the parameterless super()\n        super().__init__(\n            id=id,\n            etag=etag,\n            submissionAnnotations=submission_annotations,\n            **kwargs,\n        )\n\n    # def postURI(self):\n    #     return '/evaluation/submission/%s/status' % self.id\n\n    def putURI(self):\n        return f\"/evaluation/submission/{self.id}/status\"\n\n    # def deleteURI(self):\n    #     return '/evaluation/submission/%s/status' % self.id\n\n    def json(self, ensure_ascii: bool = True):\n        \"\"\"Overloaded json function, turning submissionAnnotations into\n        synapse style annotations.\n\n        Arguments:\n            ensure_ascii: (default = True) If false, then the return value can contain non-ASCII\n            characters. Otherwise, all such characters are escaped in JSON strings.\n        Returns:\n            A Synapse-style JSON dictionary of annotations.\n        \"\"\"\n\n        json_dict = self\n        # If not synapse annotations, turn them into synapseclient.Annotations\n        # must have id and etag to turn into synapse annotations\n        if not is_synapse_annotations(self.submissionAnnotations):\n            json_dict = self.copy()\n\n            annotations = _convert_to_annotation_cls(\n                id=self.id, etag=self.etag, values=self.submissionAnnotations\n            )\n            # Turn into synapse annotation\n            json_dict[\"submissionAnnotations\"] = to_synapse_annotations(annotations)\n        return json.dumps(\n            json_dict, sort_keys=True, indent=2, ensure_ascii=ensure_ascii\n        )\n</code></pre>"},{"location":"reference/evaluation/#synapseclient.evaluation.SubmissionStatus-functions","title":"Functions","text":""},{"location":"reference/evaluation/#synapseclient.evaluation.SubmissionStatus.json","title":"<code>json(ensure_ascii=True)</code>","text":"<p>Overloaded json function, turning submissionAnnotations into synapse style annotations.</p> PARAMETER DESCRIPTION <code>ensure_ascii</code> <p>(default = True) If false, then the return value can contain non-ASCII</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> <p>Returns:     A Synapse-style JSON dictionary of annotations.</p> Source code in <code>synapseclient/evaluation.py</code> <pre><code>def json(self, ensure_ascii: bool = True):\n    \"\"\"Overloaded json function, turning submissionAnnotations into\n    synapse style annotations.\n\n    Arguments:\n        ensure_ascii: (default = True) If false, then the return value can contain non-ASCII\n        characters. Otherwise, all such characters are escaped in JSON strings.\n    Returns:\n        A Synapse-style JSON dictionary of annotations.\n    \"\"\"\n\n    json_dict = self\n    # If not synapse annotations, turn them into synapseclient.Annotations\n    # must have id and etag to turn into synapse annotations\n    if not is_synapse_annotations(self.submissionAnnotations):\n        json_dict = self.copy()\n\n        annotations = _convert_to_annotation_cls(\n            id=self.id, etag=self.etag, values=self.submissionAnnotations\n        )\n        # Turn into synapse annotation\n        json_dict[\"submissionAnnotations\"] = to_synapse_annotations(annotations)\n    return json.dumps(\n        json_dict, sort_keys=True, indent=2, ensure_ascii=ensure_ascii\n    )\n</code></pre>"},{"location":"reference/evaluation/#synapseclient.evaluation-functions","title":"Functions","text":""},{"location":"reference/exceptions/","title":"Exceptions","text":""},{"location":"reference/exceptions/#synapseclient.core.exceptions","title":"<code>synapseclient.core.exceptions</code>","text":"<p>Contains all of the exceptions that can be thrown within this Python client as well as handling error cases for HTTP requests.</p>"},{"location":"reference/exceptions/#synapseclient.core.exceptions-classes","title":"Classes","text":""},{"location":"reference/exceptions/#synapseclient.core.exceptions.SynapseError","title":"<code>SynapseError</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Generic exception thrown by the client.</p> Source code in <code>synapseclient/core/exceptions.py</code> <pre><code>class SynapseError(Exception):\n    \"\"\"Generic exception thrown by the client.\"\"\"\n</code></pre>"},{"location":"reference/exceptions/#synapseclient.core.exceptions.SynapseMd5MismatchError","title":"<code>SynapseMd5MismatchError</code>","text":"<p>               Bases: <code>SynapseError</code>, <code>IOError</code></p> <p>Error raised when MD5 computed for a download file fails to match the MD5 of its file handle.</p> Source code in <code>synapseclient/core/exceptions.py</code> <pre><code>class SynapseMd5MismatchError(SynapseError, IOError):\n    \"\"\"Error raised when MD5 computed for a download file fails to match the MD5 of its file handle.\"\"\"\n</code></pre>"},{"location":"reference/exceptions/#synapseclient.core.exceptions.SynapseFileNotFoundError","title":"<code>SynapseFileNotFoundError</code>","text":"<p>               Bases: <code>SynapseError</code></p> <p>Error thrown when a local file is not found in Synapse.</p> Source code in <code>synapseclient/core/exceptions.py</code> <pre><code>class SynapseFileNotFoundError(SynapseError):\n    \"\"\"Error thrown when a local file is not found in Synapse.\"\"\"\n</code></pre>"},{"location":"reference/exceptions/#synapseclient.core.exceptions.SynapseNotFoundError","title":"<code>SynapseNotFoundError</code>","text":"<p>               Bases: <code>SynapseError</code></p> <p>Error thrown when a requested resource is not found in Synapse.</p> Source code in <code>synapseclient/core/exceptions.py</code> <pre><code>class SynapseNotFoundError(SynapseError):\n    \"\"\"Error thrown when a requested resource is not found in Synapse.\"\"\"\n</code></pre>"},{"location":"reference/exceptions/#synapseclient.core.exceptions.SynapseTimeoutError","title":"<code>SynapseTimeoutError</code>","text":"<p>               Bases: <code>SynapseError</code></p> <p>Timed out waiting for response from Synapse.</p> Source code in <code>synapseclient/core/exceptions.py</code> <pre><code>class SynapseTimeoutError(SynapseError):\n    \"\"\"Timed out waiting for response from Synapse.\"\"\"\n</code></pre>"},{"location":"reference/exceptions/#synapseclient.core.exceptions.SynapseAuthenticationError","title":"<code>SynapseAuthenticationError</code>","text":"<p>               Bases: <code>SynapseError</code></p> <p>Authentication errors.</p> Source code in <code>synapseclient/core/exceptions.py</code> <pre><code>class SynapseAuthenticationError(SynapseError):\n    \"\"\"Authentication errors.\"\"\"\n</code></pre>"},{"location":"reference/exceptions/#synapseclient.core.exceptions.SynapseAuthorizationError","title":"<code>SynapseAuthorizationError</code>","text":"<p>               Bases: <code>SynapseError</code></p> <p>Authorization errors.</p> Source code in <code>synapseclient/core/exceptions.py</code> <pre><code>class SynapseAuthorizationError(SynapseError):\n    \"\"\"Authorization errors.\"\"\"\n</code></pre>"},{"location":"reference/exceptions/#synapseclient.core.exceptions.SynapseNoCredentialsError","title":"<code>SynapseNoCredentialsError</code>","text":"<p>               Bases: <code>SynapseAuthenticationError</code></p> <p>No credentials for authentication</p> Source code in <code>synapseclient/core/exceptions.py</code> <pre><code>class SynapseNoCredentialsError(SynapseAuthenticationError):\n    \"\"\"No credentials for authentication\"\"\"\n</code></pre>"},{"location":"reference/exceptions/#synapseclient.core.exceptions.SynapseFileCacheError","title":"<code>SynapseFileCacheError</code>","text":"<p>               Bases: <code>SynapseError</code></p> <p>Error related to local file storage.</p> Source code in <code>synapseclient/core/exceptions.py</code> <pre><code>class SynapseFileCacheError(SynapseError):\n    \"\"\"Error related to local file storage.\"\"\"\n</code></pre>"},{"location":"reference/exceptions/#synapseclient.core.exceptions.SynapseMalformedEntityError","title":"<code>SynapseMalformedEntityError</code>","text":"<p>               Bases: <code>SynapseError</code></p> <p>Unexpected structure of Entities.</p> Source code in <code>synapseclient/core/exceptions.py</code> <pre><code>class SynapseMalformedEntityError(SynapseError):\n    \"\"\"Unexpected structure of Entities.\"\"\"\n</code></pre>"},{"location":"reference/exceptions/#synapseclient.core.exceptions.SynapseUnmetAccessRestrictions","title":"<code>SynapseUnmetAccessRestrictions</code>","text":"<p>               Bases: <code>SynapseError</code></p> <p>Request cannot be completed due to unmet access restrictions.</p> Source code in <code>synapseclient/core/exceptions.py</code> <pre><code>class SynapseUnmetAccessRestrictions(SynapseError):\n    \"\"\"Request cannot be completed due to unmet access restrictions.\"\"\"\n</code></pre>"},{"location":"reference/exceptions/#synapseclient.core.exceptions.SynapseProvenanceError","title":"<code>SynapseProvenanceError</code>","text":"<p>               Bases: <code>SynapseError</code></p> <p>Incorrect usage of provenance objects.</p> Source code in <code>synapseclient/core/exceptions.py</code> <pre><code>class SynapseProvenanceError(SynapseError):\n    \"\"\"Incorrect usage of provenance objects.\"\"\"\n</code></pre>"},{"location":"reference/exceptions/#synapseclient.core.exceptions.SynapseHTTPError","title":"<code>SynapseHTTPError</code>","text":"<p>               Bases: <code>SynapseError</code>, <code>HTTPError</code></p> <p>Wraps recognized HTTP errors.  See <code>HTTPError &lt;http://docs.python-requests.org/en/latest/api/?highlight=exceptions#requests.exceptions.HTTPError&gt;</code>_</p> Source code in <code>synapseclient/core/exceptions.py</code> <pre><code>class SynapseHTTPError(SynapseError, requests.exceptions.HTTPError):\n    \"\"\"Wraps recognized HTTP errors.  See\n    `HTTPError &lt;http://docs.python-requests.org/en/latest/api/?highlight=exceptions#requests.exceptions.HTTPError&gt;`_\n    \"\"\"\n</code></pre>"},{"location":"reference/exceptions/#synapseclient.core.exceptions.SynapseUploadAbortedException","title":"<code>SynapseUploadAbortedException</code>","text":"<p>               Bases: <code>SynapseError</code></p> <p>Raised when a worker thread detects the upload was aborted and stops further processing.</p> Source code in <code>synapseclient/core/exceptions.py</code> <pre><code>class SynapseUploadAbortedException(SynapseError):\n    \"\"\"Raised when a worker thread detects the upload was\n    aborted and stops further processing.\"\"\"\n</code></pre>"},{"location":"reference/exceptions/#synapseclient.core.exceptions.SynapseDownloadAbortedException","title":"<code>SynapseDownloadAbortedException</code>","text":"<p>               Bases: <code>SynapseError</code></p> <p>Raised when a worker thread detects the download was aborted and stops further processing.</p> Source code in <code>synapseclient/core/exceptions.py</code> <pre><code>class SynapseDownloadAbortedException(SynapseError):\n    \"\"\"Raised when a worker thread detects the download was\n    aborted and stops further processing.\"\"\"\n</code></pre>"},{"location":"reference/exceptions/#synapseclient.core.exceptions.SynapseUploadFailedException","title":"<code>SynapseUploadFailedException</code>","text":"<p>               Bases: <code>SynapseError</code></p> <p>Raised when an upload failed. Should be chained to a cause Exception</p> Source code in <code>synapseclient/core/exceptions.py</code> <pre><code>class SynapseUploadFailedException(SynapseError):\n    \"\"\"Raised when an upload failed. Should be chained to a cause Exception\"\"\"\n</code></pre>"},{"location":"reference/file/","title":"File","text":""},{"location":"reference/file/#synapseclient.entity.File","title":"<code>synapseclient.entity.File</code>","text":"<p>               Bases: <code>Entity</code>, <code>Versionable</code></p> <p>Represents a file in Synapse.</p> <p>When a File object is stored, the associated local file or its URL will be stored in Synapse. A File must have a path (or URL) and a parent. By default, the name of the file in Synapse matches the filename, but by specifying the <code>name</code> attribute, the File Entity name can be different.</p>"},{"location":"reference/file/#synapseclient.entity.File--changing-file-names","title":"Changing File Names","text":"<p>A Synapse File Entity has a name separate from the name of the actual file it represents. When a file is uploaded to Synapse, its filename is fixed, even though the name of the entity can be changed at any time. Synapse provides a way to change this filename and the content-type of the file for future downloads by creating a new version of the file with a modified copy of itself. This can be done with the synapseutils.copy_functions.changeFileMetaData function.</p> <pre><code>import synapseutils\ne = syn.get(synid)\nprint(os.path.basename(e.path))  ## prints, e.g., \"my_file.txt\"\ne = synapseutils.changeFileMetaData(syn, e, \"my_newname_file.txt\")\n</code></pre> <p>Setting fileNameOverride will not change the name of a copy of the file that's already downloaded into your local cache. Either rename the local copy manually or remove it from the cache and re-download.:</p> <pre><code>syn.cache.remove(e.dataFileHandleId)\ne = syn.get(e)\nprint(os.path.basename(e.path))  ## prints \"my_newname_file.txt\"\n</code></pre> PARAMETER DESCRIPTION <code>path</code> <p>Location to be represented by this File</p> <p> DEFAULT: <code>None</code> </p> <code>name</code> <p>Name of the file in Synapse, not to be confused with the name within the path</p> <p> </p> <code>parent</code> <p>Project or Folder where this File is stored</p> <p> DEFAULT: <code>None</code> </p> <code>synapseStore</code> <p>Whether the File should be uploaded or if only the path should             be stored when synapseclient.Synapse.store is called on the File object.</p> <p> DEFAULT: <code>True</code> </p> <code>contentType</code> <p>Manually specify Content-type header, for example \"application/png\" or             \"application/json; charset=UTF-8\"</p> <p> </p> <code>dataFileHandleId</code> <p>Defining an existing dataFileHandleId will use the existing dataFileHandleId                 The creator of the file must also be the owner of the dataFileHandleId                 to have permission to store the file.</p> <p> </p> <code>properties</code> <p>A map of Synapse properties</p> <p> DEFAULT: <code>None</code> </p> <code>annotations</code> <p>A map of user defined annotations</p> <p> DEFAULT: <code>None</code> </p> <code>local_state</code> <p>Internal use only</p> <p> DEFAULT: <code>None</code> </p> Creating instances <p>Creating and storing a File</p> <pre><code># The Entity name is derived from the path and is 'data.xyz'\ndata = File('/path/to/file/data.xyz', parent=folder)\ndata = syn.store(data)\n</code></pre> <p>Setting the name of the file in Synapse to 'my entity'</p> <pre><code># The Entity name is specified as 'my entity'\ndata = File('/path/to/file/data.xyz', name=\"my entity\", parent=folder)\ndata = syn.store(data)\n</code></pre> Source code in <code>synapseclient/entity.py</code> <pre><code>class File(Entity, Versionable):\n    \"\"\"\n    Represents a file in Synapse.\n\n    When a File object is stored, the associated local file or its URL will be stored in Synapse.\n    A File must have a path (or URL) and a parent. By default, the name of the file in Synapse\n    matches the filename, but by specifying the `name` attribute, the File Entity name can be different.\n\n    ## Changing File Names\n\n    A Synapse File Entity has a name separate from the name of the actual file it represents.\n    When a file is uploaded to Synapse, its filename is fixed, even though the name of the entity\n    can be changed at any time. Synapse provides a way to change this filename and the\n    content-type of the file for future downloads by creating a new version of the file\n    with a modified copy of itself. This can be done with the\n    [synapseutils.copy_functions.changeFileMetaData][] function.\n\n        import synapseutils\n        e = syn.get(synid)\n        print(os.path.basename(e.path))  ## prints, e.g., \"my_file.txt\"\n        e = synapseutils.changeFileMetaData(syn, e, \"my_newname_file.txt\")\n\n    Setting *fileNameOverride* will **not** change the name of a copy of the\n    file that's already downloaded into your local cache. Either rename the\n    local copy manually or remove it from the cache and re-download.:\n\n        syn.cache.remove(e.dataFileHandleId)\n        e = syn.get(e)\n        print(os.path.basename(e.path))  ## prints \"my_newname_file.txt\"\n\n    Parameters:\n        path: Location to be represented by this File\n        name: Name of the file in Synapse, not to be confused with the name within the path\n        parent: Project or Folder where this File is stored\n        synapseStore: Whether the File should be uploaded or if only the path should\n                        be stored when [synapseclient.Synapse.store][] is called on the File object.\n        contentType: Manually specify Content-type header, for example \"application/png\" or\n                        \"application/json; charset=UTF-8\"\n        dataFileHandleId: Defining an existing dataFileHandleId will use the existing dataFileHandleId\n                            The creator of the file must also be the owner of the dataFileHandleId\n                            to have permission to store the file.\n        properties: A map of Synapse properties\n        annotations: A map of user defined annotations\n        local_state: Internal use only\n\n    Example: Creating instances\n        Creating and storing a File\n\n            # The Entity name is derived from the path and is 'data.xyz'\n            data = File('/path/to/file/data.xyz', parent=folder)\n            data = syn.store(data)\n\n        Setting the name of the file in Synapse to 'my entity'\n\n            # The Entity name is specified as 'my entity'\n            data = File('/path/to/file/data.xyz', name=\"my entity\", parent=folder)\n            data = syn.store(data)\n    \"\"\"\n\n    # Note: externalURL technically should not be in the keys since it's only a field/member variable of\n    # ExternalFileHandle, but for backwards compatibility it's included\n    _file_handle_keys = [\n        \"createdOn\",\n        \"id\",\n        \"concreteType\",\n        \"contentSize\",\n        \"createdBy\",\n        \"etag\",\n        \"fileName\",\n        \"contentType\",\n        \"contentMd5\",\n        \"storageLocationId\",\n        \"externalURL\",\n    ]\n    # Used for backwards compatability. The keys found below used to located in the entity's local_state\n    # (i.e. __dict__).\n    _file_handle_aliases = {\n        \"md5\": \"contentMd5\",\n        \"externalURL\": \"externalURL\",\n        \"fileSize\": \"contentSize\",\n        \"contentType\": \"contentType\",\n    }\n    _file_handle_aliases_inverse = {v: k for k, v in _file_handle_aliases.items()}\n\n    _property_keys = (\n        Entity._property_keys + Versionable._property_keys + [\"dataFileHandleId\"]\n    )\n    _local_keys = Entity._local_keys + [\n        \"path\",\n        \"cacheDir\",\n        \"files\",\n        \"synapseStore\",\n        \"_file_handle\",\n    ]\n    _synapse_entity_type = \"org.sagebionetworks.repo.model.FileEntity\"\n\n    # TODO: File(path=\"/path/to/file\", synapseStore=True, parentId=\"syn101\")\n    def __init__(\n        self,\n        path=None,\n        parent=None,\n        synapseStore=True,\n        properties=None,\n        annotations=None,\n        local_state=None,\n        **kwargs,\n    ):\n        if path and \"name\" not in kwargs:\n            kwargs[\"name\"] = utils.guess_file_name(path)\n        self.__dict__[\"path\"] = path\n        if path:\n            cacheDir, basename = os.path.split(path)\n            self.__dict__[\"cacheDir\"] = cacheDir\n            self.__dict__[\"files\"] = [basename]\n        else:\n            self.__dict__[\"cacheDir\"] = None\n            self.__dict__[\"files\"] = []\n        self.__dict__[\"synapseStore\"] = synapseStore\n\n        # pop the _file_handle from local properties because it is handled differently from other local_state\n        self._update_file_handle(\n            local_state.pop(\"_file_handle\", None) if (local_state is not None) else None\n        )\n\n        super(File, self).__init__(\n            concreteType=File._synapse_entity_type,\n            properties=properties,\n            annotations=annotations,\n            local_state=local_state,\n            parent=parent,\n            **kwargs,\n        )\n\n    def _update_file_handle(self, file_handle_update_dict=None):\n        \"\"\"Sets the file handle. Should not need to be called by users.\n\n        Args:\n            file_handle_update_dict: A dictionary containing the file handle information.\n        \"\"\"\n\n        # replace the file handle dict\n        fh_dict = (\n            DictObject(file_handle_update_dict)\n            if file_handle_update_dict is not None\n            else DictObject()\n        )\n        self.__dict__[\"_file_handle\"] = fh_dict\n\n        if (\n            file_handle_update_dict is not None\n            and file_handle_update_dict.get(\"concreteType\")\n            == \"org.sagebionetworks.repo.model.file.ExternalFileHandle\"\n            and urllib_parse.urlparse(file_handle_update_dict.get(\"externalURL\")).scheme\n            != \"sftp\"\n        ):\n            self.__dict__[\"synapseStore\"] = False\n\n        # initialize all nonexistent keys to have value of None\n        for key in self.__class__._file_handle_keys:\n            if key not in fh_dict:\n                fh_dict[key] = None\n\n    def __setitem__(self, key, value):\n        if key == \"_file_handle\":\n            self._update_file_handle(value)\n        elif key in self.__class__._file_handle_aliases:\n            self._file_handle[self.__class__._file_handle_aliases[key]] = value\n        else:\n\n            def expand_and_convert_to_URL(path):\n                return utils.as_url(os.path.expandvars(os.path.expanduser(path)))\n\n            # hacky solution to allowing immediate switching into a ExternalFileHandle pointing to the current path\n            # yes, there is boolean zen but I feel like it is easier to read/understand this way\n            if (\n                key == \"synapseStore\"\n                and value is False\n                and self[\"synapseStore\"] is True\n                and utils.caller_module_name(inspect.currentframe()) != \"client\"\n            ):\n                self[\"externalURL\"] = expand_and_convert_to_URL(self[\"path\"])\n\n            # hacky solution because we historically allowed modifying 'path' to indicate wanting to change to a new\n            # ExternalFileHandle\n            # don't change exernalURL if it's just the synapseclient setting metadata after a function call such as\n            # syn.get()\n            if (\n                key == \"path\"\n                and not self[\"synapseStore\"]\n                and utils.caller_module_name(inspect.currentframe()) != \"client\"\n                and utils.caller_module_name(inspect.currentframe())\n                != \"download_functions\"\n            ):\n                self[\"externalURL\"] = expand_and_convert_to_URL(value)\n                self[\"contentMd5\"] = None\n                self[\"contentSize\"] = None\n            super(File, self).__setitem__(key, value)\n\n    def __getitem__(self, item):\n        if item in self.__class__._file_handle_aliases:\n            return self._file_handle[self.__class__._file_handle_aliases[item]]\n        else:\n            return super(File, self).__getitem__(item)\n\n    def _str_localstate(self, f):\n        self._write_kvps(\n            f,\n            self._file_handle,\n            lambda key: key\n            in [\"externalURL\", \"contentMd5\", \"contentSize\", \"contentType\"],\n            self._file_handle_aliases_inverse,\n        )\n        self._write_kvps(\n            f,\n            self.__dict__,\n            lambda key: not (\n                key in [\"properties\", \"annotations\", \"_file_handle\"]\n                or key.startswith(\"__\")\n            ),\n        )\n</code></pre>"},{"location":"reference/folder/","title":"Folder","text":""},{"location":"reference/folder/#synapseclient.entity.Folder","title":"<code>synapseclient.entity.Folder</code>","text":"<p>               Bases: <code>Entity</code></p> <p>Represents a folder in Synapse.</p> <p>Folders must have a name and a parent and can optionally have annotations.</p> ATTRIBUTE DESCRIPTION <code>name</code> <p>The name of the folder</p> <p> </p> <code>parent</code> <p>The parent project or folder</p> <p> </p> <code>properties</code> <p>A map of Synapse properties</p> <p> </p> <code>annotations</code> <p>A map of user defined annotations</p> <p> </p> <code>local_state</code> <p>Internal use only</p> <p> </p> Using this class <p>Creating an instance and storing the folder</p> <pre><code>folder = Folder(name='my data', parent=project)\nfolder = syn.store(folder)\n</code></pre> Source code in <code>synapseclient/entity.py</code> <pre><code>class Folder(Entity):\n    \"\"\"\n    Represents a folder in Synapse.\n\n    Folders must have a name and a parent and can optionally have annotations.\n\n    Attributes:\n        name: The name of the folder\n        parent: The parent project or folder\n        properties: A map of Synapse properties\n        annotations: A map of user defined annotations\n        local_state: Internal use only\n\n    Example: Using this class\n        Creating an instance and storing the folder\n\n            folder = Folder(name='my data', parent=project)\n            folder = syn.store(folder)\n    \"\"\"\n\n    _synapse_entity_type = \"org.sagebionetworks.repo.model.Folder\"\n\n    def __init__(\n        self,\n        name=None,\n        parent=None,\n        properties=None,\n        annotations=None,\n        local_state=None,\n        **kwargs,\n    ):\n        if name:\n            kwargs[\"name\"] = name\n        super(Folder, self).__init__(\n            concreteType=Folder._synapse_entity_type,\n            properties=properties,\n            annotations=annotations,\n            local_state=local_state,\n            parent=parent,\n            **kwargs,\n        )\n</code></pre>"},{"location":"reference/json_schema/","title":"JSON Schema","text":""},{"location":"reference/json_schema/#synapseclient.services.json_schema","title":"<code>synapseclient.services.json_schema</code>","text":"<p>JSON Schema</p> <p>.. warning::     This is a beta implementation and is subject to change.  Use at your own risk.</p>"},{"location":"reference/json_schema/#synapseclient.services.json_schema-classes","title":"Classes","text":""},{"location":"reference/json_schema/#synapseclient.services.json_schema.JsonSchemaVersion","title":"<code>JsonSchemaVersion</code>","text":"<p>Json schema version response object</p> <p>:param organization:     JSON schema organization. :type organization:      JsonSchemaOrganization :param name:             Name of the JSON schema. :type name:              str :param semantic_version: Version of JSON schema. Defaults to None. :type semantic_version:  str, optional</p> Source code in <code>synapseclient/services/json_schema.py</code> <pre><code>class JsonSchemaVersion:\n    \"\"\"Json schema version response object\n\n    :param organization:     JSON schema organization.\n    :type organization:      JsonSchemaOrganization\n    :param name:             Name of the JSON schema.\n    :type name:              str\n    :param semantic_version: Version of JSON schema. Defaults to None.\n    :type semantic_version:  str, optional\n    \"\"\"\n\n    def __init__(\n        self,\n        organization: JsonSchemaOrganization,\n        name: str,\n        semantic_version: str = None,\n    ) -&gt; None:\n        self.organization = organization\n        self.name = name\n        self.semantic_version = semantic_version\n        self.uri = None\n        self.version_id = None\n        self.created_on = None\n        self.created_by = None\n        self.json_sha256_hex = None\n        self.set_service(self.organization.service)\n\n    def __repr__(self):\n        string = (\n            f\"JsonSchemaVersion(org={self.organization.name!r}, name={self.name!r}, \"\n            f\"version={self.semantic_version!r})\"\n        )\n        return string\n\n    def set_service(self, service):\n        self.service = service\n\n    @property\n    def raw(self):\n        self.must_get()\n        return self._raw\n\n    def parse_response(self, response):\n        self._raw = response\n        self.uri = response[\"$id\"]\n        self.version_id = response[\"versionId\"]\n        self.created_on = response[\"createdOn\"]\n        self.created_by = response[\"createdBy\"]\n        self.json_sha256_hex = response[\"jsonSHA256Hex\"]\n\n    @classmethod\n    def from_response(cls, organization, response):\n        semver = response.get(\"semanticVersion\")\n        version = cls(organization, response[\"schemaName\"], semver)\n        version.parse_response(response)\n        return version\n\n    def get(self):\n        \"\"\"Get the JSON Schema Version\"\"\"\n        if self.uri is not None:\n            return True\n        json_schema = self.organization.get_json_schema(self.name)\n        if json_schema is None:\n            return False\n        raw_version = json_schema.get_version(self.semantic_version, raw=True)\n        if raw_version is None:\n            return False\n        self.parse_response(raw_version)\n        return True\n\n    def must_get(self):\n        already_exists = self.get()\n        assert already_exists, (\n            \"This operation requires that the JSON Schema name is created first.\"\n            \"Call the 'create_version()' method to trigger the creation.\"\n        )\n\n    def create(\n        self,\n        json_schema_body: dict,\n        dry_run: bool = False,\n    ):\n        \"\"\"Create JSON schema version\n\n        :param json_schema_body: JSON schema body\n        :type json_schema_body:  dict\n        :param dry_run:          Do not store to Synapse. Defaults to False.\n        :type dry_run:           bool, optional\n        :returns: JSON Schema\n        \"\"\"\n        uri = f\"{self.organization.name}-{self.name}\"\n        if self.semantic_version:\n            uri = f\"{uri}-{self.semantic_version}\"\n        json_schema_body[\"$id\"] = uri\n        response = self.service.create_json_schema(json_schema_body, dry_run)\n        if dry_run:\n            return response\n        raw_version = response[\"newVersionInfo\"]\n        self.parse_response(raw_version)\n        return self\n\n    def delete(self):\n        \"\"\"Delete the JSON schema version\"\"\"\n        self.must_get()\n        response = self.service.delete_json_schema(self.uri)\n        return response\n\n    @property\n    def body(self):\n        self.must_get()\n        json_schema_body = self.service.get_json_schema_body(self.uri)\n        return json_schema_body\n\n    def expand(self):\n        \"\"\"Validate entities with schema\"\"\"\n        self.must_get()\n        response = self.service.json_schema_validation(self.uri)\n        json_schema_body = response[\"validationSchema\"]\n        return json_schema_body\n\n    def bind_to_object(self, synapse_id: str):\n        \"\"\"Bind schema to an entity\n\n        :param synapse_id: Synapse Id to bind json schema to.\n        :type synapse_id:  str\n        \"\"\"\n        self.must_get()\n        response = self.service.bind_json_schema_to_entity(synapse_id, self.uri)\n        return response\n</code></pre>"},{"location":"reference/json_schema/#synapseclient.services.json_schema.JsonSchemaVersion-functions","title":"Functions","text":""},{"location":"reference/json_schema/#synapseclient.services.json_schema.JsonSchemaVersion.get","title":"<code>get()</code>","text":"<p>Get the JSON Schema Version</p> Source code in <code>synapseclient/services/json_schema.py</code> <pre><code>def get(self):\n    \"\"\"Get the JSON Schema Version\"\"\"\n    if self.uri is not None:\n        return True\n    json_schema = self.organization.get_json_schema(self.name)\n    if json_schema is None:\n        return False\n    raw_version = json_schema.get_version(self.semantic_version, raw=True)\n    if raw_version is None:\n        return False\n    self.parse_response(raw_version)\n    return True\n</code></pre>"},{"location":"reference/json_schema/#synapseclient.services.json_schema.JsonSchemaVersion.create","title":"<code>create(json_schema_body, dry_run=False)</code>","text":"<p>Create JSON schema version</p> <p>:param json_schema_body: JSON schema body :type json_schema_body:  dict :param dry_run:          Do not store to Synapse. Defaults to False. :type dry_run:           bool, optional :returns: JSON Schema</p> Source code in <code>synapseclient/services/json_schema.py</code> <pre><code>def create(\n    self,\n    json_schema_body: dict,\n    dry_run: bool = False,\n):\n    \"\"\"Create JSON schema version\n\n    :param json_schema_body: JSON schema body\n    :type json_schema_body:  dict\n    :param dry_run:          Do not store to Synapse. Defaults to False.\n    :type dry_run:           bool, optional\n    :returns: JSON Schema\n    \"\"\"\n    uri = f\"{self.organization.name}-{self.name}\"\n    if self.semantic_version:\n        uri = f\"{uri}-{self.semantic_version}\"\n    json_schema_body[\"$id\"] = uri\n    response = self.service.create_json_schema(json_schema_body, dry_run)\n    if dry_run:\n        return response\n    raw_version = response[\"newVersionInfo\"]\n    self.parse_response(raw_version)\n    return self\n</code></pre>"},{"location":"reference/json_schema/#synapseclient.services.json_schema.JsonSchemaVersion.delete","title":"<code>delete()</code>","text":"<p>Delete the JSON schema version</p> Source code in <code>synapseclient/services/json_schema.py</code> <pre><code>def delete(self):\n    \"\"\"Delete the JSON schema version\"\"\"\n    self.must_get()\n    response = self.service.delete_json_schema(self.uri)\n    return response\n</code></pre>"},{"location":"reference/json_schema/#synapseclient.services.json_schema.JsonSchemaVersion.expand","title":"<code>expand()</code>","text":"<p>Validate entities with schema</p> Source code in <code>synapseclient/services/json_schema.py</code> <pre><code>def expand(self):\n    \"\"\"Validate entities with schema\"\"\"\n    self.must_get()\n    response = self.service.json_schema_validation(self.uri)\n    json_schema_body = response[\"validationSchema\"]\n    return json_schema_body\n</code></pre>"},{"location":"reference/json_schema/#synapseclient.services.json_schema.JsonSchemaVersion.bind_to_object","title":"<code>bind_to_object(synapse_id)</code>","text":"<p>Bind schema to an entity</p> <p>:param synapse_id: Synapse Id to bind json schema to. :type synapse_id:  str</p> Source code in <code>synapseclient/services/json_schema.py</code> <pre><code>def bind_to_object(self, synapse_id: str):\n    \"\"\"Bind schema to an entity\n\n    :param synapse_id: Synapse Id to bind json schema to.\n    :type synapse_id:  str\n    \"\"\"\n    self.must_get()\n    response = self.service.bind_json_schema_to_entity(synapse_id, self.uri)\n    return response\n</code></pre>"},{"location":"reference/json_schema/#synapseclient.services.json_schema.JsonSchema","title":"<code>JsonSchema</code>","text":"<p>Json schema response object</p> <p>:param organization:     JSON schema organization. :type organization:      JsonSchemaOrganization :param name:             Name of the JSON schema. :type name:              str</p> Source code in <code>synapseclient/services/json_schema.py</code> <pre><code>class JsonSchema:\n    \"\"\"Json schema response object\n\n    :param organization:     JSON schema organization.\n    :type organization:      JsonSchemaOrganization\n    :param name:             Name of the JSON schema.\n    :type name:              str\n    \"\"\"\n\n    def __init__(self, organization: JsonSchemaOrganization, name: str) -&gt; None:\n        self.organization = organization\n        self.name = name\n        self.id = None\n        self.created_on = None\n        self.created_by = None\n        self._versions = dict()\n        self.set_service(self.organization.service)\n\n    def __repr__(self):\n        string = f\"JsonSchema(org={self.organization.name!r}, name={self.name!r})\"\n        return string\n\n    def set_service(self, service):\n        self.service = service\n\n    @property\n    def raw(self):\n        self.must_get()\n        return self._raw\n\n    def parse_response(self, response):\n        self._raw = response\n        self.id = response[\"schemaId\"]\n        self.created_on = response[\"createdOn\"]\n        self.created_by = response[\"createdBy\"]\n\n    @classmethod\n    def from_response(cls, organization, response):\n        json_schema = cls(organization, response[\"schemaName\"])\n        json_schema.parse_response(response)\n        return json_schema\n\n    def get(self):\n        \"\"\"Get Json schema\"\"\"\n        if self.id is not None:\n            return True\n        response = self.organization.get_json_schema(self.name, raw=True)\n        if response is None:\n            return False\n        self.parse_response(response)\n        return True\n\n    def must_get(self):\n        already_exists = self.get()\n        assert already_exists, (\n            \"This operation requires that the JSON Schema name is created first.\"\n            \"Call the 'create_version()' method to trigger the creation.\"\n        )\n\n    def list_versions(self):\n        \"\"\"List versions of the json schema\"\"\"\n        self.must_get()\n        self._versions = dict()\n        response = self.service.list_json_schema_versions(\n            self.organization.name, self.name\n        )\n        for raw_version in response:\n            semver = raw_version.get(\"semanticVersion\")\n            version = JsonSchemaVersion.from_response(self.organization, raw_version)\n            # Handle that multiple versions can have None/null as their semver\n            if semver is None:\n                update_none_version = (\n                    # Is this the first null version?\n                    semver not in self._versions\n                    # Or is the version ID higher (i.e.,  more recent)?\n                    or version.version_id &gt; self._versions[semver].version_id\n                )\n                if update_none_version:\n                    self._versions[semver] = (raw_version, version)\n            else:\n                self._versions[semver] = (raw_version, version)\n            # Skip versions w/o semver until the end\n            if semver is not None:\n                yield version\n        # Return version w/o semver now (if applicable) to ensure latest is returned\n        if None in self._versions:\n            yield self._versions[None]\n\n    def get_version(self, semantic_version: str = None, raw: bool = False):\n        self.must_get()\n        if semantic_version not in self._versions:\n            list(self.list_versions())\n        raw_version, version = self._versions.get(semantic_version, [None, None])\n        return raw_version if raw else version\n\n    def create(\n        self,\n        json_schema_body: dict,\n        semantic_version: str = None,\n        dry_run: bool = False,\n    ):\n        \"\"\"Create JSON schema\n\n        :param json_schema_body: JSON schema body\n        :type json_schema_body:  dict\n        :param semantic_version: Version of JSON schema. Defaults to None.\n        :type semantic_version:  str, optional\n        :param dry_run:          Do not store to Synapse. Defaults to False.\n        :type dry_run:           bool, optional\n        \"\"\"\n        uri = f\"{self.organization.name}-{self.name}\"\n        if semantic_version:\n            uri = f\"{uri}-{semantic_version}\"\n        json_schema_body[\"$id\"] = uri\n        response = self.service.create_json_schema(json_schema_body, dry_run)\n        if dry_run:\n            return response\n        raw_version = response[\"newVersionInfo\"]\n        version = JsonSchemaVersion.from_response(self.organization, raw_version)\n        self._versions[semantic_version] = (raw_version, version)\n        return version\n</code></pre>"},{"location":"reference/json_schema/#synapseclient.services.json_schema.JsonSchema-functions","title":"Functions","text":""},{"location":"reference/json_schema/#synapseclient.services.json_schema.JsonSchema.get","title":"<code>get()</code>","text":"<p>Get Json schema</p> Source code in <code>synapseclient/services/json_schema.py</code> <pre><code>def get(self):\n    \"\"\"Get Json schema\"\"\"\n    if self.id is not None:\n        return True\n    response = self.organization.get_json_schema(self.name, raw=True)\n    if response is None:\n        return False\n    self.parse_response(response)\n    return True\n</code></pre>"},{"location":"reference/json_schema/#synapseclient.services.json_schema.JsonSchema.list_versions","title":"<code>list_versions()</code>","text":"<p>List versions of the json schema</p> Source code in <code>synapseclient/services/json_schema.py</code> <pre><code>def list_versions(self):\n    \"\"\"List versions of the json schema\"\"\"\n    self.must_get()\n    self._versions = dict()\n    response = self.service.list_json_schema_versions(\n        self.organization.name, self.name\n    )\n    for raw_version in response:\n        semver = raw_version.get(\"semanticVersion\")\n        version = JsonSchemaVersion.from_response(self.organization, raw_version)\n        # Handle that multiple versions can have None/null as their semver\n        if semver is None:\n            update_none_version = (\n                # Is this the first null version?\n                semver not in self._versions\n                # Or is the version ID higher (i.e.,  more recent)?\n                or version.version_id &gt; self._versions[semver].version_id\n            )\n            if update_none_version:\n                self._versions[semver] = (raw_version, version)\n        else:\n            self._versions[semver] = (raw_version, version)\n        # Skip versions w/o semver until the end\n        if semver is not None:\n            yield version\n    # Return version w/o semver now (if applicable) to ensure latest is returned\n    if None in self._versions:\n        yield self._versions[None]\n</code></pre>"},{"location":"reference/json_schema/#synapseclient.services.json_schema.JsonSchema.create","title":"<code>create(json_schema_body, semantic_version=None, dry_run=False)</code>","text":"<p>Create JSON schema</p> <p>:param json_schema_body: JSON schema body :type json_schema_body:  dict :param semantic_version: Version of JSON schema. Defaults to None. :type semantic_version:  str, optional :param dry_run:          Do not store to Synapse. Defaults to False. :type dry_run:           bool, optional</p> Source code in <code>synapseclient/services/json_schema.py</code> <pre><code>def create(\n    self,\n    json_schema_body: dict,\n    semantic_version: str = None,\n    dry_run: bool = False,\n):\n    \"\"\"Create JSON schema\n\n    :param json_schema_body: JSON schema body\n    :type json_schema_body:  dict\n    :param semantic_version: Version of JSON schema. Defaults to None.\n    :type semantic_version:  str, optional\n    :param dry_run:          Do not store to Synapse. Defaults to False.\n    :type dry_run:           bool, optional\n    \"\"\"\n    uri = f\"{self.organization.name}-{self.name}\"\n    if semantic_version:\n        uri = f\"{uri}-{semantic_version}\"\n    json_schema_body[\"$id\"] = uri\n    response = self.service.create_json_schema(json_schema_body, dry_run)\n    if dry_run:\n        return response\n    raw_version = response[\"newVersionInfo\"]\n    version = JsonSchemaVersion.from_response(self.organization, raw_version)\n    self._versions[semantic_version] = (raw_version, version)\n    return version\n</code></pre>"},{"location":"reference/json_schema/#synapseclient.services.json_schema.JsonSchemaOrganization","title":"<code>JsonSchemaOrganization</code>","text":"<p>Json Schema Organization</p> <p>:param name: Name of JSON schema organization :type name:  str</p> Source code in <code>synapseclient/services/json_schema.py</code> <pre><code>class JsonSchemaOrganization:\n    \"\"\"Json Schema Organization\n\n    :param name: Name of JSON schema organization\n    :type name:  str\n    \"\"\"\n\n    def __init__(self, name: str) -&gt; None:\n        self.name = name\n        self.id = None\n        self.created_on = None\n        self.created_by = None\n        self._json_schemas = dict()\n        self._raw_json_schemas = dict()\n\n    def __repr__(self):\n        string = f\"JsonSchemaOrganization(name={self.name!r})\"\n        return string\n\n    def set_service(self, service):\n        self.service = service\n\n    def get(self):\n        \"\"\"Gets Json Schema organization\"\"\"\n        if self.id is not None:\n            return True\n        try:\n            response = self.service.get_organization(self.name)\n        except SynapseHTTPError as e:\n            error_msg = str(e)\n            if \"not found\" in error_msg:\n                return False\n            else:\n                raise e\n        self.id = response[\"id\"]\n        self.created_on = response[\"createdOn\"]\n        self.created_by = response[\"createdBy\"]\n        return True\n\n    def must_get(self):\n        already_exists = self.get()\n        assert already_exists, (\n            \"This operation requires that the organization is created first. \"\n            \"Call the 'create()' method to trigger the creation.\"\n        )\n\n    @property\n    def name(self):\n        return self._name\n\n    @name.setter\n    def name(self, value):\n        if len(value) &lt; 6:\n            raise ValueError(\"Name must be at least 6 characters.\")\n        if len(value) &gt; 250:\n            raise ValueError(\"Name cannot exceed 250 characters. \")\n        if value[0].isdigit():\n            raise ValueError(\"Name must not start with a number.\")\n        self._name = value\n\n    @property\n    def raw(self):\n        self.must_get()\n        return self._raw\n\n    def parse_response(self, response):\n        self._raw = response\n        self.id = response[\"id\"]\n        self.created_on = response[\"createdOn\"]\n        self.created_by = response[\"createdBy\"]\n\n    @classmethod\n    def from_response(cls, response):\n        organization = cls(response[\"name\"])\n        organization.parse_response(response)\n        return organization\n\n    def create(self):\n        \"\"\"Create the JSON schema organization\"\"\"\n        already_exists = self.get()\n        if already_exists:\n            return\n        response = self.service.create_organization(self.name)\n        self.parse_response(response)\n        return self\n\n    def delete(self):\n        \"\"\"Delete the JSON schema organization\"\"\"\n        self.must_get()\n        response = self.service.delete_organization(self.id)\n        return response\n\n    def get_acl(self):\n        \"\"\"Get ACL of JSON schema organization\"\"\"\n        self.must_get()\n        response = self.service.get_organization_acl(self.id)\n        return response\n\n    def set_acl(\n        self,\n        principal_ids: Sequence[int],\n        access_type: Sequence[str] = DEFAULT_ACCESS,\n        etag: str = None,\n    ):\n        \"\"\"Set ACL of JSON schema organization\n\n        :param principal_ids: List of Synapse user or team ids.\n        :type principal_ids:  list\n        :param access_type:   Access control list. Defaults to [\"CHANGE_PERMISSIONS\", \"DELETE\", \"READ\", \"CREATE\", \"UPDATE\"].\n        :type access_type:    list, optional\n        :param etag:          Etag. Defaults to None.\n        :type etag:           str, optional\n        \"\"\"\n        self.must_get()\n        if etag is None:\n            acl = self.get_acl()\n            etag = acl[\"etag\"]\n        resource_access = [\n            {\"principalId\": principal_id, \"accessType\": access_type}\n            for principal_id in principal_ids\n        ]\n        response = self.service.update_organization_acl(self.id, resource_access, etag)\n        return response\n\n    def update_acl(\n        self,\n        principal_ids: Sequence[int],\n        access_type: Sequence[str] = DEFAULT_ACCESS,\n        etag: str = None,\n    ):\n        \"\"\"Update ACL of JSON schema organization\n\n        :param principal_ids: List of Synapse user or team ids.\n        :type principal_ids:  list\n        :param access_type:   Access control list. Defaults to [\"CHANGE_PERMISSIONS\", \"DELETE\", \"READ\", \"CREATE\", \"UPDATE\"].\n        :type access_type:    list, optional\n        :param etag:          Etag. Defaults to None.\n        :type etag:           str, optional\n        \"\"\"\n        self.must_get()\n        principal_ids = set(principal_ids)\n        acl = self.get_acl()\n        resource_access = acl[\"resourceAccess\"]\n        if etag is None:\n            etag = acl[\"etag\"]\n        for entry in resource_access:\n            if entry[\"principalId\"] in principal_ids:\n                entry[\"accessType\"] = access_type\n                principal_ids.remove(entry[\"principalId\"])\n        for principal_id in principal_ids:\n            entry = {\n                \"principalId\": principal_id,\n                \"accessType\": access_type,\n            }\n            resource_access.append(entry)\n        response = self.service.update_organization_acl(self.id, resource_access, etag)\n        return response\n\n    def list_json_schemas(self):\n        \"\"\"List JSON schemas available from the organization\"\"\"\n        self.must_get()\n        response = self.service.list_json_schemas(self.name)\n        for raw_json_schema in response:\n            json_schema = JsonSchema.from_response(self, raw_json_schema)\n            self._raw_json_schemas[json_schema.name] = raw_json_schema\n            self._json_schemas[json_schema.name] = json_schema\n            yield json_schema\n\n    def get_json_schema(self, json_schema_name: str, raw: bool = False):\n        \"\"\"Get JSON schema\n\n        :param json_schema_name: Name of JSON schema.\n        :type json_schema_name:  str\n        :param raw:              Return raw JSON schema. Default is False.\n        :type raw:               bool, optional\n        \"\"\"\n        self.must_get()\n        if json_schema_name not in self._json_schemas:\n            list(self.list_json_schemas())\n        if raw:\n            json_schema = self._raw_json_schemas.get(json_schema_name)\n        else:\n            json_schema = self._json_schemas.get(json_schema_name)\n        return json_schema\n\n    def create_json_schema(\n        self,\n        json_schema_body: dict,\n        name: str = None,\n        semantic_version: str = None,\n        dry_run: bool = False,\n    ):\n        \"\"\"Create JSON schema\n\n        :param json_schema_body: JSON schema dict\n        :type json_schema_body:  dict\n        :param name:             Name of JSON schema. Defaults to None.\n        :type name:              str, optional\n        :param semantic_version: Version of JSON schema. Defaults to None.\n        :type semantic_version:  str, optional\n        :param dry_run:          Don't store to Synapse. Defaults to False.\n        :type dry_run:           bool, optional\n        \"\"\"\n        if name:\n            uri = f\"{self.name}-{name}\"\n            if semantic_version:\n                uri = f\"{uri}-{semantic_version}\"\n            json_schema_body[\"$id\"] = uri\n        else:\n            assert (\n                semantic_version is not None\n            ), \"Specify both the name and the semantic version (not just the latter)\"\n        response = self.service.create_json_schema(json_schema_body, dry_run)\n        if dry_run:\n            return response\n        raw_version = response[\"newVersionInfo\"]\n        json_schema = JsonSchemaVersion.from_response(self, raw_version)\n        return json_schema\n</code></pre>"},{"location":"reference/json_schema/#synapseclient.services.json_schema.JsonSchemaOrganization-functions","title":"Functions","text":""},{"location":"reference/json_schema/#synapseclient.services.json_schema.JsonSchemaOrganization.get","title":"<code>get()</code>","text":"<p>Gets Json Schema organization</p> Source code in <code>synapseclient/services/json_schema.py</code> <pre><code>def get(self):\n    \"\"\"Gets Json Schema organization\"\"\"\n    if self.id is not None:\n        return True\n    try:\n        response = self.service.get_organization(self.name)\n    except SynapseHTTPError as e:\n        error_msg = str(e)\n        if \"not found\" in error_msg:\n            return False\n        else:\n            raise e\n    self.id = response[\"id\"]\n    self.created_on = response[\"createdOn\"]\n    self.created_by = response[\"createdBy\"]\n    return True\n</code></pre>"},{"location":"reference/json_schema/#synapseclient.services.json_schema.JsonSchemaOrganization.create","title":"<code>create()</code>","text":"<p>Create the JSON schema organization</p> Source code in <code>synapseclient/services/json_schema.py</code> <pre><code>def create(self):\n    \"\"\"Create the JSON schema organization\"\"\"\n    already_exists = self.get()\n    if already_exists:\n        return\n    response = self.service.create_organization(self.name)\n    self.parse_response(response)\n    return self\n</code></pre>"},{"location":"reference/json_schema/#synapseclient.services.json_schema.JsonSchemaOrganization.delete","title":"<code>delete()</code>","text":"<p>Delete the JSON schema organization</p> Source code in <code>synapseclient/services/json_schema.py</code> <pre><code>def delete(self):\n    \"\"\"Delete the JSON schema organization\"\"\"\n    self.must_get()\n    response = self.service.delete_organization(self.id)\n    return response\n</code></pre>"},{"location":"reference/json_schema/#synapseclient.services.json_schema.JsonSchemaOrganization.get_acl","title":"<code>get_acl()</code>","text":"<p>Get ACL of JSON schema organization</p> Source code in <code>synapseclient/services/json_schema.py</code> <pre><code>def get_acl(self):\n    \"\"\"Get ACL of JSON schema organization\"\"\"\n    self.must_get()\n    response = self.service.get_organization_acl(self.id)\n    return response\n</code></pre>"},{"location":"reference/json_schema/#synapseclient.services.json_schema.JsonSchemaOrganization.set_acl","title":"<code>set_acl(principal_ids, access_type=DEFAULT_ACCESS, etag=None)</code>","text":"<p>Set ACL of JSON schema organization</p> <p>:param principal_ids: List of Synapse user or team ids. :type principal_ids:  list :param access_type:   Access control list. Defaults to [\"CHANGE_PERMISSIONS\", \"DELETE\", \"READ\", \"CREATE\", \"UPDATE\"]. :type access_type:    list, optional :param etag:          Etag. Defaults to None. :type etag:           str, optional</p> Source code in <code>synapseclient/services/json_schema.py</code> <pre><code>def set_acl(\n    self,\n    principal_ids: Sequence[int],\n    access_type: Sequence[str] = DEFAULT_ACCESS,\n    etag: str = None,\n):\n    \"\"\"Set ACL of JSON schema organization\n\n    :param principal_ids: List of Synapse user or team ids.\n    :type principal_ids:  list\n    :param access_type:   Access control list. Defaults to [\"CHANGE_PERMISSIONS\", \"DELETE\", \"READ\", \"CREATE\", \"UPDATE\"].\n    :type access_type:    list, optional\n    :param etag:          Etag. Defaults to None.\n    :type etag:           str, optional\n    \"\"\"\n    self.must_get()\n    if etag is None:\n        acl = self.get_acl()\n        etag = acl[\"etag\"]\n    resource_access = [\n        {\"principalId\": principal_id, \"accessType\": access_type}\n        for principal_id in principal_ids\n    ]\n    response = self.service.update_organization_acl(self.id, resource_access, etag)\n    return response\n</code></pre>"},{"location":"reference/json_schema/#synapseclient.services.json_schema.JsonSchemaOrganization.update_acl","title":"<code>update_acl(principal_ids, access_type=DEFAULT_ACCESS, etag=None)</code>","text":"<p>Update ACL of JSON schema organization</p> <p>:param principal_ids: List of Synapse user or team ids. :type principal_ids:  list :param access_type:   Access control list. Defaults to [\"CHANGE_PERMISSIONS\", \"DELETE\", \"READ\", \"CREATE\", \"UPDATE\"]. :type access_type:    list, optional :param etag:          Etag. Defaults to None. :type etag:           str, optional</p> Source code in <code>synapseclient/services/json_schema.py</code> <pre><code>def update_acl(\n    self,\n    principal_ids: Sequence[int],\n    access_type: Sequence[str] = DEFAULT_ACCESS,\n    etag: str = None,\n):\n    \"\"\"Update ACL of JSON schema organization\n\n    :param principal_ids: List of Synapse user or team ids.\n    :type principal_ids:  list\n    :param access_type:   Access control list. Defaults to [\"CHANGE_PERMISSIONS\", \"DELETE\", \"READ\", \"CREATE\", \"UPDATE\"].\n    :type access_type:    list, optional\n    :param etag:          Etag. Defaults to None.\n    :type etag:           str, optional\n    \"\"\"\n    self.must_get()\n    principal_ids = set(principal_ids)\n    acl = self.get_acl()\n    resource_access = acl[\"resourceAccess\"]\n    if etag is None:\n        etag = acl[\"etag\"]\n    for entry in resource_access:\n        if entry[\"principalId\"] in principal_ids:\n            entry[\"accessType\"] = access_type\n            principal_ids.remove(entry[\"principalId\"])\n    for principal_id in principal_ids:\n        entry = {\n            \"principalId\": principal_id,\n            \"accessType\": access_type,\n        }\n        resource_access.append(entry)\n    response = self.service.update_organization_acl(self.id, resource_access, etag)\n    return response\n</code></pre>"},{"location":"reference/json_schema/#synapseclient.services.json_schema.JsonSchemaOrganization.list_json_schemas","title":"<code>list_json_schemas()</code>","text":"<p>List JSON schemas available from the organization</p> Source code in <code>synapseclient/services/json_schema.py</code> <pre><code>def list_json_schemas(self):\n    \"\"\"List JSON schemas available from the organization\"\"\"\n    self.must_get()\n    response = self.service.list_json_schemas(self.name)\n    for raw_json_schema in response:\n        json_schema = JsonSchema.from_response(self, raw_json_schema)\n        self._raw_json_schemas[json_schema.name] = raw_json_schema\n        self._json_schemas[json_schema.name] = json_schema\n        yield json_schema\n</code></pre>"},{"location":"reference/json_schema/#synapseclient.services.json_schema.JsonSchemaOrganization.get_json_schema","title":"<code>get_json_schema(json_schema_name, raw=False)</code>","text":"<p>Get JSON schema</p> <p>:param json_schema_name: Name of JSON schema. :type json_schema_name:  str :param raw:              Return raw JSON schema. Default is False. :type raw:               bool, optional</p> Source code in <code>synapseclient/services/json_schema.py</code> <pre><code>def get_json_schema(self, json_schema_name: str, raw: bool = False):\n    \"\"\"Get JSON schema\n\n    :param json_schema_name: Name of JSON schema.\n    :type json_schema_name:  str\n    :param raw:              Return raw JSON schema. Default is False.\n    :type raw:               bool, optional\n    \"\"\"\n    self.must_get()\n    if json_schema_name not in self._json_schemas:\n        list(self.list_json_schemas())\n    if raw:\n        json_schema = self._raw_json_schemas.get(json_schema_name)\n    else:\n        json_schema = self._json_schemas.get(json_schema_name)\n    return json_schema\n</code></pre>"},{"location":"reference/json_schema/#synapseclient.services.json_schema.JsonSchemaOrganization.create_json_schema","title":"<code>create_json_schema(json_schema_body, name=None, semantic_version=None, dry_run=False)</code>","text":"<p>Create JSON schema</p> <p>:param json_schema_body: JSON schema dict :type json_schema_body:  dict :param name:             Name of JSON schema. Defaults to None. :type name:              str, optional :param semantic_version: Version of JSON schema. Defaults to None. :type semantic_version:  str, optional :param dry_run:          Don't store to Synapse. Defaults to False. :type dry_run:           bool, optional</p> Source code in <code>synapseclient/services/json_schema.py</code> <pre><code>def create_json_schema(\n    self,\n    json_schema_body: dict,\n    name: str = None,\n    semantic_version: str = None,\n    dry_run: bool = False,\n):\n    \"\"\"Create JSON schema\n\n    :param json_schema_body: JSON schema dict\n    :type json_schema_body:  dict\n    :param name:             Name of JSON schema. Defaults to None.\n    :type name:              str, optional\n    :param semantic_version: Version of JSON schema. Defaults to None.\n    :type semantic_version:  str, optional\n    :param dry_run:          Don't store to Synapse. Defaults to False.\n    :type dry_run:           bool, optional\n    \"\"\"\n    if name:\n        uri = f\"{self.name}-{name}\"\n        if semantic_version:\n            uri = f\"{uri}-{semantic_version}\"\n        json_schema_body[\"$id\"] = uri\n    else:\n        assert (\n            semantic_version is not None\n        ), \"Specify both the name and the semantic version (not just the latter)\"\n    response = self.service.create_json_schema(json_schema_body, dry_run)\n    if dry_run:\n        return response\n    raw_version = response[\"newVersionInfo\"]\n    json_schema = JsonSchemaVersion.from_response(self, raw_version)\n    return json_schema\n</code></pre>"},{"location":"reference/json_schema/#synapseclient.services.json_schema.JsonSchemaService","title":"<code>JsonSchemaService</code>","text":"<p>Json Schema Service</p> <p>:param synapse: Synapse connection :type synapse:  Synapse</p> Source code in <code>synapseclient/services/json_schema.py</code> <pre><code>class JsonSchemaService:\n    \"\"\"Json Schema Service\n\n    :param synapse: Synapse connection\n    :type synapse:  Synapse\n    \"\"\"\n\n    def __init__(self, synapse: Synapse = None) -&gt; None:\n        self.synapse = synapse\n\n    @wraps(Synapse.login)\n    def login(self, *args, **kwargs):\n        synapse = Synapse()\n        synapse.login(*args, **kwargs)\n        self.synapse = synapse\n\n    @wraps(JsonSchemaOrganization)\n    def JsonSchemaOrganization(self, *args, **kwargs):\n        instance = JsonSchemaOrganization(*args, **kwargs)\n        instance.set_service(self)\n        return instance\n\n    @wraps(JsonSchemaVersion)\n    def JsonSchemaVersion(self, *args, **kwargs):\n        instance = JsonSchemaVersion(*args, **kwargs)\n        instance.set_service(self)\n        return instance\n\n    @wraps(JsonSchema)\n    def JsonSchema(self, *args, **kwargs):\n        instance = JsonSchema(*args, **kwargs)\n        instance.set_service(self)\n        return instance\n\n    def authentication_required(func):\n        @wraps(func)\n        def wrapper(self, *args, **kwargs):\n            msg = (\n                f\"`JsonSchemaService.{func.__name__}()` requests must be authenticated.\"\n                \" Login using the `login()` method on the existing `JsonSchemaService`\"\n                \" instance (e.g., `js.login()` or `js.login(authToken=...)`).\"\n            )\n            assert self.synapse is not None, msg\n            try:\n                result = func(self, *args, **kwargs)\n            except SynapseAuthenticationError as e:\n                raise SynapseAuthenticationError(msg).with_traceback(e.__traceback__)\n            return result\n\n        return wrapper\n\n    @authentication_required\n    def create_organization(self, organization_name: str):\n        \"\"\"Create a new organization\n\n        :param organization_name: JSON schema organization name\n        :type organization_name:  str\n        \"\"\"\n        request_body = {\"organizationName\": organization_name}\n        response = self.synapse.restPOST(\n            \"/schema/organization\", body=json.dumps(request_body)\n        )\n        return response\n\n    @authentication_required\n    def get_organization(self, organization_name: str):\n        \"\"\"Get a organization\n\n        :param organization_name: JSON schema organization name\n        :type organization_name:  str\n        \"\"\"\n        response = self.synapse.restGET(\n            f\"/schema/organization?name={organization_name}\"\n        )\n        return response\n\n    def list_organizations(self):\n        \"\"\"List organizations\"\"\"\n        request_body = {}\n        response = self.synapse._POST_paginated(\n            \"/schema/organization/list\", request_body\n        )\n        return response\n\n    @authentication_required\n    def delete_organization(self, organization_id: str):\n        \"\"\"Delete organization\n\n        :param organization_id: JSON schema organization Id\n        :type organization_id:  str\n        \"\"\"\n        response = self.synapse.restDELETE(f\"/schema/organization/{organization_id}\")\n        return response\n\n    @authentication_required\n    def get_organization_acl(self, organization_id: str):\n        \"\"\"Get ACL associated with Organization\n\n        :param organization_id: JSON schema organization Id\n        :type organization_id:  str\n        \"\"\"\n        response = self.synapse.restGET(f\"/schema/organization/{organization_id}/acl\")\n        return response\n\n    @authentication_required\n    def update_organization_acl(\n        self,\n        organization_id: str,\n        resource_access: Sequence[Mapping[str, Sequence[str]]],\n        etag: str,\n    ):\n        \"\"\"Get ACL associated with Organization\n\n        :param organization_id: JSON schema organization Id\n        :type organization_id:  str\n        :param resource_access: Resource access array\n        :type resource_access:  list\n        :param etag:            Etag\n        :type etag:             str\n        \"\"\"\n        request_body = {\"resourceAccess\": resource_access, \"etag\": etag}\n        response = self.synapse.restPUT(\n            f\"/schema/organization/{organization_id}/acl\", body=json.dumps(request_body)\n        )\n        return response\n\n    def list_json_schemas(self, organization_name: str):\n        \"\"\"List JSON schemas for an organization\n\n        :param organization_name: JSON schema organization name\n        :type organization_name:  str\n        \"\"\"\n        request_body = {\"organizationName\": organization_name}\n        response = self.synapse._POST_paginated(\"/schema/list\", request_body)\n        return response\n\n    def list_json_schema_versions(self, organization_name: str, json_schema_name: str):\n        \"\"\"List version information for each JSON schema\n\n        :param organization_name: JSON schema organization name\n        :type organization_name:  str\n        :param json_schema_name:  JSON schema name\n        :type json_schema_name:   str\n        \"\"\"\n        request_body = {\n            \"organizationName\": organization_name,\n            \"schemaName\": json_schema_name,\n        }\n        response = self.synapse._POST_paginated(\"/schema/version/list\", request_body)\n        return response\n\n    @authentication_required\n    def create_json_schema(self, json_schema_body: dict, dry_run: bool = False):\n        \"\"\"Create a JSON schema\n\n        :param json_schema_body: JSON schema body\n        :type json_schema_body:  dict\n        :param dry_run:          Don't store to Synapse. Default to False.\n        :type dry_run:           bool, optional\n        \"\"\"\n        request_body = {\n            \"concreteType\": \"org.sagebionetworks.repo.model.schema.CreateSchemaRequest\",\n            \"schema\": json_schema_body,\n            \"dryRun\": dry_run,\n        }\n        response = self.synapse._waitForAsync(\"/schema/type/create/async\", request_body)\n        return response\n\n    def get_json_schema_body(self, json_schema_uri: str):\n        \"\"\"Get registered JSON schema with its $id\n\n        :param json_schema_uri: JSON schema URI\n        :type json_schema_uri:  str\n        \"\"\"\n        response = self.synapse.restGET(f\"/schema/type/registered/{json_schema_uri}\")\n        return response\n\n    @authentication_required\n    def delete_json_schema(self, json_schema_uri: str):\n        \"\"\"Delete the given schema using its $id\n\n        :param json_schema_uri: JSON schema URI\n        :type json_schema_uri:  str\n        \"\"\"\n        response = self.synapse.restDELETE(f\"/schema/type/registered/{json_schema_uri}\")\n        return response\n\n    @authentication_required\n    def json_schema_validation(self, json_schema_uri: str):\n        \"\"\"Use a JSON schema for validation\n\n        :param json_schema_uri: JSON schema URI\n        :type json_schema_uri:  str\n        \"\"\"\n        request_body = {\n            \"concreteType\": (\n                \"org.sagebionetworks.repo.model.schema.GetValidationSchemaRequest\"\n            ),\n            \"$id\": json_schema_uri,\n        }\n        response = self.synapse._waitForAsync(\n            \"/schema/type/validation/async\", request_body\n        )\n        return response\n\n    @authentication_required\n    def bind_json_schema_to_entity(self, synapse_id: str, json_schema_uri: str):\n        \"\"\"Bind a JSON schema to an entity\n\n        :param synapse_id:      Synapse Id\n        :type synapse_id:       str\n        :param json_schema_uri: JSON schema URI\n        :type json_schema_uri:  str\n        \"\"\"\n        request_body = {\"entityId\": synapse_id, \"schema$id\": json_schema_uri}\n        response = self.synapse.restPUT(\n            f\"/entity/{synapse_id}/schema/binding\", body=json.dumps(request_body)\n        )\n        return response\n\n    @authentication_required\n    def get_json_schema_from_entity(self, synapse_id: str):\n        \"\"\"Get bound schema from entity\n\n        :param synapse_id:      Synapse Id\n        :type synapse_id:       str\n        \"\"\"\n        response = self.synapse.restGET(f\"/entity/{synapse_id}/schema/binding\")\n        return response\n\n    @authentication_required\n    def delete_json_schema_from_entity(self, synapse_id: str):\n        \"\"\"Delete bound schema from entity\n\n        :param synapse_id:      Synapse Id\n        :type synapse_id:       str\n        \"\"\"\n        response = self.synapse.restDELETE(f\"/entity/{synapse_id}/schema/binding\")\n        return response\n\n    @authentication_required\n    def validate_entity_with_json_schema(self, synapse_id: str):\n        \"\"\"Get validation results of an entity against bound JSON schema\n\n        :param synapse_id:      Synapse Id\n        :type synapse_id:       str\n        \"\"\"\n        response = self.synapse.restGET(f\"/entity/{synapse_id}/schema/validation\")\n        return response\n\n    @authentication_required\n    def get_json_schema_validation_statistics(self, synapse_id: str):\n        \"\"\"Get the summary statistic of json schema validation results for\n        a container entity\n\n        :param synapse_id:      Synapse Id\n        :type synapse_id:       str\n        \"\"\"\n        response = self.synapse.restGET(\n            f\"/entity/{synapse_id}/schema/validation/statistics\"\n        )\n        return response\n\n    @authentication_required\n    def get_invalid_json_schema_validation(self, synapse_id: str):\n        \"\"\"Get a single page of invalid JSON schema validation results for a container Entity\n        (Project or Folder).\n\n        :param synapse_id:      Synapse Id\n        :type synapse_id:       str\n        \"\"\"\n        request_body = {\"containerId\": synapse_id}\n        response = self.synapse._POST_paginated(\n            f\"/entity/{synapse_id}/schema/validation/invalid\", request_body\n        )\n        return response\n\n    # The methods below are here until they are integrated with Synapse/Entity\n\n    def bind_json_schema(self, json_schema_uri: str, entity: Union[str, Entity]):\n        \"\"\"Bind a JSON schema to an entity\n\n        :param json_schema_uri: JSON schema URI\n        :type json_schema_uri:  str\n        :param entity:          Synapse Entity or Synapse Id\n        :type entity:           str, Entity\n        \"\"\"\n        synapse_id = id_of(entity)\n        response = self.bind_json_schema_to_entity(synapse_id, json_schema_uri)\n        return response\n\n    def get_json_schema(self, entity: Union[str, Entity]):\n        \"\"\"Get a JSON schema associated to an Entity\n\n        :param entity:          Synapse Entity or Synapse Id\n        :type entity:           str, Entity\n        \"\"\"\n        synapse_id = id_of(entity)\n        response = self.get_json_schema_from_entity(synapse_id)\n        return response\n\n    def unbind_json_schema(self, entity: Union[str, Entity]):\n        \"\"\"Unbind a JSON schema from an entity\n\n        :param entity:          Synapse Entity or Synapse Id\n        :type entity:           str, Entity\n        \"\"\"\n        synapse_id = id_of(entity)\n        response = self.delete_json_schema_from_entity(synapse_id)\n        return response\n\n    def validate(self, entity: Union[str, Entity]):\n        \"\"\"Validate an entity based on the bound JSON schema\n\n        :param entity:          Synapse Entity or Synapse Id\n        :type entity:           str, Entity\n        \"\"\"\n        synapse_id = id_of(entity)\n        response = self.validate_entity_with_json_schema(synapse_id)\n        return response\n\n    def validation_stats(self, entity: Union[str, Entity]):\n        \"\"\"Get validation statistics of an entity based on the bound JSON schema\n\n        :param entity:          Synapse Entity or Synapse Id\n        :type entity:           str, Entity\n        \"\"\"\n        synapse_id = id_of(entity)\n        response = self.get_json_schema_validation_statistics(synapse_id)\n        return response\n\n    def validate_children(self, entity: Union[str, Entity]):\n        \"\"\"Validate an entity and it's children based on the bound JSON schema\n\n        :param entity:          Synapse Entity or Synapse Id of a project or folder.\n        :type entity:           str, Entity\n        \"\"\"\n        synapse_id = id_of(entity)\n        response = self.get_invalid_json_schema_validation(synapse_id)\n        return response\n</code></pre>"},{"location":"reference/json_schema/#synapseclient.services.json_schema.JsonSchemaService-functions","title":"Functions","text":""},{"location":"reference/json_schema/#synapseclient.services.json_schema.JsonSchemaService.create_organization","title":"<code>create_organization(organization_name)</code>","text":"<p>Create a new organization</p> <p>:param organization_name: JSON schema organization name :type organization_name:  str</p> Source code in <code>synapseclient/services/json_schema.py</code> <pre><code>@authentication_required\ndef create_organization(self, organization_name: str):\n    \"\"\"Create a new organization\n\n    :param organization_name: JSON schema organization name\n    :type organization_name:  str\n    \"\"\"\n    request_body = {\"organizationName\": organization_name}\n    response = self.synapse.restPOST(\n        \"/schema/organization\", body=json.dumps(request_body)\n    )\n    return response\n</code></pre>"},{"location":"reference/json_schema/#synapseclient.services.json_schema.JsonSchemaService.get_organization","title":"<code>get_organization(organization_name)</code>","text":"<p>Get a organization</p> <p>:param organization_name: JSON schema organization name :type organization_name:  str</p> Source code in <code>synapseclient/services/json_schema.py</code> <pre><code>@authentication_required\ndef get_organization(self, organization_name: str):\n    \"\"\"Get a organization\n\n    :param organization_name: JSON schema organization name\n    :type organization_name:  str\n    \"\"\"\n    response = self.synapse.restGET(\n        f\"/schema/organization?name={organization_name}\"\n    )\n    return response\n</code></pre>"},{"location":"reference/json_schema/#synapseclient.services.json_schema.JsonSchemaService.list_organizations","title":"<code>list_organizations()</code>","text":"<p>List organizations</p> Source code in <code>synapseclient/services/json_schema.py</code> <pre><code>def list_organizations(self):\n    \"\"\"List organizations\"\"\"\n    request_body = {}\n    response = self.synapse._POST_paginated(\n        \"/schema/organization/list\", request_body\n    )\n    return response\n</code></pre>"},{"location":"reference/json_schema/#synapseclient.services.json_schema.JsonSchemaService.delete_organization","title":"<code>delete_organization(organization_id)</code>","text":"<p>Delete organization</p> <p>:param organization_id: JSON schema organization Id :type organization_id:  str</p> Source code in <code>synapseclient/services/json_schema.py</code> <pre><code>@authentication_required\ndef delete_organization(self, organization_id: str):\n    \"\"\"Delete organization\n\n    :param organization_id: JSON schema organization Id\n    :type organization_id:  str\n    \"\"\"\n    response = self.synapse.restDELETE(f\"/schema/organization/{organization_id}\")\n    return response\n</code></pre>"},{"location":"reference/json_schema/#synapseclient.services.json_schema.JsonSchemaService.get_organization_acl","title":"<code>get_organization_acl(organization_id)</code>","text":"<p>Get ACL associated with Organization</p> <p>:param organization_id: JSON schema organization Id :type organization_id:  str</p> Source code in <code>synapseclient/services/json_schema.py</code> <pre><code>@authentication_required\ndef get_organization_acl(self, organization_id: str):\n    \"\"\"Get ACL associated with Organization\n\n    :param organization_id: JSON schema organization Id\n    :type organization_id:  str\n    \"\"\"\n    response = self.synapse.restGET(f\"/schema/organization/{organization_id}/acl\")\n    return response\n</code></pre>"},{"location":"reference/json_schema/#synapseclient.services.json_schema.JsonSchemaService.update_organization_acl","title":"<code>update_organization_acl(organization_id, resource_access, etag)</code>","text":"<p>Get ACL associated with Organization</p> <p>:param organization_id: JSON schema organization Id :type organization_id:  str :param resource_access: Resource access array :type resource_access:  list :param etag:            Etag :type etag:             str</p> Source code in <code>synapseclient/services/json_schema.py</code> <pre><code>@authentication_required\ndef update_organization_acl(\n    self,\n    organization_id: str,\n    resource_access: Sequence[Mapping[str, Sequence[str]]],\n    etag: str,\n):\n    \"\"\"Get ACL associated with Organization\n\n    :param organization_id: JSON schema organization Id\n    :type organization_id:  str\n    :param resource_access: Resource access array\n    :type resource_access:  list\n    :param etag:            Etag\n    :type etag:             str\n    \"\"\"\n    request_body = {\"resourceAccess\": resource_access, \"etag\": etag}\n    response = self.synapse.restPUT(\n        f\"/schema/organization/{organization_id}/acl\", body=json.dumps(request_body)\n    )\n    return response\n</code></pre>"},{"location":"reference/json_schema/#synapseclient.services.json_schema.JsonSchemaService.list_json_schemas","title":"<code>list_json_schemas(organization_name)</code>","text":"<p>List JSON schemas for an organization</p> <p>:param organization_name: JSON schema organization name :type organization_name:  str</p> Source code in <code>synapseclient/services/json_schema.py</code> <pre><code>def list_json_schemas(self, organization_name: str):\n    \"\"\"List JSON schemas for an organization\n\n    :param organization_name: JSON schema organization name\n    :type organization_name:  str\n    \"\"\"\n    request_body = {\"organizationName\": organization_name}\n    response = self.synapse._POST_paginated(\"/schema/list\", request_body)\n    return response\n</code></pre>"},{"location":"reference/json_schema/#synapseclient.services.json_schema.JsonSchemaService.list_json_schema_versions","title":"<code>list_json_schema_versions(organization_name, json_schema_name)</code>","text":"<p>List version information for each JSON schema</p> <p>:param organization_name: JSON schema organization name :type organization_name:  str :param json_schema_name:  JSON schema name :type json_schema_name:   str</p> Source code in <code>synapseclient/services/json_schema.py</code> <pre><code>def list_json_schema_versions(self, organization_name: str, json_schema_name: str):\n    \"\"\"List version information for each JSON schema\n\n    :param organization_name: JSON schema organization name\n    :type organization_name:  str\n    :param json_schema_name:  JSON schema name\n    :type json_schema_name:   str\n    \"\"\"\n    request_body = {\n        \"organizationName\": organization_name,\n        \"schemaName\": json_schema_name,\n    }\n    response = self.synapse._POST_paginated(\"/schema/version/list\", request_body)\n    return response\n</code></pre>"},{"location":"reference/json_schema/#synapseclient.services.json_schema.JsonSchemaService.create_json_schema","title":"<code>create_json_schema(json_schema_body, dry_run=False)</code>","text":"<p>Create a JSON schema</p> <p>:param json_schema_body: JSON schema body :type json_schema_body:  dict :param dry_run:          Don't store to Synapse. Default to False. :type dry_run:           bool, optional</p> Source code in <code>synapseclient/services/json_schema.py</code> <pre><code>@authentication_required\ndef create_json_schema(self, json_schema_body: dict, dry_run: bool = False):\n    \"\"\"Create a JSON schema\n\n    :param json_schema_body: JSON schema body\n    :type json_schema_body:  dict\n    :param dry_run:          Don't store to Synapse. Default to False.\n    :type dry_run:           bool, optional\n    \"\"\"\n    request_body = {\n        \"concreteType\": \"org.sagebionetworks.repo.model.schema.CreateSchemaRequest\",\n        \"schema\": json_schema_body,\n        \"dryRun\": dry_run,\n    }\n    response = self.synapse._waitForAsync(\"/schema/type/create/async\", request_body)\n    return response\n</code></pre>"},{"location":"reference/json_schema/#synapseclient.services.json_schema.JsonSchemaService.get_json_schema_body","title":"<code>get_json_schema_body(json_schema_uri)</code>","text":"<p>Get registered JSON schema with its $id</p> <p>:param json_schema_uri: JSON schema URI :type json_schema_uri:  str</p> Source code in <code>synapseclient/services/json_schema.py</code> <pre><code>def get_json_schema_body(self, json_schema_uri: str):\n    \"\"\"Get registered JSON schema with its $id\n\n    :param json_schema_uri: JSON schema URI\n    :type json_schema_uri:  str\n    \"\"\"\n    response = self.synapse.restGET(f\"/schema/type/registered/{json_schema_uri}\")\n    return response\n</code></pre>"},{"location":"reference/json_schema/#synapseclient.services.json_schema.JsonSchemaService.delete_json_schema","title":"<code>delete_json_schema(json_schema_uri)</code>","text":"<p>Delete the given schema using its $id</p> <p>:param json_schema_uri: JSON schema URI :type json_schema_uri:  str</p> Source code in <code>synapseclient/services/json_schema.py</code> <pre><code>@authentication_required\ndef delete_json_schema(self, json_schema_uri: str):\n    \"\"\"Delete the given schema using its $id\n\n    :param json_schema_uri: JSON schema URI\n    :type json_schema_uri:  str\n    \"\"\"\n    response = self.synapse.restDELETE(f\"/schema/type/registered/{json_schema_uri}\")\n    return response\n</code></pre>"},{"location":"reference/json_schema/#synapseclient.services.json_schema.JsonSchemaService.json_schema_validation","title":"<code>json_schema_validation(json_schema_uri)</code>","text":"<p>Use a JSON schema for validation</p> <p>:param json_schema_uri: JSON schema URI :type json_schema_uri:  str</p> Source code in <code>synapseclient/services/json_schema.py</code> <pre><code>@authentication_required\ndef json_schema_validation(self, json_schema_uri: str):\n    \"\"\"Use a JSON schema for validation\n\n    :param json_schema_uri: JSON schema URI\n    :type json_schema_uri:  str\n    \"\"\"\n    request_body = {\n        \"concreteType\": (\n            \"org.sagebionetworks.repo.model.schema.GetValidationSchemaRequest\"\n        ),\n        \"$id\": json_schema_uri,\n    }\n    response = self.synapse._waitForAsync(\n        \"/schema/type/validation/async\", request_body\n    )\n    return response\n</code></pre>"},{"location":"reference/json_schema/#synapseclient.services.json_schema.JsonSchemaService.bind_json_schema_to_entity","title":"<code>bind_json_schema_to_entity(synapse_id, json_schema_uri)</code>","text":"<p>Bind a JSON schema to an entity</p> <p>:param synapse_id:      Synapse Id :type synapse_id:       str :param json_schema_uri: JSON schema URI :type json_schema_uri:  str</p> Source code in <code>synapseclient/services/json_schema.py</code> <pre><code>@authentication_required\ndef bind_json_schema_to_entity(self, synapse_id: str, json_schema_uri: str):\n    \"\"\"Bind a JSON schema to an entity\n\n    :param synapse_id:      Synapse Id\n    :type synapse_id:       str\n    :param json_schema_uri: JSON schema URI\n    :type json_schema_uri:  str\n    \"\"\"\n    request_body = {\"entityId\": synapse_id, \"schema$id\": json_schema_uri}\n    response = self.synapse.restPUT(\n        f\"/entity/{synapse_id}/schema/binding\", body=json.dumps(request_body)\n    )\n    return response\n</code></pre>"},{"location":"reference/json_schema/#synapseclient.services.json_schema.JsonSchemaService.get_json_schema_from_entity","title":"<code>get_json_schema_from_entity(synapse_id)</code>","text":"<p>Get bound schema from entity</p> <p>:param synapse_id:      Synapse Id :type synapse_id:       str</p> Source code in <code>synapseclient/services/json_schema.py</code> <pre><code>@authentication_required\ndef get_json_schema_from_entity(self, synapse_id: str):\n    \"\"\"Get bound schema from entity\n\n    :param synapse_id:      Synapse Id\n    :type synapse_id:       str\n    \"\"\"\n    response = self.synapse.restGET(f\"/entity/{synapse_id}/schema/binding\")\n    return response\n</code></pre>"},{"location":"reference/json_schema/#synapseclient.services.json_schema.JsonSchemaService.delete_json_schema_from_entity","title":"<code>delete_json_schema_from_entity(synapse_id)</code>","text":"<p>Delete bound schema from entity</p> <p>:param synapse_id:      Synapse Id :type synapse_id:       str</p> Source code in <code>synapseclient/services/json_schema.py</code> <pre><code>@authentication_required\ndef delete_json_schema_from_entity(self, synapse_id: str):\n    \"\"\"Delete bound schema from entity\n\n    :param synapse_id:      Synapse Id\n    :type synapse_id:       str\n    \"\"\"\n    response = self.synapse.restDELETE(f\"/entity/{synapse_id}/schema/binding\")\n    return response\n</code></pre>"},{"location":"reference/json_schema/#synapseclient.services.json_schema.JsonSchemaService.validate_entity_with_json_schema","title":"<code>validate_entity_with_json_schema(synapse_id)</code>","text":"<p>Get validation results of an entity against bound JSON schema</p> <p>:param synapse_id:      Synapse Id :type synapse_id:       str</p> Source code in <code>synapseclient/services/json_schema.py</code> <pre><code>@authentication_required\ndef validate_entity_with_json_schema(self, synapse_id: str):\n    \"\"\"Get validation results of an entity against bound JSON schema\n\n    :param synapse_id:      Synapse Id\n    :type synapse_id:       str\n    \"\"\"\n    response = self.synapse.restGET(f\"/entity/{synapse_id}/schema/validation\")\n    return response\n</code></pre>"},{"location":"reference/json_schema/#synapseclient.services.json_schema.JsonSchemaService.get_json_schema_validation_statistics","title":"<code>get_json_schema_validation_statistics(synapse_id)</code>","text":"<p>Get the summary statistic of json schema validation results for a container entity</p> <p>:param synapse_id:      Synapse Id :type synapse_id:       str</p> Source code in <code>synapseclient/services/json_schema.py</code> <pre><code>@authentication_required\ndef get_json_schema_validation_statistics(self, synapse_id: str):\n    \"\"\"Get the summary statistic of json schema validation results for\n    a container entity\n\n    :param synapse_id:      Synapse Id\n    :type synapse_id:       str\n    \"\"\"\n    response = self.synapse.restGET(\n        f\"/entity/{synapse_id}/schema/validation/statistics\"\n    )\n    return response\n</code></pre>"},{"location":"reference/json_schema/#synapseclient.services.json_schema.JsonSchemaService.get_invalid_json_schema_validation","title":"<code>get_invalid_json_schema_validation(synapse_id)</code>","text":"<p>Get a single page of invalid JSON schema validation results for a container Entity (Project or Folder).</p> <p>:param synapse_id:      Synapse Id :type synapse_id:       str</p> Source code in <code>synapseclient/services/json_schema.py</code> <pre><code>@authentication_required\ndef get_invalid_json_schema_validation(self, synapse_id: str):\n    \"\"\"Get a single page of invalid JSON schema validation results for a container Entity\n    (Project or Folder).\n\n    :param synapse_id:      Synapse Id\n    :type synapse_id:       str\n    \"\"\"\n    request_body = {\"containerId\": synapse_id}\n    response = self.synapse._POST_paginated(\n        f\"/entity/{synapse_id}/schema/validation/invalid\", request_body\n    )\n    return response\n</code></pre>"},{"location":"reference/json_schema/#synapseclient.services.json_schema.JsonSchemaService.bind_json_schema","title":"<code>bind_json_schema(json_schema_uri, entity)</code>","text":"<p>Bind a JSON schema to an entity</p> <p>:param json_schema_uri: JSON schema URI :type json_schema_uri:  str :param entity:          Synapse Entity or Synapse Id :type entity:           str, Entity</p> Source code in <code>synapseclient/services/json_schema.py</code> <pre><code>def bind_json_schema(self, json_schema_uri: str, entity: Union[str, Entity]):\n    \"\"\"Bind a JSON schema to an entity\n\n    :param json_schema_uri: JSON schema URI\n    :type json_schema_uri:  str\n    :param entity:          Synapse Entity or Synapse Id\n    :type entity:           str, Entity\n    \"\"\"\n    synapse_id = id_of(entity)\n    response = self.bind_json_schema_to_entity(synapse_id, json_schema_uri)\n    return response\n</code></pre>"},{"location":"reference/json_schema/#synapseclient.services.json_schema.JsonSchemaService.get_json_schema","title":"<code>get_json_schema(entity)</code>","text":"<p>Get a JSON schema associated to an Entity</p> <p>:param entity:          Synapse Entity or Synapse Id :type entity:           str, Entity</p> Source code in <code>synapseclient/services/json_schema.py</code> <pre><code>def get_json_schema(self, entity: Union[str, Entity]):\n    \"\"\"Get a JSON schema associated to an Entity\n\n    :param entity:          Synapse Entity or Synapse Id\n    :type entity:           str, Entity\n    \"\"\"\n    synapse_id = id_of(entity)\n    response = self.get_json_schema_from_entity(synapse_id)\n    return response\n</code></pre>"},{"location":"reference/json_schema/#synapseclient.services.json_schema.JsonSchemaService.unbind_json_schema","title":"<code>unbind_json_schema(entity)</code>","text":"<p>Unbind a JSON schema from an entity</p> <p>:param entity:          Synapse Entity or Synapse Id :type entity:           str, Entity</p> Source code in <code>synapseclient/services/json_schema.py</code> <pre><code>def unbind_json_schema(self, entity: Union[str, Entity]):\n    \"\"\"Unbind a JSON schema from an entity\n\n    :param entity:          Synapse Entity or Synapse Id\n    :type entity:           str, Entity\n    \"\"\"\n    synapse_id = id_of(entity)\n    response = self.delete_json_schema_from_entity(synapse_id)\n    return response\n</code></pre>"},{"location":"reference/json_schema/#synapseclient.services.json_schema.JsonSchemaService.validate","title":"<code>validate(entity)</code>","text":"<p>Validate an entity based on the bound JSON schema</p> <p>:param entity:          Synapse Entity or Synapse Id :type entity:           str, Entity</p> Source code in <code>synapseclient/services/json_schema.py</code> <pre><code>def validate(self, entity: Union[str, Entity]):\n    \"\"\"Validate an entity based on the bound JSON schema\n\n    :param entity:          Synapse Entity or Synapse Id\n    :type entity:           str, Entity\n    \"\"\"\n    synapse_id = id_of(entity)\n    response = self.validate_entity_with_json_schema(synapse_id)\n    return response\n</code></pre>"},{"location":"reference/json_schema/#synapseclient.services.json_schema.JsonSchemaService.validation_stats","title":"<code>validation_stats(entity)</code>","text":"<p>Get validation statistics of an entity based on the bound JSON schema</p> <p>:param entity:          Synapse Entity or Synapse Id :type entity:           str, Entity</p> Source code in <code>synapseclient/services/json_schema.py</code> <pre><code>def validation_stats(self, entity: Union[str, Entity]):\n    \"\"\"Get validation statistics of an entity based on the bound JSON schema\n\n    :param entity:          Synapse Entity or Synapse Id\n    :type entity:           str, Entity\n    \"\"\"\n    synapse_id = id_of(entity)\n    response = self.get_json_schema_validation_statistics(synapse_id)\n    return response\n</code></pre>"},{"location":"reference/json_schema/#synapseclient.services.json_schema.JsonSchemaService.validate_children","title":"<code>validate_children(entity)</code>","text":"<p>Validate an entity and it's children based on the bound JSON schema</p> <p>:param entity:          Synapse Entity or Synapse Id of a project or folder. :type entity:           str, Entity</p> Source code in <code>synapseclient/services/json_schema.py</code> <pre><code>def validate_children(self, entity: Union[str, Entity]):\n    \"\"\"Validate an entity and it's children based on the bound JSON schema\n\n    :param entity:          Synapse Entity or Synapse Id of a project or folder.\n    :type entity:           str, Entity\n    \"\"\"\n    synapse_id = id_of(entity)\n    response = self.get_invalid_json_schema_validation(synapse_id)\n    return response\n</code></pre>"},{"location":"reference/json_schema/#synapseclient.services.json_schema-functions","title":"Functions","text":""},{"location":"reference/link/","title":"Link","text":""},{"location":"reference/link/#synapseclient.entity.Link","title":"<code>synapseclient.entity.Link</code>","text":"<p>               Bases: <code>Entity</code></p> <p>Represents a link in Synapse.</p> <p>Links must have a target ID and a parent. When you do synapseclient.Synapse.get on a Link object, the Link object is returned. If the target is desired, specify followLink=True in synapseclient.Synapse.get.</p> ATTRIBUTE DESCRIPTION <code>targetId</code> <p>The ID of the entity to be linked</p> <p> </p> <code>targetVersion</code> <p>The version of the entity to be linked</p> <p> </p> <code>parent</code> <p>The parent project or folder</p> <p> </p> <code>properties</code> <p>A map of Synapse properties</p> <p> </p> <code>annotations</code> <p>A map of user defined annotations</p> <p> </p> <code>local_state</code> <p>Internal use only</p> <p> </p> Using this class <p>Creating an instance and storing the link</p> <pre><code>link = Link('targetID', parent=folder)\nlink = syn.store(link)\n</code></pre> Source code in <code>synapseclient/entity.py</code> <pre><code>class Link(Entity):\n    \"\"\"\n    Represents a link in Synapse.\n\n    Links must have a target ID and a parent. When you do [synapseclient.Synapse.get][] on a Link object,\n    the Link object is returned. If the target is desired, specify followLink=True in synapseclient.Synapse.get.\n\n    Attributes:\n        targetId: The ID of the entity to be linked\n        targetVersion: The version of the entity to be linked\n        parent: The parent project or folder\n        properties: A map of Synapse properties\n        annotations: A map of user defined annotations\n        local_state: Internal use only\n\n\n    Example: Using this class\n        Creating an instance and storing the link\n\n            link = Link('targetID', parent=folder)\n            link = syn.store(link)\n    \"\"\"\n\n    _property_keys = Entity._property_keys + [\"linksTo\", \"linksToClassName\"]\n    _local_keys = Entity._local_keys\n    _synapse_entity_type = \"org.sagebionetworks.repo.model.Link\"\n\n    def __init__(\n        self,\n        targetId=None,\n        targetVersion=None,\n        parent=None,\n        properties=None,\n        annotations=None,\n        local_state=None,\n        **kwargs,\n    ):\n        if targetId is not None and targetVersion is not None:\n            kwargs[\"linksTo\"] = dict(\n                targetId=utils.id_of(targetId), targetVersionNumber=targetVersion\n            )\n        elif targetId is not None and targetVersion is None:\n            kwargs[\"linksTo\"] = dict(targetId=utils.id_of(targetId))\n        elif properties is not None and \"linksTo\" in properties:\n            pass\n        else:\n            raise SynapseMalformedEntityError(\"Must provide a target id\")\n        super(Link, self).__init__(\n            concreteType=Link._synapse_entity_type,\n            properties=properties,\n            annotations=annotations,\n            local_state=local_state,\n            parent=parent,\n            **kwargs,\n        )\n</code></pre>"},{"location":"reference/permissions/","title":"Permissions","text":""},{"location":"reference/permissions/#synapseclient.Permissions","title":"<code>synapseclient.Permissions</code>  <code>dataclass</code>","text":"<p>The permission a user has for a given Entity. The set of permissoins is a calculation based several factors including the permission granted by the Entity's ACL and the User's group membership.</p> ATTRIBUTE DESCRIPTION <code>can_view</code> <p>Can the user view this entity?</p> <p> </p> <code>can_edit</code> <p>Can the user edit this entity?</p> <p> </p> <code>can_move</code> <p>(Read Only) Can the user move this entity by changing its parentId?</p> <p> </p> <code>can_add_child</code> <p>Can the user add a child entity to this entity?</p> <p> </p> <code>can_certified_user_edit</code> <p>(Read Only) Can the user edit this entity once they become a Certified User?</p> <p> </p> <code>can_certified_user_add_child</code> <p>(Read Only) Can the user add a child entity to this entity once they become a Certified User?</p> <p> </p> <code>is_certified_user</code> <p>(Read Only) True, if the user has passed the user certification quiz.</p> <p> </p> <code>can_change_permissions</code> <p>Can the user change the permissions of this entity?</p> <p> </p> <code>can_change_settings</code> <p>Can the user change the settings of this entity?</p> <p> </p> <code>can_delete</code> <p>Can the user delete this entity?</p> <p> </p> <code>can_download</code> <p>Are there any access requirements precluding the user from downloading this entity?</p> <p> </p> <code>can_upload</code> <p>(Read Only) Are there any access requirements precluding the user from uploading into this entity (folder or project)?</p> <p> </p> <code>can_enable_inheritance</code> <p>(Read Only) Can the user delete the entity's access control list (so it inherits settings from an ancestor)?</p> <p> </p> <code>owner_principal_id</code> <p>(Read Only) The principal ID of the entity's owner (i.e. the entity's 'createdBy').</p> <p> </p> <code>can_public_read</code> <p>(Read Only) Is this entity considered public?</p> <p> </p> <code>can_moderate</code> <p>Can the user moderate the forum associated with this entity? Note that only project entity has forum.</p> <p> </p> <code>is_certification_required</code> <p>(Read Only) Is the certification requirement enabled for the project of the entity?</p> <p> </p> <code>is_entity_open_data</code> <p>(Read Only) Returns true if the Entity's DateType equals 'OPEN_DATA', indicating that the data is safe to be released to the public.</p> <p> </p> Source code in <code>synapseclient/core/models/permission.py</code> <pre><code>@dataclass\nclass Permissions:\n    \"\"\"\n    The permission a user has for a given Entity. The set of permissoins is a calculation\n    based several factors including the permission granted by the Entity's ACL and the\n    User's group membership.\n\n\n    Attributes:\n        can_view : Can the user view this entity?\n        can_edit : Can the user edit this entity?\n        can_move : (Read Only) Can the user move this entity by changing its parentId?\n        can_add_child : Can the user add a child entity to this entity?\n        can_certified_user_edit : (Read Only) Can the user edit this entity once they become a Certified User?\n        can_certified_user_add_child : (Read Only) Can the user add a child entity to this entity once they become\n            a Certified User?\n        is_certified_user : (Read Only) True, if the user has passed the user certification quiz.\n        can_change_permissions : Can the user change the permissions of this entity?\n        can_change_settings : Can the user change the settings of this entity?\n        can_delete : Can the user delete this entity?\n        can_download : Are there any access requirements precluding the user from downloading this entity?\n        can_upload : (Read Only) Are there any access requirements precluding the user from uploading into this entity\n            (folder or project)?\n        can_enable_inheritance : (Read Only) Can the user delete the entity's access control list (so it inherits\n            settings from an ancestor)?\n        owner_principal_id : (Read Only) The principal ID of the entity's owner (i.e. the entity's 'createdBy').\n        can_public_read : (Read Only) Is this entity considered public?\n        can_moderate : Can the user moderate the forum associated with this entity?\n            Note that only project entity has forum.\n        is_certification_required : (Read Only) Is the certification requirement enabled for the project of the entity?\n        is_entity_open_data : (Read Only) Returns true if the Entity's DateType equals 'OPEN_DATA', indicating that the\n            data is safe to be released to the public.\n    \"\"\"\n\n    can_view: Optional[bool] = None\n    \"\"\"Can the user view this entity?\"\"\"\n\n    can_edit: Optional[bool] = None\n    \"\"\"Can the user edit this entity?\"\"\"\n\n    can_move: Optional[bool] = None\n    \"\"\"(Read Only) Can the user move this entity by changing its parentId?\"\"\"\n\n    can_add_child: Optional[bool] = None\n    \"\"\"Can the user add a child entity to this entity?\"\"\"\n\n    can_certified_user_edit: Optional[bool] = None\n    \"\"\"(Read Only) Can the user edit this entity once they become a Certified User?\"\"\"\n\n    can_certified_user_add_child: Optional[bool] = None\n    \"\"\"(Read Only) Can the user add a child entity to this entity once they become a Certified User?\"\"\"\n\n    is_certified_user: Optional[bool] = None\n    \"\"\"(Read Only) True, if the user has passed the user certification quiz.\"\"\"\n\n    can_change_permissions: Optional[bool] = None\n    \"\"\"Can the user change the permissions of this entity?\"\"\"\n\n    can_change_settings: Optional[bool] = None\n    \"\"\"Can the user change the settings of this entity?\"\"\"\n\n    can_delete: Optional[bool] = None\n    \"\"\"Can the user delete this entity?\"\"\"\n\n    can_download: Optional[bool] = None\n    \"\"\"Are there any access requirements precluding the user from downloading this entity?\"\"\"\n\n    can_upload: Optional[bool] = None\n    \"\"\"(Read Only) Are there any access requirements precluding the user\n    from uploading into this entity (folder or project)?\"\"\"\n\n    can_enable_inheritance: Optional[bool] = None\n    \"\"\"(Read Only) Can the user delete the entity's access control list (so it inherits settings from an ancestor)?\"\"\"\n\n    owner_principal_id: Optional[int] = None\n    \"\"\"(Read Only) The principal ID of the entity's owner (i.e. the entity's 'createdBy').\"\"\"\n\n    can_public_read: Optional[bool] = None\n    \"\"\"(Read Only) Is this entity considered public?\"\"\"\n\n    can_moderate: Optional[bool] = None\n    \"\"\"Can the user moderate the forum associated with this entity? Note that only project entity has forum.\"\"\"\n\n    is_certification_required: Optional[bool] = None\n    \"\"\"(Read Only) Is the certification requirement enabled for the project of the entity?\"\"\"\n\n    is_entity_open_data: Optional[bool] = None\n    \"\"\"(Read Only) Returns true if the Entity's DateType equals 'OPEN_DATA',\n    indicating that the data is safe to be released to the public.\"\"\"\n\n    @classmethod\n    def from_dict(cls, data: Dict[str, bool]) -&gt; \"Permissions\":\n        \"\"\"Convert a data dictionary to an instance of this dataclass\n\n        Arguments:\n            data: a data dictionary of the\n                [UserEntityPermissions](https://rest-docs.synapse.org/rest/org/sagebionetworks/repo/model/auth/UserEntityPermissions.html)\n\n        Returns:\n            A Permission object\n        \"\"\"\n\n        return cls(\n            can_view=data[\"canView\"],\n            can_edit=data[\"canEdit\"],\n            can_move=data[\"canMove\"],\n            can_add_child=data[\"canAddChild\"],\n            can_certified_user_edit=data[\"canCertifiedUserEdit\"],\n            can_certified_user_add_child=data[\"canCertifiedUserAddChild\"],\n            is_certified_user=data[\"isCertifiedUser\"],\n            can_change_permissions=data[\"canChangePermissions\"],\n            can_change_settings=data[\"canChangeSettings\"],\n            can_delete=data[\"canDelete\"],\n            can_download=data[\"canDownload\"],\n            can_upload=data[\"canUpload\"],\n            can_enable_inheritance=data[\"canEnableInheritance\"],\n            owner_principal_id=data[\"ownerPrincipalId\"],\n            can_public_read=data[\"canPublicRead\"],\n            can_moderate=data[\"canModerate\"],\n            is_certification_required=data[\"isCertificationRequired\"],\n            is_entity_open_data=data[\"isEntityOpenData\"],\n        )\n\n    @property\n    def access_types(self) -&gt; List[str]:\n        \"\"\"\n        Determine from the permissions set on this object what the access types are.\n\n        Returns:\n            A list of access type strings for this object based off of what permissions are set.\n\n\n        Example: Using this property\n            A permission that has nothing set\n\n                no_permissions = Permissions()\n                print(no_permissions.access_types)\n                # Prints: []\n\n            A permission that has can_view set to True and nothing else set\n\n                read_permission = Permissions()\n                read_permission.can_view = True\n                print(read_permission.access_types)\n                # Prints: ['READ']\n\n            Special Case: a permission that has can_view set to True and nothing else set on an entity created by you.\n            CHANGE_SETTINGS is bound to ownerId. Since the entity is created by you,\n            the CHANGE_SETTINGS will always be True.\n\n                read_permission = Permissions()\n                read_permission.can_view = True\n                print(read_permission.access_types)\n                # Prints: ['READ','CHANGE_SETTINGS']\n\n            A permission that has can_view and can_edit set to True and nothing else set\n\n                read_write_permission = Permissions()\n                read_write_permission.can_view = True\n                read_write_permission.can_edit = True\n                print(read_write_permission.access_types)\n                # Prints: ['READ', 'UPDATE']\n        \"\"\"\n\n        access_types = []\n        if self.can_view:\n            access_types.append(\"READ\")\n        if self.can_edit:\n            access_types.append(\"UPDATE\")\n        if self.can_add_child:\n            access_types.append(\"CREATE\")\n        if self.can_delete:\n            access_types.append(\"DELETE\")\n        if self.can_download:\n            access_types.append(\"DOWNLOAD\")\n        if self.can_moderate:\n            access_types.append(\"MODERATE\")\n        if self.can_change_permissions:\n            access_types.append(\"CHANGE_PERMISSIONS\")\n        if self.can_change_settings:\n            access_types.append(\"CHANGE_SETTINGS\")\n        return access_types\n</code></pre>"},{"location":"reference/permissions/#synapseclient.Permissions-attributes","title":"Attributes","text":""},{"location":"reference/permissions/#synapseclient.Permissions.access_types","title":"<code>access_types: List[str]</code>  <code>property</code>","text":"<p>Determine from the permissions set on this object what the access types are.</p> RETURNS DESCRIPTION <code>List[str]</code> <p>A list of access type strings for this object based off of what permissions are set.</p> Using this property <p>A permission that has nothing set</p> <pre><code>no_permissions = Permissions()\nprint(no_permissions.access_types)\n# Prints: []\n</code></pre> <p>A permission that has can_view set to True and nothing else set</p> <pre><code>read_permission = Permissions()\nread_permission.can_view = True\nprint(read_permission.access_types)\n# Prints: ['READ']\n</code></pre> <p>Special Case: a permission that has can_view set to True and nothing else set on an entity created by you. CHANGE_SETTINGS is bound to ownerId. Since the entity is created by you, the CHANGE_SETTINGS will always be True.</p> <pre><code>read_permission = Permissions()\nread_permission.can_view = True\nprint(read_permission.access_types)\n# Prints: ['READ','CHANGE_SETTINGS']\n</code></pre> <p>A permission that has can_view and can_edit set to True and nothing else set</p> <pre><code>read_write_permission = Permissions()\nread_write_permission.can_view = True\nread_write_permission.can_edit = True\nprint(read_write_permission.access_types)\n# Prints: ['READ', 'UPDATE']\n</code></pre>"},{"location":"reference/permissions/#synapseclient.Permissions-functions","title":"Functions","text":""},{"location":"reference/permissions/#synapseclient.Permissions.from_dict","title":"<code>from_dict(data)</code>  <code>classmethod</code>","text":"<p>Convert a data dictionary to an instance of this dataclass</p> PARAMETER DESCRIPTION <code>data</code> <p>a data dictionary of the UserEntityPermissions</p> <p> TYPE: <code>Dict[str, bool]</code> </p> RETURNS DESCRIPTION <code>Permissions</code> <p>A Permission object</p> Source code in <code>synapseclient/core/models/permission.py</code> <pre><code>@classmethod\ndef from_dict(cls, data: Dict[str, bool]) -&gt; \"Permissions\":\n    \"\"\"Convert a data dictionary to an instance of this dataclass\n\n    Arguments:\n        data: a data dictionary of the\n            [UserEntityPermissions](https://rest-docs.synapse.org/rest/org/sagebionetworks/repo/model/auth/UserEntityPermissions.html)\n\n    Returns:\n        A Permission object\n    \"\"\"\n\n    return cls(\n        can_view=data[\"canView\"],\n        can_edit=data[\"canEdit\"],\n        can_move=data[\"canMove\"],\n        can_add_child=data[\"canAddChild\"],\n        can_certified_user_edit=data[\"canCertifiedUserEdit\"],\n        can_certified_user_add_child=data[\"canCertifiedUserAddChild\"],\n        is_certified_user=data[\"isCertifiedUser\"],\n        can_change_permissions=data[\"canChangePermissions\"],\n        can_change_settings=data[\"canChangeSettings\"],\n        can_delete=data[\"canDelete\"],\n        can_download=data[\"canDownload\"],\n        can_upload=data[\"canUpload\"],\n        can_enable_inheritance=data[\"canEnableInheritance\"],\n        owner_principal_id=data[\"ownerPrincipalId\"],\n        can_public_read=data[\"canPublicRead\"],\n        can_moderate=data[\"canModerate\"],\n        is_certification_required=data[\"isCertificationRequired\"],\n        is_entity_open_data=data[\"isEntityOpenData\"],\n    )\n</code></pre>"},{"location":"reference/project/","title":"Project","text":""},{"location":"reference/project/#synapseclient.entity.Project","title":"<code>synapseclient.entity.Project</code>","text":"<p>               Bases: <code>Entity</code></p> <p>Represents a project in Synapse.</p> <p>Projects in Synapse must be uniquely named. Trying to create a project with a name that's already taken, say 'My project', will result in an error</p> ATTRIBUTE DESCRIPTION <code>name</code> <p>The name of the project</p> <p> </p> <code>alias</code> <p>The project alias for use in friendly project urls.</p> <p> </p> <code>properties</code> <p>A map of Synapse properties</p> <p> </p> <code>annotations</code> <p>A map of user defined annotations</p> <p> </p> <code>local_state</code> <p>Internal use only</p> <p> </p> Using this class <p>Creating an instance and storing the project</p> <pre><code>project = Project('Foobarbat project')\nproject = syn.store(project)\n</code></pre> Source code in <code>synapseclient/entity.py</code> <pre><code>class Project(Entity):\n    \"\"\"\n    Represents a project in Synapse.\n\n    Projects in Synapse must be uniquely named. Trying to create a project with a name that's already taken, say\n    'My project', will result in an error\n\n    Attributes:\n        name: The name of the project\n        alias: The project alias for use in friendly project urls.\n        properties: A map of Synapse properties\n        annotations: A map of user defined annotations\n        local_state: Internal use only\n\n\n    Example: Using this class\n        Creating an instance and storing the project\n\n            project = Project('Foobarbat project')\n            project = syn.store(project)\n    \"\"\"\n\n    _synapse_entity_type = \"org.sagebionetworks.repo.model.Project\"\n\n    _property_keys = Entity._property_keys + [\"alias\"]\n\n    def __init__(\n        self,\n        name=None,\n        properties=None,\n        annotations=None,\n        local_state=None,\n        alias=None,\n        **kwargs,\n    ):\n        if name:\n            kwargs[\"name\"] = name\n        if alias:\n            kwargs[\"alias\"] = alias\n        super(Project, self).__init__(\n            concreteType=Project._synapse_entity_type,\n            properties=properties,\n            annotations=annotations,\n            local_state=local_state,\n            **kwargs,\n        )\n</code></pre>"},{"location":"reference/rest_apis/","title":"Rest APIs","text":"<p>This section is for super users / developers only. These functions are subject to change as they are internal development functions. Use at your own risk.</p> <p>The functions provided in these documents are generally direct representations of the Synapse REST API. They're used within the Synapse Python Client to interact with the Synapse servers. These will eventually be removed from the Synapse Python Client in favor of an auto-generated client derived from the Synapse Open API Spec.</p>"},{"location":"reference/rest_apis/#synapseclient.api.entity_bundle_services_v2","title":"<code>synapseclient.api.entity_bundle_services_v2</code>","text":"<p>This module is responsible for exposing the services defined at: https://rest-docs.synapse.org/rest/#org.sagebionetworks.repo.web.controller.EntityBundleV2Controller</p>"},{"location":"reference/rest_apis/#synapseclient.api.entity_bundle_services_v2-classes","title":"Classes","text":""},{"location":"reference/rest_apis/#synapseclient.api.entity_bundle_services_v2-functions","title":"Functions","text":""},{"location":"reference/rest_apis/#synapseclient.api.entity_bundle_services_v2.get_entity_id_bundle2","title":"<code>get_entity_id_bundle2(entity_id, request=None, *, synapse_client=None)</code>  <code>async</code>","text":"PARAMETER DESCRIPTION <code>entity_id</code> <p>The ID of the entity to which the bundle belongs</p> <p> TYPE: <code>str</code> </p> <code>request</code> <p>The request for the bundle matching https://rest-docs.synapse.org/rest/org/sagebionetworks/repo/model/entitybundle/v2/EntityBundleRequest.html. If not passed in or None, the default request will be used:</p> <ul> <li>includeEntity: True</li> <li>includeAnnotations: True</li> <li>includeFileHandles: True</li> <li>includeRestrictionInformation: True</li> </ul> <p> TYPE: <code>Optional[Dict[str, bool]]</code> DEFAULT: <code>None</code> </p> <code>synapse_client</code> <p>If not passed in or None this will use the last client from the <code>.login()</code> method.</p> <p> TYPE: <code>Optional[Synapse]</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>Dict[str, Any]</code> <p>The requested entity bundle matching https://rest-docs.synapse.org/rest/org/sagebionetworks/repo/model/entitybundle/v2/EntityBundle.html</p> Source code in <code>synapseclient/api/entity_bundle_services_v2.py</code> <pre><code>async def get_entity_id_bundle2(\n    entity_id: str,\n    request: Optional[Dict[str, bool]] = None,\n    *,\n    synapse_client: Optional[\"Synapse\"] = None,\n) -&gt; Dict[str, Any]:\n    \"\"\"\n    Arguments:\n        entity_id: The ID of the entity to which the bundle belongs\n        request: The request for the bundle matching\n            &lt;https://rest-docs.synapse.org/rest/org/sagebionetworks/repo/model/entitybundle/v2/EntityBundleRequest.html&gt;.\n            If not passed in or None, the default request will be used:\n\n            - includeEntity: True\n            - includeAnnotations: True\n            - includeFileHandles: True\n            - includeRestrictionInformation: True\n        synapse_client: If not passed in or None this will use the last client from\n            the `.login()` method.\n\n    Returns:\n        The requested entity bundle matching\n            &lt;https://rest-docs.synapse.org/rest/org/sagebionetworks/repo/model/entitybundle/v2/EntityBundle.html&gt;\n    \"\"\"\n    from synapseclient import Synapse\n\n    if not request:\n        request = {\n            \"includeEntity\": True,\n            \"includeAnnotations\": True,\n            \"includeFileHandles\": True,\n            \"includeRestrictionInformation\": True,\n        }\n\n    client = Synapse.get_client(synapse_client=synapse_client)\n    return await client.rest_post_async(\n        uri=f\"/entity/{entity_id}/bundle2\",\n        body=json.dumps(request),\n    )\n</code></pre>"},{"location":"reference/rest_apis/#synapseclient.api.entity_bundle_services_v2.get_entity_id_version_bundle2","title":"<code>get_entity_id_version_bundle2(entity_id, version, request=None, *, synapse_client=None)</code>  <code>async</code>","text":"PARAMETER DESCRIPTION <code>entity_id</code> <p>The ID of the entity to which the bundle belongs</p> <p> TYPE: <code>str</code> </p> <code>version</code> <p>The version of the entity to which the bundle belongs</p> <p> TYPE: <code>int</code> </p> <code>request</code> <p>The request for the bundle matching https://rest-docs.synapse.org/rest/org/sagebionetworks/repo/model/entitybundle/v2/EntityBundleRequest.html. If not passed in or None, the default request will be used:</p> <ul> <li>includeEntity: True</li> <li>includeAnnotations: True</li> <li>includeFileHandles: True</li> <li>includeRestrictionInformation: True</li> </ul> <p> TYPE: <code>Optional[Dict[str, bool]]</code> DEFAULT: <code>None</code> </p> <code>synapse_client</code> <p>If not passed in or None this will use the last client from the <code>.login()</code> method.</p> <p> TYPE: <code>Optional[Synapse]</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>Dict[str, Any]</code> <p>The requested entity bundle matching https://rest-docs.synapse.org/rest/org/sagebionetworks/repo/model/entitybundle/v2/EntityBundle.html</p> Source code in <code>synapseclient/api/entity_bundle_services_v2.py</code> <pre><code>async def get_entity_id_version_bundle2(\n    entity_id: str,\n    version: int,\n    request: Optional[Dict[str, bool]] = None,\n    *,\n    synapse_client: Optional[\"Synapse\"] = None,\n) -&gt; Dict[str, Any]:\n    \"\"\"\n    Arguments:\n        entity_id: The ID of the entity to which the bundle belongs\n        version: The version of the entity to which the bundle belongs\n        request: The request for the bundle matching\n            &lt;https://rest-docs.synapse.org/rest/org/sagebionetworks/repo/model/entitybundle/v2/EntityBundleRequest.html&gt;.\n            If not passed in or None, the default request will be used:\n\n            - includeEntity: True\n            - includeAnnotations: True\n            - includeFileHandles: True\n            - includeRestrictionInformation: True\n        synapse_client: If not passed in or None this will use the last client from\n            the `.login()` method.\n\n    Returns:\n        The requested entity bundle matching\n            &lt;https://rest-docs.synapse.org/rest/org/sagebionetworks/repo/model/entitybundle/v2/EntityBundle.html&gt;\n    \"\"\"\n    from synapseclient import Synapse\n\n    if not request:\n        request = {\n            \"includeEntity\": True,\n            \"includeAnnotations\": True,\n            \"includeFileHandles\": True,\n            \"includeRestrictionInformation\": True,\n        }\n    client = Synapse.get_client(synapse_client=synapse_client)\n    return await client.rest_post_async(\n        uri=f\"/entity/{entity_id}/version/{version}/bundle2\",\n        body=json.dumps(request),\n    )\n</code></pre>"},{"location":"reference/rest_apis/#synapseclient.api.entity_bundle_services_v2.post_entity_bundle2_create","title":"<code>post_entity_bundle2_create(request, generated_by=None, *, synapse_client=None)</code>  <code>async</code>","text":"PARAMETER DESCRIPTION <code>request</code> <p>The request for the bundle matching https://rest-docs.synapse.org/rest/org/sagebionetworks/repo/model/entitybundle/v2/EntityBundleCreate.html</p> <p> TYPE: <code>Dict[str, Any]</code> </p> <code>generated_by</code> <p>The ID of the activity to associate with the entity.</p> <p> TYPE: <code>Optional[str]</code> DEFAULT: <code>None</code> </p> <code>synapse_client</code> <p>If not passed in or None this will use the last client from the <code>.login()</code> method.</p> <p> TYPE: <code>Optional[Synapse]</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>Dict[str, Any]</code> <p>The requested entity bundle matching https://rest-docs.synapse.org/rest/org/sagebionetworks/repo/model/entitybundle/v2/EntityBundle.html</p> Source code in <code>synapseclient/api/entity_bundle_services_v2.py</code> <pre><code>async def post_entity_bundle2_create(\n    request: Dict[str, Any],\n    generated_by: Optional[str] = None,\n    *,\n    synapse_client: Optional[\"Synapse\"] = None,\n) -&gt; Dict[str, Any]:\n    \"\"\"\n    Arguments:\n        request: The request for the bundle matching\n            &lt;https://rest-docs.synapse.org/rest/org/sagebionetworks/repo/model/entitybundle/v2/EntityBundleCreate.html&gt;\n        generated_by: The ID of the activity to associate with the entity.\n        synapse_client: If not passed in or None this will use the last client from\n            the `.login()` method.\n\n    Returns:\n        The requested entity bundle matching\n            &lt;https://rest-docs.synapse.org/rest/org/sagebionetworks/repo/model/entitybundle/v2/EntityBundle.html&gt;\n    \"\"\"\n    from synapseclient import Synapse\n\n    client = Synapse.get_client(synapse_client=synapse_client)\n    return await client.rest_post_async(\n        uri=\"/entity/bundle2/create\"\n        + (f\"?generatedBy={generated_by}\" if generated_by else \"\"),\n        body=json.dumps(request),\n    )\n</code></pre>"},{"location":"reference/rest_apis/#synapseclient.api.entity_bundle_services_v2.put_entity_id_bundle2","title":"<code>put_entity_id_bundle2(entity_id, request, generated_by=None, *, synapse_client=None)</code>  <code>async</code>","text":"PARAMETER DESCRIPTION <code>entity_id</code> <p>The ID of the entity to which the bundle belongs.</p> <p> TYPE: <code>str</code> </p> <code>request</code> <p>The request for the bundle matching https://rest-docs.synapse.org/rest/org/sagebionetworks/repo/model/entitybundle/v2/EntityBundleCreate.html</p> <p> TYPE: <code>Dict[str, Any]</code> </p> <code>generated_by</code> <p>The ID of the activity to associate with the entity.</p> <p> TYPE: <code>Optional[str]</code> DEFAULT: <code>None</code> </p> <code>synapse_client</code> <p>If not passed in or None this will use the last client from the <code>.login()</code> method.</p> <p> TYPE: <code>Optional[Synapse]</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>Dict[str, Any]</code> <p>The requested entity bundle matching https://rest-docs.synapse.org/rest/org/sagebionetworks/repo/model/entitybundle/v2/EntityBundle.html</p> Source code in <code>synapseclient/api/entity_bundle_services_v2.py</code> <pre><code>async def put_entity_id_bundle2(\n    entity_id: str,\n    request: Dict[str, Any],\n    generated_by: Optional[str] = None,\n    *,\n    synapse_client: Optional[\"Synapse\"] = None,\n) -&gt; Dict[str, Any]:\n    \"\"\"\n    Arguments:\n        entity_id: The ID of the entity to which the bundle belongs.\n        request: The request for the bundle matching\n            &lt;https://rest-docs.synapse.org/rest/org/sagebionetworks/repo/model/entitybundle/v2/EntityBundleCreate.html&gt;\n        generated_by: The ID of the activity to associate with the entity.\n        synapse_client: If not passed in or None this will use the last client from\n            the `.login()` method.\n\n    Returns:\n        The requested entity bundle matching\n            &lt;https://rest-docs.synapse.org/rest/org/sagebionetworks/repo/model/entitybundle/v2/EntityBundle.html&gt;\n    \"\"\"\n    from synapseclient import Synapse\n\n    client = Synapse.get_client(synapse_client=synapse_client)\n    return await client.rest_put_async(\n        uri=f\"/entity/{entity_id}/bundle2\"\n        + (f\"?generatedBy={generated_by}\" if generated_by else \"\"),\n        body=json.dumps(request),\n    )\n</code></pre>"},{"location":"reference/rest_apis/#synapseclient.api.annotations","title":"<code>synapseclient.api.annotations</code>","text":"<p>The purpose of this module is to provide any functions that are needed to interact with annotations that are not cleanly provided by the synapseclient library.</p>"},{"location":"reference/rest_apis/#synapseclient.api.annotations-classes","title":"Classes","text":""},{"location":"reference/rest_apis/#synapseclient.api.annotations-functions","title":"Functions","text":""},{"location":"reference/rest_apis/#synapseclient.api.annotations.set_annotations","title":"<code>set_annotations(annotations, *, synapse_client=None)</code>","text":"<p>Call to synapse and set the annotations for the given input.</p> PARAMETER DESCRIPTION <code>annotations</code> <p>The annotations to set. This is expected to have the id, etag, and annotations filled in.</p> <p> TYPE: <code>Annotations</code> </p> <code>synapse_client</code> <p>If not passed in or None this will use the last client from the <code>.login()</code> method.</p> <p> TYPE: <code>Optional[Synapse]</code> DEFAULT: <code>None</code> </p> <p>Returns: The annotations set in Synapse.</p> Source code in <code>synapseclient/api/annotations.py</code> <pre><code>def set_annotations(\n    annotations: \"Annotations\",\n    *,\n    synapse_client: Optional[\"Synapse\"] = None,\n):\n    \"\"\"Call to synapse and set the annotations for the given input.\n\n    Arguments:\n        annotations: The annotations to set. This is expected to have the id, etag,\n            and annotations filled in.\n        synapse_client: If not passed in or None this will use the last client from\n            the `.login()` method.\n\n    Returns: The annotations set in Synapse.\n    \"\"\"\n    annotations_dict = asdict(annotations)\n\n    synapse_annotations = _convert_to_annotations_list(\n        annotations_dict[\"annotations\"] or {}\n    )\n    from synapseclient import Synapse\n\n    return Synapse.get_client(synapse_client=synapse_client).restPUT(\n        f\"/entity/{annotations.id}/annotations2\",\n        body=json.dumps(\n            {\n                \"id\": annotations.id,\n                \"etag\": annotations.etag,\n                \"annotations\": synapse_annotations,\n            }\n        ),\n    )\n</code></pre>"},{"location":"reference/rest_apis/#synapseclient.api.annotations.set_annotations_async","title":"<code>set_annotations_async(annotations, *, synapse_client=None)</code>  <code>async</code>","text":"<p>Call to synapse and set the annotations for the given input.</p> PARAMETER DESCRIPTION <code>annotations</code> <p>The annotations to set. This is expected to have the id, etag, and annotations filled in.</p> <p> TYPE: <code>Annotations</code> </p> <code>synapse_client</code> <p>If not passed in or None this will use the last client from the <code>.login()</code> method.</p> <p> TYPE: <code>Optional[Synapse]</code> DEFAULT: <code>None</code> </p> <p>Returns: The annotations set in Synapse.</p> Source code in <code>synapseclient/api/annotations.py</code> <pre><code>async def set_annotations_async(\n    annotations: \"Annotations\",\n    *,\n    synapse_client: Optional[\"Synapse\"] = None,\n):\n    \"\"\"Call to synapse and set the annotations for the given input.\n\n    Arguments:\n        annotations: The annotations to set. This is expected to have the id, etag,\n            and annotations filled in.\n        synapse_client: If not passed in or None this will use the last client from\n            the `.login()` method.\n\n    Returns: The annotations set in Synapse.\n    \"\"\"\n    annotations_dict = asdict(annotations)\n\n    synapse_annotations = _convert_to_annotations_list(\n        annotations_dict[\"annotations\"] or {}\n    )\n    from synapseclient import Synapse\n\n    return await Synapse.get_client(synapse_client=synapse_client).rest_put_async(\n        f\"/entity/{annotations.id}/annotations2\",\n        body=json.dumps(\n            {\n                \"id\": annotations.id,\n                \"etag\": annotations.etag,\n                \"annotations\": synapse_annotations,\n            }\n        ),\n    )\n</code></pre>"},{"location":"reference/synapse_utils/","title":"Synapse Utils","text":""},{"location":"reference/synapse_utils/#synapseutils","title":"<code>synapseutils</code>","text":""},{"location":"reference/synapse_utils/#synapseutils--overview","title":"Overview","text":"<p>The <code>synapseutils</code> package provides both higher level beta functions as well as utilities for interacting with Synapse.  The behavior of these functions are subject to change.</p>"},{"location":"reference/synapse_utils/#synapseutils-functions","title":"Functions","text":""},{"location":"reference/synapse_utils/#synapseutils.sync","title":"<code>synapseutils.sync</code>","text":"<p>This module is responsible for holding sync to/from synapse utility functions.</p>"},{"location":"reference/synapse_utils/#synapseutils.sync-functions","title":"Functions","text":""},{"location":"reference/synapse_utils/#synapseutils.sync.syncFromSynapse","title":"<code>syncFromSynapse(syn, entity, path=None, ifcollision='overwrite.local', allFiles=None, followLink=False, manifest='all', downloadFile=True)</code>","text":"<p>Synchronizes a File entity, or a Folder entity, meaning all the files in a folder (including subfolders) from Synapse, and adds a readme manifest with file metadata.</p> <p>There are a few conversions around annotations to call out here.</p>"},{"location":"reference/synapse_utils/#synapseutils.sync.syncFromSynapse--conversion-of-objects-from-the-rest-api-to-python-native-objects","title":"Conversion of objects from the REST API to Python native objects","text":"<p>The first annotation conversion is to take the annotations from the REST API and convert them into Python native objects. For example the REST API will return a milliseconds since epoch timestamp for a datetime annotation, however, we want to convert that into a Python datetime object. These conversions take place in the annotations module.</p>"},{"location":"reference/synapse_utils/#synapseutils.sync.syncFromSynapse--conversion-of-python-native-objects-into-strings","title":"Conversion of Python native objects into strings","text":"<p>The second annotation conversion occurs when we are writing to the manifest TSV file. In this case we need to convert the Python native objects into strings that can be written to the manifest file. In addition we also need to handle the case where the annotation value is a list of objects. In this case we are converting the list into a single cell of data with a comma <code>,</code> delimiter wrapped in brackets <code>[]</code>.</p> PARAMETER DESCRIPTION <code>syn</code> <p>A Synapse object with user's login, e.g. syn = synapseclient.login()</p> <p> TYPE: <code>Synapse</code> </p> <code>entity</code> <p>A Synapse ID, a Synapse Entity object of type file, folder or     project.</p> <p> TYPE: <code>Union[str, File, Project, Folder]</code> </p> <code>path</code> <p>An optional path where the file hierarchy will be reproduced. If not specified the files will by default be placed in the synapseCache. A path is required in order to create a manifest file. A manifest is TSV file that is automatically created that contains metadata (annotations, storage location and provenance) of all downloaded files. If no files were downloaded, no manifest file will be created.</p> <p> TYPE: <code>str</code> DEFAULT: <code>None</code> </p> <code>ifcollision</code> <p>Determines how to handle file collisions. Maybe          \"overwrite.local\", \"keep.local\", or \"keep.both\".</p> <p> TYPE: <code>str</code> DEFAULT: <code>'overwrite.local'</code> </p> <code>allFiles</code> <p>Deprecated and not to be used. This will be removed in v5.0.0.</p> <p> DEFAULT: <code>None</code> </p> <code>followLink</code> <p>Determines whether the link returns the target Entity.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>manifest</code> <p>Determines whether creating manifest file automatically. The       optional values here (<code>all</code>, <code>root</code>, <code>suppress</code>).</p> <p> TYPE: <code>str</code> DEFAULT: <code>'all'</code> </p> <code>downloadFile</code> <p>Determines whether downloading the files.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> RETURNS DESCRIPTION <p>List of files</p> <p>When entity is a Project or Folder, this function will crawl all subfolders of the project/folder specified by <code>entity</code> and download all files that have not already been downloaded. When entity is a File the function will download the latest version of the file unless version is denoted in the synid with .version notiation (e.g. syn123.1) If there are newer files in Synapse (or a local file has been edited outside of the cache) since the last download then local the file will be replaced by the new file unless \"ifcollision\" is changed.</p> <p>If the files are being downloaded to a specific location outside of the Synapse cache a file (SYNAPSE_METADATA_MANIFEST.tsv) will also be added in the path that contains the metadata (annotations, storage location and provenance of all downloaded files).</p> <p>See also:</p> <ul> <li>synapseutils.sync.syncToSynapse</li> </ul> Using this function <p>Download and print the paths of all downloaded files:</p> <pre><code>entities = syncFromSynapse(syn, \"syn1234\")\nfor f in entities:\n    print(f.path)\n</code></pre> Source code in <code>synapseutils/sync.py</code> <pre><code>def syncFromSynapse(\n    syn: Synapse,\n    entity: Union[str, SynapseFile, SynapseProject, SynapseFolder],\n    path: str = None,\n    ifcollision: str = \"overwrite.local\",\n    allFiles=None,\n    followLink: bool = False,\n    manifest: str = \"all\",\n    downloadFile: bool = True,\n):\n    \"\"\"Synchronizes a File entity, or a Folder entity, meaning all the files in a folder\n    (including subfolders) from Synapse, and adds a readme manifest with file metadata.\n\n    There are a few conversions around annotations to call out here.\n\n    ## Conversion of objects from the REST API to Python native objects\n\n    The first annotation conversion is to take the annotations from the REST API and\n    convert them into Python native objects. For example the REST API will return a\n    milliseconds since epoch timestamp for a datetime annotation, however, we want to\n    convert that into a Python datetime object. These conversions take place in the\n    [annotations module][synapseclient.annotations].\n\n\n    ## Conversion of Python native objects into strings\n\n    The second annotation conversion occurs when we are writing to the manifest TSV file.\n    In this case we need to convert the Python native objects into strings that can be\n    written to the manifest file. In addition we also need to handle the case where the\n    annotation value is a list of objects. In this case we are converting the list\n    into a single cell of data with a comma `,` delimiter wrapped in brackets `[]`.\n\n    Arguments:\n        syn: A Synapse object with user's login, e.g. syn = synapseclient.login()\n        entity: A Synapse ID, a Synapse Entity object of type file, folder or\n                project.\n        path: An optional path where the file hierarchy will be reproduced. If not\n            specified the files will by default be placed in the synapseCache. A path\n            is required in order to create a manifest file. A manifest is TSV file\n            that is automatically created that contains metadata (annotations, storage\n            location and provenance) of all downloaded files. If no files were\n            downloaded, no manifest file will be created.\n        ifcollision: Determines how to handle file collisions. Maybe\n                     \"overwrite.local\", \"keep.local\", or \"keep.both\".\n        allFiles: Deprecated and not to be used. This will be removed in v5.0.0.\n        followLink: Determines whether the link returns the target Entity.\n        manifest: Determines whether creating manifest file automatically. The\n                  optional values here (`all`, `root`, `suppress`).\n        downloadFile: Determines whether downloading the files.\n\n    Returns:\n        List of [files][synapseclient.File]\n\n\n    When entity is a Project or Folder, this function will crawl all subfolders\n    of the project/folder specified by `entity` and download all files that have\n    not already been downloaded. When entity is a File the function will download the\n    latest version of the file unless version is denoted in the synid with .version\n    notiation (e.g. syn123.1) If there are newer files in Synapse (or a local file\n    has been edited outside of the cache) since the last download then local the file\n    will be replaced by the new file unless \"ifcollision\" is changed.\n\n    If the files are being downloaded to a specific location outside of the Synapse\n    cache a file (SYNAPSE_METADATA_MANIFEST.tsv) will also be added in the path that\n    contains the metadata (annotations, storage location and provenance of all\n    downloaded files).\n\n    See also:\n\n    - [synapseutils.sync.syncToSynapse][]\n\n    Example: Using this function\n        Download and print the paths of all downloaded files:\n\n            entities = syncFromSynapse(syn, \"syn1234\")\n            for f in entities:\n                print(f.path)\n    \"\"\"\n\n    if manifest not in (\"all\", \"root\", \"suppress\"):\n        raise ValueError(\n            'Value of manifest option should be one of the (\"all\", \"root\", \"suppress\")'\n        )\n\n    # we'll have the following threads:\n    # 1. the entrant thread to this function walks the folder hierarchy and\n    #    schedules files for download,\n    #    and then waits for all the file downloads to complete\n    # 2. each file download will run in a separate thread in an Executor\n    # 3. downloads that support S3 multipart concurrent downloads will be scheduled\n    #    by the thread in #2 and have\n    #    their parts downloaded in additional threads in the same Executor\n\n    with shared_download_progress_bar(file_size=1, synapse_client=syn):\n        root_entity = wrap_async_to_sync(\n            coroutine=_sync(\n                syn=syn,\n                entity=entity,\n                path=path,\n                if_collision=ifcollision,\n                follow_link=followLink,\n                download_file=downloadFile,\n                manifest=manifest,\n            ),\n            syn=syn,\n        )\n\n    files = []\n\n    from synapseclient.models import Folder, Project\n\n    # Handle the creation of a manifest TSV file. The way that this works is that\n    # a manifest is created for each directory level if \"all\" is specified. If \"root\"\n    # is specified then only the root directory will have a manifest created.\n    if isinstance(root_entity, Project) or isinstance(root_entity, Folder):\n        files = root_entity.flatten_file_list()\n        if manifest == \"all\" and path:\n            for (\n                directory_path,\n                file_entities,\n            ) in root_entity.map_directory_to_all_contained_files(\n                root_path=path\n            ).items():\n                generate_manifest(\n                    all_files=file_entities,\n                    path=directory_path,\n                )\n        elif manifest == \"root\" and path:\n            generate_manifest(\n                all_files=files,\n                path=path,\n            )\n    elif isinstance(root_entity, File):\n        # When the root entity is a file we do not create a manifest file. This is\n        # to match the behavior present in v4.x.x of the client.\n        files = [root_entity]\n\n    synapse_files = []\n    for file in files:\n        synapse_files.append(file._convert_into_legacy_file())\n\n    # the allFiles parameter used to be passed in as part of the recursive\n    # implementation of this function with the public signature invoking itself. now\n    # that this isn't a recursive any longer we don't need allFiles as a parameter\n    # (especially on the public signature) but it is retained for now for backwards\n    # compatibility with external invokers. To be removed in v5.0.0.\n    if allFiles is not None:\n        allFiles.extend(synapse_files)\n        synapse_files = allFiles\n\n    return synapse_files\n</code></pre>"},{"location":"reference/synapse_utils/#synapseutils.sync.syncToSynapse","title":"<code>syncToSynapse(syn, manifestFile, dryRun=False, sendMessages=True, retries=MAX_RETRIES, merge_existing_annotations=True, associate_activity_to_new_version=False)</code>","text":"<p>Synchronizes files specified in the manifest file to Synapse.</p> <p>Given a file describing all of the uploads, this uploads the content to Synapse and optionally notifies you via Synapse messagging (email) at specific intervals, on errors and on completion.</p> <p>Read more about the manifest file format</p> <p>There are a few conversions around annotations to call out here.</p>"},{"location":"reference/synapse_utils/#synapseutils.sync.syncToSynapse--conversion-of-annotations-from-the-tsv-file-to-python-native-objects","title":"Conversion of annotations from the TSV file to Python native objects","text":"<p>The first annotation conversion is from the TSV file into a Python native object. For example Pandas will read a TSV file and convert the string \"True\" into a boolean True, however, Pandas will NOT convert our comma delimited and bracket wrapped list of annotations into their Python native objects. This means that we need to do that conversion here after splitting them apart.</p>"},{"location":"reference/synapse_utils/#synapseutils.sync.syncToSynapse--conversion-of-python-native-objects-for-the-rest-api","title":"Conversion of Python native objects for the REST API","text":"<p>The second annotation conversion occurs when we are taking the Python native objects and converting them into a string that can be sent to the REST API. For example the datetime objects which may have timezone information are converted to milliseconds since epoch.</p> PARAMETER DESCRIPTION <code>syn</code> <p>A Synapse object with user's login, e.g. syn = synapseclient.login()</p> <p> TYPE: <code>Synapse</code> </p> <code>manifestFile</code> <p>A tsv file with file locations and metadata to be pushed to Synapse.</p> <p> </p> <code>dryRun</code> <p>Performs validation without uploading if set to True.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>sendMessages</code> <p>Sends out messages on completion if set to True.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> <code>retries</code> <p>Number of retries to attempt if an error occurs.</p> <p> TYPE: <code>int</code> DEFAULT: <code>MAX_RETRIES</code> </p> <code>merge_existing_annotations</code> <p>If True, will merge the annotations in the manifest file with the existing annotations on Synapse. If False, will overwrite the existing annotations on Synapse with the annotations in the manifest file.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> <code>associate_activity_to_new_version</code> <p>If True, and a version update occurs, the existing activity in Synapse will be associated with the new version. The exception is if you are specifying new values to be used/executed, it will create a new activity for the new version of the entity.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> RETURNS DESCRIPTION <code>None</code> <p>None</p> Source code in <code>synapseutils/sync.py</code> <pre><code>def syncToSynapse(\n    syn: Synapse,\n    manifestFile,\n    dryRun: bool = False,\n    sendMessages: bool = True,\n    retries: int = MAX_RETRIES,\n    merge_existing_annotations: bool = True,\n    associate_activity_to_new_version: bool = False,\n) -&gt; None:\n    \"\"\"Synchronizes files specified in the manifest file to Synapse.\n\n    Given a file describing all of the uploads, this uploads the content to Synapse and\n    optionally notifies you via Synapse messagging (email) at specific intervals, on\n    errors and on completion.\n\n    [Read more about the manifest file format](../../explanations/manifest_tsv/)\n\n    There are a few conversions around annotations to call out here.\n\n    ## Conversion of annotations from the TSV file to Python native objects\n\n    The first annotation conversion is from the TSV file into a Python native object. For\n    example Pandas will read a TSV file and convert the string \"True\" into a boolean True,\n    however, Pandas will NOT convert our comma delimited and bracket wrapped list of\n    annotations into their Python native objects. This means that we need to do that\n    conversion here after splitting them apart.\n\n    ## Conversion of Python native objects for the REST API\n\n    The second annotation conversion occurs when we are taking the Python native objects\n    and converting them into a string that can be sent to the REST API. For example\n    the datetime objects which may have timezone information are converted to milliseconds\n    since epoch.\n\n    Arguments:\n        syn: A Synapse object with user's login, e.g. syn = synapseclient.login()\n        manifestFile: A tsv file with file locations and metadata to be pushed to Synapse.\n        dryRun: Performs validation without uploading if set to True.\n        sendMessages: Sends out messages on completion if set to True.\n        retries: Number of retries to attempt if an error occurs.\n        merge_existing_annotations: If True, will merge the annotations in the manifest\n            file with the existing annotations on Synapse. If False, will overwrite the\n            existing annotations on Synapse with the annotations in the manifest file.\n        associate_activity_to_new_version: If True, and a version update occurs, the\n            existing activity in Synapse will be associated with the new version. The\n            exception is if you are specifying new values to be used/executed, it will\n            create a new activity for the new version of the entity.\n\n    Returns:\n        None\n    \"\"\"\n    df = readManifestFile(syn, manifestFile)\n\n    sizes = [\n        os.stat(os.path.expandvars(os.path.expanduser(f))).st_size\n        for f in df.path\n        if not is_url(f)\n    ]\n\n    total_upload_size = sum(sizes)\n\n    syn.logger.info(\n        f\"We are about to upload {len(df)} files with a total size of {total_upload_size}.\"\n    )\n\n    if dryRun:\n        syn.logger.info(\"Returning due to Dry Run.\")\n        return\n\n    progress_bar = tqdm(\n        total=total_upload_size,\n        desc=f\"Uploading {len(df)} files\",\n        unit=\"B\",\n        unit_scale=True,\n        smoothing=0,\n    )\n    with upload_shared_progress_bar(progress_bar):\n        if sendMessages:\n            notify_decorator = notify_me_async(\n                syn, \"Upload of %s\" % manifestFile, retries=retries\n            )\n            upload = notify_decorator(_manifest_upload)\n            wrap_async_to_sync(\n                upload(\n                    syn,\n                    df,\n                    merge_existing_annotations,\n                    associate_activity_to_new_version,\n                ),\n                syn,\n            )\n        else:\n            wrap_async_to_sync(\n                _manifest_upload(\n                    syn,\n                    df,\n                    merge_existing_annotations,\n                    associate_activity_to_new_version,\n                ),\n                syn,\n            )\n        progress_bar.update(total_upload_size - progress_bar.n)\n        progress_bar.close()\n</code></pre>"},{"location":"reference/synapse_utils/#synapseutils.sync.generateManifest","title":"<code>generateManifest(syn, allFiles, filename, provenance_cache=None)</code>","text":"<p>Generates a manifest file based on a list of entities objects.</p> <p>Read more about the manifest file format</p> PARAMETER DESCRIPTION <code>syn</code> <p>A Synapse object with user's login, e.g. syn = synapseclient.login()</p> <p> </p> <code>allFiles</code> <p>A list of File Entity objects on Synapse (can't be Synapse IDs)</p> <p> </p> <code>filename</code> <p>file where manifest will be written</p> <p> </p> <code>provenance_cache</code> <p>an optional dict of known provenance dicts keyed by entity               ids</p> <p> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>None</code> <p>None</p> Source code in <code>synapseutils/sync.py</code> <pre><code>@deprecated(\n    version=\"4.4.0\",\n    reason=\"To be removed in 5.0.0. This is being replaced by `generate_manifest`.\",\n)\ndef generateManifest(syn, allFiles, filename, provenance_cache=None) -&gt; None:\n    \"\"\"Generates a manifest file based on a list of entities objects.\n\n    [Read more about the manifest file format](../../explanations/manifest_tsv/)\n\n    Arguments:\n        syn: A Synapse object with user's login, e.g. syn = synapseclient.login()\n        allFiles: A list of File Entity objects on Synapse (can't be Synapse IDs)\n        filename: file where manifest will be written\n        provenance_cache: an optional dict of known provenance dicts keyed by entity\n                          ids\n\n    Returns:\n        None\n    \"\"\"\n    keys, data = _extract_file_entity_metadata(\n        syn=syn, allFiles=allFiles, provenance_cache=provenance_cache\n    )\n    _write_manifest_data(filename, keys, data)\n</code></pre>"},{"location":"reference/synapse_utils/#synapseutils.sync.generate_sync_manifest","title":"<code>generate_sync_manifest(syn, directory_path, parent_id, manifest_path)</code>","text":"<p>Generate manifest for syncToSynapse from a local directory.</p> <p>Read more about the manifest file format</p> PARAMETER DESCRIPTION <code>syn</code> <p>A Synapse object with user's login, e.g. syn = synapseclient.login()</p> <p> </p> <code>directory_path</code> <p>Path to local directory to be pushed to Synapse.</p> <p> </p> <code>parent_id</code> <p>Synapse ID of the parent folder/project on Synapse.</p> <p> </p> <code>manifest_path</code> <p>Path to the manifest file to be generated.</p> <p> </p> RETURNS DESCRIPTION <code>None</code> <p>None</p> Source code in <code>synapseutils/sync.py</code> <pre><code>def generate_sync_manifest(syn, directory_path, parent_id, manifest_path) -&gt; None:\n    \"\"\"Generate manifest for [syncToSynapse][synapseutils.sync.syncToSynapse] from a local directory.\n\n    [Read more about the manifest file format](../../explanations/manifest_tsv/)\n\n    Arguments:\n        syn: A Synapse object with user's login, e.g. syn = synapseclient.login()\n        directory_path: Path to local directory to be pushed to Synapse.\n        parent_id: Synapse ID of the parent folder/project on Synapse.\n        manifest_path: Path to the manifest file to be generated.\n\n    Returns:\n        None\n    \"\"\"\n    manifest_cols = [\"path\", \"parent\"]\n    manifest_rows = _walk_directory_tree(syn, directory_path, parent_id)\n    _write_manifest_data(manifest_path, manifest_cols, manifest_rows)\n</code></pre>"},{"location":"reference/synapse_utils/#synapseutils.sync.readManifestFile","title":"<code>readManifestFile(syn, manifestFile)</code>","text":"<p>Verifies a file manifest and returns a reordered dataframe ready for upload.</p> <p>Read more about the manifest file format</p> PARAMETER DESCRIPTION <code>syn</code> <p>A Synapse object with user's login, e.g. syn = synapseclient.login()</p> <p> </p> <code>manifestFile</code> <p>A tsv file with file locations and metadata to be pushed to Synapse.</p> <p> </p> RETURNS DESCRIPTION <p>A pandas dataframe if the manifest is validated.</p> Source code in <code>synapseutils/sync.py</code> <pre><code>def readManifestFile(syn, manifestFile):\n    \"\"\"Verifies a file manifest and returns a reordered dataframe ready for upload.\n\n    [Read more about the manifest file format](../../explanations/manifest_tsv/)\n\n    Arguments:\n        syn: A Synapse object with user's login, e.g. syn = synapseclient.login()\n        manifestFile: A tsv file with file locations and metadata to be pushed to Synapse.\n\n    Returns:\n        A pandas dataframe if the manifest is validated.\n    \"\"\"\n    table.test_import_pandas()\n    import pandas as pd\n\n    if manifestFile is sys.stdin:\n        sys.stdout.write(\"Validation and upload of: &lt;stdin&gt;\\n\")\n    else:\n        sys.stdout.write(\"Validation and upload of: %s\\n\" % manifestFile)\n    # Read manifest file into pandas dataframe\n    df = pd.read_csv(manifestFile, sep=\"\\t\")\n    if \"synapseStore\" not in df:\n        df = df.assign(synapseStore=None)\n    df.loc[\n        df[\"path\"].apply(is_url), \"synapseStore\"\n    ] = False  # override synapseStore values to False when path is a url\n    df.loc[\n        df[\"synapseStore\"].isnull(), \"synapseStore\"\n    ] = True  # remaining unset values default to True\n    df.synapseStore = df.synapseStore.astype(bool)\n    df = df.fillna(\"\")\n\n    sys.stdout.write(\"Validating columns of manifest...\")\n    for field in REQUIRED_FIELDS:\n        sys.stdout.write(\".\")\n        if field not in df.columns:\n            sys.stdout.write(\"\\n\")\n            raise ValueError(\"Manifest must contain a column of %s\" % field)\n    sys.stdout.write(\"OK\\n\")\n\n    sys.stdout.write(\"Validating that all paths exist...\")\n    df.path = df.path.apply(_check_path_and_normalize)\n\n    sys.stdout.write(\"OK\\n\")\n\n    sys.stdout.write(\"Validating that all files are unique...\")\n    # Both the path and the combination of entity name and parent must be unique\n    if len(df.path) != len(set(df.path)):\n        raise ValueError(\"All rows in manifest must contain a unique file to upload\")\n    sys.stdout.write(\"OK\\n\")\n\n    # Check each size of uploaded file\n    sys.stdout.write(\"Validating that all the files are not empty...\")\n    _check_size_each_file(df)\n    sys.stdout.write(\"OK\\n\")\n\n    # check the name of each file should be store on Synapse\n    name_column = \"name\"\n    # Create entity name column from basename\n    if name_column not in df.columns:\n        filenames = [os.path.basename(path) for path in df[\"path\"]]\n        df[\"name\"] = filenames\n\n    sys.stdout.write(\"Validating file names... \\n\")\n    _check_file_name(df)\n    sys.stdout.write(\"OK\\n\")\n\n    sys.stdout.write(\"Validating provenance...\")\n    df = _sortAndFixProvenance(syn, df)\n    sys.stdout.write(\"OK\\n\")\n\n    sys.stdout.write(\"Validating that parents exist and are containers...\")\n    parents = set(df.parent)\n    for synId in parents:\n        try:\n            container = syn.get(synId, downloadFile=False)\n        except SynapseHTTPError:\n            sys.stdout.write(\n                \"\\n%s in the parent column is not a valid Synapse Id\\n\" % synId\n            )\n            raise\n        if not is_container(container):\n            sys.stdout.write(\n                \"\\n%s in the parent column is is not a Folder or Project\\n\" % synId\n            )\n            raise SynapseHTTPError\n    sys.stdout.write(\"OK\\n\")\n    return df\n</code></pre>"},{"location":"reference/synapse_utils/#synapseutils.copy_functions","title":"<code>synapseutils.copy_functions</code>","text":""},{"location":"reference/synapse_utils/#synapseutils.copy_functions-functions","title":"Functions","text":""},{"location":"reference/synapse_utils/#synapseutils.copy_functions.copy","title":"<code>copy(syn, entity, destinationId, skipCopyWikiPage=False, skipCopyAnnotations=False, **kwargs)</code>","text":"<ul> <li>This function will assist users in copying entities     (     Tables,     Links,     Files,     Folders,     Projects     ),   and will recursively copy everything in directories.</li> <li>A Mapping of the old entities to the new entities will be created and all the wikis of each entity   will also be copied over and links to synapse Ids will be updated.</li> </ul> PARAMETER DESCRIPTION <code>syn</code> <p>A Synapse object with user's login, e.g. syn = synapseclient.login()</p> <p> TYPE: <code>Synapse</code> </p> <code>entity</code> <p>A synapse entity ID</p> <p> TYPE: <code>str</code> </p> <code>destinationId</code> <p>Synapse ID of a folder/project that the copied entity is being copied to</p> <p> TYPE: <code>str</code> </p> <code>skipCopyWikiPage</code> <p>Skip copying the wiki pages.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>skipCopyAnnotations</code> <p>Skips copying the annotations.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>version</code> <p>(File copy only) Can specify version of a file. Default to None</p> <p> </p> <code>updateExisting</code> <p>(File copy only) When the destination has an entity that has the same name,             users can choose to update that entity. It must be the same entity type             Default to False</p> <p> </p> <code>setProvenance</code> <p>(File copy only) Has three values to set the provenance of the copied entity:             traceback: Sets to the source entity             existing: Sets to source entity's original provenance (if it exists)             None: No provenance is set</p> <p> </p> <code>excludeTypes</code> <p>(Folder/Project copy only) Accepts a list of entity types (file, table, link)             which determines which entity types to not copy. Defaults to an empty list.</p> <p> </p> RETURNS DESCRIPTION <code>Dict[str, str]</code> <p>A mapping between the original and copied entity: {'syn1234':'syn33455'}</p> Using this function <p>Sample copy:</p> <pre><code>import synapseutils\nimport synapseclient\nsyn = synapseclient.login()\nsynapseutils.copy(syn, ...)\n</code></pre> <p>Copying Files:</p> <pre><code>synapseutils.copy(syn, \"syn12345\", \"syn45678\", updateExisting=False, setProvenance = \"traceback\",version=None)\n</code></pre> <p>Copying Folders/Projects:</p> <pre><code># This will copy everything in the project into the destinationId except files and tables.\nsynapseutils.copy(syn, \"syn123450\",\"syn345678\",excludeTypes=[\"file\",\"table\"])\n</code></pre> Source code in <code>synapseutils/copy_functions.py</code> <pre><code>def copy(\n    syn: synapseclient.Synapse,\n    entity: str,\n    destinationId: str,\n    skipCopyWikiPage: bool = False,\n    skipCopyAnnotations: bool = False,\n    **kwargs,\n) -&gt; typing.Dict[str, str]:\n    \"\"\"\n    - This function will assist users in copying entities\n        (\n        [Tables][synapseclient.table.Table],\n        [Links][synapseclient.entity.Link],\n        [Files][synapseclient.entity.File],\n        [Folders][synapseclient.entity.Folder],\n        [Projects][synapseclient.entity.Project]\n        ),\n      and will recursively copy everything in directories.\n    - A Mapping of the old entities to the new entities will be created and all the wikis of each entity\n      will also be copied over and links to synapse Ids will be updated.\n\n    Arguments:\n        syn: A Synapse object with user's login, e.g. syn = synapseclient.login()\n        entity: A synapse entity ID\n        destinationId: Synapse ID of a folder/project that the copied entity is being copied to\n        skipCopyWikiPage: Skip copying the wiki pages.\n        skipCopyAnnotations: Skips copying the annotations.\n        version: (File copy only) Can specify version of a file. Default to None\n        updateExisting: (File copy only) When the destination has an entity that has the same name,\n                        users can choose to update that entity. It must be the same entity type\n                        Default to False\n        setProvenance: (File copy only) Has three values to set the provenance of the copied entity:\n                        traceback: Sets to the source entity\n                        existing: Sets to source entity's original provenance (if it exists)\n                        None: No provenance is set\n        excludeTypes: (Folder/Project copy only) Accepts a list of entity types (file, table, link)\n                        which determines which entity types to not copy. Defaults to an empty list.\n\n    Returns:\n        A mapping between the original and copied entity: {'syn1234':'syn33455'}\n\n    Example: Using this function\n        Sample copy:\n\n            import synapseutils\n            import synapseclient\n            syn = synapseclient.login()\n            synapseutils.copy(syn, ...)\n\n        Copying Files:\n\n            synapseutils.copy(syn, \"syn12345\", \"syn45678\", updateExisting=False, setProvenance = \"traceback\",version=None)\n\n        Copying Folders/Projects:\n\n            # This will copy everything in the project into the destinationId except files and tables.\n            synapseutils.copy(syn, \"syn123450\",\"syn345678\",excludeTypes=[\"file\",\"table\"])\n    \"\"\"\n    updateLinks = kwargs.get(\"updateLinks\", True)\n    updateSynIds = kwargs.get(\"updateSynIds\", True)\n    entitySubPageId = kwargs.get(\"entitySubPageId\", None)\n    destinationSubPageId = kwargs.get(\"destinationSubPageId\", None)\n\n    mapping = _copyRecursive(\n        syn, entity, destinationId, skipCopyAnnotations=skipCopyAnnotations, **kwargs\n    )\n    if not skipCopyWikiPage:\n        for oldEnt in mapping:\n            copyWiki(\n                syn,\n                oldEnt,\n                mapping[oldEnt],\n                entitySubPageId=entitySubPageId,\n                destinationSubPageId=destinationSubPageId,\n                updateLinks=updateLinks,\n                updateSynIds=updateSynIds,\n                entityMap=mapping,\n            )\n    return mapping\n</code></pre>"},{"location":"reference/synapse_utils/#synapseutils.copy_functions.changeFileMetaData","title":"<code>changeFileMetaData(syn, entity, downloadAs=None, contentType=None, forceVersion=True, name=None)</code>","text":"<p>Change File Entity metadata like the download as name.</p> PARAMETER DESCRIPTION <code>syn</code> <p>A Synapse object with user's login, e.g. syn = synapseclient.login()</p> <p> TYPE: <code>Synapse</code> </p> <code>entity</code> <p>Synapse entity Id or object.</p> <p> TYPE: <code>Union[str, Entity]</code> </p> <code>downloadAs</code> <p>Specify filename to change the filename of a filehandle.</p> <p> TYPE: <code>str</code> DEFAULT: <code>None</code> </p> <code>contentType</code> <p>Specify content type to change the content type of a filehandle.</p> <p> TYPE: <code>str</code> DEFAULT: <code>None</code> </p> <code>forceVersion</code> <p>Indicates whether the method should increment the version of             the object even if nothing has changed. Defaults to True.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> <code>name</code> <p>Specify filename to change the filename of the file.</p> <p> TYPE: <code>str</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>Entity</code> <p>Synapse Entity</p> Using this function <p>Updating all file 'downloadAs' names within a folder to match the name of the entity.</p> <pre><code>import synapseclient\nimport synapseutils\n\n\nsyn = synapseclient.Synapse()\nsyn.login()\n\nMY_FOLDER_TO_UPDATE_ALL_FILES_IN = \"syn123\"\n\nfor files_to_update in syn.getChildren(\n    parent=MY_FOLDER_TO_UPDATE_ALL_FILES_IN, includeTypes=[\"file\"]\n):\n    file_to_check = syn.get(files_to_update[\"id\"], downloadFile=False)\n    if file_to_check.name != file_to_check[\"_file_handle\"][\"fileName\"]:\n        print(\n            f\"Updating downloadAs for {file_to_check['_file_handle']['fileName']} to {file_to_check.name}\"\n        )\n\n        synapseutils.changeFileMetaData(\n            syn=syn,\n            entity=file_to_check.id,\n            downloadAs=file_to_check.name,\n            forceVersion=False,\n        )\n</code></pre> <p>Can be used to change the filename, the filename when the file is downloaded, or the file content-type without downloading:</p> <pre><code>file_entity = syn.get(synid)\nprint(os.path.basename(file_entity.path))  ## prints, e.g., \"my_file.txt\"\nfile_entity = synapseutils.changeFileMetaData(syn=syn, entity=file_entity, downloadAs=\"my_new_downloadAs_name_file.txt\", name=\"my_new_name_file.txt\")\nprint(os.path.basename(file_entity.path))  ## prints, \"my_new_downloadAs_name_file.txt\"\nprint(file_entity.name) ## prints, \"my_new_name_file.txt\"\n</code></pre> Source code in <code>synapseutils/copy_functions.py</code> <pre><code>def changeFileMetaData(\n    syn: synapseclient.Synapse,\n    entity: typing.Union[str, Entity],\n    downloadAs: str = None,\n    contentType: str = None,\n    forceVersion: bool = True,\n    name: str = None,\n) -&gt; Entity:\n    \"\"\"\n    Change File Entity metadata like the download as name.\n\n    Arguments:\n        syn: A Synapse object with user's login, e.g. syn = synapseclient.login()\n        entity: Synapse entity Id or object.\n        downloadAs: Specify filename to change the filename of a filehandle.\n        contentType: Specify content type to change the content type of a filehandle.\n        forceVersion: Indicates whether the method should increment the version of\n                        the object even if nothing has changed. Defaults to True.\n        name: Specify filename to change the filename of the file.\n\n    Returns:\n        Synapse Entity\n\n    Example: Using this function\n        Updating all file 'downloadAs' names within a folder to match the name of the\n        entity.\n\n            import synapseclient\n            import synapseutils\n\n\n            syn = synapseclient.Synapse()\n            syn.login()\n\n            MY_FOLDER_TO_UPDATE_ALL_FILES_IN = \"syn123\"\n\n            for files_to_update in syn.getChildren(\n                parent=MY_FOLDER_TO_UPDATE_ALL_FILES_IN, includeTypes=[\"file\"]\n            ):\n                file_to_check = syn.get(files_to_update[\"id\"], downloadFile=False)\n                if file_to_check.name != file_to_check[\"_file_handle\"][\"fileName\"]:\n                    print(\n                        f\"Updating downloadAs for {file_to_check['_file_handle']['fileName']} to {file_to_check.name}\"\n                    )\n\n                    synapseutils.changeFileMetaData(\n                        syn=syn,\n                        entity=file_to_check.id,\n                        downloadAs=file_to_check.name,\n                        forceVersion=False,\n                    )\n\n\n        Can be used to change the filename, the filename when the file is downloaded,\n        or the file content-type without downloading:\n\n            file_entity = syn.get(synid)\n            print(os.path.basename(file_entity.path))  ## prints, e.g., \"my_file.txt\"\n            file_entity = synapseutils.changeFileMetaData(syn=syn, entity=file_entity, downloadAs=\"my_new_downloadAs_name_file.txt\", name=\"my_new_name_file.txt\")\n            print(os.path.basename(file_entity.path))  ## prints, \"my_new_downloadAs_name_file.txt\"\n            print(file_entity.name) ## prints, \"my_new_name_file.txt\"\n    \"\"\"\n    ent = syn.get(entity, downloadFile=False)\n    fileResult = syn._getFileHandleDownload(ent.dataFileHandleId, ent.id)\n    ent.contentType = ent.contentType if contentType is None else contentType\n    downloadAs = (\n        fileResult[\"fileHandle\"][\"fileName\"] if downloadAs is None else downloadAs\n    )\n    copiedFileHandle = copyFileHandles(\n        syn,\n        [ent.dataFileHandleId],\n        [ent.concreteType.split(\".\")[-1]],\n        [ent.id],\n        [contentType],\n        [downloadAs],\n    )\n    copyResult = copiedFileHandle[0]\n    if copyResult.get(\"failureCode\") is not None:\n        raise ValueError(\n            \"%s dataFileHandleId: %s\"\n            % (copyResult[\"failureCode\"], copyResult[\"originalFileHandleId\"])\n        )\n    ent.dataFileHandleId = copyResult[\"newFileHandle\"][\"id\"]\n    ent.name = ent.name if name is None else name\n    ent = syn.store(ent, forceVersion=forceVersion)\n    return ent\n</code></pre>"},{"location":"reference/synapse_utils/#synapseutils.copy_functions.copyFileHandles","title":"<code>copyFileHandles(syn, fileHandles, associateObjectTypes, associateObjectIds, newContentTypes=None, newFileNames=None)</code>","text":"<p>Given a list of fileHandle Ids or Objects, copy the fileHandles</p> PARAMETER DESCRIPTION <code>syn</code> <p>A Synapse object with user's login, e.g. syn = synapseclient.login()</p> <p> TYPE: <code>Synapse</code> </p> <code>fileHandles</code> <p>List of fileHandle Ids or Objects</p> <p> TYPE: <code>List[Union[File, Entity]]</code> </p> <code>associateObjectTypes</code> <p>List of associated object types: FileEntity, TableEntity,                     WikiAttachment, UserProfileAttachment, MessageAttachment,                     TeamAttachment, SubmissionAttachment, VerificationSubmission                     (Must be the same length as fileHandles)</p> <p> TYPE: <code>List[str]</code> </p> <code>associateObjectIds</code> <p>List of associated object Ids: If copying a file,                 the objectId is the synapse id, and if copying a wiki attachment,                 the object id is the wiki subpage id.                 (Must be the same length as fileHandles)</p> <p> TYPE: <code>List[str]</code> </p> <code>newContentTypes</code> <p>List of content types. Set each item to a new content type for each file                 handle, or leave the item as None to keep the original content type.                 Default None, which keeps all original content types.</p> <p> TYPE: <code>List[str]</code> DEFAULT: <code>None</code> </p> <code>newFileNames</code> <p>List of filenames. Set each item to a new filename for each file handle,             or leave the item as None to keep the original name. Default None,             which keeps all original file names.</p> <p> TYPE: <code>List[str]</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <p>List of batch filehandle copy results, can include failureCodes: UNAUTHORIZED and NOT_FOUND</p> RAISES DESCRIPTION <code>ValueError</code> <p>If length of all input arguments are not the same</p> Source code in <code>synapseutils/copy_functions.py</code> <pre><code>def copyFileHandles(\n    syn: synapseclient.Synapse,\n    fileHandles: typing.List[typing.Union[File, Entity]],\n    associateObjectTypes: typing.List[str],\n    associateObjectIds: typing.List[str],\n    newContentTypes: typing.List[str] = None,\n    newFileNames: typing.List[str] = None,\n):\n    \"\"\"\n    Given a list of fileHandle Ids or Objects, copy the fileHandles\n\n    Arguments:\n        syn: A Synapse object with user's login, e.g. syn = synapseclient.login()\n        fileHandles: List of fileHandle Ids or Objects\n        associateObjectTypes: List of associated object types: FileEntity, TableEntity,\n                                WikiAttachment, UserProfileAttachment, MessageAttachment,\n                                TeamAttachment, SubmissionAttachment, VerificationSubmission\n                                (Must be the same length as fileHandles)\n        associateObjectIds: List of associated object Ids: If copying a file,\n                            the objectId is the synapse id, and if copying a wiki attachment,\n                            the object id is the wiki subpage id.\n                            (Must be the same length as fileHandles)\n        newContentTypes: List of content types. Set each item to a new content type for each file\n                            handle, or leave the item as None to keep the original content type.\n                            Default None, which keeps all original content types.\n        newFileNames: List of filenames. Set each item to a new filename for each file handle,\n                        or leave the item as None to keep the original name. Default None,\n                        which keeps all original file names.\n\n    Returns:\n        List of batch filehandle copy results, can include failureCodes: UNAUTHORIZED and NOT_FOUND\n\n    Raises:\n        ValueError: If length of all input arguments are not the same\n    \"\"\"\n\n    # Check if length of all inputs are equal\n    if not (\n        len(fileHandles) == len(associateObjectTypes) == len(associateObjectIds)\n        and (newContentTypes is None or len(newContentTypes) == len(associateObjectIds))\n        and (newFileNames is None or len(newFileNames) == len(associateObjectIds))\n    ):\n        raise ValueError(\"Length of all input arguments must be the same\")\n\n    # If no optional params passed, assign to empty list\n    if newContentTypes is None:\n        newContentTypes = []\n    if newFileNames is None:\n        newFileNames = []\n\n    # Remove this line if we change API to only take fileHandleIds and not Objects\n    file_handle_ids = [synapseclient.core.utils.id_of(handle) for handle in fileHandles]\n\n    # division logic for POST call here\n    master_copy_results_list = []  # list which holds all results from POST call\n    for (\n        batch_file_handles_ids,\n        batch_assoc_obj_types,\n        batch_assoc_obj_ids,\n        batch_con_type,\n        batch_file_name,\n    ) in _batch_iterator_generator(\n        [\n            file_handle_ids,\n            associateObjectTypes,\n            associateObjectIds,\n            newContentTypes,\n            newFileNames,\n        ],\n        MAX_FILE_HANDLE_PER_COPY_REQUEST,\n    ):\n        batch_copy_results = _copy_file_handles_batch(\n            syn,\n            batch_file_handles_ids,\n            batch_assoc_obj_types,\n            batch_assoc_obj_ids,\n            batch_con_type,\n            batch_file_name,\n        )\n        master_copy_results_list.extend(batch_copy_results)\n\n    return master_copy_results_list\n</code></pre>"},{"location":"reference/synapse_utils/#synapseutils.copy_functions.copyWiki","title":"<code>copyWiki(syn, entity, destinationId, entitySubPageId=None, destinationSubPageId=None, updateLinks=True, updateSynIds=True, entityMap=None)</code>","text":"<p>Copies wikis and updates internal links</p> PARAMETER DESCRIPTION <code>syn</code> <p>A Synapse object with user's login, e.g. syn = synapseclient.login()</p> <p> </p> <code>entity</code> <p>A synapse ID of an entity whose wiki you want to copy</p> <p> </p> <code>destinationId</code> <p>Synapse ID of a folder/project that the wiki wants to be copied to</p> <p> </p> <code>updateLinks</code> <p>Update all the internal links.          (e.g. syn1234/wiki/34345 becomes syn3345/wiki/49508)</p> <p> DEFAULT: <code>True</code> </p> <code>updateSynIds</code> <p>Update all the synapse ID's referenced in the wikis.             (e.g. syn1234 becomes syn2345)             Defaults to True but needs an entityMap</p> <p> DEFAULT: <code>True</code> </p> <code>entityMap</code> <p>An entity map {'oldSynId','newSynId'} to update the synapse IDs         referenced in the wiki.</p> <p> DEFAULT: <code>None</code> </p> <code>entitySubPageId</code> <p>Can specify subPageId and copy all of its subwikis                 Defaults to None, which copies the entire wiki subPageId can be found:                 https://www.synapse.org/#!Synapse:syn123/wiki/1234                 In this case, 1234 is the subPageId.</p> <p> DEFAULT: <code>None</code> </p> <code>destinationSubPageId</code> <p>Can specify destination subPageId to copy wikis to.</p> <p> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <p>A list of Objects with three fields: id, title and parentId.</p> Source code in <code>synapseutils/copy_functions.py</code> <pre><code>def copyWiki(\n    syn,\n    entity,\n    destinationId,\n    entitySubPageId=None,\n    destinationSubPageId=None,\n    updateLinks=True,\n    updateSynIds=True,\n    entityMap=None,\n):\n    \"\"\"\n    Copies wikis and updates internal links\n\n    Arguments:\n        syn: A Synapse object with user's login, e.g. syn = synapseclient.login()\n        entity: A synapse ID of an entity whose wiki you want to copy\n        destinationId: Synapse ID of a folder/project that the wiki wants to be copied to\n        updateLinks: Update all the internal links.\n                     (e.g. syn1234/wiki/34345 becomes syn3345/wiki/49508)\n        updateSynIds: Update all the synapse ID's referenced in the wikis.\n                        (e.g. syn1234 becomes syn2345)\n                        Defaults to True but needs an entityMap\n        entityMap: An entity map {'oldSynId','newSynId'} to update the synapse IDs\n                    referenced in the wiki.\n        entitySubPageId: Can specify subPageId and copy all of its subwikis\n                            Defaults to None, which copies the entire wiki subPageId can be found:\n                            https://www.synapse.org/#!Synapse:syn123/wiki/1234\n                            In this case, 1234 is the subPageId.\n        destinationSubPageId: Can specify destination subPageId to copy wikis to.\n\n    Returns:\n        A list of Objects with three fields: id, title and parentId.\n    \"\"\"\n\n    # Validate input parameters\n    if entitySubPageId:\n        entitySubPageId = str(int(entitySubPageId))\n    if destinationSubPageId:\n        destinationSubPageId = str(int(destinationSubPageId))\n\n    oldOwn = syn.get(entity, downloadFile=False)\n    # getWikiHeaders fails when there is no wiki\n\n    try:\n        oldWikiHeaders = syn.getWikiHeaders(oldOwn)\n    except SynapseHTTPError as e:\n        if e.response.status_code == 404:\n            return []\n        else:\n            raise e\n\n    newOwn = syn.get(destinationId, downloadFile=False)\n    wikiIdMap = dict()\n    newWikis = dict()\n    # If entitySubPageId is given but not destinationSubPageId, set the pageId to \"\" (will get the root page)\n    # A entitySubPage could be copied to a project without any wiki pages, this has to be checked\n    newWikiPage = None\n    if destinationSubPageId:\n        try:\n            newWikiPage = syn.getWiki(newOwn, destinationSubPageId)\n        except SynapseHTTPError as e:\n            if e.response.status_code == 404:\n                pass\n            else:\n                raise e\n    if entitySubPageId:\n        oldWikiHeaders = _getSubWikiHeaders(oldWikiHeaders, entitySubPageId)\n\n    if not oldWikiHeaders:\n        return []\n\n    for wikiHeader in oldWikiHeaders:\n        wiki = syn.getWiki(oldOwn, wikiHeader[\"id\"])\n        syn.logger.info(\"Got wiki %s\" % wikiHeader[\"id\"])\n        if not wiki.get(\"attachmentFileHandleIds\"):\n            new_file_handles = []\n        else:\n            results = [\n                syn._getFileHandleDownload(\n                    filehandleId, wiki.id, objectType=\"WikiAttachment\"\n                )\n                for filehandleId in wiki[\"attachmentFileHandleIds\"]\n            ]\n            # Get rid of the previews\n            nopreviews = [\n                attach[\"fileHandle\"]\n                for attach in results\n                if not attach[\"fileHandle\"][\"isPreview\"]\n            ]\n            contentTypes = [attach[\"contentType\"] for attach in nopreviews]\n            fileNames = [attach[\"fileName\"] for attach in nopreviews]\n            copiedFileHandles = copyFileHandles(\n                syn,\n                nopreviews,\n                [\"WikiAttachment\"] * len(nopreviews),\n                [wiki.id] * len(nopreviews),\n                contentTypes,\n                fileNames,\n            )\n            # Check if failurecodes exist\n            for filehandle in copiedFileHandles:\n                if filehandle.get(\"failureCode\") is not None:\n                    raise ValueError(\n                        \"%s dataFileHandleId: %s\"\n                        % (\n                            filehandle[\"failureCode\"],\n                            filehandle[\"originalFileHandleId\"],\n                        )\n                    )\n            new_file_handles = [\n                filehandle[\"newFileHandle\"][\"id\"] for filehandle in copiedFileHandles\n            ]\n        # for some reason some wikis don't have titles?\n        if hasattr(wikiHeader, \"parentId\"):\n            newWikiPage = Wiki(\n                owner=newOwn,\n                title=wiki.get(\"title\", \"\"),\n                markdown=wiki.markdown,\n                fileHandles=new_file_handles,\n                parentWikiId=wikiIdMap[wiki.parentWikiId],\n            )\n            newWikiPage = syn.store(newWikiPage)\n        else:\n            if destinationSubPageId is not None and newWikiPage is not None:\n                newWikiPage[\"attachmentFileHandleIds\"] = new_file_handles\n                newWikiPage[\"markdown\"] = wiki[\"markdown\"]\n                newWikiPage[\"title\"] = wiki.get(\"title\", \"\")\n                # Need to add logic to update titles here\n                newWikiPage = syn.store(newWikiPage)\n            else:\n                newWikiPage = Wiki(\n                    owner=newOwn,\n                    title=wiki.get(\"title\", \"\"),\n                    markdown=wiki.markdown,\n                    fileHandles=new_file_handles,\n                    parentWikiId=destinationSubPageId,\n                )\n                newWikiPage = syn.store(newWikiPage)\n        newWikis[newWikiPage[\"id\"]] = newWikiPage\n        wikiIdMap[wiki[\"id\"]] = newWikiPage[\"id\"]\n\n    if updateLinks:\n        syn.logger.info(\"Updating internal links:\\n\")\n        newWikis = _updateInternalLinks(newWikis, wikiIdMap, entity, destinationId)\n        syn.logger.info(\"Done updating internal links.\\n\")\n\n    if updateSynIds and entityMap is not None:\n        syn.logger.info(\"Updating Synapse references:\\n\")\n        newWikis = _updateSynIds(newWikis, wikiIdMap, entityMap)\n        syn.logger.info(\"Done updating Synapse IDs.\\n\")\n\n    syn.logger.info(\"Storing new Wikis\\n\")\n    for oldWikiId in wikiIdMap.keys():\n        newWikiId = wikiIdMap[oldWikiId]\n        newWikis[newWikiId] = syn.store(newWikis[newWikiId])\n        syn.logger.info(\"\\tStored: %s\\n\" % newWikiId)\n    return syn.getWikiHeaders(newOwn)\n</code></pre>"},{"location":"reference/synapse_utils/#synapseutils.walk_functions","title":"<code>synapseutils.walk_functions</code>","text":""},{"location":"reference/synapse_utils/#synapseutils.walk_functions-functions","title":"Functions","text":""},{"location":"reference/synapse_utils/#synapseutils.walk_functions.walk","title":"<code>walk(syn, synId, includeTypes=['folder', 'file', 'table', 'link', 'entityview', 'dockerrepo', 'submissionview', 'dataset', 'materializedview'])</code>","text":"<p>Traverse through the hierarchy of files and folders stored under the synId. Has the same behavior as os.walk()</p> PARAMETER DESCRIPTION <code>syn</code> <p>A Synapse object with user's login, e.g. syn = synapseclient.login()</p> <p> TYPE: <code>Synapse</code> </p> <code>synId</code> <p>A synapse ID of a folder or project</p> <p> TYPE: <code>str</code> </p> <code>includeTypes</code> <p>Must be a list of entity types (ie.[\"file\", \"table\"])             The \"folder\" type is always included so the hierarchy can be traversed</p> <p> TYPE: <code>List[str]</code> DEFAULT: <code>['folder', 'file', 'table', 'link', 'entityview', 'dockerrepo', 'submissionview', 'dataset', 'materializedview']</code> </p> Print Project &amp; Files in slash delimited format <p>Traversing through a project and print out each Folder and File</p> <pre><code>import synapseclient\nimport synapseutils\nsyn = synapseclient.login()\n\nfor directory_path, directory_names, file_name in synapseutils.walk(\n    syn=syn, synId=\"syn1234\", includeTypes=[\"file\"]\n):\n    for directory_name in directory_names:\n        print(\n            f\"Directory ({directory_name[1]}): {directory_path[0]}/{directory_name[0]}\"\n        )\n\n    for file in file_name:\n        print(f\"File ({file[1]}): {directory_path[0]}/{file[0]}\")\n</code></pre> <p>The output will look like this assuming only 1 folder and 1 file in the directory:</p> <pre><code>Directory (syn12345678): My Project Name/my_directory_name\nFile (syn23456789): My Project Name/my_directory_name/fileA.txt\n</code></pre> Using this function <p>Traversing through a project and printing out the directory path, folders, and files</p> <pre><code>walkedPath = walk(syn, \"syn1234\", [\"file\"]) #Exclude tables and views\n\nfor dirpath, dirname, filename in walkedPath:\n    print(dirpath)\n    print(dirname) #All the folders in the directory path\n    print(filename) #All the files in the directory path\n</code></pre> <p>This is a high level sequence diagram of the walk function:</p> <pre><code>sequenceDiagram\n    autonumber\n    participant walk\n\n    opt Not start_entity\n        walk-&gt;&gt;client: Call `.get()` method\n        client--&gt;&gt;walk: Metadata about the root start_entity\n    end\n\n    alt Root is not a container\n        note over walk: Return early\n    else newpath is none\n        note over walk: Get directory path from name of entity and synapse ID\n    else\n        note over walk: Use path passed in from recursive call\n    end\n\n    loop Get children for container\n        walk-&gt;&gt;client: Call `.getChildren()` method\n        client--&gt;&gt;walk: return immediate children\n        note over walk: Aggregation of all children into dirs and non-dirs list\n    end\n\n    loop For each directory\n        walk-&gt;&gt;walk: Recursively call walk\n    end</code></pre> Source code in <code>synapseutils/walk_functions.py</code> <pre><code>def walk(\n    syn: synapseclient.Synapse,\n    synId: str,\n    includeTypes: typing.List[str] = [\n        \"folder\",\n        \"file\",\n        \"table\",\n        \"link\",\n        \"entityview\",\n        \"dockerrepo\",\n        \"submissionview\",\n        \"dataset\",\n        \"materializedview\",\n    ],\n):\n    \"\"\"\n    Traverse through the hierarchy of files and folders stored under the synId.\n    Has the same behavior as os.walk()\n\n    Arguments:\n        syn: A Synapse object with user's login, e.g. syn = synapseclient.login()\n        synId: A synapse ID of a folder or project\n        includeTypes: Must be a list of entity types (ie.[\"file\", \"table\"])\n                        The \"folder\" type is always included so the hierarchy can be traversed\n\n    Example: Print Project &amp; Files in slash delimited format\n        Traversing through a project and print out each Folder and File\n\n            import synapseclient\n            import synapseutils\n            syn = synapseclient.login()\n\n            for directory_path, directory_names, file_name in synapseutils.walk(\n                syn=syn, synId=\"syn1234\", includeTypes=[\"file\"]\n            ):\n                for directory_name in directory_names:\n                    print(\n                        f\"Directory ({directory_name[1]}): {directory_path[0]}/{directory_name[0]}\"\n                    )\n\n                for file in file_name:\n                    print(f\"File ({file[1]}): {directory_path[0]}/{file[0]}\")\n\n        The output will look like this assuming only 1 folder and 1 file in the directory:\n\n            Directory (syn12345678): My Project Name/my_directory_name\n            File (syn23456789): My Project Name/my_directory_name/fileA.txt\n\n    Example: Using this function\n        Traversing through a project and printing out the directory path, folders, and files\n\n            walkedPath = walk(syn, \"syn1234\", [\"file\"]) #Exclude tables and views\n\n            for dirpath, dirname, filename in walkedPath:\n                print(dirpath)\n                print(dirname) #All the folders in the directory path\n                print(filename) #All the files in the directory path\n\n    This is a high level sequence diagram of the walk function:\n\n    ```mermaid\n    sequenceDiagram\n        autonumber\n        participant walk\n\n        opt Not start_entity\n            walk-&gt;&gt;client: Call `.get()` method\n            client--&gt;&gt;walk: Metadata about the root start_entity\n        end\n\n        alt Root is not a container\n            note over walk: Return early\n        else newpath is none\n            note over walk: Get directory path from name of entity and synapse ID\n        else\n            note over walk: Use path passed in from recursive call\n        end\n\n        loop Get children for container\n            walk-&gt;&gt;client: Call `.getChildren()` method\n            client--&gt;&gt;walk: return immediate children\n            note over walk: Aggregation of all children into dirs and non-dirs list\n        end\n\n        loop For each directory\n            walk-&gt;&gt;walk: Recursively call walk\n        end\n    ```\n    \"\"\"\n    # Ensure that \"folder\" is included so the hierarchy can be traversed\n    if \"folder\" not in includeTypes:\n        includeTypes.append(\"folder\")\n    return _help_walk(syn=syn, syn_id=synId, include_types=includeTypes)\n</code></pre>"},{"location":"reference/synapse_utils/#synapseutils.monitor","title":"<code>synapseutils.monitor</code>","text":""},{"location":"reference/synapse_utils/#synapseutils.monitor-functions","title":"Functions","text":""},{"location":"reference/synapse_utils/#synapseutils.monitor.notifyMe","title":"<code>notifyMe(syn, messageSubject='', retries=0)</code>","text":"<p>Function decorator that notifies you via email whenever an function completes running or there is a failure.</p> PARAMETER DESCRIPTION <code>syn</code> <p>A Synapse object with user's login, e.g. syn = synapseclient.login()</p> <p> TYPE: <code>Synapse</code> </p> <code>messageSubject</code> <p>A string with subject line for sent out messages.</p> <p> TYPE: <code>str</code> DEFAULT: <code>''</code> </p> <code>retries</code> <p>Number of retries to attempt on failure</p> <p> TYPE: <code>int</code> DEFAULT: <code>0</code> </p> Using this function <p>As a decorator:</p> <pre><code># to decorate a function that you define\nfrom synapseutils import notifyMe\nimport synapseclient\nsyn = synapseclient.login()\n\n@notifyMe(syn, 'Long running function', retries=2)\ndef my_function(x):\n    doing_something()\n    return long_runtime_func(x)\n\nmy_function(123)\n</code></pre> <p>Wrapping a function:</p> <pre><code># to wrap a function that already exists\nfrom synapseutils import notifyMe\nimport synapseclient\nsyn = synapseclient.login()\n\nnotify_decorator = notifyMe(syn, 'Long running query', retries=2)\nmy_query = notify_decorator(syn.tableQuery)\nresults = my_query(\"select id from syn1223\")\n</code></pre> Source code in <code>synapseutils/monitor.py</code> <pre><code>def notifyMe(syn: \"Synapse\", messageSubject: str = \"\", retries: int = 0):\n    \"\"\"Function decorator that notifies you via email whenever an function completes running or there is a failure.\n\n    Arguments:\n        syn: A Synapse object with user's login, e.g. syn = synapseclient.login()\n        messageSubject: A string with subject line for sent out messages.\n        retries: Number of retries to attempt on failure\n\n    Example: Using this function\n        As a decorator:\n\n            # to decorate a function that you define\n            from synapseutils import notifyMe\n            import synapseclient\n            syn = synapseclient.login()\n\n            @notifyMe(syn, 'Long running function', retries=2)\n            def my_function(x):\n                doing_something()\n                return long_runtime_func(x)\n\n            my_function(123)\n\n        Wrapping a function:\n\n            # to wrap a function that already exists\n            from synapseutils import notifyMe\n            import synapseclient\n            syn = synapseclient.login()\n\n            notify_decorator = notifyMe(syn, 'Long running query', retries=2)\n            my_query = notify_decorator(syn.tableQuery)\n            results = my_query(\"select id from syn1223\")\n    \"\"\"\n\n    def notify_decorator(func):\n        @functools.wraps(func)\n        def with_retry_and_messaging(*args, **kwargs):\n            attempt = 0\n            destination = syn.getUserProfile()[\"ownerId\"]\n            while attempt &lt;= retries:\n                try:\n                    output = func(*args, **kwargs)\n                    syn.sendMessage(\n                        [destination],\n                        messageSubject,\n                        messageBody=\"Call to %s completed successfully!\"\n                        % func.__name__,\n                    )\n                    return output\n                except Exception as e:\n                    sys.stderr.write(traceback.format_exc())\n                    syn.sendMessage(\n                        [destination],\n                        messageSubject,\n                        messageBody=(\n                            \"Encountered a temporary Failure during upload.  \"\n                            \"Will retry %i more times. \\n\\n Error message was:\\n%s\\n\\n%s\"\n                            % (retries - attempt, e, traceback.format_exc())\n                        ),\n                    )\n                    attempt += 1\n\n        return with_retry_and_messaging\n\n    return notify_decorator\n</code></pre>"},{"location":"reference/synapse_utils/#synapseutils.monitor.with_progress_bar","title":"<code>with_progress_bar(func, totalCalls, prefix='', postfix='', isBytes=False)</code>","text":"<p>Wraps a function to add a progress bar based on the number of calls to that function.</p> PARAMETER DESCRIPTION <code>func</code> <p>Function being wrapped with progress Bar</p> <p> </p> <code>totalCalls</code> <p>total number of items/bytes when completed</p> <p> </p> <code>prefix</code> <p>String printed before progress bar</p> <p> DEFAULT: <code>''</code> </p> <code>prefix</code> <p>String printed after progress bar</p> <p> DEFAULT: <code>''</code> </p> <code>isBytes</code> <p>A boolean indicating weather to convert bytes to kB, MB, GB etc.</p> <p> DEFAULT: <code>False</code> </p> RETURNS DESCRIPTION <p>A wrapped function that contains a progress bar</p> Source code in <code>synapseutils/monitor.py</code> <pre><code>def with_progress_bar(func, totalCalls, prefix=\"\", postfix=\"\", isBytes=False):\n    \"\"\"Wraps a function to add a progress bar based on the number of calls to that function.\n\n    Arguments:\n        func: Function being wrapped with progress Bar\n        totalCalls: total number of items/bytes when completed\n        prefix: String printed before progress bar\n        prefix: String printed after progress bar\n        isBytes: A boolean indicating weather to convert bytes to kB, MB, GB etc.\n\n    Returns:\n        A wrapped function that contains a progress bar\n    \"\"\"\n    completed = Value(\"d\", 0)\n    lock = Lock()\n\n    def progress(*args, **kwargs):\n        with lock:\n            completed.value += 1\n        printTransferProgress(completed.value, totalCalls, prefix, postfix, isBytes)\n        return func(*args, **kwargs)\n\n    return progress\n</code></pre>"},{"location":"reference/synapse_utils/#synapseutils.migrate_functions","title":"<code>synapseutils.migrate_functions</code>","text":""},{"location":"reference/synapse_utils/#synapseutils.migrate_functions-classes","title":"Classes","text":""},{"location":"reference/synapse_utils/#synapseutils.migrate_functions.MigrationResult","title":"<code>MigrationResult</code>","text":"<p>A MigrationResult is a proxy object to the underlying sqlite db. It provides a programmatic interface that allows the caller to iterate over the file handles that were migrated without having to connect to or know the schema of the sqlite db, and also avoids the potential memory liability of putting everything into an in memory data structure that could be a liability when migrating a huge project of hundreds of thousands/millions of entities.</p> <p>As this proxy object is not thread safe since it accesses an underlying sqlite db.</p> Source code in <code>synapseutils/migrate_functions.py</code> <pre><code>class MigrationResult:\n    \"\"\"A MigrationResult is a proxy object to the underlying sqlite db.\n    It provides a programmatic interface that allows the caller to iterate over the\n    file handles that were migrated without having to connect to or know the schema\n    of the sqlite db, and also avoids the potential memory liability of putting\n    everything into an in memory data structure that could be a liability when\n    migrating a huge project of hundreds of thousands/millions of entities.\n\n    As this proxy object is not thread safe since it accesses an underlying sqlite db.\n    \"\"\"\n\n    def __init__(self, syn, db_path):\n        self._syn = syn\n        self.db_path = db_path\n\n    def get_counts_by_status(self):\n        \"\"\"\n        Returns a dictionary of counts by the migration status of each indexed file/version.\n        Keys are as follows:\n\n        - `INDEXED` - the file/version has been indexed and will be migrated on a call to migrate_indexed_files\n        - `MIGRATED` - the file/version has been migrated\n        - `ALREADY_MIGRATED` - the file/version was already stored at the target storage location and no migration is needed\n        - `ERRORED` - an error occurred while indexing or migrating the file/version\n        \"\"\"  # noqa\n        import sqlite3\n\n        with sqlite3.connect(self.db_path) as conn:\n            cursor = conn.cursor()\n\n            # for the purposes of these counts, containers (Projects and Folders) do not count.\n            # we are counting actual files only\n            result = cursor.execute(\n                \"select status, count(*) from migrations where type in (?, ?) group by status\",\n                (_MigrationType.FILE.value, _MigrationType.TABLE_ATTACHED_FILE.value),\n            )\n\n            counts_by_status = {status.name: 0 for status in _MigrationStatus}\n            for row in result:\n                status = row[0]\n                count = row[1]\n                counts_by_status[_MigrationStatus(status).name] = count\n\n            return counts_by_status\n\n    def get_migrations(self):\n        \"\"\"\n        A generator yielding each file/version in the migration index.\n        A dictionary of the properties of the migration row is yielded as follows\n\n        Yields:\n            id: the Synapse id\n            type: the concrete type of the entity\n            version: the verson of the file entity (if applicable)\n            row_id: the row of the table attached file (if applicable)\n            col_id: the column id of the table attached file (if applicable)\n            from_storage_location_id: - the previous storage location id where the file/version was stored\n            from_file_handle_id: the id file handle of the existing file/version\n            to_file_handle_id: if migrated, the new file handle id\n            status: one of INDEXED, MIGRATED, ALREADY_MIGRATED, ERRORED indicating the status of the file/version\n            exception: if an error was encountered indexing/migrating the file/version its stack is here\n        \"\"\"\n        import sqlite3\n\n        with sqlite3.connect(self.db_path) as conn:\n            cursor = conn.cursor()\n\n            last_id = None\n            column_names = None\n\n            rowid = -1\n            while True:\n                results = cursor.execute(\n                    \"\"\"\n                        select\n                            rowid,\n\n                            id,\n                            type,\n                            version,\n                            row_id,\n                            col_id,\n                            from_storage_location_id,\n                            from_file_handle_id,\n                            to_file_handle_id,\n                            file_size,\n                            status,\n                            exception\n                        from migrations\n                        where\n                            rowid &gt; ?\n                            and type in (?, ?)\n                        order by\n                            rowid\n                        limit ?\n                    \"\"\",\n                    (\n                        rowid,\n                        _MigrationType.FILE.value,\n                        _MigrationType.TABLE_ATTACHED_FILE.value,\n                        _get_batch_size(),\n                    ),\n                )\n\n                row_count = 0\n                for row in results:\n                    row_count += 1\n\n                    # using the internal sqlite rowid for ordering only\n                    rowid = row[0]\n\n                    # exclude the sqlite internal rowid\n                    row_dict = _get_row_dict(cursor, row, False)\n                    entity_id = row_dict[\"id\"]\n                    if entity_id != last_id:\n                        # if the next row is dealing with a different entity than the last table\n                        # id then we discard any cached column names we looked up\n                        column_names = {}\n\n                    row_dict[\"type\"] = (\n                        \"file\"\n                        if row_dict[\"type\"] == _MigrationType.FILE.value\n                        else \"table\"\n                    )\n\n                    for int_arg in (\n                        \"version\",\n                        \"row_id\",\n                        \"from_storage_location_id\",\n                        \"from_file_handle_id\",\n                        \"to_file_handle_id\",\n                    ):\n                        int_val = row_dict.get(int_arg)\n                        if int_val is not None:\n                            row_dict[int_arg] = int(int_val)\n\n                    col_id = row_dict.pop(\"col_id\", None)\n                    if col_id is not None:\n                        column_name = column_names.get(col_id)\n\n                        # for usability we look up the actual column name from the id,\n                        # but that involves a lookup so we cache them for re-use across\n                        # rows that deal with the same table entity\n                        if column_name is None:\n                            column = self._syn.restGET(\"/column/{}\".format(col_id))\n                            column_name = column_names[col_id] = column[\"name\"]\n\n                        row_dict[\"col_name\"] = column_name\n\n                    row_dict[\"status\"] = _MigrationStatus(row_dict[\"status\"]).name\n\n                    yield row_dict\n\n                    last_id = entity_id\n\n                if row_count == 0:\n                    # out of rows\n                    break\n\n    def as_csv(self, path):\n        \"\"\"\n        Output a flat csv file of the contents of the Migration index.\n\n        Arguments:\n            path: The path to the csv file to be created\n\n        Returns:\n            None: But a csv file is created at the given path with the following columns:\n            id: the Synapse id\n            type: the concrete type of the entity\n            version: the verson of the file entity (if applicable)\n            row_id: the row of the table attached file (if applicable)\n            col_name: the column name of the column the table attached file resides in (if applicable)\n            from_storage_location_id: the previous storage location id where the file/version was stored\n            from_file_handle_id: the id file handle of the existing file/version\n            to_file_handle_id: if migrated, the new file handle id\n            status: one of INDEXED, MIGRATED, ALREADY_MIGRATED, ERRORED indicating the status of the file/version\n            exception: if an error was encountered indexing/migrating the file/version its stack is here\n\n        \"\"\"\n\n        with open(path, \"w\", newline=\"\") as csv_file:\n            csv_writer = csv.writer(csv_file)\n\n            # headers\n            csv_writer.writerow(\n                [\n                    \"id\",\n                    \"type\",\n                    \"version\",\n                    \"row_id\",\n                    \"col_name\",\n                    \"from_storage_location_id\",\n                    \"from_file_handle_id\",\n                    \"to_file_handle_id\",\n                    \"status\",\n                    \"exception\",\n                ]\n            )\n\n            for row_dict in self.get_migrations():\n                row_data = [\n                    row_dict[\"id\"],\n                    row_dict[\"type\"],\n                    row_dict.get(\"version\"),\n                    row_dict.get(\"row_id\"),\n                    row_dict.get(\"col_name\"),\n                    row_dict.get(\"from_storage_location_id\"),\n                    row_dict.get(\"from_file_handle_id\"),\n                    row_dict.get(\"to_file_handle_id\"),\n                    row_dict[\"status\"],\n                    row_dict.get(\"exception\"),\n                ]\n\n                csv_writer.writerow(row_data)\n</code></pre>"},{"location":"reference/synapse_utils/#synapseutils.migrate_functions.MigrationResult-functions","title":"Functions","text":""},{"location":"reference/synapse_utils/#synapseutils.migrate_functions.MigrationResult.get_counts_by_status","title":"<code>get_counts_by_status()</code>","text":"<p>Returns a dictionary of counts by the migration status of each indexed file/version. Keys are as follows:</p> <ul> <li><code>INDEXED</code> - the file/version has been indexed and will be migrated on a call to migrate_indexed_files</li> <li><code>MIGRATED</code> - the file/version has been migrated</li> <li><code>ALREADY_MIGRATED</code> - the file/version was already stored at the target storage location and no migration is needed</li> <li><code>ERRORED</code> - an error occurred while indexing or migrating the file/version</li> </ul> Source code in <code>synapseutils/migrate_functions.py</code> <pre><code>def get_counts_by_status(self):\n    \"\"\"\n    Returns a dictionary of counts by the migration status of each indexed file/version.\n    Keys are as follows:\n\n    - `INDEXED` - the file/version has been indexed and will be migrated on a call to migrate_indexed_files\n    - `MIGRATED` - the file/version has been migrated\n    - `ALREADY_MIGRATED` - the file/version was already stored at the target storage location and no migration is needed\n    - `ERRORED` - an error occurred while indexing or migrating the file/version\n    \"\"\"  # noqa\n    import sqlite3\n\n    with sqlite3.connect(self.db_path) as conn:\n        cursor = conn.cursor()\n\n        # for the purposes of these counts, containers (Projects and Folders) do not count.\n        # we are counting actual files only\n        result = cursor.execute(\n            \"select status, count(*) from migrations where type in (?, ?) group by status\",\n            (_MigrationType.FILE.value, _MigrationType.TABLE_ATTACHED_FILE.value),\n        )\n\n        counts_by_status = {status.name: 0 for status in _MigrationStatus}\n        for row in result:\n            status = row[0]\n            count = row[1]\n            counts_by_status[_MigrationStatus(status).name] = count\n\n        return counts_by_status\n</code></pre>"},{"location":"reference/synapse_utils/#synapseutils.migrate_functions.MigrationResult.get_migrations","title":"<code>get_migrations()</code>","text":"<p>A generator yielding each file/version in the migration index. A dictionary of the properties of the migration row is yielded as follows</p> YIELDS DESCRIPTION <code>id</code> <p>the Synapse id</p> <code>type</code> <p>the concrete type of the entity</p> <code>version</code> <p>the verson of the file entity (if applicable)</p> <code>row_id</code> <p>the row of the table attached file (if applicable)</p> <code>col_id</code> <p>the column id of the table attached file (if applicable)</p> <code>from_storage_location_id</code> <ul> <li>the previous storage location id where the file/version was stored</li> </ul> <code>from_file_handle_id</code> <p>the id file handle of the existing file/version</p> <code>to_file_handle_id</code> <p>if migrated, the new file handle id</p> <code>status</code> <p>one of INDEXED, MIGRATED, ALREADY_MIGRATED, ERRORED indicating the status of the file/version</p> <code>exception</code> <p>if an error was encountered indexing/migrating the file/version its stack is here</p> Source code in <code>synapseutils/migrate_functions.py</code> <pre><code>def get_migrations(self):\n    \"\"\"\n    A generator yielding each file/version in the migration index.\n    A dictionary of the properties of the migration row is yielded as follows\n\n    Yields:\n        id: the Synapse id\n        type: the concrete type of the entity\n        version: the verson of the file entity (if applicable)\n        row_id: the row of the table attached file (if applicable)\n        col_id: the column id of the table attached file (if applicable)\n        from_storage_location_id: - the previous storage location id where the file/version was stored\n        from_file_handle_id: the id file handle of the existing file/version\n        to_file_handle_id: if migrated, the new file handle id\n        status: one of INDEXED, MIGRATED, ALREADY_MIGRATED, ERRORED indicating the status of the file/version\n        exception: if an error was encountered indexing/migrating the file/version its stack is here\n    \"\"\"\n    import sqlite3\n\n    with sqlite3.connect(self.db_path) as conn:\n        cursor = conn.cursor()\n\n        last_id = None\n        column_names = None\n\n        rowid = -1\n        while True:\n            results = cursor.execute(\n                \"\"\"\n                    select\n                        rowid,\n\n                        id,\n                        type,\n                        version,\n                        row_id,\n                        col_id,\n                        from_storage_location_id,\n                        from_file_handle_id,\n                        to_file_handle_id,\n                        file_size,\n                        status,\n                        exception\n                    from migrations\n                    where\n                        rowid &gt; ?\n                        and type in (?, ?)\n                    order by\n                        rowid\n                    limit ?\n                \"\"\",\n                (\n                    rowid,\n                    _MigrationType.FILE.value,\n                    _MigrationType.TABLE_ATTACHED_FILE.value,\n                    _get_batch_size(),\n                ),\n            )\n\n            row_count = 0\n            for row in results:\n                row_count += 1\n\n                # using the internal sqlite rowid for ordering only\n                rowid = row[0]\n\n                # exclude the sqlite internal rowid\n                row_dict = _get_row_dict(cursor, row, False)\n                entity_id = row_dict[\"id\"]\n                if entity_id != last_id:\n                    # if the next row is dealing with a different entity than the last table\n                    # id then we discard any cached column names we looked up\n                    column_names = {}\n\n                row_dict[\"type\"] = (\n                    \"file\"\n                    if row_dict[\"type\"] == _MigrationType.FILE.value\n                    else \"table\"\n                )\n\n                for int_arg in (\n                    \"version\",\n                    \"row_id\",\n                    \"from_storage_location_id\",\n                    \"from_file_handle_id\",\n                    \"to_file_handle_id\",\n                ):\n                    int_val = row_dict.get(int_arg)\n                    if int_val is not None:\n                        row_dict[int_arg] = int(int_val)\n\n                col_id = row_dict.pop(\"col_id\", None)\n                if col_id is not None:\n                    column_name = column_names.get(col_id)\n\n                    # for usability we look up the actual column name from the id,\n                    # but that involves a lookup so we cache them for re-use across\n                    # rows that deal with the same table entity\n                    if column_name is None:\n                        column = self._syn.restGET(\"/column/{}\".format(col_id))\n                        column_name = column_names[col_id] = column[\"name\"]\n\n                    row_dict[\"col_name\"] = column_name\n\n                row_dict[\"status\"] = _MigrationStatus(row_dict[\"status\"]).name\n\n                yield row_dict\n\n                last_id = entity_id\n\n            if row_count == 0:\n                # out of rows\n                break\n</code></pre>"},{"location":"reference/synapse_utils/#synapseutils.migrate_functions.MigrationResult.as_csv","title":"<code>as_csv(path)</code>","text":"<p>Output a flat csv file of the contents of the Migration index.</p> PARAMETER DESCRIPTION <code>path</code> <p>The path to the csv file to be created</p> <p> </p> RETURNS DESCRIPTION <code>None</code> <p>But a csv file is created at the given path with the following columns:</p> <code>id</code> <p>the Synapse id</p> <code>type</code> <p>the concrete type of the entity</p> <code>version</code> <p>the verson of the file entity (if applicable)</p> <code>row_id</code> <p>the row of the table attached file (if applicable)</p> <code>col_name</code> <p>the column name of the column the table attached file resides in (if applicable)</p> <code>from_storage_location_id</code> <p>the previous storage location id where the file/version was stored</p> <code>from_file_handle_id</code> <p>the id file handle of the existing file/version</p> <code>to_file_handle_id</code> <p>if migrated, the new file handle id</p> <code>status</code> <p>one of INDEXED, MIGRATED, ALREADY_MIGRATED, ERRORED indicating the status of the file/version</p> <code>exception</code> <p>if an error was encountered indexing/migrating the file/version its stack is here</p> Source code in <code>synapseutils/migrate_functions.py</code> <pre><code>def as_csv(self, path):\n    \"\"\"\n    Output a flat csv file of the contents of the Migration index.\n\n    Arguments:\n        path: The path to the csv file to be created\n\n    Returns:\n        None: But a csv file is created at the given path with the following columns:\n        id: the Synapse id\n        type: the concrete type of the entity\n        version: the verson of the file entity (if applicable)\n        row_id: the row of the table attached file (if applicable)\n        col_name: the column name of the column the table attached file resides in (if applicable)\n        from_storage_location_id: the previous storage location id where the file/version was stored\n        from_file_handle_id: the id file handle of the existing file/version\n        to_file_handle_id: if migrated, the new file handle id\n        status: one of INDEXED, MIGRATED, ALREADY_MIGRATED, ERRORED indicating the status of the file/version\n        exception: if an error was encountered indexing/migrating the file/version its stack is here\n\n    \"\"\"\n\n    with open(path, \"w\", newline=\"\") as csv_file:\n        csv_writer = csv.writer(csv_file)\n\n        # headers\n        csv_writer.writerow(\n            [\n                \"id\",\n                \"type\",\n                \"version\",\n                \"row_id\",\n                \"col_name\",\n                \"from_storage_location_id\",\n                \"from_file_handle_id\",\n                \"to_file_handle_id\",\n                \"status\",\n                \"exception\",\n            ]\n        )\n\n        for row_dict in self.get_migrations():\n            row_data = [\n                row_dict[\"id\"],\n                row_dict[\"type\"],\n                row_dict.get(\"version\"),\n                row_dict.get(\"row_id\"),\n                row_dict.get(\"col_name\"),\n                row_dict.get(\"from_storage_location_id\"),\n                row_dict.get(\"from_file_handle_id\"),\n                row_dict.get(\"to_file_handle_id\"),\n                row_dict[\"status\"],\n                row_dict.get(\"exception\"),\n            ]\n\n            csv_writer.writerow(row_data)\n</code></pre>"},{"location":"reference/synapse_utils/#synapseutils.migrate_functions-functions","title":"Functions","text":""},{"location":"reference/synapse_utils/#synapseutils.migrate_functions.index_files_for_migration","title":"<code>index_files_for_migration(syn, entity, dest_storage_location_id, db_path, source_storage_location_ids=None, file_version_strategy='new', include_table_files=False, continue_on_error=False)</code>","text":"<p>Index the given entity for migration to a new storage location. This is the first step in migrating an entity to a new storage location using synapseutils.</p> <p>This function will create a sqlite database at the given db_path that can be subsequently passed to the migrate_indexed_files function for actual migration. This function itself does not modify the given entity in any way.</p> PARAMETER DESCRIPTION <code>syn</code> <p>A Synapse object with user's login, e.g. syn = synapseclient.login()</p> <p> TYPE: <code>Synapse</code> </p> <code>entity</code> <p>A Synapse entity whose files should be migrated. Can be a Project, Folder,     File entity, or Table entity. If it is a container (a Project or Folder)     its contents will be recursively indexed.</p> <p> </p> <code>dest_storage_location_id</code> <p>The id of the new storage location to be migrated to.</p> <p> TYPE: <code>str</code> </p> <code>db_path</code> <p>A path on disk where a sqlite db can be created to store the contents of the         created index.</p> <p> TYPE: <code>str</code> </p> <code>source_storage_location_ids</code> <p>An optional iterable of storage location ids that                             will be migrated. If provided, files outside of                             one of the listed storage locations will not be                             indexed for migration. If not provided, then all                             files not already in the destination storage                             location will be indexed for migrated.</p> <p> TYPE: <code>Iterable[str]</code> DEFAULT: <code>None</code> </p> <code>file_version_strategy</code> <p>One of \"new\" (default), \"all\", \"latest\", \"skip\" as follows:</p> <ul> <li><code>new</code>: will create a new version of file entities in the new storage location, leaving existing versions unchanged</li> <li><code>all</code>: all existing versions will be migrated in place to the new storage location</li> <li><code>latest</code>: the latest version will be migrated in place to the new storage location</li> <li><code>skip</code>: skip migrating file entities. use this e.g. if wanting to e.g. migrate table attached files in a container while leaving the files unchanged</li> </ul> <p> DEFAULT: <code>'new'</code> </p> <code>include_table_files</code> <p>Whether to migrate files attached to tables. If False (default) then e.g. only                     file entities in the container will be migrated and tables will be untouched.</p> <p> DEFAULT: <code>False</code> </p> <code>continue_on_error</code> <p>Whether any errors encountered while indexing an entity (access etc) will be raised                     or instead just recorded in the index while allowing the index creation                     to continue. Default is False (any errors are raised).</p> <p> DEFAULT: <code>False</code> </p> RETURNS DESCRIPTION <p>A MigrationResult object that can be used to inspect the contents of the index or output the index to a CSV for manual inspection.</p> Source code in <code>synapseutils/migrate_functions.py</code> <pre><code>def index_files_for_migration(\n    syn: synapseclient.Synapse,\n    entity,\n    dest_storage_location_id: str,\n    db_path: str,\n    source_storage_location_ids: typing.Iterable[str] = None,\n    file_version_strategy=\"new\",\n    include_table_files=False,\n    continue_on_error=False,\n):\n    \"\"\"\n    Index the given entity for migration to a new storage location. This is the first step in migrating an entity\n    to a new storage location using synapseutils.\n\n    This function will create a sqlite database at the given db_path that can be subsequently passed\n    to the migrate_indexed_files function for actual migration. This function itself does not modify the given entity\n    in any way.\n\n    Arguments:\n        syn: A Synapse object with user's login, e.g. syn = synapseclient.login()\n        entity: A Synapse entity whose files should be migrated. Can be a Project, Folder,\n                File entity, or Table entity. If it is a container (a Project or Folder)\n                its contents will be recursively indexed.\n        dest_storage_location_id: The id of the new storage location to be migrated to.\n        db_path: A path on disk where a sqlite db can be created to store the contents of the\n                    created index.\n        source_storage_location_ids: An optional iterable of storage location ids that\n                                        will be migrated. If provided, files outside of\n                                        one of the listed storage locations will not be\n                                        indexed for migration. If not provided, then all\n                                        files not already in the destination storage\n                                        location will be indexed for migrated.\n        file_version_strategy: One of \"new\" (default), \"all\", \"latest\", \"skip\" as follows:\n\n            - `new`: will create a new version of file entities in the new storage location, leaving existing versions unchanged\n            - `all`: all existing versions will be migrated in place to the new storage location\n            - `latest`: the latest version will be migrated in place to the new storage location\n            - `skip`: skip migrating file entities. use this e.g. if wanting to e.g. migrate table attached files in a container while leaving the files unchanged\n        include_table_files: Whether to migrate files attached to tables. If False (default) then e.g. only\n                                file entities in the container will be migrated and tables will be untouched.\n        continue_on_error: Whether any errors encountered while indexing an entity (access etc) will be raised\n                                or instead just recorded in the index while allowing the index creation\n                                to continue. Default is False (any errors are raised).\n\n    Returns:\n        A MigrationResult object that can be used to inspect the contents of the index or output the index to a CSV for manual inspection.\n    \"\"\"  # noqa\n    root_id = utils.id_of(entity)\n\n    # accept an Iterable, but easier to work internally if we can assume a list of strings\n    source_storage_location_ids = [str(s) for s in source_storage_location_ids or []]\n\n    file_version_strategies = {\"new\", \"all\", \"latest\", \"skip\"}\n    if file_version_strategy not in file_version_strategies:\n        raise ValueError(\n            \"Invalid file_version_strategy: {}, must be one of {}\".format(\n                file_version_strategy, file_version_strategies\n            )\n        )\n\n    if file_version_strategy == \"skip\" and not include_table_files:\n        raise ValueError(\n            \"Skipping both files entities and table attached files, nothing to migrate\"\n        )\n\n    _verify_storage_location_ownership(syn, dest_storage_location_id)\n\n    test_import_sqlite3()\n    import sqlite3\n\n    with sqlite3.connect(db_path) as conn:\n        cursor = conn.cursor()\n        _ensure_schema(cursor)\n\n        _verify_index_settings(\n            cursor,\n            db_path,\n            root_id,\n            dest_storage_location_id,\n            source_storage_location_ids,\n            file_version_strategy,\n            include_table_files,\n        )\n        conn.commit()\n\n        entity = syn.get(root_id, downloadFile=False)\n        try:\n            _index_entity(\n                conn,\n                cursor,\n                syn,\n                entity,\n                None,\n                dest_storage_location_id,\n                source_storage_location_ids,\n                file_version_strategy,\n                include_table_files,\n                continue_on_error,\n            )\n\n        except _IndexingError as indexing_ex:\n            logging.exception(\n                \"Aborted due to failure to index entity %s of type %s. Use the continue_on_error option to skip \"\n                \"over entities due to individual failures.\",\n                indexing_ex.entity_id,\n                indexing_ex.concrete_type,\n            )\n\n            raise indexing_ex.__cause__\n\n    return MigrationResult(syn, db_path)\n</code></pre>"},{"location":"reference/synapse_utils/#synapseutils.migrate_functions.migrate_indexed_files","title":"<code>migrate_indexed_files(syn, db_path, create_table_snapshots=True, continue_on_error=False, force=False)</code>","text":"<p>Migrate files previously indexed in a sqlite database at the given db_path using the separate index_files_for_migration function. The files listed in the index will be migrated according to the configuration of that index.</p> PARAMETER DESCRIPTION <code>syn</code> <p>A Synapse object with user's login, e.g. syn = synapseclient.login()</p> <p> TYPE: <code>Synapse</code> </p> <code>db_path</code> <p>A path on disk where a sqlite db was created using the index_files_for_migration function.</p> <p> TYPE: <code>str</code> </p> <code>create_table_snapshots</code> <p>When updating the files in any table, whether the a snapshot of the table is                     first created.</p> <p> DEFAULT: <code>True</code> </p> <code>continue_on_error</code> <p>Whether any errors encountered while migrating will be raised                 or instead just recorded in the sqlite database while allowing the migration                 to continue. Default is False (any errors are raised).</p> <p> DEFAULT: <code>False</code> </p> <code>force</code> <p>If running in an interactive shell, migration requires an interactice confirmation.     This can be bypassed by using the force=True option.</p> <p> DEFAULT: <code>False</code> </p> RETURNS DESCRIPTION <code>Union[MigrationResult, None]</code> <p>A MigrationResult object that can be used to inspect the results of the migration.</p> Source code in <code>synapseutils/migrate_functions.py</code> <pre><code>def migrate_indexed_files(\n    syn: synapseclient.Synapse,\n    db_path: str,\n    create_table_snapshots=True,\n    continue_on_error=False,\n    force=False,\n) -&gt; typing.Union[MigrationResult, None]:\n    \"\"\"\n    Migrate files previously indexed in a sqlite database at the given db_path using the separate\n    index_files_for_migration function. The files listed in the index will be migrated according to the\n    configuration of that index.\n\n    Arguments:\n        syn: A Synapse object with user's login, e.g. syn = synapseclient.login()\n        db_path: A path on disk where a sqlite db was created using the index_files_for_migration function.\n        create_table_snapshots: When updating the files in any table, whether the a snapshot of the table is\n                                first created.\n        continue_on_error: Whether any errors encountered while migrating will be raised\n                            or instead just recorded in the sqlite database while allowing the migration\n                            to continue. Default is False (any errors are raised).\n        force: If running in an interactive shell, migration requires an interactice confirmation.\n                This can be bypassed by using the force=True option.\n\n    Returns:\n        A MigrationResult object that can be used to inspect the results of the migration.\n    \"\"\"\n    executor, max_concurrent_file_copies = _get_executor(syn)\n\n    test_import_sqlite3()\n    import sqlite3\n\n    with sqlite3.connect(db_path) as conn:\n        cursor = conn.cursor()\n\n        _ensure_schema(cursor)\n        settings = _retrieve_index_settings(cursor)\n        if settings is None:\n            # no settings were available at the index given\n            raise ValueError(\n                \"Unable to retrieve existing index settings from '{}'. \"\n                \"Either this path does represent a previously created migration index file or the file is corrupt.\"\n            )\n\n        dest_storage_location_id = settings[\"dest_storage_location_id\"]\n        if not _confirm_migration(cursor, force, dest_storage_location_id):\n            logging.info(\"Migration aborted.\")\n            return\n\n        key = _MigrationKey(id=\"\", type=None, row_id=-1, col_id=-1, version=-1)\n\n        futures = set()\n\n        # we keep track of the file handles that are currently being migrated\n        # so that if we encounter multiple entities associated with the same\n        # file handle we can copy the file handle once and update all the entities\n        # with the single copied file handle\n        pending_file_handle_ids = set()\n        completed_file_handle_ids = set()\n\n        # we keep track of the entity keys (syn id + version) so that we know\n        # if we encounter the same one twice. normally we wouldn't but when we backtrack\n        # to update any entities skipped because of a shared file handle we might\n        # query for the same key as is already being operated on.\n        pending_keys = set()\n\n        batch_size = _get_batch_size()\n        while True:\n            # we query for additional file or table associated file handles to migrate in batches\n            # ordering by synapse id. there can be multiple file handles associated with a particular\n            # synapse id (i.e. multiple file entity versions or multiple table attached files per table),\n            # so the ordering and where clause need to account for that.\n            # we also include in the query any unmigrated files that were skipped previously through\n            # the query loop that share a file handle with a file handle id that is now finished.\n            version = key.version if key.version is not None else -1\n            row_id = key.row_id if key.row_id is not None else -1\n            col_id = key.col_id if key.col_id is not None else -1\n\n            query_kwargs = {\n                \"indexed_status\": _MigrationStatus.INDEXED.value,\n                \"id\": key.id,\n                \"file_type\": _MigrationType.FILE.value,\n                \"table_type\": _MigrationType.TABLE_ATTACHED_FILE.value,\n                \"version\": version,\n                \"row_id\": row_id,\n                \"col_id\": col_id,\n                # ensure that we aren't ever adding more items to the shared executor than allowed\n                \"limit\": min(batch_size, max_concurrent_file_copies - len(futures)),\n            }\n\n            # we can't use both named and positional literals in a query, so we use named\n            # literals and then inline a string for the values for our file handle ids\n            # since these are a dynamic list of values\n            pending_file_handle_in = \"('\" + \"','\".join(pending_file_handle_ids) + \"')\"\n            completed_file_handle_in = (\n                \"('\" + \"','\".join(completed_file_handle_ids) + \"')\"\n            )\n\n            results = cursor.execute(\n                f\"\"\"\n                    select\n                        id,\n                        type,\n                        version,\n                        row_id,\n                        col_id,\n                        from_file_handle_id,\n                        file_size\n                    from migrations\n                    where\n                        status = :indexed_status\n                        and (\n                                (\n                                    ((id &gt; :id and type in (:file_type, :table_type))\n                                    or (id = :id and type = :file_type and version is not null and version &gt; :version)\n                                    or (id = :id and type = :table_type and (row_id &gt; :row_id or (row_id = :row_id and col_id &gt; :col_id))))\n                                    and from_file_handle_id not in {pending_file_handle_in}\n                                ) or\n                                (\n                                    id &lt;= :id\n                                    and from_file_handle_id in {completed_file_handle_in}\n                                )\n                        )\n                    order by\n                        id,\n                        type,\n                        row_id,\n                        col_id,\n                        version\n                    limit :limit\n                \"\"\",  # noqa\n                query_kwargs,\n            )\n\n            row_count = 0\n            for row in results:\n                row_count += 1\n\n                row_dict = _get_row_dict(cursor, row, True)\n                key_dict = {\n                    k: v\n                    for k, v in row_dict.items()\n                    if k in (\"id\", \"type\", \"version\", \"row_id\", \"col_id\")\n                }\n\n                last_key = key\n                key = _MigrationKey(**key_dict)\n                from_file_handle_id = row_dict[\"from_file_handle_id\"]\n\n                if (\n                    key in pending_keys\n                    or from_file_handle_id in pending_file_handle_ids\n                ):\n                    # if this record is already being migrated or it shares a file handle\n                    # with a record that is being migrated then skip this.\n                    # if it the record shares a file handle it will be picked up later\n                    # when its file handle is completed.\n                    continue\n\n                file_size = row_dict[\"file_size\"]\n\n                pending_keys.add(key)\n                to_file_handle_id = _check_file_handle_exists(\n                    conn.cursor(), from_file_handle_id\n                )\n                if not to_file_handle_id:\n                    pending_file_handle_ids.add(from_file_handle_id)\n\n                if key.type == _MigrationType.FILE.value:\n                    if key.version is None:\n                        migration_fn = _create_new_file_version\n\n                    else:\n                        migration_fn = _migrate_file_version\n\n                elif key.type == _MigrationType.TABLE_ATTACHED_FILE.value:\n                    if last_key.id != key.id and create_table_snapshots:\n                        syn.create_snapshot_version(key.id)\n\n                    migration_fn = _migrate_table_attached_file\n\n                else:\n                    raise ValueError(\n                        \"Unexpected type {} with id {}\".format(key.type, key.id)\n                    )\n\n                def migration_task(\n                    syn,\n                    key,\n                    from_file_handle_id,\n                    to_file_handle_id,\n                    file_size,\n                    storage_location_id,\n                ):\n                    # a closure to wrap the actual function call so that we an add some local variables\n                    # to the return tuple which will be consumed when the future is processed\n                    with shared_executor(executor):\n                        try:\n                            # instrument the shared executor in this thread so that we won't\n                            # create a new executor to perform the multipart copy\n                            to_file_handle_id = migration_fn(\n                                syn,\n                                key,\n                                from_file_handle_id,\n                                to_file_handle_id,\n                                file_size,\n                                storage_location_id,\n                            )\n                            return key, from_file_handle_id, to_file_handle_id\n                        except Exception as ex:\n                            raise _MigrationError(\n                                key, from_file_handle_id, to_file_handle_id\n                            ) from ex\n\n                future = executor.submit(\n                    migration_task,\n                    syn,\n                    key,\n                    from_file_handle_id,\n                    to_file_handle_id,\n                    file_size,\n                    dest_storage_location_id,\n                )\n                futures.add(future)\n\n            if row_count == 0 and not pending_file_handle_ids:\n                # we've run out of migratable sqlite rows, we have nothing else\n                # to submit, so we break out and wait for all remaining\n                # tasks to conclude.\n                break\n\n            if len(futures) &gt;= max_concurrent_file_copies or row_count &lt; batch_size:\n                # if we have no concurrency left to process any additional entities\n                # or if we're near the end of he migration and have a small\n                # remainder batch then we wait for one of the processing migrations\n                # to finish. a small batch doesn't mean this is the last batch since\n                # a completed file handle here could be associated with another\n                # entity that we deferred before because it shared the same file handle id\n                futures, completed_file_handle_ids = _wait_futures(\n                    conn,\n                    cursor,\n                    futures,\n                    pending_keys,\n                    concurrent.futures.FIRST_COMPLETED,\n                    continue_on_error,\n                )\n\n                pending_file_handle_ids -= completed_file_handle_ids\n\n        if futures:\n            # wait for all remaining migrations to conclude before returning\n            _wait_futures(\n                conn,\n                cursor,\n                futures,\n                pending_keys,\n                concurrent.futures.ALL_COMPLETED,\n                continue_on_error,\n            )\n\n    return MigrationResult(syn, db_path)\n</code></pre>"},{"location":"reference/synapse_utils/#synapseutils.describe_functions","title":"<code>synapseutils.describe_functions</code>","text":""},{"location":"reference/synapse_utils/#synapseutils.describe_functions-functions","title":"Functions","text":""},{"location":"reference/synapse_utils/#synapseutils.describe_functions.describe","title":"<code>describe(syn, entity)</code>","text":"<p>Gets a synapse entity and returns summary statistics about it.</p> PARAMETER DESCRIPTION <code>syn</code> <p>A Synapse object with user's login, e.g. syn = synapseclient.login()</p> <p> </p> <code>entity</code> <p>synapse id of the entity to be described</p> <p> TYPE: <code>str</code> </p> Using this function <p>Describing columns of a table</p> <pre><code>import synapseclient\nimport synapseutils\nsyn = synapseclient.login()\nstatistics = synapseutils(syn, entity=\"syn123\")\nprint(statistics)\n{\n    \"column1\": {\n        \"dtype\": \"object\",\n        \"mode\": \"FOOBAR\"\n    },\n    \"column2\": {\n        \"dtype\": \"int64\",\n        \"mode\": 1,\n        \"min\": 1,\n        \"max\": 2,\n        \"mean\": 1.4\n    },\n    \"column3\": {\n        \"dtype\": \"bool\",\n        \"mode\": false,\n        \"min\": false,\n        \"max\": true,\n        \"mean\": 0.5\n    }\n}\n</code></pre> RETURNS DESCRIPTION <code>Union[dict, None]</code> <p>A dict if the dataset is valid; None if not.</p> Source code in <code>synapseutils/describe_functions.py</code> <pre><code>def describe(syn, entity: str) -&gt; typing.Union[dict, None]:\n    \"\"\"\n    Gets a synapse entity and returns summary statistics about it.\n\n    Arguments:\n        syn: A Synapse object with user's login, e.g. syn = synapseclient.login()\n        entity: synapse id of the entity to be described\n\n    Example: Using this function\n        Describing columns of a table\n\n            import synapseclient\n            import synapseutils\n            syn = synapseclient.login()\n            statistics = synapseutils(syn, entity=\"syn123\")\n            print(statistics)\n            {\n                \"column1\": {\n                    \"dtype\": \"object\",\n                    \"mode\": \"FOOBAR\"\n                },\n                \"column2\": {\n                    \"dtype\": \"int64\",\n                    \"mode\": 1,\n                    \"min\": 1,\n                    \"max\": 2,\n                    \"mean\": 1.4\n                },\n                \"column3\": {\n                    \"dtype\": \"bool\",\n                    \"mode\": false,\n                    \"min\": false,\n                    \"max\": true,\n                    \"mean\": 0.5\n                }\n            }\n\n    Returns:\n        A dict if the dataset is valid; None if not.\n    \"\"\"\n    df = _open_entity_as_df(syn=syn, entity=entity)\n\n    if df is None:\n        return None\n\n    stats = _describe_wrapper(df)\n    syn.logger.info(json.dumps(stats, indent=2, default=str))\n    return stats\n</code></pre>"},{"location":"reference/table_schema/","title":"Table Schema","text":""},{"location":"reference/table_schema/#synapseclient.table.Schema","title":"<code>synapseclient.table.Schema</code>","text":"<p>               Bases: <code>SchemaBase</code></p> <p>A Schema is an Entity that defines a set of columns in a table.</p> ATTRIBUTE DESCRIPTION <code>name</code> <p>The name for the Table Schema object</p> <p> </p> <code>description</code> <p>User readable description of the schema</p> <p> </p> <code>columns</code> <p>A list of Column objects or their IDs</p> <p> </p> <code>parent</code> <p>The project in Synapse to which this table belongs</p> <p> </p> <code>properties</code> <p>A map of Synapse properties</p> <p> </p> <code>annotations</code> <p>A map of user defined annotations</p> <p> </p> <code>local_state</code> <p>Internal use only</p> <p> </p> <p>Example:</p> <pre><code>cols = [Column(name='Isotope', columnType='STRING'),\n        Column(name='Atomic Mass', columnType='INTEGER'),\n        Column(name='Halflife', columnType='DOUBLE'),\n        Column(name='Discovered', columnType='DATE')]\n\nschema = syn.store(Schema(name='MyTable', columns=cols, parent=project))\n</code></pre> Source code in <code>synapseclient/table.py</code> <pre><code>class Schema(SchemaBase):\n    \"\"\"\n    A Schema is an [Entity][synapseclient.entity.Entity] that defines a set of columns in a table.\n\n    Attributes:\n        name:        The name for the Table Schema object\n        description: User readable description of the schema\n        columns:     A list of [Column][synapseclient.table.Column] objects or their IDs\n        parent:      The project in Synapse to which this table belongs\n        properties:  A map of Synapse properties\n        annotations: A map of user defined annotations\n        local_state: Internal use only\n\n    Example:\n\n        cols = [Column(name='Isotope', columnType='STRING'),\n                Column(name='Atomic Mass', columnType='INTEGER'),\n                Column(name='Halflife', columnType='DOUBLE'),\n                Column(name='Discovered', columnType='DATE')]\n\n        schema = syn.store(Schema(name='MyTable', columns=cols, parent=project))\n    \"\"\"\n\n    _synapse_entity_type = \"org.sagebionetworks.repo.model.table.TableEntity\"\n\n    def __init__(\n        self,\n        name=None,\n        columns=None,\n        parent=None,\n        properties=None,\n        annotations=None,\n        local_state=None,\n        **kwargs,\n    ):\n        super(Schema, self).__init__(\n            name=name,\n            columns=columns,\n            properties=properties,\n            annotations=annotations,\n            local_state=local_state,\n            parent=parent,\n            **kwargs,\n        )\n</code></pre>"},{"location":"reference/tables/","title":"Tables","text":""},{"location":"reference/tables/#synapseclient.table","title":"<code>synapseclient.table</code>","text":""},{"location":"reference/tables/#synapseclient.table--tables","title":"Tables","text":"<p>Synapse Tables enable storage of tabular data in Synapse in a form that can be queried using a SQL-like query language.</p> <p>A table has a Schema and holds a set of rows conforming to that schema.</p> <p>A Schema defines a series of Column of the following types:</p> <ul> <li><code>STRING</code></li> <li><code>DOUBLE</code></li> <li><code>INTEGER</code></li> <li><code>BOOLEAN</code></li> <li><code>DATE</code></li> <li><code>ENTITYID</code></li> <li><code>FILEHANDLEID</code></li> <li><code>LINK</code></li> <li><code>LARGETEXT</code></li> <li><code>USERID</code></li> </ul> <p>Read more information about using Table in synapse in the tutorials section.</p>"},{"location":"reference/tables/#synapseclient.table-classes","title":"Classes","text":""},{"location":"reference/tables/#synapseclient.table.SchemaBase","title":"<code>SchemaBase</code>","text":"<p>               Bases: <code>Entity</code></p> <p>This is the an Abstract Class for EntityViewSchema and Schema containing the common methods for both. You can not create an object of this type.</p> Source code in <code>synapseclient/table.py</code> <pre><code>class SchemaBase(Entity, metaclass=abc.ABCMeta):\n    \"\"\"\n    This is the an Abstract Class for EntityViewSchema and Schema containing the common methods for both.\n    You can not create an object of this type.\n    \"\"\"\n\n    _property_keys = Entity._property_keys + [\"columnIds\"]\n    _local_keys = Entity._local_keys + [\"columns_to_store\"]\n\n    @property\n    @abc.abstractmethod  # forces subclasses to define _synapse_entity_type\n    def _synapse_entity_type(self):\n        pass\n\n    @abc.abstractmethod\n    def __init__(\n        self, name, columns, properties, annotations, local_state, parent, **kwargs\n    ):\n        self.properties.setdefault(\"columnIds\", [])\n        self.__dict__.setdefault(\"columns_to_store\", [])\n\n        if name:\n            kwargs[\"name\"] = name\n        super(SchemaBase, self).__init__(\n            properties=properties,\n            annotations=annotations,\n            local_state=local_state,\n            parent=parent,\n            **kwargs,\n        )\n        if columns:\n            self.addColumns(columns)\n\n    def addColumn(self, column) -&gt; None:\n        \"\"\"\n        Store the column\n\n        Arguments:\n            column: A column object or its ID\n\n        Raises:\n            ValueError: If the given column is not a string, integer or [Column][synapseclient.table.Column] object\n        \"\"\"\n        if isinstance(column, str) or isinstance(column, int) or hasattr(column, \"id\"):\n            self.properties.columnIds.append(id_of(column))\n        elif isinstance(column, Column):\n            if not self.__dict__.get(\"columns_to_store\", None):\n                self.__dict__[\"columns_to_store\"] = []\n            self.__dict__[\"columns_to_store\"].append(column)\n        else:\n            raise ValueError(\"Not a column? %s\" % str(column))\n\n    def addColumns(self, columns: list) -&gt; None:\n        \"\"\"\n        Add columns\n\n        Arguments:\n            columns: A list of column objects or their ID\n        \"\"\"\n        for column in columns:\n            self.addColumn(column)\n\n    def removeColumn(self, column) -&gt; None:\n        \"\"\"\n        Remove column\n\n        Arguments:\n            column: A column object or its ID\n\n        Raises:\n            ValueError: If the given column is not a string, integer or [Column][synapseclient.table.Column] object\n        \"\"\"\n        if isinstance(column, str) or isinstance(column, int) or hasattr(column, \"id\"):\n            self.properties.columnIds.remove(id_of(column))\n        elif isinstance(column, Column) and self.columns_to_store:\n            self.columns_to_store.remove(column)\n        else:\n            ValueError(\"Can't remove column %s\" + str(column))\n\n    def has_columns(self):\n        \"\"\"Does this schema have columns specified?\"\"\"\n        return bool(\n            self.properties.get(\"columnIds\", None)\n            or self.__dict__.get(\"columns_to_store\", None)\n        )\n\n    def _before_synapse_store(self, syn):\n        if len(self.columns_to_store) + len(self.columnIds) &gt; MAX_NUM_TABLE_COLUMNS:\n            raise ValueError(\n                \"Too many columns. The limit is %s columns per table\"\n                % MAX_NUM_TABLE_COLUMNS\n            )\n\n        # store any columns before storing table\n        if self.columns_to_store:\n            self.properties.columnIds.extend(\n                column.id for column in syn.createColumns(self.columns_to_store)\n            )\n            self.columns_to_store = []\n</code></pre>"},{"location":"reference/tables/#synapseclient.table.SchemaBase-functions","title":"Functions","text":""},{"location":"reference/tables/#synapseclient.table.SchemaBase.addColumn","title":"<code>addColumn(column)</code>","text":"<p>Store the column</p> PARAMETER DESCRIPTION <code>column</code> <p>A column object or its ID</p> <p> </p> RAISES DESCRIPTION <code>ValueError</code> <p>If the given column is not a string, integer or Column object</p> Source code in <code>synapseclient/table.py</code> <pre><code>def addColumn(self, column) -&gt; None:\n    \"\"\"\n    Store the column\n\n    Arguments:\n        column: A column object or its ID\n\n    Raises:\n        ValueError: If the given column is not a string, integer or [Column][synapseclient.table.Column] object\n    \"\"\"\n    if isinstance(column, str) or isinstance(column, int) or hasattr(column, \"id\"):\n        self.properties.columnIds.append(id_of(column))\n    elif isinstance(column, Column):\n        if not self.__dict__.get(\"columns_to_store\", None):\n            self.__dict__[\"columns_to_store\"] = []\n        self.__dict__[\"columns_to_store\"].append(column)\n    else:\n        raise ValueError(\"Not a column? %s\" % str(column))\n</code></pre>"},{"location":"reference/tables/#synapseclient.table.SchemaBase.addColumns","title":"<code>addColumns(columns)</code>","text":"<p>Add columns</p> PARAMETER DESCRIPTION <code>columns</code> <p>A list of column objects or their ID</p> <p> TYPE: <code>list</code> </p> Source code in <code>synapseclient/table.py</code> <pre><code>def addColumns(self, columns: list) -&gt; None:\n    \"\"\"\n    Add columns\n\n    Arguments:\n        columns: A list of column objects or their ID\n    \"\"\"\n    for column in columns:\n        self.addColumn(column)\n</code></pre>"},{"location":"reference/tables/#synapseclient.table.SchemaBase.removeColumn","title":"<code>removeColumn(column)</code>","text":"<p>Remove column</p> PARAMETER DESCRIPTION <code>column</code> <p>A column object or its ID</p> <p> </p> RAISES DESCRIPTION <code>ValueError</code> <p>If the given column is not a string, integer or Column object</p> Source code in <code>synapseclient/table.py</code> <pre><code>def removeColumn(self, column) -&gt; None:\n    \"\"\"\n    Remove column\n\n    Arguments:\n        column: A column object or its ID\n\n    Raises:\n        ValueError: If the given column is not a string, integer or [Column][synapseclient.table.Column] object\n    \"\"\"\n    if isinstance(column, str) or isinstance(column, int) or hasattr(column, \"id\"):\n        self.properties.columnIds.remove(id_of(column))\n    elif isinstance(column, Column) and self.columns_to_store:\n        self.columns_to_store.remove(column)\n    else:\n        ValueError(\"Can't remove column %s\" + str(column))\n</code></pre>"},{"location":"reference/tables/#synapseclient.table.SchemaBase.has_columns","title":"<code>has_columns()</code>","text":"<p>Does this schema have columns specified?</p> Source code in <code>synapseclient/table.py</code> <pre><code>def has_columns(self):\n    \"\"\"Does this schema have columns specified?\"\"\"\n    return bool(\n        self.properties.get(\"columnIds\", None)\n        or self.__dict__.get(\"columns_to_store\", None)\n    )\n</code></pre>"},{"location":"reference/tables/#synapseclient.table.Schema","title":"<code>Schema</code>","text":"<p>               Bases: <code>SchemaBase</code></p> <p>A Schema is an Entity that defines a set of columns in a table.</p> ATTRIBUTE DESCRIPTION <code>name</code> <p>The name for the Table Schema object</p> <p> </p> <code>description</code> <p>User readable description of the schema</p> <p> </p> <code>columns</code> <p>A list of Column objects or their IDs</p> <p> </p> <code>parent</code> <p>The project in Synapse to which this table belongs</p> <p> </p> <code>properties</code> <p>A map of Synapse properties</p> <p> </p> <code>annotations</code> <p>A map of user defined annotations</p> <p> </p> <code>local_state</code> <p>Internal use only</p> <p> </p> <p>Example:</p> <pre><code>cols = [Column(name='Isotope', columnType='STRING'),\n        Column(name='Atomic Mass', columnType='INTEGER'),\n        Column(name='Halflife', columnType='DOUBLE'),\n        Column(name='Discovered', columnType='DATE')]\n\nschema = syn.store(Schema(name='MyTable', columns=cols, parent=project))\n</code></pre> Source code in <code>synapseclient/table.py</code> <pre><code>class Schema(SchemaBase):\n    \"\"\"\n    A Schema is an [Entity][synapseclient.entity.Entity] that defines a set of columns in a table.\n\n    Attributes:\n        name:        The name for the Table Schema object\n        description: User readable description of the schema\n        columns:     A list of [Column][synapseclient.table.Column] objects or their IDs\n        parent:      The project in Synapse to which this table belongs\n        properties:  A map of Synapse properties\n        annotations: A map of user defined annotations\n        local_state: Internal use only\n\n    Example:\n\n        cols = [Column(name='Isotope', columnType='STRING'),\n                Column(name='Atomic Mass', columnType='INTEGER'),\n                Column(name='Halflife', columnType='DOUBLE'),\n                Column(name='Discovered', columnType='DATE')]\n\n        schema = syn.store(Schema(name='MyTable', columns=cols, parent=project))\n    \"\"\"\n\n    _synapse_entity_type = \"org.sagebionetworks.repo.model.table.TableEntity\"\n\n    def __init__(\n        self,\n        name=None,\n        columns=None,\n        parent=None,\n        properties=None,\n        annotations=None,\n        local_state=None,\n        **kwargs,\n    ):\n        super(Schema, self).__init__(\n            name=name,\n            columns=columns,\n            properties=properties,\n            annotations=annotations,\n            local_state=local_state,\n            parent=parent,\n            **kwargs,\n        )\n</code></pre>"},{"location":"reference/tables/#synapseclient.table.MaterializedViewSchema","title":"<code>MaterializedViewSchema</code>","text":"<p>               Bases: <code>SchemaBase</code></p> <p>A MaterializedViewSchema is an Entity that defines a set of columns in a materialized view along with the SQL statement.</p> ATTRIBUTE DESCRIPTION <code>name</code> <p>The name for the Materialized View Schema object</p> <p> </p> <code>description</code> <p>User readable description of the schema</p> <p> </p> <code>definingSQL</code> <p>The synapse SQL statement that defines the data in the materialized view. The SQL                   contain JOIN clauses on multiple tables.</p> <p> </p> <code>columns</code> <p>A list of Column objects or their IDs</p> <p> </p> <code>parent</code> <p>The project in Synapse to which this Materialized View belongs</p> <p> </p> <code>properties</code> <p>A map of Synapse properties</p> <p> </p> <code>annotations</code> <p>A map of user defined annotations</p> <p> </p> <code>local_state</code> <p>Internal use only</p> <p> </p> <p>Example:</p> <pre><code>defining_sql = \"SELECT * FROM syn111 F JOIN syn2222 P on (F.patient_id = P.patient_id)\"\n\nschema = syn.store(MaterializedViewSchema(name='MyTable', parent=project, definingSQL=defining_sql))\n</code></pre> Source code in <code>synapseclient/table.py</code> <pre><code>class MaterializedViewSchema(SchemaBase):\n    \"\"\"\n    A MaterializedViewSchema is an [Entity][synapseclient.entity.Entity] that defines a set of columns in a\n    materialized view along with the SQL statement.\n\n    Attributes:\n        name:        The name for the Materialized View Schema object\n        description: User readable description of the schema\n        definingSQL: The synapse SQL statement that defines the data in the materialized view. The SQL                   contain JOIN clauses on multiple tables.\n        columns:     A list of [Column][synapseclient.table.Column] objects or their IDs\n        parent:      The project in Synapse to which this Materialized View belongs\n        properties:  A map of Synapse properties\n        annotations: A map of user defined annotations\n        local_state: Internal use only\n\n    Example:\n\n        defining_sql = \"SELECT * FROM syn111 F JOIN syn2222 P on (F.patient_id = P.patient_id)\"\n\n        schema = syn.store(MaterializedViewSchema(name='MyTable', parent=project, definingSQL=defining_sql))\n    \"\"\"\n\n    _synapse_entity_type = \"org.sagebionetworks.repo.model.table.MaterializedView\"\n    _property_keys = SchemaBase._property_keys + [\"definingSQL\"]\n\n    def __init__(\n        self,\n        name=None,\n        columns=None,\n        parent=None,\n        definingSQL=None,\n        properties=None,\n        annotations=None,\n        local_state=None,\n        **kwargs,\n    ):\n        if definingSQL is not None:\n            kwargs[\"definingSQL\"] = definingSQL\n        super(MaterializedViewSchema, self).__init__(\n            name=name,\n            columns=columns,\n            properties=properties,\n            annotations=annotations,\n            local_state=local_state,\n            parent=parent,\n            **kwargs,\n        )\n</code></pre>"},{"location":"reference/tables/#synapseclient.table.ViewBase","title":"<code>ViewBase</code>","text":"<p>               Bases: <code>SchemaBase</code></p> <p>This is a helper class for EntityViewSchema and SubmissionViewSchema containing the common methods for both.</p> Source code in <code>synapseclient/table.py</code> <pre><code>class ViewBase(SchemaBase):\n    \"\"\"\n    This is a helper class for EntityViewSchema and SubmissionViewSchema\n    containing the common methods for both.\n    \"\"\"\n\n    _synapse_entity_type = \"\"\n    _property_keys = SchemaBase._property_keys + [\"viewTypeMask\", \"scopeIds\"]\n    _local_keys = SchemaBase._local_keys + [\n        \"addDefaultViewColumns\",\n        \"addAnnotationColumns\",\n        \"ignoredAnnotationColumnNames\",\n    ]\n\n    def add_scope(self, entities: Union[Project, Folder, Evaluation, list, str]):\n        \"\"\"\n        Add scope\n\n        Arguments:\n            entities: A [Project][synapseclient.entity.Project], [Folder][synapseclient.entity.Folder],\n                      [Evaluation][synapseclient.evaluation.Evaluation] object or its ID, can also be a list of them\n        \"\"\"\n        if isinstance(entities, list):\n            # add ids to a temp list so that we don't partially modify scopeIds on an exception in id_of()\n            temp_list = [id_of(entity) for entity in entities]\n            self.scopeIds.extend(temp_list)\n        else:\n            self.scopeIds.append(id_of(entities))\n\n    def _filter_duplicate_columns(self, syn, columns_to_add):\n        \"\"\"\n        If a column to be added has the same name and same type as an existing column, it will be considered a duplicate\n         and not added.\n\n        Arguments:\n            syn:             A [Synapse][synapseclient.client.Synapse] object that is logged in\n            columns_to_add:  A iterable collection of type [Column][synapseclient.table.Column] objects\n\n        Returns:\n            A filtered list of columns to add\n        \"\"\"\n\n        # no point in making HTTP calls to retrieve existing Columns if we not adding any new columns\n        if not columns_to_add:\n            return columns_to_add\n\n        # set up Column name/type tracking\n        # map of str -&gt; set(str), where str is the column type as a string and set is a set of column name strings\n        column_type_to_annotation_names = {}\n\n        # add to existing columns the columns that user has added but not yet created in synapse\n        column_generator = (\n            itertools.chain(syn.getColumns(self.columnIds), self.columns_to_store)\n            if self.columns_to_store\n            else syn.getColumns(self.columnIds)\n        )\n\n        for column in column_generator:\n            column_name = column[\"name\"]\n            column_type = column[\"columnType\"]\n\n            column_type_to_annotation_names.setdefault(column_type, set()).add(\n                column_name\n            )\n\n        valid_columns = []\n        for column in columns_to_add:\n            new_col_name = column[\"name\"]\n            new_col_type = column[\"columnType\"]\n\n            typed_col_name_set = column_type_to_annotation_names.setdefault(\n                new_col_type, set()\n            )\n            if new_col_name not in typed_col_name_set:\n                typed_col_name_set.add(new_col_name)\n                valid_columns.append(column)\n        return valid_columns\n\n    def _before_synapse_store(self, syn):\n        # get the default EntityView columns from Synapse and add them to the columns list\n        additional_columns = []\n        view_type = self._synapse_entity_type.split(\".\")[-1].lower()\n        mask = self.get(\"viewTypeMask\")\n\n        if self.addDefaultViewColumns:\n            additional_columns.extend(\n                syn._get_default_view_columns(view_type, view_type_mask=mask)\n            )\n\n        # get default annotations\n        if self.addAnnotationColumns:\n            anno_columns = [\n                x\n                for x in syn._get_annotation_view_columns(\n                    self.scopeIds, view_type, view_type_mask=mask\n                )\n                if x[\"name\"] not in self.ignoredAnnotationColumnNames\n            ]\n            additional_columns.extend(anno_columns)\n\n        self.addColumns(self._filter_duplicate_columns(syn, additional_columns))\n\n        # set these boolean flags to false so they are not repeated.\n        self.addDefaultViewColumns = False\n        self.addAnnotationColumns = False\n\n        super(ViewBase, self)._before_synapse_store(syn)\n</code></pre>"},{"location":"reference/tables/#synapseclient.table.ViewBase-functions","title":"Functions","text":""},{"location":"reference/tables/#synapseclient.table.ViewBase.add_scope","title":"<code>add_scope(entities)</code>","text":"<p>Add scope</p> PARAMETER DESCRIPTION <code>entities</code> <p>A Project, Folder,       Evaluation object or its ID, can also be a list of them</p> <p> TYPE: <code>Union[Project, Folder, Evaluation, list, str]</code> </p> Source code in <code>synapseclient/table.py</code> <pre><code>def add_scope(self, entities: Union[Project, Folder, Evaluation, list, str]):\n    \"\"\"\n    Add scope\n\n    Arguments:\n        entities: A [Project][synapseclient.entity.Project], [Folder][synapseclient.entity.Folder],\n                  [Evaluation][synapseclient.evaluation.Evaluation] object or its ID, can also be a list of them\n    \"\"\"\n    if isinstance(entities, list):\n        # add ids to a temp list so that we don't partially modify scopeIds on an exception in id_of()\n        temp_list = [id_of(entity) for entity in entities]\n        self.scopeIds.extend(temp_list)\n    else:\n        self.scopeIds.append(id_of(entities))\n</code></pre>"},{"location":"reference/tables/#synapseclient.table.Dataset","title":"<code>Dataset</code>","text":"<p>               Bases: <code>ViewBase</code></p> <p>A Dataset is an Entity that defines a flat list of entities as a tableview (a.k.a. a \"dataset\").</p> ATTRIBUTE DESCRIPTION <code>name</code> <p>The name for the Dataset object</p> <p> </p> <code>description</code> <p>User readable description of the schema</p> <p> </p> <code>columns</code> <p>A list of Column objects or their IDs</p> <p> </p> <code>parent</code> <p>The Synapse Project to which this Dataset belongs</p> <p> </p> <code>properties</code> <p>A map of Synapse properties</p> <p> </p> <code>annotations</code> <p>A map of user defined annotations</p> <p> </p> <code>dataset_items</code> <p>A list of items characterized by entityId and versionNumber</p> <p> </p> <code>folder</code> <p>A list of Folder IDs</p> <p> </p> <code>local_state</code> <p>Internal use only</p> <p> </p> Using Dataset <p>Load Dataset</p> <pre><code>from synapseclient import Dataset\n</code></pre> <p>Create a Dataset with pre-defined DatasetItems. Default Dataset columns are used if no schema is provided.</p> <pre><code>dataset_items = [\n    {'entityId': \"syn000\", 'versionNumber': 1},\n    {...},\n]\n\ndataset = syn.store(Dataset(\n    name=\"My Dataset\",\n    parent=project,\n    dataset_items=dataset_items))\n</code></pre> <p>Add/remove specific Synapse IDs to/from the Dataset</p> <pre><code>dataset.add_item({'entityId': \"syn111\", 'versionNumber': 1})\ndataset.remove_item(\"syn000\")\ndataset = syn.store(dataset)\n</code></pre> <p>Add a list of Synapse IDs to the Dataset</p> <pre><code>new_items = [\n    {'entityId': \"syn222\", 'versionNumber': 2},\n    {'entityId': \"syn333\", 'versionNumber': 1}\n]\ndataset.add_items(new_items)\ndataset = syn.store(dataset)\n</code></pre> <p>Folders can easily be added recursively to a dataset, that is, all files within the folder (including sub-folders) will be added.  Note that using the following methods will add files with the latest version number ONLY. If another version number is desired, use add_item or add_items.</p> Add folder to Dataset <p>Add a single Folder to the Dataset.</p> <pre><code>dataset.add_folder(\"syn123\")\n</code></pre> <p>Add a list of Folders, overwriting any existing files in the dataset.</p> <pre><code>dataset.add_folders([\"syn456\", \"syn789\"], force=True)\ndataset = syn.store(dataset)\n</code></pre> Truncate a Dataset <p>empty() can be used to truncate a dataset, that is, remove all current items from the set.</p> <pre><code>dataset.empty()\ndataset = syn.store(dataset)\n</code></pre> Check items in a Dataset <p>To get the number of entities in the dataset, use len().</p> <pre><code>print(f\"{dataset.name} has {len(dataset)} items.\")\n</code></pre> Create a snapshot of the Dataset <p>To create a snapshot version of the Dataset, use create_snapshot_version.</p> <pre><code>syn = synapseclient.login()\nsyn.create_snapshot_version(\n    dataset.id,\n    label=\"v1.0\",\n    comment=\"This is version 1\")\n</code></pre> Source code in <code>synapseclient/table.py</code> <pre><code>class Dataset(ViewBase):\n    \"\"\"\n    A Dataset is an [Entity][synapseclient.entity.Entity] that defines a\n    flat list of entities as a tableview (a.k.a. a \"dataset\").\n\n    Attributes:\n        name:          The name for the Dataset object\n        description:   User readable description of the schema\n        columns:       A list of [Column][synapseclient.table.Column] objects or their IDs\n        parent:        The Synapse Project to which this Dataset belongs\n        properties:    A map of Synapse properties\n        annotations:   A map of user defined annotations\n        dataset_items: A list of items characterized by entityId and versionNumber\n        folder:        A list of Folder IDs\n        local_state:   Internal use only\n\n    Example: Using Dataset\n        Load Dataset\n\n            from synapseclient import Dataset\n\n        Create a Dataset with pre-defined DatasetItems. Default Dataset columns\n        are used if no schema is provided.\n\n            dataset_items = [\n                {'entityId': \"syn000\", 'versionNumber': 1},\n                {...},\n            ]\n\n            dataset = syn.store(Dataset(\n                name=\"My Dataset\",\n                parent=project,\n                dataset_items=dataset_items))\n\n        Add/remove specific Synapse IDs to/from the Dataset\n\n            dataset.add_item({'entityId': \"syn111\", 'versionNumber': 1})\n            dataset.remove_item(\"syn000\")\n            dataset = syn.store(dataset)\n\n        Add a list of Synapse IDs to the Dataset\n\n            new_items = [\n                {'entityId': \"syn222\", 'versionNumber': 2},\n                {'entityId': \"syn333\", 'versionNumber': 1}\n            ]\n            dataset.add_items(new_items)\n            dataset = syn.store(dataset)\n\n    Folders can easily be added recursively to a dataset, that is, all files\n    within the folder (including sub-folders) will be added.  Note that using\n    the following methods will add files with the latest version number ONLY.\n    If another version number is desired, use [add_item][synapseclient.table.Dataset.add_item]\n    or [add_items][synapseclient.table.Dataset.add_items].\n\n    Example: Add folder to Dataset\n        Add a single Folder to the Dataset.\n\n            dataset.add_folder(\"syn123\")\n\n        Add a list of Folders, overwriting any existing files in the dataset.\n\n            dataset.add_folders([\"syn456\", \"syn789\"], force=True)\n            dataset = syn.store(dataset)\n\n    Example: Truncate a Dataset\n        empty() can be used to truncate a dataset, that is, remove all current items from the set.\n\n            dataset.empty()\n            dataset = syn.store(dataset)\n\n\n\n    Example: Check items in a Dataset\n        To get the number of entities in the dataset, use len().\n\n            print(f\"{dataset.name} has {len(dataset)} items.\")\n\n    Example: Create a snapshot of the Dataset\n        To create a snapshot version of the Dataset, use\n        [create_snapshot_version][synapseclient.Synapse.create_snapshot_version].\n\n            syn = synapseclient.login()\n            syn.create_snapshot_version(\n                dataset.id,\n                label=\"v1.0\",\n                comment=\"This is version 1\")\n    \"\"\"\n\n    _synapse_entity_type: str = \"org.sagebionetworks.repo.model.table.Dataset\"\n    _property_keys: List[str] = ViewBase._property_keys + [\"datasetItems\"]\n    _local_keys: List[str] = ViewBase._local_keys + [\"folders_to_add\", \"force\"]\n\n    def __init__(\n        self,\n        name=None,\n        columns=None,\n        parent=None,\n        properties=None,\n        addDefaultViewColumns=True,\n        addAnnotationColumns=True,\n        ignoredAnnotationColumnNames=[],\n        annotations=None,\n        local_state=None,\n        dataset_items=None,\n        folders=None,\n        force=False,\n        **kwargs,\n    ):\n        self.properties.setdefault(\"datasetItems\", [])\n        self.__dict__.setdefault(\"folders_to_add\", set())\n        self.ignoredAnnotationColumnNames = set(ignoredAnnotationColumnNames)\n        self.viewTypeMask = EntityViewType.DATASET.value\n        super(Dataset, self).__init__(\n            name=name,\n            columns=columns,\n            properties=properties,\n            annotations=annotations,\n            local_state=local_state,\n            parent=parent,\n            **kwargs,\n        )\n\n        self.force = force\n        if dataset_items:\n            self.add_items(dataset_items, force)\n        if folders:\n            self.add_folders(folders, force)\n\n        # HACK: make sure we don't try to add columns to schemas that we retrieve from synapse\n        is_from_normal_constructor = not (properties or local_state)\n        # allowing annotations because user might want to update annotations all at once\n        self.addDefaultViewColumns = (\n            addDefaultViewColumns and is_from_normal_constructor\n        )\n        self.addAnnotationColumns = addAnnotationColumns and is_from_normal_constructor\n\n    def __len__(self):\n        return len(self.properties.datasetItems)\n\n    @staticmethod\n    def _check_needed_keys(keys: List[str]):\n        required_keys = {\"entityId\", \"versionNumber\"}\n        if required_keys - keys:\n            raise LookupError(\n                \"DatasetItem missing a required property: %s\"\n                % str(required_keys - keys)\n            )\n        return True\n\n    def add_item(self, dataset_item: Dict[str, str], force: bool = True):\n        \"\"\"\n        Add a dataset item\n\n        Arguments:\n            dataset_item: A single dataset item\n            force:        Force add item\n\n        Raises:\n            ValueError: If duplicate item is found\n            ValueError: The item is not a DatasetItem\n        \"\"\"\n        if isinstance(dataset_item, dict) and self._check_needed_keys(\n            dataset_item.keys()\n        ):\n            if not self.has_item(dataset_item.get(\"entityId\")):\n                self.properties.datasetItems.append(dataset_item)\n            else:\n                if force:\n                    self.remove_item(dataset_item.get(\"entityId\"))\n                    self.properties.datasetItems.append(dataset_item)\n                else:\n                    raise ValueError(\n                        f\"Duplicate item found: {dataset_item.get('entityId')}. \"\n                        \"Set force=True to overwrite the existing item.\"\n                    )\n        else:\n            raise ValueError(\"Not a DatasetItem? %s\" % str(dataset_item))\n\n    def add_items(self, dataset_items: List[Dict[str, str]], force: bool = True):\n        \"\"\"\n        Add items\n\n        Arguments:\n            dataset_items: A list of dataset items\n            force:         Force add items\n        \"\"\"\n        for dataset_item in dataset_items:\n            self.add_item(dataset_item, force)\n\n    def remove_item(self, item_id: str):\n        \"\"\"\n        Remove item\n\n        Arguments:\n            item_id: A single dataset item Synapse ID\n        \"\"\"\n        item_id = id_of(item_id)\n        if item_id.startswith(\"syn\"):\n            for i, curr_item in enumerate(self.properties.datasetItems):\n                if curr_item.get(\"entityId\") == item_id:\n                    del self.properties.datasetItems[i]\n                    break\n        else:\n            raise ValueError(\"Not a Synapse ID: %s\" % str(item_id))\n\n    def empty(self):\n        self.properties.datasetItems = []\n\n    def has_item(self, item_id: str) -&gt; bool:\n        \"\"\"\n        Check if has dataset item\n\n        Arguments:\n            item_id: A single dataset item Synapse ID\n        \"\"\"\n        return any(item[\"entityId\"] == item_id for item in self.properties.datasetItems)\n\n    def add_folder(self, folder: str, force: bool = True):\n        \"\"\"\n        Add a folder\n\n        Arguments:\n            folder: A single Synapse Folder ID\n            force:  Force add items from folder\n        \"\"\"\n        if not self.__dict__.get(\"folders_to_add\", None):\n            self.__dict__[\"folders_to_add\"] = set()\n        self.__dict__[\"folders_to_add\"].add(folder)\n        # if self.force != force:\n        self.force = force\n\n    def add_folders(self, folders: List[str], force: bool = True):\n        \"\"\"\n        Add folders\n\n        Arguments:\n            folders: A list of Synapse Folder IDs\n            force:   Force add items from folders\n        \"\"\"\n        if (\n            isinstance(folders, list)\n            or isinstance(folders, set)\n            or isinstance(folders, tuple)\n        ):\n            self.force = force\n            for folder in folders:\n                self.add_folder(folder, force)\n        else:\n            raise ValueError(f\"Not a list of Folder IDs: {folders}\")\n\n    def _add_folder_files(self, syn, folder):\n        files = []\n        children = syn.getChildren(folder)\n        for child in children:\n            if child.get(\"type\") == \"org.sagebionetworks.repo.model.Folder\":\n                files.extend(self._add_folder_files(syn, child.get(\"id\")))\n            elif child.get(\"type\") == \"org.sagebionetworks.repo.model.FileEntity\":\n                files.append(\n                    {\n                        \"entityId\": child.get(\"id\"),\n                        \"versionNumber\": child.get(\"versionNumber\"),\n                    }\n                )\n            else:\n                raise ValueError(f\"Not a Folder?: {folder}\")\n        return files\n\n    def _before_synapse_store(self, syn):\n        # Add files from folders (if any) before storing dataset.\n        if self.folders_to_add:\n            for folder in self.folders_to_add:\n                items_to_add = self._add_folder_files(syn, folder)\n                self.add_items(items_to_add, self.force)\n            self.folders_to_add = set()\n        # Must set this scopeIds is used to get all annotations from the\n        # entities\n        self.scopeIds = [item[\"entityId\"] for item in self.properties.datasetItems]\n        super()._before_synapse_store(syn)\n        # Reset attribute to force-add items from folders.\n        self.force = True\n        # Remap `datasetItems` back to `items` before storing (since `items`\n        # is the accepted field name in the API, not `datasetItems`).\n        self.properties.items = self.properties.datasetItems\n</code></pre>"},{"location":"reference/tables/#synapseclient.table.Dataset-functions","title":"Functions","text":""},{"location":"reference/tables/#synapseclient.table.Dataset.add_item","title":"<code>add_item(dataset_item, force=True)</code>","text":"<p>Add a dataset item</p> PARAMETER DESCRIPTION <code>dataset_item</code> <p>A single dataset item</p> <p> TYPE: <code>Dict[str, str]</code> </p> <code>force</code> <p>Force add item</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> RAISES DESCRIPTION <code>ValueError</code> <p>If duplicate item is found</p> <code>ValueError</code> <p>The item is not a DatasetItem</p> Source code in <code>synapseclient/table.py</code> <pre><code>def add_item(self, dataset_item: Dict[str, str], force: bool = True):\n    \"\"\"\n    Add a dataset item\n\n    Arguments:\n        dataset_item: A single dataset item\n        force:        Force add item\n\n    Raises:\n        ValueError: If duplicate item is found\n        ValueError: The item is not a DatasetItem\n    \"\"\"\n    if isinstance(dataset_item, dict) and self._check_needed_keys(\n        dataset_item.keys()\n    ):\n        if not self.has_item(dataset_item.get(\"entityId\")):\n            self.properties.datasetItems.append(dataset_item)\n        else:\n            if force:\n                self.remove_item(dataset_item.get(\"entityId\"))\n                self.properties.datasetItems.append(dataset_item)\n            else:\n                raise ValueError(\n                    f\"Duplicate item found: {dataset_item.get('entityId')}. \"\n                    \"Set force=True to overwrite the existing item.\"\n                )\n    else:\n        raise ValueError(\"Not a DatasetItem? %s\" % str(dataset_item))\n</code></pre>"},{"location":"reference/tables/#synapseclient.table.Dataset.add_items","title":"<code>add_items(dataset_items, force=True)</code>","text":"<p>Add items</p> PARAMETER DESCRIPTION <code>dataset_items</code> <p>A list of dataset items</p> <p> TYPE: <code>List[Dict[str, str]]</code> </p> <code>force</code> <p>Force add items</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> Source code in <code>synapseclient/table.py</code> <pre><code>def add_items(self, dataset_items: List[Dict[str, str]], force: bool = True):\n    \"\"\"\n    Add items\n\n    Arguments:\n        dataset_items: A list of dataset items\n        force:         Force add items\n    \"\"\"\n    for dataset_item in dataset_items:\n        self.add_item(dataset_item, force)\n</code></pre>"},{"location":"reference/tables/#synapseclient.table.Dataset.remove_item","title":"<code>remove_item(item_id)</code>","text":"<p>Remove item</p> PARAMETER DESCRIPTION <code>item_id</code> <p>A single dataset item Synapse ID</p> <p> TYPE: <code>str</code> </p> Source code in <code>synapseclient/table.py</code> <pre><code>def remove_item(self, item_id: str):\n    \"\"\"\n    Remove item\n\n    Arguments:\n        item_id: A single dataset item Synapse ID\n    \"\"\"\n    item_id = id_of(item_id)\n    if item_id.startswith(\"syn\"):\n        for i, curr_item in enumerate(self.properties.datasetItems):\n            if curr_item.get(\"entityId\") == item_id:\n                del self.properties.datasetItems[i]\n                break\n    else:\n        raise ValueError(\"Not a Synapse ID: %s\" % str(item_id))\n</code></pre>"},{"location":"reference/tables/#synapseclient.table.Dataset.has_item","title":"<code>has_item(item_id)</code>","text":"<p>Check if has dataset item</p> PARAMETER DESCRIPTION <code>item_id</code> <p>A single dataset item Synapse ID</p> <p> TYPE: <code>str</code> </p> Source code in <code>synapseclient/table.py</code> <pre><code>def has_item(self, item_id: str) -&gt; bool:\n    \"\"\"\n    Check if has dataset item\n\n    Arguments:\n        item_id: A single dataset item Synapse ID\n    \"\"\"\n    return any(item[\"entityId\"] == item_id for item in self.properties.datasetItems)\n</code></pre>"},{"location":"reference/tables/#synapseclient.table.Dataset.add_folder","title":"<code>add_folder(folder, force=True)</code>","text":"<p>Add a folder</p> PARAMETER DESCRIPTION <code>folder</code> <p>A single Synapse Folder ID</p> <p> TYPE: <code>str</code> </p> <code>force</code> <p>Force add items from folder</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> Source code in <code>synapseclient/table.py</code> <pre><code>def add_folder(self, folder: str, force: bool = True):\n    \"\"\"\n    Add a folder\n\n    Arguments:\n        folder: A single Synapse Folder ID\n        force:  Force add items from folder\n    \"\"\"\n    if not self.__dict__.get(\"folders_to_add\", None):\n        self.__dict__[\"folders_to_add\"] = set()\n    self.__dict__[\"folders_to_add\"].add(folder)\n    # if self.force != force:\n    self.force = force\n</code></pre>"},{"location":"reference/tables/#synapseclient.table.Dataset.add_folders","title":"<code>add_folders(folders, force=True)</code>","text":"<p>Add folders</p> PARAMETER DESCRIPTION <code>folders</code> <p>A list of Synapse Folder IDs</p> <p> TYPE: <code>List[str]</code> </p> <code>force</code> <p>Force add items from folders</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> Source code in <code>synapseclient/table.py</code> <pre><code>def add_folders(self, folders: List[str], force: bool = True):\n    \"\"\"\n    Add folders\n\n    Arguments:\n        folders: A list of Synapse Folder IDs\n        force:   Force add items from folders\n    \"\"\"\n    if (\n        isinstance(folders, list)\n        or isinstance(folders, set)\n        or isinstance(folders, tuple)\n    ):\n        self.force = force\n        for folder in folders:\n            self.add_folder(folder, force)\n    else:\n        raise ValueError(f\"Not a list of Folder IDs: {folders}\")\n</code></pre>"},{"location":"reference/tables/#synapseclient.table.EntityViewSchema","title":"<code>EntityViewSchema</code>","text":"<p>               Bases: <code>ViewBase</code></p> <p>A EntityViewSchema is a Entity that displays all files/projects (depending on user choice) within a given set of scopes.</p> ATTRIBUTE DESCRIPTION <code>name</code> <p>The name of the Entity View Table object</p> <p> </p> <code>columns</code> <p>(Optional) A list of Column objects or their IDs.</p> <p> </p> <code>parent</code> <p>The project in Synapse to which this table belongs</p> <p> </p> <code>scopes</code> <p>A list of Projects/Folders or their ids</p> <p> </p> <code>type</code> <p>This field is deprecated. Please use <code>includeEntityTypes</code></p> <p> </p> <code>includeEntityTypes</code> <p>A list of entity types to include in the view. Supported entity types are:</p> <ul> <li><code>EntityViewType.FILE</code></li> <li><code>EntityViewType.PROJECT</code></li> <li><code>EntityViewType.TABLE</code></li> <li><code>EntityViewType.FOLDER</code></li> <li><code>EntityViewType.VIEW</code></li> <li><code>EntityViewType.DOCKER</code></li> </ul> <p>If none is provided, the view will default to include <code>EntityViewType.FILE</code>.</p> <p> </p> <code>addDefaultViewColumns</code> <p>If true, adds all default columns (e.g. name, createdOn, modifiedBy etc.)                           Defaults to True.                           The default columns will be added after a call to                           store.</p> <p> </p> <code>addAnnotationColumns</code> <p>If true, adds columns for all annotation keys defined across all Entities in                           the EntityViewSchema's scope. Defaults to True.                           The annotation columns will be added after a call to                           store.</p> <p> </p> <code>ignoredAnnotationColumnNames</code> <p>A list of strings representing annotation names.                           When addAnnotationColumns is True, the names in this list will not be                           automatically added as columns to the EntityViewSchema if they exist in any                           of the defined scopes.</p> <p> </p> <code>properties</code> <p>A map of Synapse properties</p> <p> </p> <code>annotations</code> <p>A map of user defined annotations</p> <p> </p> <code>local_state</code> <p>Internal use only</p> <p> </p> <p>Example:</p> <pre><code>from synapseclient import EntityViewType\n\nproject_or_folder = syn.get(\"syn123\")\nschema = syn.store(EntityViewSchema(name='MyTable', parent=project, scopes=[project_or_folder_id, 'syn123'],\n includeEntityTypes=[EntityViewType.FILE]))\n</code></pre> Source code in <code>synapseclient/table.py</code> <pre><code>class EntityViewSchema(ViewBase):\n    \"\"\"\n    A EntityViewSchema is a [Entity][synapseclient.entity.Entity] that displays all files/projects\n    (depending on user choice) within a given set of scopes.\n\n    Attributes:\n        name:                         The name of the Entity View Table object\n        columns:                      (Optional) A list of [Column][synapseclient.table.Column] objects or their IDs.\n        parent:                       The project in Synapse to which this table belongs\n        scopes:                       A list of Projects/Folders or their ids\n        type:                         This field is deprecated. Please use `includeEntityTypes`\n        includeEntityTypes:           A list of entity types to include in the view. Supported entity types are:\n\n            - `EntityViewType.FILE`\n            - `EntityViewType.PROJECT`\n            - `EntityViewType.TABLE`\n            - `EntityViewType.FOLDER`\n            - `EntityViewType.VIEW`\n            - `EntityViewType.DOCKER`\n\n            If none is provided, the view will default to include `EntityViewType.FILE`.\n        addDefaultViewColumns:        If true, adds all default columns (e.g. name, createdOn, modifiedBy etc.)\n                                      Defaults to True.\n                                      The default columns will be added after a call to\n                                      [store][synapseclient.Synapse.store].\n        addAnnotationColumns:         If true, adds columns for all annotation keys defined across all Entities in\n                                      the EntityViewSchema's scope. Defaults to True.\n                                      The annotation columns will be added after a call to\n                                      [store][synapseclient.Synapse.store].\n        ignoredAnnotationColumnNames: A list of strings representing annotation names.\n                                      When addAnnotationColumns is True, the names in this list will not be\n                                      automatically added as columns to the EntityViewSchema if they exist in any\n                                      of the defined scopes.\n        properties:                   A map of Synapse properties\n        annotations:                  A map of user defined annotations\n        local_state:                  Internal use only\n\n    Example:\n\n        from synapseclient import EntityViewType\n\n        project_or_folder = syn.get(\"syn123\")\n        schema = syn.store(EntityViewSchema(name='MyTable', parent=project, scopes=[project_or_folder_id, 'syn123'],\n         includeEntityTypes=[EntityViewType.FILE]))\n    \"\"\"\n\n    _synapse_entity_type = \"org.sagebionetworks.repo.model.table.EntityView\"\n\n    def __init__(\n        self,\n        name=None,\n        columns=None,\n        parent=None,\n        scopes=None,\n        type=None,\n        includeEntityTypes=None,\n        addDefaultViewColumns=True,\n        addAnnotationColumns=True,\n        ignoredAnnotationColumnNames=[],\n        properties=None,\n        annotations=None,\n        local_state=None,\n        **kwargs,\n    ):\n        if includeEntityTypes:\n            kwargs[\"viewTypeMask\"] = _get_view_type_mask(includeEntityTypes)\n        elif type:\n            kwargs[\"viewTypeMask\"] = _get_view_type_mask_for_deprecated_type(type)\n        elif properties and \"type\" in properties:\n            kwargs[\"viewTypeMask\"] = _get_view_type_mask_for_deprecated_type(\n                properties[\"type\"]\n            )\n            properties[\"type\"] = None\n\n        self.ignoredAnnotationColumnNames = set(ignoredAnnotationColumnNames)\n        super(EntityViewSchema, self).__init__(\n            name=name,\n            columns=columns,\n            properties=properties,\n            annotations=annotations,\n            local_state=local_state,\n            parent=parent,\n            **kwargs,\n        )\n\n        # This is a hacky solution to make sure we don't try to add columns to schemas that we retrieve from synapse\n        is_from_normal_constructor = not (properties or local_state)\n        # allowing annotations because user might want to update annotations all at once\n        self.addDefaultViewColumns = (\n            addDefaultViewColumns and is_from_normal_constructor\n        )\n        self.addAnnotationColumns = addAnnotationColumns and is_from_normal_constructor\n\n        # set default values after constructor so we don't overwrite the values defined in properties using .get()\n        # because properties, unlike local_state, do not have nonexistent keys assigned with a value of None\n        if self.get(\"viewTypeMask\") is None:\n            self.viewTypeMask = EntityViewType.FILE.value\n        if self.get(\"scopeIds\") is None:\n            self.scopeIds = []\n\n        # add the scopes last so that we can append the passed in scopes to those defined in properties\n        if scopes is not None:\n            self.add_scope(scopes)\n\n    def set_entity_types(self, includeEntityTypes):\n        \"\"\"\n        Set entity types\n\n        Arguments:\n            includeEntityTypes: A list of entity types to include in the view. This list will replace the previous\n                                settings. Supported entity types are:\n\n                - `EntityViewType.FILE`\n                - `EntityViewType.PROJECT`\n                - `EntityViewType.TABLE`\n                - `EntityViewType.FOLDER`\n                - `EntityViewType.VIEW`\n                - `EntityViewType.DOCKER`\n        \"\"\"\n        self.viewTypeMask = _get_view_type_mask(includeEntityTypes)\n</code></pre>"},{"location":"reference/tables/#synapseclient.table.EntityViewSchema-functions","title":"Functions","text":""},{"location":"reference/tables/#synapseclient.table.EntityViewSchema.set_entity_types","title":"<code>set_entity_types(includeEntityTypes)</code>","text":"<p>Set entity types</p> PARAMETER DESCRIPTION <code>includeEntityTypes</code> <p>A list of entity types to include in the view. This list will replace the previous                 settings. Supported entity types are:</p> <ul> <li><code>EntityViewType.FILE</code></li> <li><code>EntityViewType.PROJECT</code></li> <li><code>EntityViewType.TABLE</code></li> <li><code>EntityViewType.FOLDER</code></li> <li><code>EntityViewType.VIEW</code></li> <li><code>EntityViewType.DOCKER</code></li> </ul> <p> </p> Source code in <code>synapseclient/table.py</code> <pre><code>def set_entity_types(self, includeEntityTypes):\n    \"\"\"\n    Set entity types\n\n    Arguments:\n        includeEntityTypes: A list of entity types to include in the view. This list will replace the previous\n                            settings. Supported entity types are:\n\n            - `EntityViewType.FILE`\n            - `EntityViewType.PROJECT`\n            - `EntityViewType.TABLE`\n            - `EntityViewType.FOLDER`\n            - `EntityViewType.VIEW`\n            - `EntityViewType.DOCKER`\n    \"\"\"\n    self.viewTypeMask = _get_view_type_mask(includeEntityTypes)\n</code></pre>"},{"location":"reference/tables/#synapseclient.table.SubmissionViewSchema","title":"<code>SubmissionViewSchema</code>","text":"<p>               Bases: <code>ViewBase</code></p> <p>A SubmissionViewSchema is a Entity that displays all files/projects (depending on user choice) within a given set of scopes.</p> ATTRIBUTE DESCRIPTION <code>name</code> <p>The name of the Entity View Table object</p> <p> </p> <code>columns</code> <p>A list of Column objects or their IDs. These are optional.</p> <p> </p> <code>parent</code> <p>The project in Synapse to which this table belongs</p> <p> </p> <code>scopes</code> <p>A list of Evaluation Queues or their ids</p> <p> </p> <code>addDefaultViewColumns</code> <p>If true, adds all default columns (e.g. name, createdOn, modifiedBy etc.)                           Defaults to True.                           The default columns will be added after a call to                           store.</p> <p> </p> <code>addAnnotationColumns</code> <p>If true, adds columns for all annotation keys defined across all Entities in                           the SubmissionViewSchema's scope. Defaults to True.                           The annotation columns will be added after a call to                           store.</p> <p> </p> <code>ignoredAnnotationColumnNames</code> <p>A list of strings representing annotation names.                           When addAnnotationColumns is True, the names in this list will not be                           automatically added as columns to the SubmissionViewSchema if they exist in                           any of the defined scopes.</p> <p> </p> <code>properties</code> <p>A map of Synapse properties</p> <p> </p> <code>annotations</code> <p>A map of user defined annotations</p> <p> </p> <code>local_state</code> <p>Internal use only</p> <p> </p> Example <p>from synapseclient import SubmissionViewSchema</p> <p>project = syn.get(\"syn123\") schema = syn.store(SubmissionViewSchema(name='My Submission View', parent=project, scopes=['9614543']))</p> Source code in <code>synapseclient/table.py</code> <pre><code>class SubmissionViewSchema(ViewBase):\n    \"\"\"\n    A SubmissionViewSchema is a [Entity][synapseclient.entity.Entity] that displays all files/projects\n    (depending on user choice) within a given set of scopes.\n\n    Attributes:\n        name:                         The name of the Entity View Table object\n        columns:                      A list of [Column][synapseclient.table.Column] objects or their IDs. These are optional.\n        parent:                       The project in Synapse to which this table belongs\n        scopes:                       A list of Evaluation Queues or their ids\n        addDefaultViewColumns:        If true, adds all default columns (e.g. name, createdOn, modifiedBy etc.)\n                                      Defaults to True.\n                                      The default columns will be added after a call to\n                                      [store][synapseclient.Synapse.store].\n        addAnnotationColumns:         If true, adds columns for all annotation keys defined across all Entities in\n                                      the SubmissionViewSchema's scope. Defaults to True.\n                                      The annotation columns will be added after a call to\n                                      [store][synapseclient.Synapse.store].\n        ignoredAnnotationColumnNames: A list of strings representing annotation names.\n                                      When addAnnotationColumns is True, the names in this list will not be\n                                      automatically added as columns to the SubmissionViewSchema if they exist in\n                                      any of the defined scopes.\n        properties:                   A map of Synapse properties\n        annotations:                  A map of user defined annotations\n        local_state:                  Internal use only\n\n    Example:\n        from synapseclient import SubmissionViewSchema\n\n        project = syn.get(\"syn123\")\n        schema = syn.store(SubmissionViewSchema(name='My Submission View', parent=project, scopes=['9614543']))\n    \"\"\"\n\n    _synapse_entity_type = \"org.sagebionetworks.repo.model.table.SubmissionView\"\n\n    def __init__(\n        self,\n        name=None,\n        columns=None,\n        parent=None,\n        scopes=None,\n        addDefaultViewColumns=True,\n        addAnnotationColumns=True,\n        ignoredAnnotationColumnNames=[],\n        properties=None,\n        annotations=None,\n        local_state=None,\n        **kwargs,\n    ):\n        self.ignoredAnnotationColumnNames = set(ignoredAnnotationColumnNames)\n        super(SubmissionViewSchema, self).__init__(\n            name=name,\n            columns=columns,\n            properties=properties,\n            annotations=annotations,\n            local_state=local_state,\n            parent=parent,\n            **kwargs,\n        )\n        # This is a hacky solution to make sure we don't try to add columns to schemas that we retrieve from synapse\n        is_from_normal_constructor = not (properties or local_state)\n        # allowing annotations because user might want to update annotations all at once\n        self.addDefaultViewColumns = (\n            addDefaultViewColumns and is_from_normal_constructor\n        )\n        self.addAnnotationColumns = addAnnotationColumns and is_from_normal_constructor\n\n        if self.get(\"scopeIds\") is None:\n            self.scopeIds = []\n\n        # add the scopes last so that we can append the passed in scopes to those defined in properties\n        if scopes is not None:\n            self.add_scope(scopes)\n</code></pre>"},{"location":"reference/tables/#synapseclient.table.SelectColumn","title":"<code>SelectColumn</code>","text":"<p>               Bases: <code>DictObject</code></p> <p>Defines a column to be used in a table Schema.</p> ATTRIBUTE DESCRIPTION <code>id</code> <p>An immutable ID issued by the platform</p> <p> </p> <code>columnType</code> <p>Can be any of:</p> <ul> <li><code>STRING</code></li> <li><code>DOUBLE</code></li> <li><code>INTEGER</code></li> <li><code>BOOLEAN</code></li> <li><code>DATE</code></li> <li><code>FILEHANDLEID</code></li> <li><code>ENTITYID</code></li> </ul> <p> </p> <code>name</code> <p>The display name of the column</p> <p> </p> Source code in <code>synapseclient/table.py</code> <pre><code>class SelectColumn(DictObject):\n    \"\"\"\n    Defines a column to be used in a table [Schema][synapseclient.table.Schema].\n\n    Attributes:\n        id:         An immutable ID issued by the platform\n        columnType: Can be any of:\n\n            - `STRING`\n            - `DOUBLE`\n            - `INTEGER`\n            - `BOOLEAN`\n            - `DATE`\n            - `FILEHANDLEID`\n            - `ENTITYID`\n\n        name:       The display name of the column\n    \"\"\"\n\n    def __init__(self, id=None, columnType=None, name=None, **kwargs):\n        super(SelectColumn, self).__init__()\n        if id:\n            self.id = id\n\n        if name:\n            self.name = name\n\n        if columnType:\n            self.columnType = columnType\n\n        # Notes that this param is only used to support forward compatibility.\n        self.update(kwargs)\n\n    @classmethod\n    def from_column(cls, column):\n        return cls(\n            column.get(\"id\", None),\n            column.get(\"columnType\", None),\n            column.get(\"name\", None),\n        )\n</code></pre>"},{"location":"reference/tables/#synapseclient.table.Column","title":"<code>Column</code>","text":"<p>               Bases: <code>DictObject</code></p> <p>Defines a column to be used in a table Schema EntityViewSchema.</p> ATTRIBUTE DESCRIPTION <code>id</code> <p>An immutable ID issued by the platform</p> <p> </p> <code>columnType</code> <p>The column type determines the type of data that can be stored in a column. It can be any                of:</p> <ul> <li><code>STRING</code></li> <li><code>DOUBLE</code></li> <li><code>INTEGER</code></li> <li><code>BOOLEAN</code></li> <li><code>DATE</code></li> <li><code>FILEHANDLEID</code></li> <li><code>ENTITYID</code></li> <li><code>LINK</code></li> <li><code>LARGETEXT</code></li> <li><code>USERID</code></li> </ul> <p>For more information, please see: https://rest-docs.synapse.org/rest/org/sagebionetworks/repo/model/table/ColumnType.html</p> <p> </p> <code>maximumSize</code> <p>A parameter for columnTypes with a maximum size. For example, ColumnType.STRINGs have a                default maximum size of 50 characters, but can be set to a <code>maximumSize</code> of 1 to 1000                characters.</p> <p> </p> <code>maximumListLength</code> <p>Required if using a columnType with a \"_LIST\" suffix. Describes the maximum number of                values that will appear in that list. Value range 1-100 inclusive. Default 100</p> <p> </p> <code>name</code> <p>The display name of the column</p> <p> </p> <code>enumValues</code> <p>Columns type of STRING can be constrained to an enumeration values set on this list.</p> <p> </p> <code>defaultValue</code> <p>The default value for this column. Columns of type FILEHANDLEID and ENTITYID are not                allowed to have default values.</p> <p> </p> Source code in <code>synapseclient/table.py</code> <pre><code>class Column(DictObject):\n    \"\"\"\n    Defines a column to be used in a table [Schema][synapseclient.table.Schema]\n    [EntityViewSchema][synapseclient.table.EntityViewSchema].\n\n    Attributes:\n        id:                An immutable ID issued by the platform\n        columnType:        The column type determines the type of data that can be stored in a column. It can be any\n                           of:\n\n            - `STRING`\n            - `DOUBLE`\n            - `INTEGER`\n            - `BOOLEAN`\n            - `DATE`\n            - `FILEHANDLEID`\n            - `ENTITYID`\n            - `LINK`\n            - `LARGETEXT`\n            - `USERID`\n\n            For more information, please see:\n            &lt;https://rest-docs.synapse.org/rest/org/sagebionetworks/repo/model/table/ColumnType.html&gt;\n        maximumSize:       A parameter for columnTypes with a maximum size. For example, ColumnType.STRINGs have a\n                           default maximum size of 50 characters, but can be set to a `maximumSize` of 1 to 1000\n                           characters.\n        maximumListLength: Required if using a columnType with a \"_LIST\" suffix. Describes the maximum number of\n                           values that will appear in that list. Value range 1-100 inclusive. Default 100\n        name:              The display name of the column\n        enumValues:        Columns type of STRING can be constrained to an enumeration values set on this list.\n        defaultValue:      The default value for this column. Columns of type FILEHANDLEID and ENTITYID are not\n                           allowed to have default values.\n    \"\"\"\n\n    @classmethod\n    def getURI(cls, id):\n        return \"/column/%s\" % id\n\n    def __init__(self, **kwargs):\n        super(Column, self).__init__(kwargs)\n        self[\"concreteType\"] = concrete_types.COLUMN_MODEL\n\n    def postURI(self):\n        return \"/column\"\n</code></pre>"},{"location":"reference/tables/#synapseclient.table.AppendableRowset","title":"<code>AppendableRowset</code>","text":"<p>               Bases: <code>DictObject</code></p> <p>Abstract Base Class for RowSet and PartialRowset</p> Source code in <code>synapseclient/table.py</code> <pre><code>class AppendableRowset(DictObject, metaclass=abc.ABCMeta):\n    \"\"\"\n    Abstract Base Class for [RowSet][synapseclient.table.RowSet] and [PartialRowset][synapseclient.table.PartialRowset]\n    \"\"\"\n\n    @abc.abstractmethod\n    def __init__(self, schema, **kwargs):\n        if (\"tableId\" not in kwargs) and schema:\n            kwargs[\"tableId\"] = id_of(schema)\n\n        if not kwargs.get(\"tableId\", None):\n            raise ValueError(\n                \"Table schema ID must be defined to create a %s\" % type(self).__name__\n            )\n        super(AppendableRowset, self).__init__(kwargs)\n\n    def _synapse_store(self, syn):\n        \"\"\"\n        Creates and POSTs an [AppendableRowSetRequest](https://rest-docs.synapse.org/rest/org/sagebionetworks/repo/model/table/AppendableRowSetRequest.html)\n        \"\"\"\n        append_rowset_request = {\n            \"concreteType\": concrete_types.APPENDABLE_ROWSET_REQUEST,\n            \"toAppend\": self,\n            \"entityId\": self.tableId,\n        }\n\n        response = syn._async_table_update(\n            self.tableId, [append_rowset_request], wait=True\n        )\n        syn._check_table_transaction_response(response)\n        return response[\"results\"][0]\n</code></pre>"},{"location":"reference/tables/#synapseclient.table.PartialRowset","title":"<code>PartialRowset</code>","text":"<p>               Bases: <code>AppendableRowset</code></p> <p>A set of Partial Rows used for updating cells of a table. PartialRowsets allow you to push only the individual cells you wish to change instead of pushing entire rows with many unchanged cells.</p> ATTRIBUTE DESCRIPTION <code>schema</code> <p>The Schema of the table to update or its tableId as a string</p> <p> </p> <code>rows</code> <p>A list of PartialRows</p> <p> </p> Update cells in <p>The following code will change cells in a hypothetical table, syn123: these same steps will also work for using EntityView tables to change Entity annotations</p> <p>From:</p> <pre><code>    +-------------+--------------+\n    | Column One  | Column Two   |\n    +=============+==============+\n    | Data 1      | Data A       |\n    +-------------+--------------+\n    | Data 2      | Data B       |\n    +-------------+--------------+\n    | Data 3      | Data C       |\n    +-------------+--------------+\n</code></pre> <p>To</p> <pre><code>    +-------------+--------------+\n    | Column One  | Column Two   |\n    +=============+==============+\n    | Data 1  2   | Data A       |\n    +-------------+--------------+\n    | Data 2      | Data B  D    |\n    +-------------+--------------+\n    | Data 3      | Data C       |\n    +-------------+--------------+\n\nquery_results = syn.tableQuery(\"SELECT * FROM syn123\")\n</code></pre> <p>The easiest way to know the rowId of the row you wish to change is by converting the table to a pandas DataFrame with rowIdAndVersionInIndex=False</p> <pre><code>df = query_results.asDataFrame(rowIdAndVersionInIndex=False)\n\npartial_changes = {df['ROW_ID'][0]: {'fooCol': 'foo foo 1'},\n                   df['ROW_ID'][1]: {'barCol': 'bar bar 2'}}\n</code></pre> <p>You will need to pass in your original query result as an argument so that we can perform column id translation and etag retrieval on your behalf:</p> <pre><code>partial_rowset = PartialRowset.from_mapping(partial_changes, query_results)\nsyn.store(partial_rowset)\n</code></pre> Source code in <code>synapseclient/table.py</code> <pre><code>class PartialRowset(AppendableRowset):\n    \"\"\"\n    A set of Partial Rows used for updating cells of a table.\n    PartialRowsets allow you to push only the individual cells you wish to change instead of pushing entire rows with\n    many unchanged cells.\n\n    Attributes:\n        schema: The [Schema][synapseclient.table.Schema] of the table to update or its tableId as a string\n        rows:   A list of PartialRows\n\n    Example: Update cells in\n        The following code will change cells in a hypothetical table, syn123:\n        these same steps will also work for using EntityView tables to change Entity annotations\n\n        From:\n\n                +-------------+--------------+\n                | Column One  | Column Two   |\n                +=============+==============+\n                | Data 1      | Data A       |\n                +-------------+--------------+\n                | Data 2      | Data B       |\n                +-------------+--------------+\n                | Data 3      | Data C       |\n                +-------------+--------------+\n\n        To\n\n                +-------------+--------------+\n                | Column One  | Column Two   |\n                +=============+==============+\n                | Data 1  2   | Data A       |\n                +-------------+--------------+\n                | Data 2      | Data B  D    |\n                +-------------+--------------+\n                | Data 3      | Data C       |\n                +-------------+--------------+\n\n            query_results = syn.tableQuery(\"SELECT * FROM syn123\")\n\n        The easiest way to know the rowId of the row you wish to change\n        is by converting the table to a pandas DataFrame with rowIdAndVersionInIndex=False\n\n            df = query_results.asDataFrame(rowIdAndVersionInIndex=False)\n\n            partial_changes = {df['ROW_ID'][0]: {'fooCol': 'foo foo 1'},\n                               df['ROW_ID'][1]: {'barCol': 'bar bar 2'}}\n\n        You will need to pass in your original query result as an argument\n        so that we can perform column id translation and etag retrieval on your behalf:\n\n            partial_rowset = PartialRowset.from_mapping(partial_changes, query_results)\n            syn.store(partial_rowset)\n    \"\"\"\n\n    @classmethod\n    def from_mapping(cls, mapping, originalQueryResult):\n        \"\"\"\n        Creates a PartialRowset\n\n        Arguments:\n            mapping:             A mapping of mappings in the structure: {ROW_ID : {COLUMN_NAME: NEW_COL_VALUE}}\n            originalQueryResult: The original query result\n\n        Returns:\n            A PartialRowset that can be syn.store()-ed to apply the changes\n        \"\"\"\n        if not isinstance(mapping, collections.abc.Mapping):\n            raise ValueError(\"mapping must be a supported Mapping type such as 'dict'\")\n\n        try:\n            name_to_column_id = {\n                col.name: col.id for col in originalQueryResult.headers if \"id\" in col\n            }\n        except AttributeError:\n            raise ValueError(\n                \"originalQueryResult must be the result of a syn.tableQuery()\"\n            )\n\n        row_ids = set(int(id) for id in mapping.keys())\n\n        # row_ids in the originalQueryResult are not guaranteed to be in ascending order\n        # iterate over all etags but only map the row_ids used for this partial update to their etags\n        row_etags = {\n            row_id: etag\n            for row_id, row_version, etag in originalQueryResult.iter_row_metadata()\n            if row_id in row_ids and etag is not None\n        }\n\n        partial_rows = [\n            PartialRow(\n                row_changes,\n                row_id,\n                etag=row_etags.get(int(row_id)),\n                nameToColumnId=name_to_column_id,\n            )\n            for row_id, row_changes in mapping.items()\n        ]\n\n        return cls(originalQueryResult.tableId, partial_rows)\n\n    def __init__(self, schema, rows):\n        super(PartialRowset, self).__init__(schema)\n        self.concreteType = concrete_types.PARTIAL_ROW_SET\n\n        if isinstance(rows, PartialRow):\n            self.rows = [rows]\n        else:\n            try:\n                if all(isinstance(row, PartialRow) for row in rows):\n                    self.rows = list(rows)\n                else:\n                    raise ValueError(\"rows must contain only values of type PartialRow\")\n            except TypeError:\n                raise ValueError(\"rows must be iterable\")\n</code></pre>"},{"location":"reference/tables/#synapseclient.table.PartialRowset-functions","title":"Functions","text":""},{"location":"reference/tables/#synapseclient.table.PartialRowset.from_mapping","title":"<code>from_mapping(mapping, originalQueryResult)</code>  <code>classmethod</code>","text":"<p>Creates a PartialRowset</p> PARAMETER DESCRIPTION <code>mapping</code> <p>A mapping of mappings in the structure: {ROW_ID : {COLUMN_NAME: NEW_COL_VALUE}}</p> <p> </p> <code>originalQueryResult</code> <p>The original query result</p> <p> </p> RETURNS DESCRIPTION <p>A PartialRowset that can be syn.store()-ed to apply the changes</p> Source code in <code>synapseclient/table.py</code> <pre><code>@classmethod\ndef from_mapping(cls, mapping, originalQueryResult):\n    \"\"\"\n    Creates a PartialRowset\n\n    Arguments:\n        mapping:             A mapping of mappings in the structure: {ROW_ID : {COLUMN_NAME: NEW_COL_VALUE}}\n        originalQueryResult: The original query result\n\n    Returns:\n        A PartialRowset that can be syn.store()-ed to apply the changes\n    \"\"\"\n    if not isinstance(mapping, collections.abc.Mapping):\n        raise ValueError(\"mapping must be a supported Mapping type such as 'dict'\")\n\n    try:\n        name_to_column_id = {\n            col.name: col.id for col in originalQueryResult.headers if \"id\" in col\n        }\n    except AttributeError:\n        raise ValueError(\n            \"originalQueryResult must be the result of a syn.tableQuery()\"\n        )\n\n    row_ids = set(int(id) for id in mapping.keys())\n\n    # row_ids in the originalQueryResult are not guaranteed to be in ascending order\n    # iterate over all etags but only map the row_ids used for this partial update to their etags\n    row_etags = {\n        row_id: etag\n        for row_id, row_version, etag in originalQueryResult.iter_row_metadata()\n        if row_id in row_ids and etag is not None\n    }\n\n    partial_rows = [\n        PartialRow(\n            row_changes,\n            row_id,\n            etag=row_etags.get(int(row_id)),\n            nameToColumnId=name_to_column_id,\n        )\n        for row_id, row_changes in mapping.items()\n    ]\n\n    return cls(originalQueryResult.tableId, partial_rows)\n</code></pre>"},{"location":"reference/tables/#synapseclient.table.RowSet","title":"<code>RowSet</code>","text":"<p>               Bases: <code>AppendableRowset</code></p> <p>A Synapse object of type org.sagebionetworks.repo.model.table.RowSet.</p> ATTRIBUTE DESCRIPTION <code>schema</code> <p>A Schema object that will be used to set the tableId</p> <p> </p> <code>headers</code> <p>The list of SelectColumn objects that describe the fields in each row.</p> <p> </p> <code>columns</code> <p>An alternative to 'headers', a list of column objects that describe the fields in each row.</p> <p> </p> <code>tableId</code> <p>The ID of the TableEntity that owns these rows</p> <p> </p> <code>rows</code> <p>The Row s of this set. The index of each row value aligns with the      index of each header.</p> <p> </p> <code>etag</code> <p>Any RowSet returned from Synapse will contain the current etag of the change set. To update any      rows from a RowSet the etag must be provided with the POST.</p> <p> </p> Source code in <code>synapseclient/table.py</code> <pre><code>class RowSet(AppendableRowset):\n    \"\"\"\n    A Synapse object of type [org.sagebionetworks.repo.model.table.RowSet](https://rest-docs.synapse.org/rest/org/sagebionetworks/repo/model/table/RowSet.html).\n\n    Attributes:\n        schema:  A [Schema][synapseclient.table.Schema] object that will be used to set the tableId\n        headers: The list of SelectColumn objects that describe the fields in each row.\n        columns: An alternative to 'headers', a list of column objects that describe the fields in each row.\n        tableId: The ID of the TableEntity that owns these rows\n        rows:    The [Row][synapseclient.table.Row] s of this set. The index of each row value aligns with the\n                 index of each header.\n        etag:    Any RowSet returned from Synapse will contain the current etag of the change set. To update any\n                 rows from a RowSet the etag must be provided with the POST.\n    \"\"\"\n\n    @classmethod\n    def from_json(cls, json):\n        headers = [SelectColumn(**header) for header in json.get(\"headers\", [])]\n        rows = [cast_row(Row(**row), headers) for row in json.get(\"rows\", [])]\n        return cls(\n            headers=headers,\n            rows=rows,\n            **{key: json[key] for key in json.keys() if key not in [\"headers\", \"rows\"]},\n        )\n\n    def __init__(self, columns=None, schema=None, **kwargs):\n        if \"headers\" not in kwargs:\n            if columns and schema:\n                raise ValueError(\n                    \"Please only user either 'columns' or 'schema' as an argument but not both.\"\n                )\n            if columns:\n                kwargs.setdefault(\"headers\", []).extend(\n                    [SelectColumn.from_column(column) for column in columns]\n                )\n            elif schema and isinstance(schema, Schema):\n                kwargs.setdefault(\"headers\", []).extend(\n                    [SelectColumn(id=id) for id in schema[\"columnIds\"]]\n                )\n\n        if not kwargs.get(\"headers\", None):\n            raise ValueError(\"Column headers must be defined to create a RowSet\")\n        kwargs[\"concreteType\"] = \"org.sagebionetworks.repo.model.table.RowSet\"\n\n        super(RowSet, self).__init__(schema, **kwargs)\n\n    def _synapse_store(self, syn):\n        response = super(RowSet, self)._synapse_store(syn)\n        return response.get(\"rowReferenceSet\", response)\n\n    def _synapse_delete(self, syn):\n        \"\"\"\n        Delete the rows in the RowSet.\n        Example:\n            syn.delete(syn.tableQuery('select name from %s where no_good = true' % schema1.id))\n        \"\"\"\n        row_id_vers_generator = ((row.rowId, row.versionNumber) for row in self.rows)\n        _delete_rows(syn, self.tableId, row_id_vers_generator)\n</code></pre>"},{"location":"reference/tables/#synapseclient.table.Row","title":"<code>Row</code>","text":"<p>               Bases: <code>DictObject</code></p> <p>A row in a Table.</p> ATTRIBUTE DESCRIPTION <code>values</code> <p>A list of values</p> <p> </p> <code>rowId</code> <p>The immutable ID issued to a new row</p> <p> </p> <code>versionNumber</code> <p>The version number of this row. Each row version is immutable, so when a row is updated a            new version is created.</p> <p> </p> Source code in <code>synapseclient/table.py</code> <pre><code>class Row(DictObject):\n    \"\"\"\n    A [row](https://rest-docs.synapse.org/rest/org/sagebionetworks/repo/model/table/Row.html) in a Table.\n\n    Attributes:\n        values:        A list of values\n        rowId:         The immutable ID issued to a new row\n        versionNumber: The version number of this row. Each row version is immutable, so when a row is updated a\n                       new version is created.\n    \"\"\"\n\n    def __init__(self, values, rowId=None, versionNumber=None, etag=None, **kwargs):\n        super(Row, self).__init__()\n        self.values = values\n        if rowId is not None:\n            self.rowId = rowId\n        if versionNumber is not None:\n            self.versionNumber = versionNumber\n        if etag is not None:\n            self.etag = etag\n\n        # Notes that this param is only used to support forward compatibility.\n        self.update(kwargs)\n</code></pre>"},{"location":"reference/tables/#synapseclient.table.PartialRow","title":"<code>PartialRow</code>","text":"<p>               Bases: <code>DictObject</code></p> <p>This is a lower-level class for use in PartialRowset to update individual cells within a table.</p> ATTRIBUTE DESCRIPTION <code>values</code> <p>A Mapping where:</p> <ul> <li>The key is name of the column (or its columnId) to change in the desired row</li> <li>The value is the new desired value for that column</li> </ul> <p> </p> <code>rowId</code> <p>The id of the row to be updated</p> <p> </p> <code>etag</code> <p>Used for updating File/Project Views(EntityViewSchema).             Not necessary for a Schema Table</p> <p> </p> <code>nameToColumnId</code> <p>Optional map column names to column Ids. If this is provided, the keys of your <code>values</code>             Mapping will be replaced with the column ids in the <code>nameToColumnId</code> dict. Include this             as an argument when you are providing the column names instead of columnIds as the keys             to the <code>values</code> Mapping.</p> <p> </p> Using PartialRow <p>It is recommended you use from_mapping to construct partial change sets to a table.</p> <p>If you want to do the tedious parts yourself:</p> <p>To change cells in the \"foo\"(colId:1234) and \"bar\"(colId:456) columns of a row with <code>rowId = 5</code> Pass in with <code>columnIds</code> as key:</p> <pre><code>PartialRow({123: 'fooVal', 456:'barVal'}, rowId)\n</code></pre> <p>Pass in with a <code>nameToColumnId</code> argument. You can either manually define:</p> <pre><code>nameToColumnId = {'foo':123, 'bar':456}\n</code></pre> <p>OR if you have the result of a <code>tableQuery()</code> you can generate <code>nameToColumnId</code> using:</p> <pre><code>query_result = syn.tableQuery(\"SELECT * FROM syn123\")\nnameToColumnId = {col.name:col.id for col in query_result.headers}\n\nPartialRow({'foo': 'fooVal', 'bar':'barVal'}, rowId, nameToColumnId=nameToColumnId)\n</code></pre> Source code in <code>synapseclient/table.py</code> <pre><code>class PartialRow(DictObject):\n    \"\"\"\n    This is a lower-level class for use in [PartialRowset][synapseclient.table.PartialRowset] to update individual\n    cells within a table.\n\n    Attributes:\n        values:         A Mapping where:\n\n            - The key is name of the column (or its columnId) to change in the desired row\n            - The value is the new desired value for that column\n\n        rowId:          The id of the row to be updated\n        etag:           Used for updating File/Project Views([EntityViewSchema][synapseclient.table.EntityViewSchema]).\n                        Not necessary for a [Schema][synapseclient.table.Schema] Table\n        nameToColumnId: Optional map column names to column Ids. If this is provided, the keys of your `values`\n                        Mapping will be replaced with the column ids in the `nameToColumnId` dict. Include this\n                        as an argument when you are providing the column names instead of columnIds as the keys\n                        to the `values` Mapping.\n\n    Example: Using PartialRow\n        It is recommended you use [from_mapping][synapseclient.table.PartialRowset.from_mapping]\n        to construct partial change sets to a table.\n\n        If you want to do the tedious parts yourself:\n\n        To change cells in the \"foo\"(colId:1234) and \"bar\"(colId:456) columns of a row with `rowId = 5`\n        Pass in with `columnIds` as key:\n\n            PartialRow({123: 'fooVal', 456:'barVal'}, rowId)\n\n        Pass in with a `nameToColumnId` argument. You can either manually define:\n\n            nameToColumnId = {'foo':123, 'bar':456}\n\n        OR if you have the result of a `tableQuery()` you can generate `nameToColumnId` using:\n\n            query_result = syn.tableQuery(\"SELECT * FROM syn123\")\n            nameToColumnId = {col.name:col.id for col in query_result.headers}\n\n            PartialRow({'foo': 'fooVal', 'bar':'barVal'}, rowId, nameToColumnId=nameToColumnId)\n    \"\"\"\n\n    def __init__(self, values, rowId, etag=None, nameToColumnId=None):\n        super(PartialRow, self).__init__()\n        if not isinstance(values, collections.abc.Mapping):\n            raise ValueError(\"values must be a Mapping\")\n\n        rowId = int(rowId)\n\n        self.values = [\n            {\n                \"key\": nameToColumnId[x_key] if nameToColumnId is not None else x_key,\n                \"value\": x_value,\n            }\n            for x_key, x_value in values.items()\n        ]\n        self.rowId = rowId\n        if etag is not None:\n            self.etag = etag\n</code></pre>"},{"location":"reference/tables/#synapseclient.table.TableAbstractBaseClass","title":"<code>TableAbstractBaseClass</code>","text":"<p>               Bases: <code>Iterable</code>, <code>Sized</code></p> <p>Abstract base class for Tables based on different data containers.</p> Source code in <code>synapseclient/table.py</code> <pre><code>class TableAbstractBaseClass(collections.abc.Iterable, collections.abc.Sized):\n    \"\"\"\n    Abstract base class for Tables based on different data containers.\n    \"\"\"\n\n    RowMetadataTuple = collections.namedtuple(\n        \"RowMetadataTuple\", [\"row_id\", \"row_version\", \"row_etag\"]\n    )\n\n    def __init__(self, schema, headers=None, etag=None):\n        if isinstance(schema, Schema):\n            self.schema = schema\n            self.tableId = schema.id if schema and \"id\" in schema else None\n            self.headers = (\n                headers if headers else [SelectColumn(id=id) for id in schema.columnIds]\n            )\n            self.etag = etag\n        elif isinstance(schema, str):\n            self.schema = None\n            self.tableId = schema\n            self.headers = headers\n            self.etag = etag\n        else:\n            ValueError(\"Must provide a schema or a synapse ID of a Table Entity\")\n\n    def asDataFrame(self):\n        raise NotImplementedError()\n\n    def asRowSet(self):\n        return RowSet(\n            headers=self.headers,\n            tableId=self.tableId,\n            etag=self.etag,\n            rows=[row if isinstance(row, Row) else Row(row) for row in self],\n        )\n\n    def _synapse_store(self, syn):\n        raise NotImplementedError()\n\n    def _synapse_delete(self, syn):\n        \"\"\"\n        Delete the rows that result from a table query.\n\n        Example:\n            syn.delete(syn.tableQuery('select name from %s where no_good = true' % schema1.id))\n        \"\"\"\n        row_id_vers_generator = (\n            (metadata.row_id, metadata.row_version)\n            for metadata in self.iter_row_metadata()\n        )\n        _delete_rows(syn, self.tableId, row_id_vers_generator)\n\n    @abc.abstractmethod\n    def iter_row_metadata(self):\n        \"\"\"\n        Iterates the table results to get row_id and row_etag. If an etag does not exist for a row, it will\n        generated as (row_id, None)\n\n        Returns:\n            A generator that gives [collections.namedtuple](https://docs.python.org/3/library/collections.html#collections.namedtuple) with format (row_id, row_etag)\n        \"\"\"\n        pass\n</code></pre>"},{"location":"reference/tables/#synapseclient.table.TableAbstractBaseClass-functions","title":"Functions","text":""},{"location":"reference/tables/#synapseclient.table.TableAbstractBaseClass.iter_row_metadata","title":"<code>iter_row_metadata()</code>  <code>abstractmethod</code>","text":"<p>Iterates the table results to get row_id and row_etag. If an etag does not exist for a row, it will generated as (row_id, None)</p> RETURNS DESCRIPTION <p>A generator that gives collections.namedtuple with format (row_id, row_etag)</p> Source code in <code>synapseclient/table.py</code> <pre><code>@abc.abstractmethod\ndef iter_row_metadata(self):\n    \"\"\"\n    Iterates the table results to get row_id and row_etag. If an etag does not exist for a row, it will\n    generated as (row_id, None)\n\n    Returns:\n        A generator that gives [collections.namedtuple](https://docs.python.org/3/library/collections.html#collections.namedtuple) with format (row_id, row_etag)\n    \"\"\"\n    pass\n</code></pre>"},{"location":"reference/tables/#synapseclient.table.RowSetTable","title":"<code>RowSetTable</code>","text":"<p>               Bases: <code>TableAbstractBaseClass</code></p> <p>A Table object that wraps a RowSet.</p> Source code in <code>synapseclient/table.py</code> <pre><code>class RowSetTable(TableAbstractBaseClass):\n    \"\"\"\n    A Table object that wraps a RowSet.\n    \"\"\"\n\n    def __init__(self, schema, rowset):\n        super(RowSetTable, self).__init__(schema, etag=rowset.get(\"etag\", None))\n        self.rowset = rowset\n\n    def _synapse_store(self, syn):\n        row_reference_set = syn.store(self.rowset)\n        return RowSetTable(self.schema, row_reference_set)\n\n    def asDataFrame(self):\n        test_import_pandas()\n        import pandas as pd\n\n        if any([row[\"rowId\"] for row in self.rowset[\"rows\"]]):\n            rownames = row_labels_from_rows(self.rowset[\"rows\"])\n        else:\n            rownames = None\n\n        series = collections.OrderedDict()\n        for i, header in enumerate(self.rowset[\"headers\"]):\n            series[header.name] = pd.Series(\n                name=header.name,\n                data=[row[\"values\"][i] for row in self.rowset[\"rows\"]],\n                index=rownames,\n            )\n\n        return pd.DataFrame(data=series, index=rownames)\n\n    def asRowSet(self):\n        return self.rowset\n\n    def __iter__(self):\n        def iterate_rows(rows, headers):\n            for row in rows:\n                yield cast_values(row, headers)\n\n        return iterate_rows(self.rowset[\"rows\"], self.rowset[\"headers\"])\n\n    def __len__(self):\n        return len(self.rowset[\"rows\"])\n\n    def iter_row_metadata(self):\n        raise NotImplementedError(\"iter_metadata is not supported for RowSetTable\")\n</code></pre>"},{"location":"reference/tables/#synapseclient.table.TableQueryResult","title":"<code>TableQueryResult</code>","text":"<p>               Bases: <code>TableAbstractBaseClass</code></p> <p>An object to wrap rows returned as a result of a table query. The TableQueryResult object can be used to iterate over results of a query.</p> <p>Example:</p> <pre><code>results = syn.tableQuery(\"select * from syn1234\")\nfor row in results:\n    print(row)\n</code></pre> Source code in <code>synapseclient/table.py</code> <pre><code>class TableQueryResult(TableAbstractBaseClass):\n    \"\"\"\n    An object to wrap rows returned as a result of a table query.\n    The TableQueryResult object can be used to iterate over results of a query.\n\n    Example:\n\n        results = syn.tableQuery(\"select * from syn1234\")\n        for row in results:\n            print(row)\n    \"\"\"\n\n    def __init__(self, synapse, query, limit=None, offset=None, isConsistent=True):\n        self.syn = synapse\n\n        self.query = query\n        self.limit = limit\n        self.offset = offset\n        self.isConsistent = isConsistent\n\n        result = self.syn._queryTable(\n            query=query, limit=limit, offset=offset, isConsistent=isConsistent\n        )\n\n        self.rowset = RowSet.from_json(result[\"queryResult\"][\"queryResults\"])\n\n        self.columnModels = [Column(**col) for col in result.get(\"columnModels\", [])]\n        self.nextPageToken = result[\"queryResult\"].get(\"nextPageToken\", None)\n        self.count = result.get(\"queryCount\", None)\n        self.maxRowsPerPage = result.get(\"maxRowsPerPage\", None)\n        self.i = -1\n\n        super(TableQueryResult, self).__init__(\n            schema=self.rowset.get(\"tableId\", None),\n            headers=self.rowset.headers,\n            etag=self.rowset.get(\"etag\", None),\n        )\n\n    def _synapse_store(self, syn):\n        raise SynapseError(\n            \"A TableQueryResult is a read only object and can't be stored in Synapse. Convert to a\"\n            \" DataFrame or RowSet instead.\"\n        )\n\n    def asDataFrame(self, rowIdAndVersionInIndex=True):\n        \"\"\"\n        Convert query result to a Pandas DataFrame.\n\n        Arguments:\n            rowIdAndVersionInIndex: Make the dataframe index consist of the row_id and row_version (and row_etag\n                                    if it exists)\n        \"\"\"\n        test_import_pandas()\n        import pandas as pd\n\n        # To turn a TableQueryResult into a data frame, we add a page of rows\n        # at a time on the untested theory that it's more efficient than\n        # adding a single row at a time to the data frame.\n\n        def construct_rownames(rowset, offset=0):\n            try:\n                return (\n                    row_labels_from_rows(rowset[\"rows\"])\n                    if rowIdAndVersionInIndex\n                    else None\n                )\n            except KeyError:\n                # if we don't have row id and version, just number the rows\n                # python3 cast range to list for safety\n                return list(range(offset, offset + len(rowset[\"rows\"])))\n\n        # first page of rows\n        offset = 0\n        rownames = construct_rownames(self.rowset, offset)\n        offset += len(self.rowset[\"rows\"])\n        series = collections.OrderedDict()\n\n        if not rowIdAndVersionInIndex:\n            # Since we use an OrderedDict this must happen before we construct the other columns\n            # add row id, verison, and etag as rows\n            append_etag = False  # only useful when (not rowIdAndVersionInIndex), hooray for lazy variables!\n            series[\"ROW_ID\"] = pd.Series(\n                name=\"ROW_ID\", data=[row[\"rowId\"] for row in self.rowset[\"rows\"]]\n            )\n            series[\"ROW_VERSION\"] = pd.Series(\n                name=\"ROW_VERSION\",\n                data=[row[\"versionNumber\"] for row in self.rowset[\"rows\"]],\n            )\n\n            row_etag = [row.get(\"etag\") for row in self.rowset[\"rows\"]]\n            if any(row_etag):\n                append_etag = True\n                series[\"ROW_ETAG\"] = pd.Series(name=\"ROW_ETAG\", data=row_etag)\n\n        for i, header in enumerate(self.rowset[\"headers\"]):\n            column_name = header.name\n            series[column_name] = pd.Series(\n                name=column_name,\n                data=[row[\"values\"][i] for row in self.rowset[\"rows\"]],\n                index=rownames,\n            )\n\n        # subsequent pages of rows\n        while self.nextPageToken:\n            result = self.syn._queryTableNext(self.nextPageToken, self.tableId)\n            self.rowset = RowSet.from_json(result[\"queryResults\"])\n            self.nextPageToken = result.get(\"nextPageToken\", None)\n            self.i = 0\n\n            rownames = construct_rownames(self.rowset, offset)\n            offset += len(self.rowset[\"rows\"])\n\n            if not rowIdAndVersionInIndex:\n                # TODO: Look into why this isn't being assigned\n                series[\"ROW_ID\"].append(\n                    pd.Series(\n                        name=\"ROW_ID\", data=[row[\"id\"] for row in self.rowset[\"rows\"]]\n                    )\n                )\n                series[\"ROW_VERSION\"].append(\n                    pd.Series(\n                        name=\"ROW_VERSION\",\n                        data=[row[\"version\"] for row in self.rowset[\"rows\"]],\n                    )\n                )\n                if append_etag:\n                    series[\"ROW_ETAG\"] = pd.Series(\n                        name=\"ROW_ETAG\",\n                        data=[row.get(\"etag\") for row in self.rowset[\"rows\"]],\n                    )\n\n            for i, header in enumerate(self.rowset[\"headers\"]):\n                column_name = header.name\n                series[column_name] = pd.concat(\n                    [\n                        series[column_name],\n                        pd.Series(\n                            name=column_name,\n                            data=[row[\"values\"][i] for row in self.rowset[\"rows\"]],\n                            index=rownames,\n                        ),\n                    ],\n                    # can't verify integrity when indices are just numbers instead of 'rowid_rowversion'\n                    verify_integrity=rowIdAndVersionInIndex,\n                )\n\n        return pd.DataFrame(data=series)\n\n    def asRowSet(self):\n        # Note that as of stack 60, an empty query will omit the headers field\n        # see PLFM-3014\n        return RowSet(\n            headers=self.headers,\n            tableId=self.tableId,\n            etag=self.etag,\n            rows=[row for row in self],\n        )\n\n    def __iter__(self):\n        return self\n\n    def next(self):\n        \"\"\"\n        Python 2 iterator\n        \"\"\"\n        self.i += 1\n        if self.i &gt;= len(self.rowset[\"rows\"]):\n            if self.nextPageToken:\n                result = self.syn._queryTableNext(self.nextPageToken, self.tableId)\n                self.rowset = RowSet.from_json(result[\"queryResults\"])\n                self.nextPageToken = result.get(\"nextPageToken\", None)\n                self.i = 0\n            else:\n                raise StopIteration()\n        return self.rowset[\"rows\"][self.i]\n\n    def __next__(self):\n        \"\"\"\n        Python 3 iterator\n        \"\"\"\n        return self.next()\n\n    def __len__(self):\n        return len(self.rowset[\"rows\"])\n\n    def iter_row_metadata(self):\n        \"\"\"\n        Iterates the table results to get row_id and row_etag. If an etag does not exist for a row, it will\n        generated as (row_id, row_version,None)\n\n        Returns:\n            A generator that gives [collections.namedtuple](https://docs.python.org/3/library/collections.html#collections.namedtuple)\n            with format (row_id, row_version, row_etag)\n        \"\"\"\n        for row in self:\n            yield type(self).RowMetadataTuple(\n                int(row[\"rowId\"]), int(row[\"versionNumber\"]), row.get(\"etag\")\n            )\n</code></pre>"},{"location":"reference/tables/#synapseclient.table.TableQueryResult-functions","title":"Functions","text":""},{"location":"reference/tables/#synapseclient.table.TableQueryResult.asDataFrame","title":"<code>asDataFrame(rowIdAndVersionInIndex=True)</code>","text":"<p>Convert query result to a Pandas DataFrame.</p> PARAMETER DESCRIPTION <code>rowIdAndVersionInIndex</code> <p>Make the dataframe index consist of the row_id and row_version (and row_etag                     if it exists)</p> <p> DEFAULT: <code>True</code> </p> Source code in <code>synapseclient/table.py</code> <pre><code>def asDataFrame(self, rowIdAndVersionInIndex=True):\n    \"\"\"\n    Convert query result to a Pandas DataFrame.\n\n    Arguments:\n        rowIdAndVersionInIndex: Make the dataframe index consist of the row_id and row_version (and row_etag\n                                if it exists)\n    \"\"\"\n    test_import_pandas()\n    import pandas as pd\n\n    # To turn a TableQueryResult into a data frame, we add a page of rows\n    # at a time on the untested theory that it's more efficient than\n    # adding a single row at a time to the data frame.\n\n    def construct_rownames(rowset, offset=0):\n        try:\n            return (\n                row_labels_from_rows(rowset[\"rows\"])\n                if rowIdAndVersionInIndex\n                else None\n            )\n        except KeyError:\n            # if we don't have row id and version, just number the rows\n            # python3 cast range to list for safety\n            return list(range(offset, offset + len(rowset[\"rows\"])))\n\n    # first page of rows\n    offset = 0\n    rownames = construct_rownames(self.rowset, offset)\n    offset += len(self.rowset[\"rows\"])\n    series = collections.OrderedDict()\n\n    if not rowIdAndVersionInIndex:\n        # Since we use an OrderedDict this must happen before we construct the other columns\n        # add row id, verison, and etag as rows\n        append_etag = False  # only useful when (not rowIdAndVersionInIndex), hooray for lazy variables!\n        series[\"ROW_ID\"] = pd.Series(\n            name=\"ROW_ID\", data=[row[\"rowId\"] for row in self.rowset[\"rows\"]]\n        )\n        series[\"ROW_VERSION\"] = pd.Series(\n            name=\"ROW_VERSION\",\n            data=[row[\"versionNumber\"] for row in self.rowset[\"rows\"]],\n        )\n\n        row_etag = [row.get(\"etag\") for row in self.rowset[\"rows\"]]\n        if any(row_etag):\n            append_etag = True\n            series[\"ROW_ETAG\"] = pd.Series(name=\"ROW_ETAG\", data=row_etag)\n\n    for i, header in enumerate(self.rowset[\"headers\"]):\n        column_name = header.name\n        series[column_name] = pd.Series(\n            name=column_name,\n            data=[row[\"values\"][i] for row in self.rowset[\"rows\"]],\n            index=rownames,\n        )\n\n    # subsequent pages of rows\n    while self.nextPageToken:\n        result = self.syn._queryTableNext(self.nextPageToken, self.tableId)\n        self.rowset = RowSet.from_json(result[\"queryResults\"])\n        self.nextPageToken = result.get(\"nextPageToken\", None)\n        self.i = 0\n\n        rownames = construct_rownames(self.rowset, offset)\n        offset += len(self.rowset[\"rows\"])\n\n        if not rowIdAndVersionInIndex:\n            # TODO: Look into why this isn't being assigned\n            series[\"ROW_ID\"].append(\n                pd.Series(\n                    name=\"ROW_ID\", data=[row[\"id\"] for row in self.rowset[\"rows\"]]\n                )\n            )\n            series[\"ROW_VERSION\"].append(\n                pd.Series(\n                    name=\"ROW_VERSION\",\n                    data=[row[\"version\"] for row in self.rowset[\"rows\"]],\n                )\n            )\n            if append_etag:\n                series[\"ROW_ETAG\"] = pd.Series(\n                    name=\"ROW_ETAG\",\n                    data=[row.get(\"etag\") for row in self.rowset[\"rows\"]],\n                )\n\n        for i, header in enumerate(self.rowset[\"headers\"]):\n            column_name = header.name\n            series[column_name] = pd.concat(\n                [\n                    series[column_name],\n                    pd.Series(\n                        name=column_name,\n                        data=[row[\"values\"][i] for row in self.rowset[\"rows\"]],\n                        index=rownames,\n                    ),\n                ],\n                # can't verify integrity when indices are just numbers instead of 'rowid_rowversion'\n                verify_integrity=rowIdAndVersionInIndex,\n            )\n\n    return pd.DataFrame(data=series)\n</code></pre>"},{"location":"reference/tables/#synapseclient.table.TableQueryResult.next","title":"<code>next()</code>","text":"<p>Python 2 iterator</p> Source code in <code>synapseclient/table.py</code> <pre><code>def next(self):\n    \"\"\"\n    Python 2 iterator\n    \"\"\"\n    self.i += 1\n    if self.i &gt;= len(self.rowset[\"rows\"]):\n        if self.nextPageToken:\n            result = self.syn._queryTableNext(self.nextPageToken, self.tableId)\n            self.rowset = RowSet.from_json(result[\"queryResults\"])\n            self.nextPageToken = result.get(\"nextPageToken\", None)\n            self.i = 0\n        else:\n            raise StopIteration()\n    return self.rowset[\"rows\"][self.i]\n</code></pre>"},{"location":"reference/tables/#synapseclient.table.TableQueryResult.iter_row_metadata","title":"<code>iter_row_metadata()</code>","text":"<p>Iterates the table results to get row_id and row_etag. If an etag does not exist for a row, it will generated as (row_id, row_version,None)</p> RETURNS DESCRIPTION <p>A generator that gives collections.namedtuple</p> <p>with format (row_id, row_version, row_etag)</p> Source code in <code>synapseclient/table.py</code> <pre><code>def iter_row_metadata(self):\n    \"\"\"\n    Iterates the table results to get row_id and row_etag. If an etag does not exist for a row, it will\n    generated as (row_id, row_version,None)\n\n    Returns:\n        A generator that gives [collections.namedtuple](https://docs.python.org/3/library/collections.html#collections.namedtuple)\n        with format (row_id, row_version, row_etag)\n    \"\"\"\n    for row in self:\n        yield type(self).RowMetadataTuple(\n            int(row[\"rowId\"]), int(row[\"versionNumber\"]), row.get(\"etag\")\n        )\n</code></pre>"},{"location":"reference/tables/#synapseclient.table.CsvFileTable","title":"<code>CsvFileTable</code>","text":"<p>               Bases: <code>TableAbstractBaseClass</code></p> <p>An object to wrap a CSV file that may be stored into a Synapse table or returned as a result of a table query.</p> Source code in <code>synapseclient/table.py</code> <pre><code>class CsvFileTable(TableAbstractBaseClass):\n    \"\"\"\n    An object to wrap a CSV file that may be stored into a Synapse table or\n    returned as a result of a table query.\n    \"\"\"\n\n    @classmethod\n    def from_table_query(\n        cls,\n        synapse,\n        query,\n        quoteCharacter='\"',\n        escapeCharacter=\"\\\\\",\n        lineEnd=str(os.linesep),\n        separator=\",\",\n        header=True,\n        includeRowIdAndRowVersion=True,\n        downloadLocation=None,\n    ):\n        \"\"\"\n        Create a Table object wrapping a CSV file resulting from querying a Synapse table.\n        Mostly for internal use.\n        \"\"\"\n\n        download_from_table_result, path = synapse._queryTableCsv(\n            query=query,\n            quoteCharacter=quoteCharacter,\n            escapeCharacter=escapeCharacter,\n            lineEnd=lineEnd,\n            separator=separator,\n            header=header,\n            includeRowIdAndRowVersion=includeRowIdAndRowVersion,\n            downloadLocation=downloadLocation,\n        )\n\n        # A dirty hack to find out if we got back row ID and Version\n        # in particular, we don't get these back from aggregate queries\n        with io.open(path, \"r\", encoding=\"utf-8\") as f:\n            reader = csv.reader(\n                f,\n                delimiter=separator,\n                escapechar=escapeCharacter,\n                lineterminator=lineEnd,\n                quotechar=quoteCharacter,\n            )\n            first_line = next(reader)\n        if len(download_from_table_result[\"headers\"]) + 2 == len(first_line):\n            includeRowIdAndRowVersion = True\n        else:\n            includeRowIdAndRowVersion = False\n\n        self = cls(\n            filepath=path,\n            schema=download_from_table_result.get(\"tableId\", None),\n            etag=download_from_table_result.get(\"etag\", None),\n            quoteCharacter=quoteCharacter,\n            escapeCharacter=escapeCharacter,\n            lineEnd=lineEnd,\n            separator=separator,\n            header=header,\n            includeRowIdAndRowVersion=includeRowIdAndRowVersion,\n            headers=[\n                SelectColumn(**header)\n                for header in download_from_table_result[\"headers\"]\n            ],\n        )\n\n        return self\n\n    @classmethod\n    def from_data_frame(\n        cls,\n        schema,\n        df,\n        filepath=None,\n        etag=None,\n        quoteCharacter='\"',\n        escapeCharacter=\"\\\\\",\n        lineEnd=str(os.linesep),\n        separator=\",\",\n        header=True,\n        includeRowIdAndRowVersion=None,\n        headers=None,\n        **kwargs,\n    ):\n        # infer columns from data frame if not specified\n        if not headers:\n            cols = as_table_columns(df)\n            headers = [SelectColumn.from_column(col) for col in cols]\n\n        # if the schema has no columns, use the inferred columns\n        if isinstance(schema, Schema) and not schema.has_columns():\n            schema.addColumns(cols)\n\n        # convert row names in the format [row_id]_[version] or [row_id]_[version]_[etag] back to columns\n        # etag is essentially a UUID\n        etag_pattern = r\"[0-9a-fA-F]{8}-[0-9a-fA-F]{4}-[1-5][0-9a-fA-F]{3}-[89abAB][0-9a-fA-F]{3}-[0-9a-fA-F]{12}\"\n        row_id_version_pattern = re.compile(r\"(\\d+)_(\\d+)(_(\" + etag_pattern + r\"))?\")\n\n        row_id = []\n        row_version = []\n        row_etag = []\n        for row_name in df.index.values:\n            m = row_id_version_pattern.match(str(row_name))\n            row_id.append(m.group(1) if m else None)\n            row_version.append(m.group(2) if m else None)\n            row_etag.append(m.group(4) if m else None)\n\n        # include row ID and version, if we're asked to OR if it's encoded in row names\n        if includeRowIdAndRowVersion or (\n            includeRowIdAndRowVersion is None and any(row_id)\n        ):\n            df2 = df.copy()\n\n            cls._insert_dataframe_column_if_not_exist(df2, 0, \"ROW_ID\", row_id)\n            cls._insert_dataframe_column_if_not_exist(\n                df2, 1, \"ROW_VERSION\", row_version\n            )\n            if any(row_etag):\n                cls._insert_dataframe_column_if_not_exist(df2, 2, \"ROW_ETAG\", row_etag)\n\n            df = df2\n            includeRowIdAndRowVersion = True\n\n        f = None\n        try:\n            if not filepath:\n                temp_dir = tempfile.mkdtemp()\n                filepath = os.path.join(temp_dir, \"table.csv\")\n\n            f = io.open(filepath, mode=\"w\", encoding=\"utf-8\", newline=\"\")\n\n            test_import_pandas()\n            import pandas as pd\n\n            if isinstance(schema, Schema):\n                for col in schema.columns_to_store:\n                    if col[\"columnType\"] == \"DATE\":\n\n                        def _trailing_date_time_millisecond(t):\n                            if isinstance(t, str):\n                                return t[:-3]\n\n                        df[col.name] = pd.to_datetime(\n                            df[col.name], errors=\"coerce\"\n                        ).dt.strftime(\"%s%f\")\n                        df[col.name] = df[col.name].apply(\n                            lambda x: _trailing_date_time_millisecond(x)\n                        )\n\n            df.to_csv(\n                f,\n                index=False,\n                sep=separator,\n                header=header,\n                quotechar=quoteCharacter,\n                escapechar=escapeCharacter,\n                lineterminator=lineEnd,\n                na_rep=kwargs.get(\"na_rep\", \"\"),\n                float_format=\"%.12g\",\n            )\n            # NOTE: reason for flat_format='%.12g':\n            # pandas automatically converts int columns into float64 columns when some cells in the column have no\n            # value. If we write the whole number back as a decimal (e.g. '3.0'), Synapse complains that we are writing\n            # a float into a INTEGER(synapse table type) column. Using the 'g' will strip off '.0' from whole number\n            # values. pandas by default (with no float_format parameter) seems to keep 12 values after decimal, so we\n            # use '%.12g'.c\n            # see SYNPY-267.\n        finally:\n            if f:\n                f.close()\n\n        return cls(\n            schema=schema,\n            filepath=filepath,\n            etag=etag,\n            quoteCharacter=quoteCharacter,\n            escapeCharacter=escapeCharacter,\n            lineEnd=lineEnd,\n            separator=separator,\n            header=header,\n            includeRowIdAndRowVersion=includeRowIdAndRowVersion,\n            headers=headers,\n        )\n\n    @staticmethod\n    def _insert_dataframe_column_if_not_exist(\n        dataframe, insert_index, col_name, insert_column_data\n    ):\n        # if the column already exists verify the column data is same as what we parsed\n        if col_name in dataframe.columns:\n            if dataframe[col_name].tolist() != insert_column_data:\n                raise SynapseError(\n                    (\n                        \"A column named '{0}' already exists and does not match the '{0}' values present in\"\n                        \" the DataFrame's row names. Please refain from using or modifying '{0}' as a\"\n                        \" column for your data because it is necessary for version tracking in Synapse's\"\n                        \" tables\"\n                    ).format(col_name)\n                )\n        else:\n            dataframe.insert(insert_index, col_name, insert_column_data)\n\n    @classmethod\n    def from_list_of_rows(\n        cls,\n        schema,\n        values,\n        filepath=None,\n        etag=None,\n        quoteCharacter='\"',\n        escapeCharacter=\"\\\\\",\n        lineEnd=str(os.linesep),\n        separator=\",\",\n        linesToSkip=0,\n        includeRowIdAndRowVersion=None,\n        headers=None,\n    ):\n        # create CSV file\n        f = None\n        try:\n            if not filepath:\n                temp_dir = tempfile.mkdtemp()\n                filepath = os.path.join(temp_dir, \"table.csv\")\n\n            f = io.open(filepath, \"w\", encoding=\"utf-8\", newline=\"\")\n\n            writer = csv.writer(\n                f,\n                quoting=csv.QUOTE_NONNUMERIC,\n                delimiter=separator,\n                escapechar=escapeCharacter,\n                lineterminator=lineEnd,\n                quotechar=quoteCharacter,\n                skipinitialspace=linesToSkip,\n            )\n\n            # if we haven't explicitly set columns, try to grab them from\n            # the schema object\n            if (\n                not headers\n                and \"columns_to_store\" in schema\n                and schema.columns_to_store is not None\n            ):\n                headers = [\n                    SelectColumn.from_column(col) for col in schema.columns_to_store\n                ]\n\n            # write headers?\n            if headers:\n                writer.writerow([header.name for header in headers])\n                header = True\n            else:\n                header = False\n\n            # write row data\n            for row in values:\n                writer.writerow(row)\n\n        finally:\n            if f:\n                f.close()\n\n        return cls(\n            schema=schema,\n            filepath=filepath,\n            etag=etag,\n            quoteCharacter=quoteCharacter,\n            escapeCharacter=escapeCharacter,\n            lineEnd=lineEnd,\n            separator=separator,\n            header=header,\n            headers=headers,\n            includeRowIdAndRowVersion=includeRowIdAndRowVersion,\n        )\n\n    def __init__(\n        self,\n        schema,\n        filepath,\n        etag=None,\n        quoteCharacter=DEFAULT_QUOTE_CHARACTER,\n        escapeCharacter=DEFAULT_ESCAPSE_CHAR,\n        lineEnd=str(os.linesep),\n        separator=DEFAULT_SEPARATOR,\n        header=True,\n        linesToSkip=0,\n        includeRowIdAndRowVersion=None,\n        headers=None,\n    ):\n        self.filepath = filepath\n\n        self.includeRowIdAndRowVersion = includeRowIdAndRowVersion\n\n        # CsvTableDescriptor fields\n        self.linesToSkip = linesToSkip\n        self.quoteCharacter = quoteCharacter\n        self.escapeCharacter = escapeCharacter\n        self.lineEnd = lineEnd\n        self.separator = separator\n        self.header = header\n\n        super(CsvFileTable, self).__init__(schema, headers=headers, etag=etag)\n\n        self.setColumnHeaders(headers)\n\n    def _synapse_store(self, syn):\n        copied_self = copy.copy(self)\n        return copied_self._update_self(syn)\n\n    def _update_self(self, syn):\n        if isinstance(self.schema, Schema) and self.schema.get(\"id\", None) is None:\n            # store schema\n            self.schema = syn.store(self.schema)\n            self.tableId = self.schema.id\n\n        result = syn._uploadCsv(\n            self.filepath,\n            self.schema if self.schema else self.tableId,\n            updateEtag=self.etag,\n            quoteCharacter=self.quoteCharacter,\n            escapeCharacter=self.escapeCharacter,\n            lineEnd=self.lineEnd,\n            separator=self.separator,\n            header=self.header,\n            linesToSkip=self.linesToSkip,\n        )\n\n        upload_to_table_result = result[\"results\"][0]\n\n        assert upload_to_table_result[\"concreteType\"] in (\n            \"org.sagebionetworks.repo.model.table.EntityUpdateResults\",\n            \"org.sagebionetworks.repo.model.table.UploadToTableResult\",\n        ), \"Not an UploadToTableResult or EntityUpdateResults.\"\n        if \"etag\" in upload_to_table_result:\n            self.etag = upload_to_table_result[\"etag\"]\n        return self\n\n    def asDataFrame(self, rowIdAndVersionInIndex=True, convert_to_datetime=False):\n        \"\"\"Convert query result to a Pandas DataFrame.\n\n        Arguments:\n            rowIdAndVersionInIndex: Make the dataframe index consist of the row_id and row_version\n                                    (and row_etag if it exists)\n            convert_to_datetime:    If set to True, will convert all Synapse DATE columns from UNIX timestamp\n                                    integers into UTC datetime objects\n\n        Returns:\n            A Pandas dataframe with results\n        \"\"\"\n        test_import_pandas()\n        import pandas as pd\n\n        try:\n            # Handle bug in pandas 0.19 requiring quotechar to be str not unicode or newstr\n            quoteChar = self.quoteCharacter\n\n            # determine which columns are DATE columns so we can convert milisecond timestamps into datetime objects\n            date_columns = []\n            list_columns = []\n            dtype = {}\n\n            if self.headers is not None:\n                for select_column in self.headers:\n                    if select_column.columnType == \"STRING\":\n                        # we want to identify string columns so that pandas doesn't try to\n                        # automatically parse strings in a string column to other data types\n                        dtype[select_column.name] = str\n                    elif select_column.columnType in LIST_COLUMN_TYPES:\n                        list_columns.append(select_column.name)\n                    elif select_column.columnType == \"DATE\" and convert_to_datetime:\n                        date_columns.append(select_column.name)\n\n            return _csv_to_pandas_df(\n                self.filepath,\n                separator=self.separator,\n                quote_char=quoteChar,\n                escape_char=self.escapeCharacter,\n                contain_headers=self.header,\n                lines_to_skip=self.linesToSkip,\n                date_columns=date_columns,\n                list_columns=list_columns,\n                rowIdAndVersionInIndex=rowIdAndVersionInIndex,\n                dtype=dtype,\n            )\n        except pd.parser.CParserError:\n            return pd.DataFrame()\n\n    def asRowSet(self):\n        # Extract row id and version, if present in rows\n        row_id_col = None\n        row_ver_col = None\n        for i, header in enumerate(self.headers):\n            if header.name == \"ROW_ID\":\n                row_id_col = i\n            elif header.name == \"ROW_VERSION\":\n                row_ver_col = i\n\n        def to_row_object(row, row_id_col=None, row_ver_col=None):\n            if isinstance(row, Row):\n                return row\n            rowId = row[row_id_col] if row_id_col is not None else None\n            versionNumber = row[row_ver_col] if row_ver_col is not None else None\n            values = [\n                elem for i, elem in enumerate(row) if i not in [row_id_col, row_ver_col]\n            ]\n            return Row(values, rowId=rowId, versionNumber=versionNumber)\n\n        return RowSet(\n            headers=[\n                elem\n                for i, elem in enumerate(self.headers)\n                if i not in [row_id_col, row_ver_col]\n            ],\n            tableId=self.tableId,\n            etag=self.etag,\n            rows=[to_row_object(row, row_id_col, row_ver_col) for row in self],\n        )\n\n    def setColumnHeaders(self, headers):\n        \"\"\"\n        Set the list of [SelectColumn][synapseclient.table.SelectColumn] objects that will be used to convert fields to the\n        appropriate data types.\n\n        Column headers are automatically set when querying.\n        \"\"\"\n        if self.includeRowIdAndRowVersion:\n            names = [header.name for header in headers]\n            if \"ROW_ID\" not in names and \"ROW_VERSION\" not in names:\n                headers = [\n                    SelectColumn(name=\"ROW_ID\", columnType=\"STRING\"),\n                    SelectColumn(name=\"ROW_VERSION\", columnType=\"STRING\"),\n                ] + headers\n        self.headers = headers\n\n    def __iter__(self):\n        def iterate_rows(filepath, headers):\n            if not self.header or not self.headers:\n                raise ValueError(\"Iteration not supported for table without headers.\")\n\n            header_name = {header.name for header in headers}\n            row_metadata_headers = {\"ROW_ID\", \"ROW_VERSION\", \"ROW_ETAG\"}\n            num_row_metadata_in_headers = len(header_name &amp; row_metadata_headers)\n            with io.open(filepath, encoding=\"utf-8\", newline=self.lineEnd) as f:\n                reader = csv.reader(\n                    f,\n                    delimiter=self.separator,\n                    escapechar=self.escapeCharacter,\n                    lineterminator=self.lineEnd,\n                    quotechar=self.quoteCharacter,\n                )\n                csv_header = set(next(reader))\n                # the number of row metadata differences between the csv headers and self.headers\n                num_metadata_cols_diff = (\n                    len(csv_header &amp; row_metadata_headers) - num_row_metadata_in_headers\n                )\n                # we only process 2 cases:\n                # 1. matching row metadata\n                # 2. if metadata does not match, self.headers must not contains row metadata\n                if num_metadata_cols_diff == 0 or num_row_metadata_in_headers == 0:\n                    for row in reader:\n                        yield cast_values(row[num_metadata_cols_diff:], headers)\n                else:\n                    raise ValueError(\n                        \"There is mismatching row metadata in the csv file and in headers.\"\n                    )\n\n        return iterate_rows(self.filepath, self.headers)\n\n    def __len__(self):\n        with io.open(self.filepath, encoding=\"utf-8\", newline=self.lineEnd) as f:\n            if self.header:  # ignore the header line\n                f.readline()\n\n            return sum(1 for line in f)\n\n    def iter_row_metadata(self):\n        \"\"\"\n        Iterates the table results to get row_id and row_etag. If an etag does not exist for a row,\n        it will generated as (row_id, None)\n\n        Returns:\n            A generator that gives [collections.namedtuple](https://docs.python.org/3/library/collections.html#collections.namedtuple) with format (row_id, row_etag)\n        \"\"\"\n        with io.open(self.filepath, encoding=\"utf-8\", newline=self.lineEnd) as f:\n            reader = csv.reader(\n                f,\n                delimiter=self.separator,\n                escapechar=self.escapeCharacter,\n                lineterminator=self.lineEnd,\n                quotechar=self.quoteCharacter,\n            )\n            header = next(reader)\n\n            # The ROW_... headers are always in a predefined order\n            row_id_index = header.index(\"ROW_ID\")\n            row_version_index = header.index(\"ROW_VERSION\")\n            try:\n                row_etag_index = header.index(\"ROW_ETAG\")\n            except ValueError:\n                row_etag_index = None\n\n            for row in reader:\n                yield type(self).RowMetadataTuple(\n                    int(row[row_id_index]),\n                    int(row[row_version_index]),\n                    row[row_etag_index] if (row_etag_index is not None) else None,\n                )\n</code></pre>"},{"location":"reference/tables/#synapseclient.table.CsvFileTable-functions","title":"Functions","text":""},{"location":"reference/tables/#synapseclient.table.CsvFileTable.from_table_query","title":"<code>from_table_query(synapse, query, quoteCharacter='\"', escapeCharacter='\\\\', lineEnd=str(os.linesep), separator=',', header=True, includeRowIdAndRowVersion=True, downloadLocation=None)</code>  <code>classmethod</code>","text":"<p>Create a Table object wrapping a CSV file resulting from querying a Synapse table. Mostly for internal use.</p> Source code in <code>synapseclient/table.py</code> <pre><code>@classmethod\ndef from_table_query(\n    cls,\n    synapse,\n    query,\n    quoteCharacter='\"',\n    escapeCharacter=\"\\\\\",\n    lineEnd=str(os.linesep),\n    separator=\",\",\n    header=True,\n    includeRowIdAndRowVersion=True,\n    downloadLocation=None,\n):\n    \"\"\"\n    Create a Table object wrapping a CSV file resulting from querying a Synapse table.\n    Mostly for internal use.\n    \"\"\"\n\n    download_from_table_result, path = synapse._queryTableCsv(\n        query=query,\n        quoteCharacter=quoteCharacter,\n        escapeCharacter=escapeCharacter,\n        lineEnd=lineEnd,\n        separator=separator,\n        header=header,\n        includeRowIdAndRowVersion=includeRowIdAndRowVersion,\n        downloadLocation=downloadLocation,\n    )\n\n    # A dirty hack to find out if we got back row ID and Version\n    # in particular, we don't get these back from aggregate queries\n    with io.open(path, \"r\", encoding=\"utf-8\") as f:\n        reader = csv.reader(\n            f,\n            delimiter=separator,\n            escapechar=escapeCharacter,\n            lineterminator=lineEnd,\n            quotechar=quoteCharacter,\n        )\n        first_line = next(reader)\n    if len(download_from_table_result[\"headers\"]) + 2 == len(first_line):\n        includeRowIdAndRowVersion = True\n    else:\n        includeRowIdAndRowVersion = False\n\n    self = cls(\n        filepath=path,\n        schema=download_from_table_result.get(\"tableId\", None),\n        etag=download_from_table_result.get(\"etag\", None),\n        quoteCharacter=quoteCharacter,\n        escapeCharacter=escapeCharacter,\n        lineEnd=lineEnd,\n        separator=separator,\n        header=header,\n        includeRowIdAndRowVersion=includeRowIdAndRowVersion,\n        headers=[\n            SelectColumn(**header)\n            for header in download_from_table_result[\"headers\"]\n        ],\n    )\n\n    return self\n</code></pre>"},{"location":"reference/tables/#synapseclient.table.CsvFileTable.asDataFrame","title":"<code>asDataFrame(rowIdAndVersionInIndex=True, convert_to_datetime=False)</code>","text":"<p>Convert query result to a Pandas DataFrame.</p> PARAMETER DESCRIPTION <code>rowIdAndVersionInIndex</code> <p>Make the dataframe index consist of the row_id and row_version                     (and row_etag if it exists)</p> <p> DEFAULT: <code>True</code> </p> <code>convert_to_datetime</code> <p>If set to True, will convert all Synapse DATE columns from UNIX timestamp                     integers into UTC datetime objects</p> <p> DEFAULT: <code>False</code> </p> RETURNS DESCRIPTION <p>A Pandas dataframe with results</p> Source code in <code>synapseclient/table.py</code> <pre><code>def asDataFrame(self, rowIdAndVersionInIndex=True, convert_to_datetime=False):\n    \"\"\"Convert query result to a Pandas DataFrame.\n\n    Arguments:\n        rowIdAndVersionInIndex: Make the dataframe index consist of the row_id and row_version\n                                (and row_etag if it exists)\n        convert_to_datetime:    If set to True, will convert all Synapse DATE columns from UNIX timestamp\n                                integers into UTC datetime objects\n\n    Returns:\n        A Pandas dataframe with results\n    \"\"\"\n    test_import_pandas()\n    import pandas as pd\n\n    try:\n        # Handle bug in pandas 0.19 requiring quotechar to be str not unicode or newstr\n        quoteChar = self.quoteCharacter\n\n        # determine which columns are DATE columns so we can convert milisecond timestamps into datetime objects\n        date_columns = []\n        list_columns = []\n        dtype = {}\n\n        if self.headers is not None:\n            for select_column in self.headers:\n                if select_column.columnType == \"STRING\":\n                    # we want to identify string columns so that pandas doesn't try to\n                    # automatically parse strings in a string column to other data types\n                    dtype[select_column.name] = str\n                elif select_column.columnType in LIST_COLUMN_TYPES:\n                    list_columns.append(select_column.name)\n                elif select_column.columnType == \"DATE\" and convert_to_datetime:\n                    date_columns.append(select_column.name)\n\n        return _csv_to_pandas_df(\n            self.filepath,\n            separator=self.separator,\n            quote_char=quoteChar,\n            escape_char=self.escapeCharacter,\n            contain_headers=self.header,\n            lines_to_skip=self.linesToSkip,\n            date_columns=date_columns,\n            list_columns=list_columns,\n            rowIdAndVersionInIndex=rowIdAndVersionInIndex,\n            dtype=dtype,\n        )\n    except pd.parser.CParserError:\n        return pd.DataFrame()\n</code></pre>"},{"location":"reference/tables/#synapseclient.table.CsvFileTable.setColumnHeaders","title":"<code>setColumnHeaders(headers)</code>","text":"<p>Set the list of SelectColumn objects that will be used to convert fields to the appropriate data types.</p> <p>Column headers are automatically set when querying.</p> Source code in <code>synapseclient/table.py</code> <pre><code>def setColumnHeaders(self, headers):\n    \"\"\"\n    Set the list of [SelectColumn][synapseclient.table.SelectColumn] objects that will be used to convert fields to the\n    appropriate data types.\n\n    Column headers are automatically set when querying.\n    \"\"\"\n    if self.includeRowIdAndRowVersion:\n        names = [header.name for header in headers]\n        if \"ROW_ID\" not in names and \"ROW_VERSION\" not in names:\n            headers = [\n                SelectColumn(name=\"ROW_ID\", columnType=\"STRING\"),\n                SelectColumn(name=\"ROW_VERSION\", columnType=\"STRING\"),\n            ] + headers\n    self.headers = headers\n</code></pre>"},{"location":"reference/tables/#synapseclient.table.CsvFileTable.iter_row_metadata","title":"<code>iter_row_metadata()</code>","text":"<p>Iterates the table results to get row_id and row_etag. If an etag does not exist for a row, it will generated as (row_id, None)</p> RETURNS DESCRIPTION <p>A generator that gives collections.namedtuple with format (row_id, row_etag)</p> Source code in <code>synapseclient/table.py</code> <pre><code>def iter_row_metadata(self):\n    \"\"\"\n    Iterates the table results to get row_id and row_etag. If an etag does not exist for a row,\n    it will generated as (row_id, None)\n\n    Returns:\n        A generator that gives [collections.namedtuple](https://docs.python.org/3/library/collections.html#collections.namedtuple) with format (row_id, row_etag)\n    \"\"\"\n    with io.open(self.filepath, encoding=\"utf-8\", newline=self.lineEnd) as f:\n        reader = csv.reader(\n            f,\n            delimiter=self.separator,\n            escapechar=self.escapeCharacter,\n            lineterminator=self.lineEnd,\n            quotechar=self.quoteCharacter,\n        )\n        header = next(reader)\n\n        # The ROW_... headers are always in a predefined order\n        row_id_index = header.index(\"ROW_ID\")\n        row_version_index = header.index(\"ROW_VERSION\")\n        try:\n            row_etag_index = header.index(\"ROW_ETAG\")\n        except ValueError:\n            row_etag_index = None\n\n        for row in reader:\n            yield type(self).RowMetadataTuple(\n                int(row[row_id_index]),\n                int(row[row_version_index]),\n                row[row_etag_index] if (row_etag_index is not None) else None,\n            )\n</code></pre>"},{"location":"reference/tables/#synapseclient.table-functions","title":"Functions","text":""},{"location":"reference/tables/#synapseclient.table.as_table_columns","title":"<code>as_table_columns(values)</code>","text":"<p>Return a list of Synapse table Column objects that correspond to the columns in the given values.</p> PARAMETER DESCRIPTION <code>values</code> <p>An object that holds the content of the tables.</p> <ul> <li>A string holding the path to a CSV file, a filehandle, or StringIO containing valid csv content</li> <li>A Pandas DataFrame</li> </ul> <p> TYPE: <code>Union[str, DataFrameType]</code> </p> RETURNS DESCRIPTION <p>A list of Synapse table Column objects</p> <p>Example:</p> <pre><code>import pandas as pd\n\ndf = pd.DataFrame(dict(a=[1, 2, 3], b=[\"c\", \"d\", \"e\"]))\ncols = as_table_columns(df)\n</code></pre> Source code in <code>synapseclient/table.py</code> <pre><code>def as_table_columns(values: Union[str, DataFrameType]):\n    \"\"\"\n    Return a list of Synapse table [Column][synapseclient.table.Column] objects\n    that correspond to the columns in the given values.\n\n    Arguments:\n        values: An object that holds the content of the tables.\n\n            - A string holding the path to a CSV file, a filehandle, or StringIO containing valid csv content\n            - A [Pandas DataFrame](http://pandas.pydata.org/pandas-docs/stable/api.html#dataframe)\n\n    Returns:\n        A list of Synapse table [Column][synapseclient.table.Column] objects\n\n    Example:\n\n        import pandas as pd\n\n        df = pd.DataFrame(dict(a=[1, 2, 3], b=[\"c\", \"d\", \"e\"]))\n        cols = as_table_columns(df)\n    \"\"\"\n    test_import_pandas()\n    import pandas as pd\n    from pandas.api.types import infer_dtype\n\n    df = None\n\n    # pandas DataFrame\n    if isinstance(values, pd.DataFrame):\n        df = values\n    # filename of a csv file\n    # in Python 3, we can check that the values is instanceof io.IOBase\n    # for now, check if values has attr `read`\n    elif isinstance(values, str) or hasattr(values, \"read\"):\n        df = _csv_to_pandas_df(values)\n\n    if df is None:\n        raise ValueError(\"Values of type %s is not yet supported.\" % type(values))\n\n    cols = list()\n    for col in df:\n        inferred_type = infer_dtype(df[col], skipna=True)\n        columnType = PANDAS_TABLE_TYPE.get(inferred_type, \"STRING\")\n        if columnType == \"STRING\":\n            maxStrLen = df[col].str.len().max()\n            if maxStrLen &gt; 1000:\n                cols.append(Column(name=col, columnType=\"LARGETEXT\", defaultValue=\"\"))\n            else:\n                size = int(\n                    round(min(1000, max(30, maxStrLen * 1.5)))\n                )  # Determine the length of the longest string\n                cols.append(\n                    Column(\n                        name=col,\n                        columnType=columnType,\n                        maximumSize=size,\n                        defaultValue=\"\",\n                    )\n                )\n        else:\n            cols.append(Column(name=col, columnType=columnType))\n    return cols\n</code></pre>"},{"location":"reference/tables/#synapseclient.table.df2Table","title":"<code>df2Table(df, syn, tableName, parentProject)</code>","text":"<p>Creates a new table from data in pandas data frame. parameters: df, tableName, parentProject</p> Source code in <code>synapseclient/table.py</code> <pre><code>def df2Table(df, syn, tableName, parentProject):\n    \"\"\"Creates a new table from data in pandas data frame.\n    parameters: df, tableName, parentProject\n    \"\"\"\n\n    # Create columns:\n    cols = as_table_columns(df)\n    cols = [syn.store(col) for col in cols]\n\n    # Create Table Schema\n    schema1 = Schema(name=tableName, columns=cols, parent=parentProject)\n    schema1 = syn.store(schema1)\n\n    # Add data to Table\n    for i in range(0, df.shape[0] / 1200 + 1):\n        start = i * 1200\n        end = min((i + 1) * 1200, df.shape[0])\n        rowset1 = RowSet(\n            columns=cols,\n            schema=schema1,\n            rows=[Row(list(df.ix[j, :])) for j in range(start, end)],\n        )\n        syn.store(rowset1)\n\n    return schema1\n</code></pre>"},{"location":"reference/tables/#synapseclient.table.to_boolean","title":"<code>to_boolean(value)</code>","text":"<p>Convert a string to boolean, case insensitively, where true values are: true, t, and 1 and false values are: false, f, 0. Raise a ValueError for all other values.</p> Source code in <code>synapseclient/table.py</code> <pre><code>def to_boolean(value):\n    \"\"\"\n    Convert a string to boolean, case insensitively,\n    where true values are: true, t, and 1 and false values are: false, f, 0.\n    Raise a ValueError for all other values.\n    \"\"\"\n    if isinstance(value, bool):\n        return value\n\n    if isinstance(value, str):\n        lower_value = value.lower()\n        if lower_value in [\"true\", \"t\", \"1\"]:\n            return True\n        if lower_value in [\"false\", \"f\", \"0\"]:\n            return False\n\n    raise ValueError(\"Can't convert %s to boolean.\" % value)\n</code></pre>"},{"location":"reference/tables/#synapseclient.table.cast_values","title":"<code>cast_values(values, headers)</code>","text":"<p>Convert a row of table query results from strings to the correct column type.</p> <p>See: https://rest-docs.synapse.org/rest/org/sagebionetworks/repo/model/table/ColumnType.html</p> Source code in <code>synapseclient/table.py</code> <pre><code>def cast_values(values, headers):\n    \"\"\"\n    Convert a row of table query results from strings to the correct column type.\n\n    See: &lt;https://rest-docs.synapse.org/rest/org/sagebionetworks/repo/model/table/ColumnType.html&gt;\n    \"\"\"\n    if len(values) != len(headers):\n        raise ValueError(\n            \"The number of columns in the csv file does not match the given headers. %d fields, %d headers\"\n            % (len(values), len(headers))\n        )\n\n    result = []\n    for header, field in zip(headers, values):\n        columnType = header.get(\"columnType\", \"STRING\")\n\n        # convert field to column type\n        if field is None or field == \"\":\n            result.append(None)\n        elif columnType in {\n            \"STRING\",\n            \"ENTITYID\",\n            \"FILEHANDLEID\",\n            \"LARGETEXT\",\n            \"USERID\",\n            \"LINK\",\n        }:\n            result.append(field)\n        elif columnType == \"DOUBLE\":\n            result.append(float(field))\n        elif columnType == \"INTEGER\":\n            result.append(int(field))\n        elif columnType == \"BOOLEAN\":\n            result.append(to_boolean(field))\n        elif columnType == \"DATE\":\n            result.append(from_unix_epoch_time(field))\n        elif columnType in {\n            \"STRING_LIST\",\n            \"INTEGER_LIST\",\n            \"BOOLEAN_LIST\",\n            \"ENTITYID_LIST\",\n            \"USERID_LIST\",\n        }:\n            result.append(json.loads(field))\n        elif columnType == \"DATE_LIST\":\n            result.append(json.loads(field, parse_int=from_unix_epoch_time))\n        else:\n            # default to string for unknown column type\n            result.append(field)\n\n    return result\n</code></pre>"},{"location":"reference/tables/#synapseclient.table.escape_column_name","title":"<code>escape_column_name(column)</code>","text":"<p>Escape the name of the given column for use in a Synapse table query statement</p> PARAMETER DESCRIPTION <code>column</code> <p>a string or column dictionary object with a 'name' key</p> <p> TYPE: <code>Union[str, Mapping]</code> </p> RETURNS DESCRIPTION <code>str</code> <p>Escaped column name</p> Source code in <code>synapseclient/table.py</code> <pre><code>def escape_column_name(column: Union[str, collections.abc.Mapping]) -&gt; str:\n    \"\"\"\n    Escape the name of the given column for use in a Synapse table query statement\n\n    Arguments:\n        column: a string or column dictionary object with a 'name' key\n\n    Returns:\n        Escaped column name\n    \"\"\"\n    col_name = (\n        column[\"name\"] if isinstance(column, collections.abc.Mapping) else str(column)\n    )\n    escaped_name = col_name.replace('\"', '\"\"')\n    return f'\"{escaped_name}\"'\n</code></pre>"},{"location":"reference/tables/#synapseclient.table.join_column_names","title":"<code>join_column_names(columns)</code>","text":"<p>Join the names of the given columns into a comma delimited list suitable for use in a Synapse table query</p> PARAMETER DESCRIPTION <code>columns</code> <p>A sequence of column string names or dictionary objets with column 'name' keys</p> <p> TYPE: <code>Union[List, Dict[str, str]]</code> </p> Source code in <code>synapseclient/table.py</code> <pre><code>def join_column_names(columns: Union[List, Dict[str, str]]):\n    \"\"\"\n    Join the names of the given columns into a comma delimited list suitable for use in a Synapse table query\n\n    Arguments:\n        columns: A sequence of column string names or dictionary objets with column 'name' keys\n    \"\"\"\n    return \",\".join(escape_column_name(c) for c in columns)\n</code></pre>"},{"location":"reference/tables/#synapseclient.table.delete_rows","title":"<code>delete_rows(syn, table_id, row_id_vers_list)</code>","text":"<p>Deletes rows from a synapse table</p> PARAMETER DESCRIPTION <code>syn</code> <p>An instance of Synapse</p> <p> </p> <code>table_id</code> <p>The ID of the table to delete rows from</p> <p> TYPE: <code>str</code> </p> <code>row_id_vers_list</code> <p>An iterable containing tuples with format: (row_id, row_version)</p> <p> TYPE: <code>List[Tuple[int, int]]</code> </p> Source code in <code>synapseclient/table.py</code> <pre><code>def delete_rows(\n    syn,\n    table_id: str,\n    row_id_vers_list: List[Tuple[int, int]],\n):\n    \"\"\"\n    Deletes rows from a synapse table\n\n    Arguments:\n        syn:              An instance of [Synapse][synapseclient.client.Synapse]\n        table_id:         The ID of the table to delete rows from\n        row_id_vers_list: An iterable containing tuples with format: (row_id, row_version)\n    \"\"\"\n    delete_row_csv_filepath = _create_row_delete_csv(\n        row_id_vers_iterable=row_id_vers_list\n    )\n    try:\n        syn._uploadCsv(filepath=delete_row_csv_filepath, schema=table_id)\n    finally:\n        os.remove(delete_row_csv_filepath)\n</code></pre>"},{"location":"reference/tables/#synapseclient.table.build_table","title":"<code>build_table(name, parent, values)</code>","text":"<p>Build a Table object</p> PARAMETER DESCRIPTION <code>name</code> <p>The name for the Table Schema object</p> <p> </p> <code>parent</code> <p>The project in Synapse to which this table belongs</p> <p> </p> <code>values</code> <p>An object that holds the content of the tables</p> <ul> <li>A string holding the path to a CSV file</li> <li>A Pandas DataFrame</li> </ul> <p> </p> RETURNS DESCRIPTION <p>A Table object suitable for storing</p> <p>Example:</p> <pre><code>path = \"/path/to/file.csv\"\ntable = build_table(\"simple_table\", \"syn123\", path)\ntable = syn.store(table)\n\nimport pandas as pd\n\ndf = pd.DataFrame(dict(a=[1, 2, 3], b=[\"c\", \"d\", \"e\"]))\ntable = build_table(\"simple_table\", \"syn123\", df)\ntable = syn.store(table)\n</code></pre> Source code in <code>synapseclient/table.py</code> <pre><code>def build_table(name, parent, values):\n    \"\"\"\n    Build a Table object\n\n    Arguments:\n        name:    The name for the Table Schema object\n        parent:  The project in Synapse to which this table belongs\n        values:  An object that holds the content of the tables\n\n            - A string holding the path to a CSV file\n            - A [Pandas DataFrame](http://pandas.pydata.org/pandas-docs/stable/api.html#dataframe)\n\n    Returns:\n        A Table object suitable for storing\n\n    Example:\n\n        path = \"/path/to/file.csv\"\n        table = build_table(\"simple_table\", \"syn123\", path)\n        table = syn.store(table)\n\n        import pandas as pd\n\n        df = pd.DataFrame(dict(a=[1, 2, 3], b=[\"c\", \"d\", \"e\"]))\n        table = build_table(\"simple_table\", \"syn123\", df)\n        table = syn.store(table)\n    \"\"\"\n    test_import_pandas()\n    import pandas as pd\n\n    if not isinstance(values, pd.DataFrame) and not isinstance(values, str):\n        raise ValueError(\"Values of type %s is not yet supported.\" % type(values))\n    cols = as_table_columns(values)\n    schema = Schema(name=name, columns=cols, parent=parent)\n    headers = [SelectColumn.from_column(col) for col in cols]\n    return Table(schema, values, headers=headers)\n</code></pre>"},{"location":"reference/tables/#synapseclient.table.Table","title":"<code>Table(schema, values, **kwargs)</code>","text":"<p>Combine a table schema and a set of values into some type of Table object depending on what type of values are given.</p> PARAMETER DESCRIPTION <code>schema</code> <p>A table Schema object or Synapse Id of Table.</p> <p> </p> <code>values</code> <p>An object that holds the content of the tables</p> <ul> <li>A RowSet</li> <li>A list of lists (or tuples) where each element is a row</li> <li>A string holding the path to a CSV file</li> <li>A Pandas DataFrame</li> <li>A dict which will be wrapped by a Pandas DataFrame</li> </ul> <p> </p> RETURNS DESCRIPTION <p>A Table object suitable for storing</p> <p>Usually, the immediate next step after creating a Table object is to store it:</p> <pre><code>table = syn.store(Table(schema, values))\n</code></pre> <p>End users should not need to know the details of these Table subclasses:</p> <ul> <li>TableAbstractBaseClass</li> <li>RowSetTable</li> <li>TableQueryResult</li> <li>CsvFileTable</li> </ul> Source code in <code>synapseclient/table.py</code> <pre><code>def Table(schema, values, **kwargs):\n    \"\"\"\n    Combine a table schema and a set of values into some type of Table object\n    depending on what type of values are given.\n\n    Arguments:\n        schema: A table [Schema][synapseclient.table.Schema] object or Synapse Id of Table.\n        values: An object that holds the content of the tables\n\n            - A [RowSet][synapseclient.table.RowSet]\n            - A list of lists (or tuples) where each element is a row\n            - A string holding the path to a CSV file\n            - A [Pandas DataFrame](http://pandas.pydata.org/pandas-docs/stable/api.html#dataframe)\n            - A dict which will be wrapped by a [Pandas DataFrame](http://pandas.pydata.org/pandas-docs/stable/api.html#dataframe)\n\n    Returns:\n        A Table object suitable for storing\n\n    Usually, the immediate next step after creating a Table object is to store it:\n\n        table = syn.store(Table(schema, values))\n\n    End users should not need to know the details of these Table subclasses:\n\n    - [TableAbstractBaseClass][synapseclient.table.TableAbstractBaseClass]\n    - [RowSetTable][synapseclient.table.RowSetTable]\n    - [TableQueryResult][synapseclient.table.TableQueryResult]\n    - [CsvFileTable][synapseclient.table.CsvFileTable]\n    \"\"\"\n\n    try:\n        import pandas as pd\n\n        pandas_available = True\n    except:  # noqa\n        pandas_available = False\n\n    # a RowSet\n    if isinstance(values, RowSet):\n        return RowSetTable(schema, values, **kwargs)\n\n    # a list of rows\n    elif isinstance(values, (list, tuple)):\n        return CsvFileTable.from_list_of_rows(schema, values, **kwargs)\n\n    # filename of a csv file\n    elif isinstance(values, str):\n        return CsvFileTable(schema, filepath=values, **kwargs)\n\n    # pandas DataFrame\n    elif pandas_available and isinstance(values, pd.DataFrame):\n        return CsvFileTable.from_data_frame(schema, values, **kwargs)\n\n    # dict\n    elif pandas_available and isinstance(values, dict):\n        return CsvFileTable.from_data_frame(schema, pd.DataFrame(values), **kwargs)\n\n    else:\n        raise ValueError(\n            \"Don't know how to make tables from values of type %s.\" % type(values)\n        )\n</code></pre>"},{"location":"reference/teams/","title":"Teams","text":""},{"location":"reference/teams/#synapseclient.team","title":"<code>synapseclient.team</code>","text":"<p>Functions that interact with Synapse Teams</p>"},{"location":"reference/teams/#synapseclient.team-classes","title":"Classes","text":""},{"location":"reference/teams/#synapseclient.team.UserProfile","title":"<code>UserProfile</code>","text":"<p>               Bases: <code>DictObject</code></p> <p>Information about a Synapse user.  In practice the constructor is not called directly by the client.</p> ATTRIBUTE DESCRIPTION <code>ownerId</code> <p>A foreign key to the ID of the 'principal' object for the user.</p> <p> </p> <code>uri</code> <p>The Uniform Resource Identifier (URI) for this entity.</p> <p> </p> <code>etag</code> <p>Synapse employs an Optimistic Concurrency Control (OCC) scheme to handle concurrent updates.</p> <p> </p> <code>firstName</code> <p>This person's given name (forename)</p> <p> </p> <code>lastName</code> <p>This person's family name (surname)</p> <p> </p> <code>emails</code> <p>The list of user email addresses registered to this user.</p> <p> </p> <code>userName</code> <p>A name chosen by the user that uniquely identifies them.</p> <p> </p> <code>summary</code> <p>A summary description about this person</p> <p> </p> <code>position</code> <p>This person's current position title</p> <p> </p> <code>location</code> <p>This person's location</p> <p> </p> <code>industry</code> <p>The industry/discipline that this person is associated with</p> <p> </p> <code>company</code> <p>This person's current affiliation</p> <p> </p> <code>profilePicureFileHandleId</code> <p>The File Handle ID of the user's profile picture.</p> <p> </p> <code>url</code> <p>A link to more information about this person</p> <p> </p> <code>notificationSettings</code> <p>An object of type org.sagebionetworks.repo.model.message.Settings</p> <p> </p> Source code in <code>synapseclient/team.py</code> <pre><code>class UserProfile(DictObject):\n    \"\"\"\n    Information about a Synapse user.  In practice the constructor is not called directly by the client.\n\n    Attributes:\n        ownerId: A foreign key to the ID of the 'principal' object for the user.\n        uri: The Uniform Resource Identifier (URI) for this entity.\n        etag: Synapse employs an Optimistic Concurrency Control (OCC) scheme to handle concurrent updates.\n        Since the E-Tag changes every time an entity is updated it is\n        used to detect when a client's current representation\n        of an entity is out-of-date.\n        firstName: This person's given name (forename)\n        lastName: This person's family name (surname)\n        emails: The list of user email addresses registered to this user.\n        userName: A name chosen by the user that uniquely identifies them.\n        summary: A summary description about this person\n        position: This person's current position title\n        location: This person's location\n        industry: The industry/discipline that this person is associated with\n        company: This person's current affiliation\n        profilePicureFileHandleId: The File Handle ID of the user's profile picture.\n        url: A link to more information about this person\n        notificationSettings: An object of type [org.sagebionetworks.repo.model.message.Settings](https://rest-docs.synapse.org/rest/org/sagebionetworks/repo/model/message/Settings.html)\n        containing the user's preferences regarding when email notifications should be sent\n    \"\"\"\n\n    def __init__(self, **kwargs):\n        super(UserProfile, self).__init__(kwargs)\n</code></pre>"},{"location":"reference/teams/#synapseclient.team.UserGroupHeader","title":"<code>UserGroupHeader</code>","text":"<p>               Bases: <code>DictObject</code></p> <p>Select metadata about a Synapse principal. In practice the constructor is not called directly by the client.</p> ATTRIBUTE DESCRIPTION <code>firstName</code> <p>First Name</p> <p> </p> <code>lastName</code> <p>Last Name</p> <p> </p> <code>userName</code> <p>A name chosen by the user that uniquely identifies them.</p> <p> </p> <code>email</code> <p>User's current email address</p> <p> </p> <code>isIndividual</code> <p>True if this is a user, false if it is a group</p> <p> </p> Source code in <code>synapseclient/team.py</code> <pre><code>class UserGroupHeader(DictObject):\n    \"\"\"\n    Select metadata about a Synapse principal.\n    In practice the constructor is not called directly by the client.\n\n    Attributes:\n        ownerId A foreign key to the ID of the 'principal' object for the user.\n        firstName: First Name\n        lastName: Last Name\n        userName: A name chosen by the user that uniquely identifies them.\n        email: User's current email address\n        isIndividual: True if this is a user, false if it is a group\n    \"\"\"\n\n    def __init__(self, **kwargs):\n        super(UserGroupHeader, self).__init__(kwargs)\n</code></pre>"},{"location":"reference/teams/#synapseclient.team.Team","title":"<code>Team</code>","text":"<p>               Bases: <code>DictObject</code></p> <p>Represents a Synapse Team. User definable fields are:</p> ATTRIBUTE DESCRIPTION <code>icon</code> <p>The fileHandleId for icon image of the Team</p> <p> </p> <code>description</code> <p>A short description of this Team.</p> <p> </p> <code>name</code> <p>The name of the Team.</p> <p> </p> <code>canPublicJoin</code> <p>true for teams which members can join without an invitation or approval</p> <p> </p> Source code in <code>synapseclient/team.py</code> <pre><code>class Team(DictObject):\n    \"\"\"\n    Represents a [Synapse Team](https://rest-docs.synapse.org/rest/org/sagebionetworks/repo/model/Team.html).\n    User definable fields are:\n\n    Attributes:\n        icon: The fileHandleId for icon image of the Team\n        description: A short description of this Team.\n        name: The name of the Team.\n        canPublicJoin: true for teams which members can join without an invitation or approval\n    \"\"\"\n\n    def __init__(self, **kwargs):\n        super(Team, self).__init__(kwargs)\n\n    @classmethod\n    def getURI(cls, id):\n        return \"/team/%s\" % id\n\n    def postURI(self):\n        return \"/team\"\n\n    def putURI(self):\n        return \"/team\"\n\n    def deleteURI(self):\n        return \"/team/%s\" % self.id\n\n    def getACLURI(self):\n        return \"/team/%s/acl\" % self.id\n\n    def putACLURI(self):\n        return \"/team/acl\"\n</code></pre>"},{"location":"reference/teams/#synapseclient.team.TeamMember","title":"<code>TeamMember</code>","text":"<p>               Bases: <code>DictObject</code></p> <p>Contains information about a user's membership in a Team. In practice the constructor is not called directly by the client.</p> ATTRIBUTE DESCRIPTION <code>teamId</code> <p>The ID of the team</p> <p> </p> <code>member</code> <p>An object of type org.sagebionetworks.repo.model.UserGroupHeader     describing the member</p> <p> </p> <code>isAdmin</code> <p>Whether the given member is an administrator of the team</p> <p> </p> Source code in <code>synapseclient/team.py</code> <pre><code>class TeamMember(DictObject):\n    \"\"\"\n    Contains information about a user's membership in a Team.\n    In practice the constructor is not called directly by the client.\n\n    Attributes:\n        teamId: The ID of the team\n        member: An object of type [org.sagebionetworks.repo.model.UserGroupHeader](https://rest-docs.synapse.org/rest/org/sagebionetworks/repo/model/UserGroupHeader.html)\n                describing the member\n        isAdmin: Whether the given member is an administrator of the team\n\n    \"\"\"\n\n    def __init__(self, **kwargs):\n        if \"member\" in kwargs:\n            kwargs[\"member\"] = UserGroupHeader(**kwargs[\"member\"])\n        super(TeamMember, self).__init__(kwargs)\n</code></pre>"},{"location":"reference/view_schema/","title":"Entity View Schema","text":""},{"location":"reference/view_schema/#synapseclient.table.EntityViewSchema","title":"<code>synapseclient.table.EntityViewSchema</code>","text":"<p>               Bases: <code>ViewBase</code></p> <p>A EntityViewSchema is a Entity that displays all files/projects (depending on user choice) within a given set of scopes.</p> ATTRIBUTE DESCRIPTION <code>name</code> <p>The name of the Entity View Table object</p> <p> </p> <code>columns</code> <p>(Optional) A list of Column objects or their IDs.</p> <p> </p> <code>parent</code> <p>The project in Synapse to which this table belongs</p> <p> </p> <code>scopes</code> <p>A list of Projects/Folders or their ids</p> <p> </p> <code>type</code> <p>This field is deprecated. Please use <code>includeEntityTypes</code></p> <p> </p> <code>includeEntityTypes</code> <p>A list of entity types to include in the view. Supported entity types are:</p> <ul> <li><code>EntityViewType.FILE</code></li> <li><code>EntityViewType.PROJECT</code></li> <li><code>EntityViewType.TABLE</code></li> <li><code>EntityViewType.FOLDER</code></li> <li><code>EntityViewType.VIEW</code></li> <li><code>EntityViewType.DOCKER</code></li> </ul> <p>If none is provided, the view will default to include <code>EntityViewType.FILE</code>.</p> <p> </p> <code>addDefaultViewColumns</code> <p>If true, adds all default columns (e.g. name, createdOn, modifiedBy etc.)                           Defaults to True.                           The default columns will be added after a call to                           store.</p> <p> </p> <code>addAnnotationColumns</code> <p>If true, adds columns for all annotation keys defined across all Entities in                           the EntityViewSchema's scope. Defaults to True.                           The annotation columns will be added after a call to                           store.</p> <p> </p> <code>ignoredAnnotationColumnNames</code> <p>A list of strings representing annotation names.                           When addAnnotationColumns is True, the names in this list will not be                           automatically added as columns to the EntityViewSchema if they exist in any                           of the defined scopes.</p> <p> </p> <code>properties</code> <p>A map of Synapse properties</p> <p> </p> <code>annotations</code> <p>A map of user defined annotations</p> <p> </p> <code>local_state</code> <p>Internal use only</p> <p> </p> <p>Example:</p> <pre><code>from synapseclient import EntityViewType\n\nproject_or_folder = syn.get(\"syn123\")\nschema = syn.store(EntityViewSchema(name='MyTable', parent=project, scopes=[project_or_folder_id, 'syn123'],\n includeEntityTypes=[EntityViewType.FILE]))\n</code></pre> Source code in <code>synapseclient/table.py</code> <pre><code>class EntityViewSchema(ViewBase):\n    \"\"\"\n    A EntityViewSchema is a [Entity][synapseclient.entity.Entity] that displays all files/projects\n    (depending on user choice) within a given set of scopes.\n\n    Attributes:\n        name:                         The name of the Entity View Table object\n        columns:                      (Optional) A list of [Column][synapseclient.table.Column] objects or their IDs.\n        parent:                       The project in Synapse to which this table belongs\n        scopes:                       A list of Projects/Folders or their ids\n        type:                         This field is deprecated. Please use `includeEntityTypes`\n        includeEntityTypes:           A list of entity types to include in the view. Supported entity types are:\n\n            - `EntityViewType.FILE`\n            - `EntityViewType.PROJECT`\n            - `EntityViewType.TABLE`\n            - `EntityViewType.FOLDER`\n            - `EntityViewType.VIEW`\n            - `EntityViewType.DOCKER`\n\n            If none is provided, the view will default to include `EntityViewType.FILE`.\n        addDefaultViewColumns:        If true, adds all default columns (e.g. name, createdOn, modifiedBy etc.)\n                                      Defaults to True.\n                                      The default columns will be added after a call to\n                                      [store][synapseclient.Synapse.store].\n        addAnnotationColumns:         If true, adds columns for all annotation keys defined across all Entities in\n                                      the EntityViewSchema's scope. Defaults to True.\n                                      The annotation columns will be added after a call to\n                                      [store][synapseclient.Synapse.store].\n        ignoredAnnotationColumnNames: A list of strings representing annotation names.\n                                      When addAnnotationColumns is True, the names in this list will not be\n                                      automatically added as columns to the EntityViewSchema if they exist in any\n                                      of the defined scopes.\n        properties:                   A map of Synapse properties\n        annotations:                  A map of user defined annotations\n        local_state:                  Internal use only\n\n    Example:\n\n        from synapseclient import EntityViewType\n\n        project_or_folder = syn.get(\"syn123\")\n        schema = syn.store(EntityViewSchema(name='MyTable', parent=project, scopes=[project_or_folder_id, 'syn123'],\n         includeEntityTypes=[EntityViewType.FILE]))\n    \"\"\"\n\n    _synapse_entity_type = \"org.sagebionetworks.repo.model.table.EntityView\"\n\n    def __init__(\n        self,\n        name=None,\n        columns=None,\n        parent=None,\n        scopes=None,\n        type=None,\n        includeEntityTypes=None,\n        addDefaultViewColumns=True,\n        addAnnotationColumns=True,\n        ignoredAnnotationColumnNames=[],\n        properties=None,\n        annotations=None,\n        local_state=None,\n        **kwargs,\n    ):\n        if includeEntityTypes:\n            kwargs[\"viewTypeMask\"] = _get_view_type_mask(includeEntityTypes)\n        elif type:\n            kwargs[\"viewTypeMask\"] = _get_view_type_mask_for_deprecated_type(type)\n        elif properties and \"type\" in properties:\n            kwargs[\"viewTypeMask\"] = _get_view_type_mask_for_deprecated_type(\n                properties[\"type\"]\n            )\n            properties[\"type\"] = None\n\n        self.ignoredAnnotationColumnNames = set(ignoredAnnotationColumnNames)\n        super(EntityViewSchema, self).__init__(\n            name=name,\n            columns=columns,\n            properties=properties,\n            annotations=annotations,\n            local_state=local_state,\n            parent=parent,\n            **kwargs,\n        )\n\n        # This is a hacky solution to make sure we don't try to add columns to schemas that we retrieve from synapse\n        is_from_normal_constructor = not (properties or local_state)\n        # allowing annotations because user might want to update annotations all at once\n        self.addDefaultViewColumns = (\n            addDefaultViewColumns and is_from_normal_constructor\n        )\n        self.addAnnotationColumns = addAnnotationColumns and is_from_normal_constructor\n\n        # set default values after constructor so we don't overwrite the values defined in properties using .get()\n        # because properties, unlike local_state, do not have nonexistent keys assigned with a value of None\n        if self.get(\"viewTypeMask\") is None:\n            self.viewTypeMask = EntityViewType.FILE.value\n        if self.get(\"scopeIds\") is None:\n            self.scopeIds = []\n\n        # add the scopes last so that we can append the passed in scopes to those defined in properties\n        if scopes is not None:\n            self.add_scope(scopes)\n\n    def set_entity_types(self, includeEntityTypes):\n        \"\"\"\n        Set entity types\n\n        Arguments:\n            includeEntityTypes: A list of entity types to include in the view. This list will replace the previous\n                                settings. Supported entity types are:\n\n                - `EntityViewType.FILE`\n                - `EntityViewType.PROJECT`\n                - `EntityViewType.TABLE`\n                - `EntityViewType.FOLDER`\n                - `EntityViewType.VIEW`\n                - `EntityViewType.DOCKER`\n        \"\"\"\n        self.viewTypeMask = _get_view_type_mask(includeEntityTypes)\n</code></pre>"},{"location":"reference/view_schema/#synapseclient.table.EntityViewSchema-functions","title":"Functions","text":""},{"location":"reference/view_schema/#synapseclient.table.EntityViewSchema.set_entity_types","title":"<code>set_entity_types(includeEntityTypes)</code>","text":"<p>Set entity types</p> PARAMETER DESCRIPTION <code>includeEntityTypes</code> <p>A list of entity types to include in the view. This list will replace the previous                 settings. Supported entity types are:</p> <ul> <li><code>EntityViewType.FILE</code></li> <li><code>EntityViewType.PROJECT</code></li> <li><code>EntityViewType.TABLE</code></li> <li><code>EntityViewType.FOLDER</code></li> <li><code>EntityViewType.VIEW</code></li> <li><code>EntityViewType.DOCKER</code></li> </ul> <p> </p> Source code in <code>synapseclient/table.py</code> <pre><code>def set_entity_types(self, includeEntityTypes):\n    \"\"\"\n    Set entity types\n\n    Arguments:\n        includeEntityTypes: A list of entity types to include in the view. This list will replace the previous\n                            settings. Supported entity types are:\n\n            - `EntityViewType.FILE`\n            - `EntityViewType.PROJECT`\n            - `EntityViewType.TABLE`\n            - `EntityViewType.FOLDER`\n            - `EntityViewType.VIEW`\n            - `EntityViewType.DOCKER`\n    \"\"\"\n    self.viewTypeMask = _get_view_type_mask(includeEntityTypes)\n</code></pre>"},{"location":"reference/wiki/","title":"Wiki","text":""},{"location":"reference/wiki/#synapseclient.wiki","title":"<code>synapseclient.wiki</code>","text":""},{"location":"reference/wiki/#synapseclient.wiki--wiki","title":"Wiki","text":"<p>A Wiki page requires a title, markdown and an owner object and can also include images.</p>"},{"location":"reference/wiki/#synapseclient.wiki--creating-a-wiki","title":"Creating a Wiki","text":"<pre><code>import synapseclient\nfrom synapseclient import Wiki\n\n## Initialize a Synapse object &amp; authenticate\nsyn = synapseclient.Synapse()\nsyn.login()\n\nentity = syn.get('syn123456')\n\ncontent = \"\"\"\n# My Wiki Page\n\nHere is a description of my **fantastic** project!\n\nAn attached image:\n${image?fileName=logo.png&amp;align=none}\n\"\"\"\n\nwiki = Wiki(title='My Wiki Page',\n            owner=entity,\n            markdown=content,\n            attachments=['/path/to/logo.png'])\n\nwiki = syn.store(wiki)\n</code></pre>"},{"location":"reference/wiki/#synapseclient.wiki--embedding-images","title":"Embedding images","text":"<p>Note that in the above example, we've attached a logo graphic and embedded it in the web page.</p> <p>Figures that are more than just decoration can be stored as Synapse entities allowing versioning and provenance information to be recorded. This is a better choice for figures with data behind them.</p>"},{"location":"reference/wiki/#synapseclient.wiki--updating-a-wiki","title":"Updating a Wiki","text":"<pre><code>import synapseclient\n\n## Initialize a Synapse object &amp; authenticate\nsyn = synapseclient.Synapse()\nsyn.login()\n\nentity = syn.get('syn123456')\nwiki = syn.getWiki(entity)\n\nwiki.markdown = \"\"\"\n# My Wiki Page\n\nHere is a description of my **fantastic** project! Let's\n*emphasize* the important stuff.\n\nAn embedded image that is also a Synapse entity:\n${image?synapseId=syn1824434&amp;align=None&amp;scale=66}\n\nNow we can track it's provenance and keep multiple versions.\n\"\"\"\n\nwiki = syn.store(wiki)\n</code></pre>"},{"location":"reference/wiki/#synapseclient.wiki-classes","title":"Classes","text":""},{"location":"reference/wiki/#synapseclient.wiki.Wiki","title":"<code>Wiki</code>","text":"<p>               Bases: <code>DictObject</code></p> <p>Represents a wiki page in Synapse with content specified in markdown.</p> PARAMETER DESCRIPTION <code>title</code> <p>Title of the Wiki</p> <p> </p> <code>owner</code> <p>Parent Entity that the Wiki will belong to</p> <p> </p> <code>markdown</code> <p>Content of the Wiki (cannot be defined if markdownFile is defined)</p> <p> </p> <code>markdownFile</code> <p>Path to file which contains the Content of Wiki (cannot be defined if markdown is defined)</p> <p> </p> <code>attachments</code> <p>List of paths to files to attach</p> <p> </p> <code>fileHandles</code> <p>List of file handle IDs representing files to be attached</p> <p> </p> <code>parentWikiId</code> <p>(optional) For sub-pages, specify parent wiki page</p> <p> </p> Source code in <code>synapseclient/wiki.py</code> <pre><code>class Wiki(DictObject):\n    \"\"\"\n    Represents a wiki page in Synapse with content specified in markdown.\n\n    Arguments:\n        title: Title of the Wiki\n        owner: Parent Entity that the Wiki will belong to\n        markdown: Content of the Wiki (cannot be defined if markdownFile is defined)\n        markdownFile: Path to file which contains the Content of Wiki (cannot be defined if markdown is defined)\n        attachments: List of paths to files to attach\n        fileHandles: List of file handle IDs representing files to be attached\n        parentWikiId: (optional) For sub-pages, specify parent wiki page\n    \"\"\"\n\n    __PROPERTIES = (\n        \"title\",\n        \"markdown\",\n        \"attachmentFileHandleIds\",\n        \"id\",\n        \"etag\",\n        \"createdBy\",\n        \"createdOn\",\n        \"modifiedBy\",\n        \"modifiedOn\",\n        \"parentWikiId\",\n    )\n\n    def __init__(self, **kwargs):\n        # Verify that the parameters are correct\n        if \"owner\" not in kwargs:\n            raise ValueError(\"Wiki constructor must have an owner specified\")\n\n        # Initialize the file handle list to be an empty list\n        if \"attachmentFileHandleIds\" not in kwargs:\n            kwargs[\"attachmentFileHandleIds\"] = []\n\n        # update the markdown\n        self.update_markdown(\n            kwargs.pop(\"markdown\", None), kwargs.pop(\"markdownFile\", None)\n        )\n\n        # Move the 'fileHandles' into the proper (wordier) bucket\n        if \"fileHandles\" in kwargs:\n            for handle in kwargs[\"fileHandles\"]:\n                kwargs[\"attachmentFileHandleIds\"].append(handle)\n            del kwargs[\"fileHandles\"]\n\n        super(Wiki, self).__init__(kwargs)\n        self.ownerId = id_of(self.owner)\n        del self[\"owner\"]\n\n    def json(self):\n        \"\"\"Returns the JSON representation of the Wiki object.\"\"\"\n        return json.dumps({k: v for k, v in self.items() if k in self.__PROPERTIES})\n\n    def getURI(self):\n        \"\"\"For internal use.\"\"\"\n\n        return \"/entity/%s/wiki/%s\" % (self.ownerId, self.id)\n\n    def postURI(self):\n        \"\"\"For internal use.\"\"\"\n\n        return \"/entity/%s/wiki\" % self.ownerId\n\n    def putURI(self):\n        \"\"\"For internal use.\"\"\"\n\n        return \"/entity/%s/wiki/%s\" % (self.ownerId, self.id)\n\n    def deleteURI(self):\n        \"\"\"For internal use.\"\"\"\n\n        return \"/entity/%s/wiki/%s\" % (self.ownerId, self.id)\n\n    def update_markdown(self, markdown=None, markdown_file=None):\n        \"\"\"\n        Updates the wiki's markdown. Specify only one of markdown or markdown_file\n\n        Arguments:\n            markdown: text that will become the markdown\n            markdown_file: path to a file. Its contents will be the markdown\n        \"\"\"\n        if markdown and markdown_file:\n            raise ValueError(\"Please use only one argument: markdown or markdownFile\")\n\n        if markdown_file:\n            # pop the 'markdownFile' kwargs because we don't actually need it in the dictionary to upload to synapse\n            markdown_path = os.path.expandvars(os.path.expanduser(markdown_file))\n            if not os.path.isfile(markdown_path):\n                raise ValueError(markdown_file + \"is not a valid file\")\n            with open(markdown_path, \"r\") as opened_markdown_file:\n                markdown = opened_markdown_file.read()\n\n        self[\"markdown\"] = markdown\n</code></pre>"},{"location":"reference/wiki/#synapseclient.wiki.Wiki-functions","title":"Functions","text":""},{"location":"reference/wiki/#synapseclient.wiki.Wiki.json","title":"<code>json()</code>","text":"<p>Returns the JSON representation of the Wiki object.</p> Source code in <code>synapseclient/wiki.py</code> <pre><code>def json(self):\n    \"\"\"Returns the JSON representation of the Wiki object.\"\"\"\n    return json.dumps({k: v for k, v in self.items() if k in self.__PROPERTIES})\n</code></pre>"},{"location":"reference/wiki/#synapseclient.wiki.Wiki.getURI","title":"<code>getURI()</code>","text":"<p>For internal use.</p> Source code in <code>synapseclient/wiki.py</code> <pre><code>def getURI(self):\n    \"\"\"For internal use.\"\"\"\n\n    return \"/entity/%s/wiki/%s\" % (self.ownerId, self.id)\n</code></pre>"},{"location":"reference/wiki/#synapseclient.wiki.Wiki.postURI","title":"<code>postURI()</code>","text":"<p>For internal use.</p> Source code in <code>synapseclient/wiki.py</code> <pre><code>def postURI(self):\n    \"\"\"For internal use.\"\"\"\n\n    return \"/entity/%s/wiki\" % self.ownerId\n</code></pre>"},{"location":"reference/wiki/#synapseclient.wiki.Wiki.putURI","title":"<code>putURI()</code>","text":"<p>For internal use.</p> Source code in <code>synapseclient/wiki.py</code> <pre><code>def putURI(self):\n    \"\"\"For internal use.\"\"\"\n\n    return \"/entity/%s/wiki/%s\" % (self.ownerId, self.id)\n</code></pre>"},{"location":"reference/wiki/#synapseclient.wiki.Wiki.deleteURI","title":"<code>deleteURI()</code>","text":"<p>For internal use.</p> Source code in <code>synapseclient/wiki.py</code> <pre><code>def deleteURI(self):\n    \"\"\"For internal use.\"\"\"\n\n    return \"/entity/%s/wiki/%s\" % (self.ownerId, self.id)\n</code></pre>"},{"location":"reference/wiki/#synapseclient.wiki.Wiki.update_markdown","title":"<code>update_markdown(markdown=None, markdown_file=None)</code>","text":"<p>Updates the wiki's markdown. Specify only one of markdown or markdown_file</p> PARAMETER DESCRIPTION <code>markdown</code> <p>text that will become the markdown</p> <p> DEFAULT: <code>None</code> </p> <code>markdown_file</code> <p>path to a file. Its contents will be the markdown</p> <p> DEFAULT: <code>None</code> </p> Source code in <code>synapseclient/wiki.py</code> <pre><code>def update_markdown(self, markdown=None, markdown_file=None):\n    \"\"\"\n    Updates the wiki's markdown. Specify only one of markdown or markdown_file\n\n    Arguments:\n        markdown: text that will become the markdown\n        markdown_file: path to a file. Its contents will be the markdown\n    \"\"\"\n    if markdown and markdown_file:\n        raise ValueError(\"Please use only one argument: markdown or markdownFile\")\n\n    if markdown_file:\n        # pop the 'markdownFile' kwargs because we don't actually need it in the dictionary to upload to synapse\n        markdown_path = os.path.expandvars(os.path.expanduser(markdown_file))\n        if not os.path.isfile(markdown_path):\n            raise ValueError(markdown_file + \"is not a valid file\")\n        with open(markdown_path, \"r\") as opened_markdown_file:\n            markdown = opened_markdown_file.read()\n\n    self[\"markdown\"] = markdown\n</code></pre>"},{"location":"reference/wiki/#synapseclient.wiki.WikiAttachment","title":"<code>WikiAttachment</code>","text":"<p>               Bases: <code>DictObject</code></p> <p>Represents a wiki page attachment.</p> Source code in <code>synapseclient/wiki.py</code> <pre><code>class WikiAttachment(DictObject):\n    \"\"\"Represents a wiki page attachment.\"\"\"\n\n    __PROPERTIES = (\"contentType\", \"fileName\", \"contentMd5\", \"contentSize\")\n\n    def __init__(self, **kwargs):\n        super(WikiAttachment, self).__init__(**kwargs)\n</code></pre>"},{"location":"reference/wiki/#synapseclient.wiki-functions","title":"Functions","text":""},{"location":"reference/oop/models/","title":"Object-Orientated Models","text":"<p>Contained within this file are experimental interfaces for working with the Synapse Python Client. Unless otherwise noted these interfaces are subject to change at any time. Use at your own risk.</p>"},{"location":"reference/oop/models/#sample-scripts","title":"Sample Scripts:","text":"Working with a project <pre><code>\"\"\"\nExpects that ~/temp exists and is a directory.\n\nThe purpose of this script is to demonstrate how to use the new OOP interface for projects.\nThe following actions are shown in this script:\n1. Creating a project\n2. Retrieving a project by id or name\n3. Upserting data on a project\n4. Storing several files to a project\n5. Storing several folders in a project\n6. Updating the annotations in bulk for a number of folders and files\n7. Downloading an entire project structure to disk\n8. Copy a project and all content to a new project\n9. Deleting a project\n\"\"\"\n\nimport os\nimport uuid\nfrom datetime import date, datetime, timedelta, timezone\n\nimport synapseclient\nfrom synapseclient.models import File, Folder, Project\n\nsyn = synapseclient.Synapse(debug=True)\nsyn.login()\n\n\ndef create_random_file(\n    path: str,\n) -&gt; None:\n    \"\"\"Create a random file with random data.\"\"\"\n    with open(path, \"wb\") as f:\n        f.write(os.urandom(1))\n\n\ndef store_project():\n    # Creating annotations for my project ==================================================\n    my_annotations = {\n        \"my_single_key_string\": \"a\",\n        \"my_key_string\": [\"b\", \"a\", \"c\"],\n        \"my_key_bool\": [False, False, False],\n        \"my_key_double\": [1.2, 3.4, 5.6],\n        \"my_key_long\": [1, 2, 3],\n        \"my_key_date\": [date.today(), date.today() - timedelta(days=1)],\n        \"my_key_datetime\": [\n            datetime.today(),\n            datetime.today() - timedelta(days=1),\n            datetime.now(tz=timezone(timedelta(hours=-5))),\n            datetime(2023, 12, 7, 13, 0, 0, tzinfo=timezone(timedelta(hours=0))),\n            datetime(2023, 12, 7, 13, 0, 0, tzinfo=timezone(timedelta(hours=-7))),\n        ],\n        \"annotation_i_want_to_delete\": \"I want to delete this annotation\",\n    }\n\n    # 1) Creating a project ==============================================================\n    project = Project(\n        name=\"my_new_project_for_testing\",\n        annotations=my_annotations,\n        description=\"This is a project with random data.\",\n        alias=\"my_project_alias_\" + str(uuid.uuid4()).replace(\"-\", \"_\"),\n    )\n\n    project = project.store()\n\n    print(f\"Project created with id: {project.id}\")\n\n    # 2) Retrieving a project by id or name ==============================================\n    project = Project(name=\"my_new_project_for_testing\").get()\n    print(f\"Project retrieved by name: {project.name} with id: {project.id}\")\n\n    project = Project(id=project.id).get()\n    print(f\"Project retrieved by id: {project.name} with id: {project.id}\")\n\n    # 3) Upserting data on a project =====================================================\n    # When you have not already use `.store()` or `.get()` on a project any updates will\n    # be a non-destructive upsert. This means that if the project does not exist it will\n    # be created, if it does exist it will be updated.\n    project = Project(\n        name=\"my_new_project_for_testing\", description=\"my new description\"\n    ).store()\n    print(f\"Project description updated to {project.description}\")\n\n    # After the instance has interacted with Synapse any changes will be destructive,\n    # meaning changes in the data will act as a replacement instead of an addition.\n    print(f\"Annotations before update: {project.annotations}\")\n    del project.annotations[\"annotation_i_want_to_delete\"]\n    project = project.store()\n    print(f\"Annotations after update: {project.annotations}\")\n\n    # 4) Storing several files to a project ==============================================\n    files_to_store = []\n    for loop in range(1, 10):\n        name_of_file = f\"my_file_with_random_data_{loop}.txt\"\n        path_to_file = os.path.join(os.path.expanduser(\"~/temp\"), name_of_file)\n        create_random_file(path_to_file)\n\n        file = File(\n            path=path_to_file,\n            name=name_of_file,\n            annotations=my_annotations,\n        )\n        files_to_store.append(file)\n    project.files = files_to_store\n    project = project.store()\n\n    # 5) Storing several folders in a project ============================================\n    folders_to_store = []\n    for loop in range(1, 10):\n        folder_to_store = Folder(\n            name=f\"my_folder_for_this_project_{loop}\",\n            annotations=my_annotations,\n        )\n        folders_to_store.append(folder_to_store)\n    project.folders = folders_to_store\n    print(\n        f\"Storing project ({project.id}) with {len(project.folders)} folders and {len(project.files)} files\"\n    )\n    project = project.store()\n\n    # 6) Updating the annotations in bulk for a number of folders and files ==============\n    project_copy = Project(id=project.id).sync_from_synapse(download_file=False)\n\n    print(\n        f\"Found {len(project_copy.files)} files and {len(project_copy.folders)} folder at the root level for {project_copy.name} with id: {project_copy.id}\"\n    )\n\n    new_annotations = {\n        \"my_new_key_string\": [\"b\", \"a\", \"c\"],\n    }\n\n    for file in project_copy.files:\n        file.annotations = new_annotations\n\n    for folder in project_copy.folders:\n        folder.annotations = new_annotations\n\n    project_copy.store()\n\n    # 7) Downloading an entire project structure to disk =================================\n    print(f\"Downloading project ({project.id}) to ~/temp\")\n    Project(id=project.id).sync_from_synapse(\n        download_file=True, path=\"~/temp/recursiveDownload\", recursive=True\n    )\n\n    # 8) Copy a project and all content to a new project =================================\n    project_to_delete = Project(\n        name=\"my_new_project_I_want_to_delete_\" + str(uuid.uuid4()).replace(\"-\", \"_\"),\n    ).store()\n    print(f\"Project created with id: {project_to_delete.id}\")\n\n    project_to_delete = project.copy(destination_id=project_to_delete.id)\n    print(\n        f\"Copied to new project, copied {len(project_to_delete.folders)} folders and {len(project_to_delete.files)} files\"\n    )\n\n    # 9) Deleting a project ==============================================================\n    project_to_delete.delete()\n    print(f\"Project with id: {project_to_delete.id} deleted\")\n\n\nstore_project()\n</code></pre> Working with folders <pre><code>\"\"\"\nExpects that ~/temp exists and is a directory.\n\nThe purpose of this script is to demonstrate how to use the new OOP interface for folders.\nThe following actions are shown in this script:\n1. Creating a folder\n2. Storing a folder to a project\n3. Storing several files to a folder\n4. Storing several folders in a folder\n5. Getting metadata about a folder and it's immediate children\n6. Updating the annotations in bulk for a number of folders and files\n7. Deleting a folder\n8. Copying a folder\n9. Moving a folder\n10. Using sync_from_synapse to download the files and folders\n\"\"\"\n\nimport os\nfrom datetime import date, datetime, timedelta, timezone\n\nimport synapseclient\nfrom synapseclient.models import File, Folder\n\nPROJECT_ID = \"syn52948289\"\n\nsyn = synapseclient.Synapse(debug=True)\nsyn.login()\n\n\ndef create_random_file(\n    path: str,\n) -&gt; None:\n    \"\"\"Create a random file with random data.\n\n    :param path: The path to create the file at.\n    \"\"\"\n    with open(path, \"wb\") as f:\n        f.write(os.urandom(1))\n\n\ndef try_delete_folder(folder_name: str, parent_id: str) -&gt; None:\n    \"\"\"Simple try catch to delete a folder.\"\"\"\n    try:\n        Folder(name=folder_name, parent_id=parent_id).get().delete()\n    except Exception:\n        pass\n\n\ndef store_folder():\n    # Clean up synapse for previous runs:\n    try_delete_folder(\"my_new_folder_for_this_project\", PROJECT_ID)\n    try_delete_folder(\"destination_for_copy\", PROJECT_ID)\n    try_delete_folder(\"my_new_folder_for_this_project_I_want_to_delete\", PROJECT_ID)\n\n    # Creating annotations for my folder ==================================================\n    annotations_for_my_folder = {\n        \"my_single_key_string\": \"a\",\n        \"my_key_string\": [\"b\", \"a\", \"c\"],\n        \"my_key_bool\": [False, False, False],\n        \"my_key_double\": [1.2, 3.4, 5.6],\n        \"my_key_long\": [1, 2, 3],\n        \"my_key_date\": [date.today(), date.today() - timedelta(days=1)],\n        \"my_key_datetime\": [\n            datetime.today(),\n            datetime.today() - timedelta(days=1),\n            datetime.now(tz=timezone(timedelta(hours=-5))),\n            datetime(2023, 12, 7, 13, 0, 0, tzinfo=timezone(timedelta(hours=0))),\n            datetime(2023, 12, 7, 13, 0, 0, tzinfo=timezone(timedelta(hours=-7))),\n        ],\n    }\n\n    # 1) Creating a folder ===============================================================\n    root_folder_for_my_project = Folder(\n        name=\"my_new_folder_for_this_project\",\n        annotations=annotations_for_my_folder,\n        parent_id=PROJECT_ID,\n        description=\"This is a folder with random data.\",\n    )\n\n    root_folder_for_my_project = root_folder_for_my_project.store()\n\n    print(\n        f\"Folder created: {root_folder_for_my_project.name} with id: {root_folder_for_my_project.id}\"\n    )\n\n    # 2) Updating and storing an annotation ==============================================\n    new_folder_instance = Folder(id=root_folder_for_my_project.id).get()\n    new_folder_instance.annotations[\"my_key_string\"] = [\"new\", \"values\", \"here\"]\n    stored_folder = new_folder_instance.store()\n    print(f\"Folder {stored_folder.name} updated with new annotations:\")\n    print(stored_folder.annotations)\n\n    # 3) Storing several files to a folder ===============================================\n    files_to_store = []\n    for loop in range(1, 10):\n        name_of_file = f\"my_file_with_random_data_{loop}.txt\"\n        path_to_file = os.path.join(os.path.expanduser(\"~/temp\"), name_of_file)\n        create_random_file(path_to_file)\n\n        file = File(\n            path=path_to_file,\n            name=name_of_file,\n        )\n        files_to_store.append(file)\n    root_folder_for_my_project.files = files_to_store\n    root_folder_for_my_project = root_folder_for_my_project.store()\n\n    # 4) Storing several folders in a folder =============================================\n    folders_to_store = []\n    for loop in range(1, 10):\n        folder_to_store = Folder(\n            name=f\"my_new_folder_for_this_project_{loop}\",\n        )\n        folders_to_store.append(folder_to_store)\n    root_folder_for_my_project.folders = folders_to_store\n    root_folder_for_my_project = root_folder_for_my_project.store()\n\n    # 5) Getting metadata about a folder and it's immediate children =====================\n    new_folder_instance = Folder(id=root_folder_for_my_project.id).sync_from_synapse(\n        download_file=False, recursive=False\n    )\n\n    print(f\"Synced folder {new_folder_instance.name} from synapse\")\n    for file in new_folder_instance.files:\n        print(f\"Found File in Synapse at: {new_folder_instance.name}/{file.name}\")\n\n    for folder in new_folder_instance.folders:\n        print(f\"Found Folder in Synapse at: {new_folder_instance.name}/{folder.name}\")\n\n    # 6) Updating the annotations in bulk for a number of folders and files ==============\n    new_annotations = {\n        \"my_new_key_string\": [\"b\", \"a\", \"c\"],\n    }\n\n    for file in new_folder_instance.files:\n        file.annotations = new_annotations\n\n    for folder in new_folder_instance.folders:\n        folder.annotations = new_annotations\n\n    new_folder_instance.store()\n\n    # 7) Deleting a folder ===============================================================\n    folder_to_delete = Folder(\n        name=\"my_new_folder_for_this_project_I_want_to_delete\",\n        parent_id=PROJECT_ID,\n    ).store()\n\n    folder_to_delete.delete()\n\n    # 8) Copying a folder ===============================================================\n    destination_folder_to_copy_to = Folder(\n        name=\"destination_for_copy\", parent_id=PROJECT_ID\n    ).store()\n    coped_folder = root_folder_for_my_project.copy(\n        parent_id=destination_folder_to_copy_to.id\n    )\n\n    print(\n        f\"Copied folder from {root_folder_for_my_project.id} to {coped_folder.id} in synapse\"\n    )\n\n    # You'll also see all the files/folders were copied too\n    for file in coped_folder.files:\n        print(f\"Found (copied) File in Synapse at: {coped_folder.name}/{file.name}\")\n\n    for folder in coped_folder.folders:\n        print(f\"Found (copied) Folder in Synapse at: {coped_folder.name}/{folder.name}\")\n\n    # 9) Moving a folder ===============================================================\n    folder_i_am_going_to_move = Folder(\n        name=\"folder_i_am_going_to_move\", parent_id=PROJECT_ID\n    ).store()\n    current_parent_id = folder_i_am_going_to_move.parent_id\n    folder_i_am_going_to_move.parent_id = destination_folder_to_copy_to.id\n    folder_i_am_going_to_move.store()\n    print(\n        f\"Moved folder from {current_parent_id} to {folder_i_am_going_to_move.parent_id}\"\n    )\n\n    # 10) Using sync_from_synapse to download the files and folders ======================\n    # This will download all the files and folders in the folder to the local file system\n    path_to_download = os.path.expanduser(\"~/temp/recursiveDownload\")\n    if not os.path.exists(path_to_download):\n        os.mkdir(path_to_download)\n    root_folder_for_my_project.sync_from_synapse(path=path_to_download)\n\n\nstore_folder()\n</code></pre> Working with files <pre><code>\"\"\"\nExpects that ~/temp exists and is a directory.\n\nThe purpose of this script is to demonstrate how to use the new OOP interface for files.\nThe following actions are shown in this script:\n1. Creating a file\n2. Storing a file\n3. Storing a file in a sub-folder\n4. Renaming a file\n5. Downloading a file\n6. Deleting a file\n7. Copying a file\n8. Storing an activity to a file\n9. Retrieve an activity from a file\n\"\"\"\n\nimport os\nfrom datetime import date, datetime, timedelta, timezone\n\nimport synapseclient\nfrom synapseclient.core import utils\nfrom synapseclient.models import Activity, File, Folder, UsedEntity, UsedURL\n\nPROJECT_ID = \"syn52948289\"\n\nsyn = synapseclient.Synapse(debug=True)\nsyn.login()\n\n\ndef create_random_file(\n    path: str,\n) -&gt; None:\n    \"\"\"Create a random file with random data.\n\n    :param path: The path to create the file at.\n    \"\"\"\n    with open(path, \"wb\") as f:\n        f.write(os.urandom(1))\n\n\ndef store_file():\n    # Cleanup synapse for previous runs - Does not delete local files/directories:\n    try:\n        Folder(name=\"file_script_folder\", parent_id=PROJECT_ID).get().delete()\n    except Exception:\n        pass\n    if not os.path.exists(os.path.expanduser(\"~/temp/myNewFolder\")):\n        os.mkdir(os.path.expanduser(\"~/temp/myNewFolder\"))\n\n    script_file_folder = Folder(name=\"file_script_folder\", parent_id=PROJECT_ID).store()\n\n    # Creating annotations for my file ==================================================\n    annotations_for_my_file = {\n        \"my_single_key_string\": \"a\",\n        \"my_key_string\": [\"b\", \"a\", \"c\"],\n        \"my_key_bool\": [False, False, False],\n        \"my_key_double\": [1.2, 3.4, 5.6],\n        \"my_key_long\": [1, 2, 3],\n        \"my_key_date\": [date.today(), date.today() - timedelta(days=1)],\n        \"my_key_datetime\": [\n            datetime.today(),\n            datetime.today() - timedelta(days=1),\n            datetime.now(tz=timezone(timedelta(hours=-5))),\n            datetime(2023, 12, 7, 13, 0, 0, tzinfo=timezone(timedelta(hours=0))),\n            datetime(2023, 12, 7, 13, 0, 0, tzinfo=timezone(timedelta(hours=-7))),\n        ],\n    }\n\n    name_of_file = \"file_script_my_file_with_random_data.txt\"\n    path_to_file = os.path.join(os.path.expanduser(\"~/temp\"), name_of_file)\n    create_random_file(path_to_file)\n\n    # 1. Creating a file =================================================================\n    file = File(\n        path=path_to_file,\n        annotations=annotations_for_my_file,\n        parent_id=script_file_folder.id,\n        description=\"This is a file with random data.\",\n    )\n\n    # 2. Storing a file ==================================================================\n    file = file.store()\n\n    print(f\"File created: ID: {file.id}, Parent ID: {file.parent_id}\")\n\n    name_of_file = \"file_in_a_sub_folder.txt\"\n    path_to_file = os.path.join(os.path.expanduser(\"~/temp\"), name_of_file)\n    create_random_file(path_to_file)\n\n    # 3. Storing a file to a sub-folder ==================================================\n    script_sub_folder = Folder(\n        name=\"file_script_sub_folder\", parent_id=script_file_folder.id\n    ).store()\n    file_in_a_sub_folder = File(\n        path=path_to_file,\n        annotations=annotations_for_my_file,\n        parent_id=script_sub_folder.id,\n        description=\"This is a file with random data.\",\n    )\n    file_in_a_sub_folder = file_in_a_sub_folder.store()\n\n    print(\n        f\"File created in sub folder: ID: {file_in_a_sub_folder.id}, Parent ID: {file_in_a_sub_folder.parent_id}\"\n    )\n\n    # 4. Renaming a file =================================================================\n    name_of_file = \"file_script_my_file_to_rename.txt\"\n    path_to_file = os.path.join(os.path.expanduser(\"~/temp\"), name_of_file)\n    create_random_file(path_to_file)\n\n    # The name of the entity, and the name of the file is disjointed.\n    # For example, the name of the file is \"file_script_my_file_to_rename.txt\"\n    # and the name of the entity is \"this_name_is_different\"\n    file: File = File(\n        path=path_to_file,\n        name=\"this_name_is_different\",\n        parent_id=script_file_folder.id,\n    ).store()\n    print(f\"File created with name: {file.name}\")\n    print(f\"The path of the file is: {file.path}\")\n\n    # You can change the name of the entity without changing the name of the file.\n    file.name = \"modified_name_attribute\"\n    file.store()\n    print(f\"File renamed to: {file.name}\")\n\n    # You can then change the name of the file that would be downloaded like:\n    file.change_metadata(download_as=\"new_name_for_downloading.txt\")\n    print(f\"File download values changed to: {file.file_handle.file_name}\")\n\n    # 5. Downloading a file ===============================================================\n    # Downloading a file to a location has a default beahvior of \"keep.both\"\n    downloaded_file = File(\n        id=file.id, download_location=os.path.expanduser(\"~/temp/myNewFolder\")\n    ).get()\n    print(f\"Downloaded file: {downloaded_file.path}\")\n\n    # I can also specify how collisions are handled when downloading a file.\n    # This will replace the file on disk if it already exists and is different (after).\n    path_to_file = downloaded_file.path\n    create_random_file(path_to_file)\n    print(f\"Before file md5: {utils.md5_for_file(path_to_file).hexdigest()}\")\n    downloaded_file = File(\n        id=downloaded_file.id,\n        download_location=os.path.expanduser(\"~/temp/myNewFolder\"),\n        if_collision=\"overwrite.local\",\n    ).get()\n    print(f\"After file md5: {utils.md5_for_file(path_to_file).hexdigest()}\")\n\n    # This will keep the file on disk (before), and no file is downloaded\n    path_to_file = downloaded_file.path\n    create_random_file(path_to_file)\n    print(f\"Before file md5: {utils.md5_for_file(path_to_file).hexdigest()}\")\n    downloaded_file = File(\n        id=downloaded_file.id,\n        download_location=os.path.expanduser(\"~/temp/myNewFolder\"),\n        if_collision=\"keep.local\",\n    ).get()\n    print(f\"After file md5: {utils.md5_for_file(path_to_file).hexdigest()}\")\n\n    # 6. Deleting a file =================================================================\n    # Suppose I have a file that I want to delete.\n    name_of_file = \"file_to_delete.txt\"\n    path_to_file = os.path.join(os.path.expanduser(\"~/temp\"), name_of_file)\n    create_random_file(path_to_file)\n    file_to_delete = File(path=path_to_file, parent_id=script_file_folder.id).store()\n    file_to_delete.delete()\n\n    # 7. Copying a file ===================================================================\n    print(\n        f\"File I am going to copy: ID: {file_in_a_sub_folder.id}, Parent ID: {file_in_a_sub_folder.parent_id}\"\n    )\n    new_sub_folder = Folder(\n        name=\"sub_sub_folder\", parent_id=script_file_folder.id\n    ).store()\n    copied_file_instance = file_in_a_sub_folder.copy(parent_id=new_sub_folder.id)\n    print(\n        f\"File I copied: ID: {copied_file_instance.id}, Parent ID: {copied_file_instance.parent_id}\"\n    )\n\n    # 8. Storing an activity to a file =====================================================\n    activity = Activity(\n        name=\"some_name\",\n        description=\"some_description\",\n        used=[\n            UsedURL(name=\"example\", url=\"https://www.synapse.org/\"),\n            UsedEntity(target_id=\"syn456\", target_version_number=1),\n        ],\n        executed=[\n            UsedURL(name=\"example\", url=\"https://www.synapse.org/\"),\n            UsedEntity(target_id=\"syn789\", target_version_number=1),\n        ],\n    )\n\n    name_of_file = \"file_with_an_activity.txt\"\n    path_to_file = os.path.join(os.path.expanduser(\"~/temp\"), name_of_file)\n    create_random_file(path_to_file)\n    file_with_activity = File(\n        path=path_to_file, parent_id=script_file_folder.id, activity=activity\n    ).store()\n    print(file_with_activity.activity)\n\n    # 9. When I am retrieving that file later on I can get the activity like =============\n    # By also specifying download_file=False, I can get the activity without downloading the file.\n    new_file_with_activity_instance = File(\n        id=file_with_activity.id, download_file=False\n    ).get(include_activity=True)\n    print(new_file_with_activity_instance.activity)\n\n\nstore_file()\n</code></pre> Working with tables <pre><code>\"\"\"The purpose of this script is to demonstrate how to use the new OOP interface for tables.\nThe following actions are shown in this script:\n1. Creating a table\n2. Storing a table\n3. Getting a table\n4. Storing rows in a table\n5. Querying for data from a table\n6. Deleting a row from a table\n7. Deleting a table\n\"\"\"\n\nimport csv\nimport os\nimport random\nimport string\nfrom datetime import date, datetime, timedelta, timezone\n\nimport synapseclient\nfrom synapseclient.models import Column, ColumnType, CsvResultFormat, Row, Table\n\nPROJECT_ID = \"syn52948289\"\n\nsyn = synapseclient.Synapse(debug=True)\nsyn.login()\n\n\ndef write_random_csv_with_data(path: str):\n    randomized_data_columns = {\n        \"my_string_column\": str,\n        \"my_integer_column\": int,\n        \"my_double_column\": float,\n        \"my_boolean_column\": bool,\n    }\n\n    # Generate randomized data\n    data = {}\n    for name, type in randomized_data_columns.items():\n        if type == int:\n            data[name] = [random.randint(0, 100) for _ in range(10)]\n        elif type == float:\n            data[name] = [random.uniform(0, 100) for _ in range(10)]\n        elif type == bool:\n            data[name] = [bool(random.getrandbits(1)) for _ in range(10)]\n        elif type == str:\n            data[name] = [\n                \"\".join(random.choices(string.ascii_uppercase + string.digits, k=5))\n                for _ in range(10)\n            ]\n\n    with open(path, \"w\", newline=\"\", encoding=\"utf-8\") as csvfile:\n        writer = csv.writer(csvfile)\n\n        # Write column names\n        writer.writerow(data.keys())\n\n        # Write data\n        for i in range(10):\n            writer.writerow([values[i] for values in data.values()])\n\n\ndef store_table():\n    # Creating annotations for my table ==================================================\n    annotations_for_my_table = {\n        \"my_single_key_string\": \"a\",\n        \"my_key_string\": [\"b\", \"a\", \"c\"],\n        \"my_key_bool\": [False, False, False],\n        \"my_key_double\": [1.2, 3.4, 5.6],\n        \"my_key_long\": [1, 2, 3],\n        \"my_key_date\": [date.today(), date.today() - timedelta(days=1)],\n        \"my_key_datetime\": [\n            datetime.today(),\n            datetime.today() - timedelta(days=1),\n            datetime.now(tz=timezone(timedelta(hours=-5))),\n            datetime(2023, 12, 7, 13, 0, 0, tzinfo=timezone(timedelta(hours=0))),\n            datetime(2023, 12, 7, 13, 0, 0, tzinfo=timezone(timedelta(hours=-7))),\n        ],\n    }\n\n    # Creating columns for my table ======================================================\n    columns = [\n        Column(id=None, name=\"my_string_column\", column_type=ColumnType.STRING),\n        Column(id=None, name=\"my_integer_column\", column_type=ColumnType.INTEGER),\n        Column(id=None, name=\"my_double_column\", column_type=ColumnType.DOUBLE),\n        Column(id=None, name=\"my_boolean_column\", column_type=ColumnType.BOOLEAN),\n    ]\n\n    # Creating a table ===============================================================\n    table = Table(\n        name=\"my_first_test_table\",\n        columns=columns,\n        parent_id=PROJECT_ID,\n        annotations=annotations_for_my_table,\n    )\n\n    table = table.store_schema()\n\n    print(\"Table created:\")\n    print(table)\n\n    # Getting a table =================================================================\n    copy_of_table = Table(id=table.id)\n\n    copy_of_table = copy_of_table.get()\n\n    print(\"Table retrieved:\")\n    print(copy_of_table)\n\n    # Updating annotations on my table ===============================================\n    copy_of_table.annotations[\"my_key_string\"] = [\"new\", \"values\", \"here\"]\n    stored_table = copy_of_table.store_schema()\n    print(\"Table updated:\")\n    print(stored_table)\n\n    # Storing data to a table =========================================================\n    name_of_csv = \"my_csv_file_with_random_data\"\n    path_to_csv = os.path.join(os.path.expanduser(\"~/temp\"), f\"{name_of_csv}.csv\")\n    write_random_csv_with_data(path_to_csv)\n\n    csv_path = copy_of_table.store_rows_from_csv(csv_path=path_to_csv)\n\n    print(\"Stored data to table from CSV:\")\n    print(csv_path)\n\n    # Querying for data from a table =================================================\n    destination_csv_location = os.path.expanduser(\"~/temp/my_query_results\")\n\n    table_id_to_query = copy_of_table.id\n    Table.query(\n        query=f\"SELECT * FROM {table_id_to_query}\",\n        result_format=CsvResultFormat(download_location=destination_csv_location),\n    )\n\n    print(f\"Created results at: {destination_csv_location}\")\n\n    # Deleting rows from a table =====================================================\n    copy_of_table.delete_rows(rows=[Row(row_id=1)])\n\n    # Deleting a table ===============================================================\n    table_to_delete = Table(\n        name=\"my_test_table_I_want_to_delete\",\n        columns=columns,\n        parent_id=PROJECT_ID,\n    ).store_schema()\n\n    table_to_delete.delete()\n\n\nstore_table()\n</code></pre> Current Synapse interface for working with a project <pre><code>\"\"\"The purpose of this script is to demonstrate how to use the current synapse interface for projects.\nThe following actions are shown in this script:\n1. Creating a project\n2. Getting metadata about a project\n3. Storing several files to a project\n4. Storing several folders in a project with a file in each folder\n5. Updating the annotations in bulk for a number of folders and files\n6. Using synapseutils to sync a project from and to synapse\n7. Deleting a project\n\nAll steps also include setting a number of annotations for the objects.\n\"\"\"\nimport os\nimport uuid\nfrom datetime import datetime, timedelta, timezone\n\nimport synapseclient\nimport synapseutils\nfrom synapseclient import Annotations, File, Folder, Project\n\nsyn = synapseclient.Synapse(debug=True)\nsyn.login()\n\n\ndef create_random_file(\n    path: str,\n) -&gt; None:\n    \"\"\"Create a random file with random data.\n\n    :param path: The path to create the file at.\n    \"\"\"\n    with open(path, \"wb\") as f:\n        f.write(os.urandom(1))\n\n\n# Creating annotations for my project ==================================================\nmy_annotations_dict = {\n    \"my_key_string\": [\"b\", \"a\", \"c\"],\n    \"my_key_bool\": [False, False, False],\n    \"my_key_double\": [1.2, 3.4, 5.6],\n    \"my_key_long\": [1, 2, 3],\n    \"my_key_timestamp\": [\n        datetime.today(),\n        datetime.today() - timedelta(days=1),\n        datetime.now(tz=timezone(timedelta(hours=-5))),\n        datetime(2023, 12, 7, 13, 0, 0, tzinfo=timezone(timedelta(hours=0))),\n        datetime(2023, 12, 7, 13, 0, 0, tzinfo=timezone(timedelta(hours=-7))),\n    ],\n}\n\n# Creating a project =====================================================================\nproject = Project(\n    name=\"my_new_project_for_testing_synapse_client\",\n    annotations=my_annotations_dict,\n    description=\"This is a project with random data.\",\n)\n\nmy_stored_project: Project = syn.store(project)\n\nprint(my_stored_project)\n\n# Getting metadata about a project =======================================================\nmy_project = syn.get(entity=my_stored_project.id)\nprint(my_project)\n\n# Storing several files to a project =====================================================\nfor loop in range(1, 10):\n    name_of_file = f\"my_file_with_random_data_{loop}.txt\"\n    path_to_file = os.path.join(os.path.expanduser(\"~/temp\"), name_of_file)\n    create_random_file(path_to_file)\n\n    # Creating and uploading a file to a project =====================================\n    file = File(\n        path=path_to_file,\n        name=name_of_file,\n        parent=my_stored_project.id,\n    )\n    my_stored_file = syn.store(obj=file)\n\n    my_annotations = Annotations(\n        id=my_stored_file.id,\n        etag=my_stored_file.etag,\n        **my_annotations_dict,\n    )\n\n    syn.set_annotations(annotations=my_annotations)\n\n# Storing several folders to a project ===================================================\nfor loop in range(1, 10):\n    # Creating and uploading a folder to a project ===================================\n    folder = Folder(\n        name=f\"my_folder_{loop}\",\n        parent=my_stored_project.id,\n    )\n\n    my_stored_folder = syn.store(obj=folder)\n\n    my_annotations = Annotations(\n        id=my_stored_folder.id,\n        etag=my_stored_folder.etag,\n        **my_annotations_dict,\n    )\n\n    syn.set_annotations(annotations=my_annotations)\n\n    # Adding a file to a folder ======================================================\n    name_of_file = f\"my_file_with_random_data_{uuid.uuid4()}.txt\"\n    path_to_file = os.path.join(os.path.expanduser(\"~/temp\"), name_of_file)\n    create_random_file(path_to_file)\n\n    file = File(\n        path=path_to_file,\n        name=name_of_file,\n        parent=my_stored_folder.id,\n    )\n    my_stored_file = syn.store(obj=file)\n\n    my_annotations = Annotations(\n        id=my_stored_file.id,\n        etag=my_stored_file.etag,\n        **my_annotations_dict,\n    )\n\n    syn.set_annotations(annotations=my_annotations)\n\n# Updating the annotations in bulk for a number of folders and files =====================\nnew_annotations = {\n    \"my_key_string\": [\"bbbbb\", \"aaaaa\", \"ccccc\"],\n}\n\n# Note: This `getChildren` function will only return the items that are directly\n# under the `parent`. You would need to recursively call this function to get all\n# of the children for all folders under the parent.\nfor child in syn.getChildren(\n    parent=my_stored_project.id, includeTypes=[\"folder\", \"file\"]\n):\n    is_folder = (\n        \"type\" in child and child[\"type\"] == \"org.sagebionetworks.repo.model.Folder\"\n    )\n    is_file = (\n        \"type\" in child and child[\"type\"] == \"org.sagebionetworks.repo.model.FileEntity\"\n    )\n\n    if is_folder:\n        my_folder = syn.get(entity=child[\"id\"])\n        new_saved_annotations = syn.set_annotations(\n            Annotations(id=child[\"id\"], etag=my_folder.etag, **new_annotations)\n        )\n        print(new_saved_annotations)\n    elif is_file:\n        my_file = syn.get(entity=child[\"id\"], downloadFile=False)\n        new_saved_annotations = syn.set_annotations(\n            Annotations(id=child[\"id\"], etag=my_file.etag, **new_annotations)\n        )\n        print(new_saved_annotations)\n\n# Using synapseutils to sync a project from and to synapse ===============================\n# This `syncFromSynapse` will download all files and folders under the project.\n# In addition it creates a manifest TSV file that contains the metadata for all\n# of the files and folders under the project.\nproject_download_location = os.path.expanduser(\"~/my_synapse_project\")\nresult = synapseutils.syncFromSynapse(\n    syn=syn, entity=my_stored_project, path=project_download_location\n)\nprint(result)\n\n# This `syncToSynapse` will upload all files and folders under the project that\n# are defined in the manifest TSV file.\n# ---\n# 12/08/2023 note: There is a bug in the `syncToSynapse` method if you are using\n# multiple annotations for a single key. This will be fixed in the next few releases.\n# Track https://sagebionetworks.jira.com/browse/SYNPY-1357 for more information.\nsynapseutils.syncToSynapse(\n    syn,\n    manifestFile=f\"{project_download_location}/SYNAPSE_METADATA_MANIFEST.tsv\",\n    sendMessages=False,\n)\n\n# Creating and then deleting a project ===================================================\nproject = Project(\n    name=\"my_new_project_for_testing_synapse_client_that_will_be_deleted\",\n    annotations=my_annotations_dict,\n    description=\"This is a project with random data.\",\n)\n\nmy_stored_project: Project = syn.store(project)\nsyn.delete(obj=my_stored_project.id)\n</code></pre> Working with activities <pre><code>\"\"\"The purpose of this script is to demonstrate how to use the OOP interface for Activity.\nThe following actions are shown in this script:\n1. Creating a file with an Activity\n2. Retrieve an activity by parent File\n3. Creating a second file with the same activity\n4. Modifying the activity attached to both Files\n5. Creating a table with an Activity\n\"\"\"\n\nimport os\n\nimport synapseclient\nfrom synapseclient.models import (\n    Activity,\n    Column,\n    ColumnType,\n    File,\n    Table,\n    UsedEntity,\n    UsedURL,\n)\n\nPROJECT_ID = \"syn52948289\"\n\nsyn = synapseclient.Synapse(debug=True)\nsyn.login()\n\n\ndef create_random_file(\n    path: str,\n) -&gt; None:\n    \"\"\"Create a random file with random data.\n\n    Arguments:\n        path: The path to create the file at.\n    \"\"\"\n    with open(path, \"wb\") as f:\n        f.write(os.urandom(1))\n\n\ndef store_activity_on_file():\n    name_of_file = \"my_file_with_random_data.txt\"\n    path_to_file = os.path.join(os.path.expanduser(\"~/temp\"), name_of_file)\n    create_random_file(path_to_file)\n\n    name_of_second_file = \"my_second_file_with_random_data.txt\"\n    path_to_second_file = os.path.join(\n        os.path.expanduser(\"~/temp\"), name_of_second_file\n    )\n    create_random_file(path_to_second_file)\n\n    # Create an activity =================================================================\n    activity = Activity(\n        name=\"My Activity\",\n        description=\"This is an activity.\",\n        used=[\n            UsedURL(name=\"Used URL\", url=\"https://www.synapse.org/\"),\n            UsedEntity(target_id=PROJECT_ID),\n        ],\n        executed=[\n            UsedURL(name=\"Used URL\", url=\"https://www.synapse.org/\"),\n            UsedEntity(target_id=PROJECT_ID),\n        ],\n    )\n\n    # Creating and uploading a file to a project =========================================\n    file = File(\n        path=path_to_file,\n        name=name_of_file,\n        parent_id=PROJECT_ID,\n        description=\"This is a file with random data.\",\n        activity=activity,\n    )\n\n    file = file.store()\n\n    print(\"File created with activity:\")\n    print(activity)\n\n    activity_copy = Activity.from_parent(parent=file)\n\n    # Storing a second file to a project and re-use the activity =========================\n    second_file = File(\n        path=path_to_second_file,\n        name=name_of_second_file,\n        parent_id=PROJECT_ID,\n        description=\"This is a file with random data.\",\n        activity=activity_copy,\n    )\n\n    second_file.store()\n\n    print(\"Second file created with activity:\")\n    print(second_file.activity)\n\n    # # Update the already created activity, which updates the activity on both files ====\n    new_activity_instance = Activity(\n        # In order to update an existing activity you must provide the id and etag.\n        id=second_file.activity.id,\n        etag=second_file.activity.etag if second_file.activity else None,\n        name=\"My Activity - MODIFIED\",\n        used=[\n            UsedURL(name=\"Used URL\", url=\"https://www.synapse.org/\"),\n            UsedEntity(target_id=PROJECT_ID),\n        ],\n        executed=[\n            UsedURL(name=\"Used URL\", url=\"https://www.synapse.org/\"),\n            UsedEntity(target_id=PROJECT_ID),\n        ],\n    )\n    # These 3 will be the same activity\n    print(\"Modified activity showing name is updated for all files:\")\n    print(new_activity_instance.store().name)\n    print(Activity.from_parent(parent=file).name)\n    print(Activity.from_parent(parent=second_file).name)\n\n\ndef store_activity_on_table():\n    # Create an activity =================================================================\n    activity = Activity(\n        name=\"My Activity\",\n        description=\"This is an activity.\",\n        used=[\n            UsedURL(name=\"Used URL\", url=\"https://www.synapse.org/\"),\n            UsedEntity(target_id=PROJECT_ID),\n        ],\n        executed=[\n            UsedURL(name=\"Used URL\", url=\"https://www.synapse.org/\"),\n            UsedEntity(target_id=PROJECT_ID),\n        ],\n    )\n\n    # Creating columns for my table ======================================================\n    columns = [\n        Column(id=None, name=\"my_string_column\", column_type=ColumnType.STRING),\n    ]\n\n    # Creating a table ===============================================================\n    table = Table(\n        name=\"my_first_test_table\",\n        columns=columns,\n        parent_id=PROJECT_ID,\n        activity=activity,\n    )\n\n    table = table.store_schema()\n\n    print(\"Table created with activity:\")\n    print(table.activity)\n\n\nstore_activity_on_file()\nstore_activity_on_table()\n</code></pre> Working with teams <pre><code>\"\"\"The purpose of this script is to demonstrate how to use the new OOP interface for teams.\nThe following actions are shown in this script:\n1. Creating a Team\n2. Instantiating a Team object from Synapse\n3. Getting information about the members of a Team\n4. Inviting a user to a Team\n5. Checking on invitations to join a Team\n6. Deleting a Team\n\"\"\"\n\nimport time\n\nimport synapseclient\nfrom synapseclient.models.team import Team\n\nsyn = synapseclient.Synapse(debug=True)\nsyn.login()\n\n\ndef new_team():\n    # Create a team\n    new_team = Team(\n        name=\"python-client-test-team\",\n        description=\"testing OOP interface\",\n        can_public_join=False,\n    )\n    my_synapse_team = new_team.create()\n    print(my_synapse_team)\n\n    # Instantiate a Team object from a Synapse team\n    my_team = Team.from_id(id=my_synapse_team.id)\n    print(my_team)\n\n    # Sleep because the API for retrieving a team by name is eventually consistent. from_id works right away, however.\n    time.sleep(5)\n    my_team = Team.from_name(name=my_synapse_team.name)\n    print(my_team)\n\n    # Refresh the team to get the latest information\n    my_team.get()\n    print(my_team)\n\n    # Get information about the members of a Team\n    members = my_team.members()\n    print(members)\n\n    # Invite a user to a Team\n    invite = my_team.invite(\n        user=\"test_account_synapse_client\",\n        message=\"testing OOP interface (do not accept)\",\n    )\n    print(invite)\n\n    # Get open invitations for the Team\n    invitations = my_team.open_invitations()\n    print(invitations)\n\n    # Delete the Team\n    my_team.delete()\n\n\nnew_team()\n</code></pre>"},{"location":"reference/oop/models/#api-reference","title":"API reference","text":""},{"location":"reference/oop/models/#synapseclient.models.Project","title":"<code>synapseclient.models.Project</code>  <code>dataclass</code>","text":"<p>               Bases: <code>ProjectSynchronousProtocol</code>, <code>AccessControllable</code>, <code>StorableContainer</code></p> <p>A Project is a top-level container for organizing data in Synapse.</p> ATTRIBUTE DESCRIPTION <code>id</code> <p>The unique immutable ID for this project. A new ID will be generated for new Projects. Once issued, this ID is guaranteed to never change or be re-issued</p> <p> TYPE: <code>Optional[str]</code> </p> <code>name</code> <p>The name of this project. Must be 256 characters or less. Names may only contain: letters, numbers, spaces, underscores, hyphens, periods, plus signs, apostrophes, and parentheses</p> <p> TYPE: <code>Optional[str]</code> </p> <code>description</code> <p>The description of this entity. Must be 1000 characters or less.</p> <p> TYPE: <code>Optional[str]</code> </p> <code>etag</code> <p>Synapse employs an Optimistic Concurrency Control (OCC) scheme to handle concurrent updates. Since the E-Tag changes every time an entity is updated it is used to detect when a client's current representation of an entity is out-of-date.</p> <p> TYPE: <code>Optional[str]</code> </p> <code>created_on</code> <p>The date this entity was created.</p> <p> TYPE: <code>Optional[str]</code> </p> <code>modified_on</code> <p>The date this entity was last modified.</p> <p> TYPE: <code>Optional[str]</code> </p> <code>created_by</code> <p>The ID of the user that created this entity.</p> <p> TYPE: <code>Optional[str]</code> </p> <code>modified_by</code> <p>The ID of the user that last modified this entity.</p> <p> TYPE: <code>Optional[str]</code> </p> <code>alias</code> <p>The project alias for use in friendly project urls.</p> <p> TYPE: <code>Optional[str]</code> </p> <code>files</code> <p>Any files that are at the root directory of the project.</p> <p> TYPE: <code>List[File]</code> </p> <code>folders</code> <p>Any folders that are at the root directory of the project.</p> <p> TYPE: <code>List[Folder]</code> </p> <code>annotations</code> <p>Additional metadata associated with the folder. The key is the name of your desired annotations. The value is an object containing a list of values (use empty list to represent no values for key) and the value type associated with all values in the list. To remove all annotations set this to an empty dict <code>{}</code> or None and store the entity.</p> <p> TYPE: <code>Optional[Dict[str, Union[List[str], List[bool], List[float], List[int], List[date], List[datetime]]]]</code> </p> <code>create_or_update</code> <p>(Store only) Indicates whether the method should automatically perform an update if the resource conflicts with an existing Synapse object. When True this means that any changes to the resource will be non-destructive.</p> <p>This boolean is ignored if you've already stored or retrieved the resource from Synapse for this instance at least once. Any changes to the resource will be destructive in this case. For example if you want to delete the content for a field you will need to call <code>.get()</code> and then modify the field.</p> <p> TYPE: <code>bool</code> </p> <code>parent_id</code> <p>The parent ID of the project. In practice projects do not have a parent, but this is required for the inner workings of Synapse.</p> <p> TYPE: <code>Optional[str]</code> </p> Creating a project <p>This example shows how to create a project</p> <pre><code>from synapseclient.models import Project, File\nimport synapseclient\n\nsynapseclient.login()\n\nmy_annotations = {\n    \"my_single_key_string\": \"a\",\n    \"my_key_string\": [\"b\", \"a\", \"c\"],\n}\nproject = Project(\n    name=\"My unique project name\",\n    annotations=my_annotations,\n    description=\"This is a project with random data.\",\n)\n\nproject = project.store()\n\nprint(project)\n</code></pre> Storing several files to a project <p>This example shows how to store several files to a project</p> <pre><code>file_1 = File(\n    path=path_to_file_1,\n    name=name_of_file_1,\n)\nfile_2 = File(\n    path=path_to_file_2,\n    name=name_of_file_2,\n)\nproject.files = [file_1, file_2]\nproject = project.store()\n</code></pre> Source code in <code>synapseclient/models/project.py</code> <pre><code>@dataclass()\n@async_to_sync\nclass Project(ProjectSynchronousProtocol, AccessControllable, StorableContainer):\n    \"\"\"A Project is a top-level container for organizing data in Synapse.\n\n    Attributes:\n        id: The unique immutable ID for this project. A new ID will be generated for new\n            Projects. Once issued, this ID is guaranteed to never change or be re-issued\n        name: The name of this project. Must be 256 characters or less. Names may only\n            contain: letters, numbers, spaces, underscores, hyphens, periods, plus\n            signs, apostrophes, and parentheses\n        description: The description of this entity. Must be 1000 characters or less.\n        etag: Synapse employs an Optimistic Concurrency Control (OCC) scheme to handle\n            concurrent updates. Since the E-Tag changes every time an entity is updated\n            it is used to detect when a client's current representation of an entity\n            is out-of-date.\n        created_on: The date this entity was created.\n        modified_on: The date this entity was last modified.\n        created_by: The ID of the user that created this entity.\n        modified_by: The ID of the user that last modified this entity.\n        alias: The project alias for use in friendly project urls.\n        files: Any files that are at the root directory of the project.\n        folders: Any folders that are at the root directory of the project.\n        annotations: Additional metadata associated with the folder. The key is the name\n            of your desired annotations. The value is an object containing a list of\n            values (use empty list to represent no values for key) and the value type\n            associated with all values in the list. To remove all annotations set this\n            to an empty dict `{}` or None and store the entity.\n        create_or_update: (Store only) Indicates whether the method should\n            automatically perform an update if the resource conflicts with an existing\n            Synapse object. When True this means that any changes to the resource will\n            be non-destructive.\n\n            This boolean is ignored if you've already stored or retrieved the resource\n            from Synapse for this instance at least once. Any changes to the resource\n            will be destructive in this case. For example if you want to delete the\n            content for a field you will need to call `.get()` and then modify the\n            field.\n        parent_id: The parent ID of the project. In practice projects do not have a\n            parent, but this is required for the inner workings of Synapse.\n\n    Example: Creating a project\n        This example shows how to create a project\n\n            from synapseclient.models import Project, File\n            import synapseclient\n\n            synapseclient.login()\n\n            my_annotations = {\n                \"my_single_key_string\": \"a\",\n                \"my_key_string\": [\"b\", \"a\", \"c\"],\n            }\n            project = Project(\n                name=\"My unique project name\",\n                annotations=my_annotations,\n                description=\"This is a project with random data.\",\n            )\n\n            project = project.store()\n\n            print(project)\n\n    Example: Storing several files to a project\n        This example shows how to store several files to a project\n\n            file_1 = File(\n                path=path_to_file_1,\n                name=name_of_file_1,\n            )\n            file_2 = File(\n                path=path_to_file_2,\n                name=name_of_file_2,\n            )\n            project.files = [file_1, file_2]\n            project = project.store()\n\n    \"\"\"\n\n    id: Optional[str] = None\n    \"\"\"The unique immutable ID for this project. A new ID will be generated for new\n    Projects. Once issued, this ID is guaranteed to never change or be re-issued\"\"\"\n\n    name: Optional[str] = None\n    \"\"\"The name of this project. Must be 256 characters or less. Names may only contain:\n    letters, numbers, spaces, underscores, hyphens, periods, plus signs, apostrophes,\n    and parentheses\"\"\"\n\n    description: Optional[str] = None\n    \"\"\"The description of this entity. Must be 1000 characters or less.\"\"\"\n\n    etag: Optional[str] = None\n    \"\"\"Synapse employs an Optimistic Concurrency Control (OCC) scheme to handle\n    concurrent updates. Since the E-Tag changes every time an entity is updated it\n    is used to detect when a client's current representation of an entity is out-of-date.\"\"\"\n\n    created_on: Optional[str] = field(default=None, compare=False)\n    \"\"\"(Read Only) The date this entity was created.\"\"\"\n\n    modified_on: Optional[str] = field(default=None, compare=False)\n    \"\"\"(Read Only) The date this entity was last modified.\"\"\"\n\n    created_by: Optional[str] = field(default=None, compare=False)\n    \"\"\"(Read Only) The ID of the user that created this entity.\"\"\"\n\n    modified_by: Optional[str] = field(default=None, compare=False)\n    \"\"\"(Read Only) The ID of the user that last modified this entity.\"\"\"\n\n    alias: Optional[str] = None\n    \"\"\"The project alias for use in friendly project urls.\"\"\"\n\n    files: List[\"File\"] = field(default_factory=list, compare=False)\n    \"\"\"Any files that are at the root directory of the project.\"\"\"\n\n    folders: List[\"Folder\"] = field(default_factory=list, compare=False)\n    \"\"\"Any folders that are at the root directory of the project.\"\"\"\n\n    annotations: Optional[\n        Dict[\n            str,\n            Union[\n                List[str],\n                List[bool],\n                List[float],\n                List[int],\n                List[date],\n                List[datetime],\n            ],\n        ]\n    ] = field(default_factory=dict, compare=False)\n    \"\"\"Additional metadata associated with the folder. The key is the name of your\n    desired annotations. The value is an object containing a list of values\n    (use empty list to represent no values for key) and the value type associated with\n    all values in the list. To remove all annotations set this to an empty dict `{}`\n    or None and store the entity.\"\"\"\n\n    create_or_update: bool = field(default=True, repr=False)\n    \"\"\"\n    (Store only)\n\n    Indicates whether the method should automatically perform an update if the resource\n    conflicts with an existing Synapse object. When True this means that any changes\n    to the resource will be non-destructive.\n\n    This boolean is ignored if you've already stored or retrieved the resource from\n    Synapse for this instance at least once. Any changes to the resource will be\n    destructive in this case. For example if you want to delete the content for a field\n    you will need to call `.get()` and then modify the field.\n    \"\"\"\n\n    parent_id: Optional[str] = None\n    \"\"\"The parent ID of the project. In practice projects do not have a parent, but this\n    is required for the inner workings of Synapse.\"\"\"\n\n    _last_persistent_instance: Optional[\"Project\"] = field(\n        default=None, repr=False, compare=False\n    )\n    \"\"\"The last persistent instance of this object. This is used to determine if the\n    object has been changed and needs to be updated in Synapse.\"\"\"\n\n    @property\n    def has_changed(self) -&gt; bool:\n        \"\"\"Determines if the object has been changed and needs to be updated in Synapse.\"\"\"\n        return (\n            not self._last_persistent_instance or self._last_persistent_instance != self\n        )\n\n    def _set_last_persistent_instance(self) -&gt; None:\n        \"\"\"Stash the last time this object interacted with Synapse. This is used to\n        determine if the object has been changed and needs to be updated in Synapse.\"\"\"\n        del self._last_persistent_instance\n        self._last_persistent_instance = replace(self)\n        self._last_persistent_instance.annotations = (\n            deepcopy(self.annotations) if self.annotations else {}\n        )\n\n    def fill_from_dict(\n        self,\n        synapse_project: Union[Synapse_Project, Dict],\n        set_annotations: bool = True,\n    ) -&gt; \"Project\":\n        \"\"\"\n        Converts a response from the REST API into this dataclass.\n\n        Arguments:\n            synapse_project: The response from the REST API.\n\n        Returns:\n            The Project object.\n        \"\"\"\n        self.id = synapse_project.get(\"id\", None)\n        self.name = synapse_project.get(\"name\", None)\n        self.description = synapse_project.get(\"description\", None)\n        self.etag = synapse_project.get(\"etag\", None)\n        self.created_on = synapse_project.get(\"createdOn\", None)\n        self.modified_on = synapse_project.get(\"modifiedOn\", None)\n        self.created_by = synapse_project.get(\"createdBy\", None)\n        self.modified_by = synapse_project.get(\"modifiedBy\", None)\n        self.alias = synapse_project.get(\"alias\", None)\n        self.parent_id = synapse_project.get(\"parentId\", None)\n        if set_annotations:\n            self.annotations = Annotations.from_dict(\n                synapse_project.get(\"annotations\", {})\n            )\n        return self\n\n    @otel_trace_method(\n        method_to_trace_name=lambda self, **kwargs: f\"Project_Store: ID: {self.id}, Name: {self.name}\"\n    )\n    async def store_async(\n        self,\n        failure_strategy: FailureStrategy = FailureStrategy.LOG_EXCEPTION,\n        *,\n        synapse_client: Optional[Synapse] = None,\n    ) -&gt; \"Project\":\n        \"\"\"\n        Store project, files, and folders to synapse. If you have any files or folders\n        attached to this project they will be stored as well. You may attach files\n        and folders to this project by setting the `files` and `folders` attributes.\n\n        By default the store operation will non-destructively update the project if\n        you have not already retrieved the project from Synapse. If you have already\n        retrieved the project from Synapse then the store operation will be destructive\n        and will overwrite the project with the current state of this object. See the\n        `create_or_update` attribute for more information.\n\n        Arguments:\n            failure_strategy: Determines how to handle failures when storing attached\n                Files and Folders under this Project and an exception occurs.\n            synapse_client: If not passed in or None this will use the last client from\n                the `.login()` method.\n\n        Returns:\n            The project object.\n\n        Example: Using this method to update the description\n            Store the project to Synapse using ID\n\n                project = await Project(id=\"syn123\", description=\"new\").store_async()\n\n            Store the project to Synapse using Name\n\n                project = await Project(name=\"my_project\", description=\"new\").store_async()\n\n        Raises:\n            ValueError: If the project name is not set.\n        \"\"\"\n        if not self.name and not self.id:\n            raise ValueError(\"Project ID or Name is required\")\n\n        if (\n            self.create_or_update\n            and not self._last_persistent_instance\n            and (\n                existing_project_id := await get_id(\n                    entity=self, synapse_client=synapse_client, failure_strategy=None\n                )\n            )\n            and (\n                existing_project := await Project(id=existing_project_id).get_async(\n                    synapse_client=synapse_client\n                )\n            )\n        ):\n            merge_dataclass_entities(source=existing_project, destination=self)\n        trace.get_current_span().set_attributes(\n            {\n                \"synapse.name\": self.name or \"\",\n                \"synapse.id\": self.id or \"\",\n            }\n        )\n        if self.has_changed:\n            loop = asyncio.get_event_loop()\n            synapse_project = Synapse_Project(\n                id=self.id,\n                etag=self.etag,\n                name=self.name,\n                description=self.description,\n                alias=self.alias,\n                parentId=self.parent_id,\n            )\n            delete_none_keys(synapse_project)\n            current_context = context.get_current()\n            entity = await loop.run_in_executor(\n                None,\n                lambda: run_and_attach_otel_context(\n                    lambda: Synapse.get_client(synapse_client=synapse_client).store(\n                        obj=synapse_project,\n                        set_annotations=False,\n                        createOrUpdate=False,\n                    ),\n                    current_context,\n                ),\n            )\n            self.fill_from_dict(synapse_project=entity, set_annotations=False)\n\n        await store_entity_components(\n            root_resource=self,\n            failure_strategy=failure_strategy,\n            synapse_client=synapse_client,\n        )\n\n        self._set_last_persistent_instance()\n        Synapse.get_client(synapse_client=synapse_client).logger.debug(\n            f\"Saved Project {self.name}, id: {self.id}\"\n        )\n\n        return self\n\n    @otel_trace_method(\n        method_to_trace_name=lambda self, **kwargs: f\"Project_Get: ID: {self.id}, Name: {self.name}\"\n    )\n    async def get_async(\n        self,\n        *,\n        synapse_client: Optional[Synapse] = None,\n    ) -&gt; \"Project\":\n        \"\"\"Get the project metadata from Synapse.\n\n        Arguments:\n            synapse_client: If not passed in or None this will use the last client from\n                the `.login()` method.\n\n        Returns:\n            The project object.\n\n        Example: Using this method\n            Retrieve the project from Synapse using ID\n\n                project = await Project(id=\"syn123\").get_async()\n\n            Retrieve the project from Synapse using Name\n\n                project = await Project(name=\"my_project\").get_async()\n\n        Raises:\n            ValueError: If the project ID or Name is not set.\n            SynapseNotFoundError: If the project is not found in Synapse.\n        \"\"\"\n        entity_id = await get_id(entity=self, synapse_client=synapse_client)\n\n        await get_from_entity_factory(\n            entity_to_update=self,\n            synapse_id_or_path=entity_id,\n        )\n\n        self._set_last_persistent_instance()\n        return self\n\n    @otel_trace_method(\n        method_to_trace_name=lambda self, **kwargs: f\"Project_Delete: {self.id}, Name: {self.name}\"\n    )\n    async def delete_async(self, *, synapse_client: Optional[Synapse] = None) -&gt; None:\n        \"\"\"Delete the project from Synapse.\n\n        Arguments:\n            synapse_client: If not passed in or None this will use the last client from\n                the `.login()` method.\n\n        Returns:\n            None\n\n        Example: Using this method\n            Delete the project from Synapse using ID\n\n                await Project(id=\"syn123\").delete_async()\n\n            Delete the project from Synapse using Name\n\n                await Project(name=\"my_project\").delete_async()\n\n        Raises:\n            ValueError: If the project ID or Name is not set.\n            SynapseNotFoundError: If the project is not found in Synapse.\n        \"\"\"\n        entity_id = await get_id(entity=self, synapse_client=synapse_client)\n\n        loop = asyncio.get_event_loop()\n        current_context = context.get_current()\n        await loop.run_in_executor(\n            None,\n            lambda: run_and_attach_otel_context(\n                lambda: Synapse.get_client(synapse_client=synapse_client).delete(\n                    obj=entity_id,\n                ),\n                current_context,\n            ),\n        )\n\n    @otel_trace_method(\n        method_to_trace_name=lambda self, **kwargs: f\"Project_Copy: {self.id}\"\n    )\n    async def copy_async(\n        self,\n        destination_id: str,\n        copy_annotations: bool = True,\n        copy_wiki: bool = True,\n        exclude_types: Optional[List[str]] = None,\n        file_update_existing: bool = False,\n        file_copy_activity: Union[str, None] = \"traceback\",\n        *,\n        synapse_client: Optional[Synapse] = None,\n    ) -&gt; \"Project\":\n        \"\"\"\n        You must have already created the Project you will be copying to. It will have\n        it's own Synapse ID and unique name that you will use as the destination_id.\n\n\n        Copy the project to another Synapse project. This will recursively copy all\n        Tables, Links, Files, and Folders within the project.\n\n        Arguments:\n            destination_id: Synapse ID of a project to copy to.\n            copy_annotations: True to copy the annotations.\n            copy_wiki: True to copy the wiki pages.\n            exclude_types: A list of entity types ['file', 'table', 'link'] which\n                determines which entity types to not copy. Defaults to an empty list.\n            file_update_existing: When the destination has a file that has the same\n                name, users can choose to update that file.\n            file_copy_activity: Has three options to set the activity of the copied file:\n\n                    - traceback: Creates a copy of the source files Activity.\n                    - existing: Link to the source file's original Activity (if it exists)\n                    - None: No activity is set\n            synapse_client: If not passed in or None this will use the last client from\n                the `.login()` method.\n\n        Returns:\n            The copied project object.\n\n        Example: Using this function\n            Assuming you have a project with the ID \"syn123\" and you want to copy it to a\n            project with the ID \"syn456\":\n\n                new_instance = await Project(id=\"syn123\").copy_async(destination_id=\"syn456\")\n\n            Copy the project but do not persist annotations:\n\n                new_instance = await Project(id=\"syn123\").copy_async(destination_id=\"syn456\", copy_annotations=False)\n\n        Raises:\n            ValueError: If the project does not have an ID and destination_id to copy.\n        \"\"\"\n        if not self.id or not destination_id:\n            raise ValueError(\"The project must have an ID and destination_id to copy.\")\n\n        loop = asyncio.get_event_loop()\n\n        current_context = context.get_current()\n        syn = Synapse.get_client(synapse_client=synapse_client)\n        source_and_destination = await loop.run_in_executor(\n            None,\n            lambda: run_and_attach_otel_context(\n                lambda: copy(\n                    syn=syn,\n                    entity=self.id,\n                    destinationId=destination_id,\n                    excludeTypes=exclude_types or [],\n                    skipCopyAnnotations=not copy_annotations,\n                    skipCopyWikiPage=not copy_wiki,\n                    updateExisting=file_update_existing,\n                    setProvenance=file_copy_activity,\n                ),\n                current_context,\n            ),\n        )\n\n        new_project_id = source_and_destination.get(self.id, None)\n        if not new_project_id:\n            raise SynapseError(\"Failed to copy project.\")\n        project_copy = await (\n            await Project(id=new_project_id).get_async()\n        ).sync_from_synapse_async(\n            download_file=False,\n            synapse_client=synapse_client,\n        )\n        Synapse.get_client(synapse_client=synapse_client).logger.debug(\n            f\"Copied from project {self.id} to {destination_id}\"\n        )\n        return project_copy\n</code></pre>"},{"location":"reference/oop/models/#synapseclient.models.Project-functions","title":"Functions","text":""},{"location":"reference/oop/models/#synapseclient.models.Project.get","title":"<code>get(*, synapse_client=None)</code>","text":"<p>Get the project metadata from Synapse.</p> PARAMETER DESCRIPTION <code>synapse_client</code> <p>If not passed in or None this will use the last client from the <code>.login()</code> method.</p> <p> TYPE: <code>Optional[Synapse]</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>Project</code> <p>The project object.</p> Using this method <p>Retrieve the project from Synapse using ID</p> <pre><code>project = Project(id=\"syn123\").get()\n</code></pre> <p>Retrieve the project from Synapse using Name</p> <pre><code>project = Project(name=\"my_project\").get()\n</code></pre> RAISES DESCRIPTION <code>ValueError</code> <p>If the project ID or Name is not set.</p> <code>SynapseNotFoundError</code> <p>If the project is not found in Synapse.</p> Source code in <code>synapseclient/models/protocols/project_protocol.py</code> <pre><code>def get(\n    self,\n    *,\n    synapse_client: Optional[Synapse] = None,\n) -&gt; \"Project\":\n    \"\"\"\n    Get the project metadata from Synapse.\n\n    Arguments:\n        synapse_client: If not passed in or None this will use the last client from\n            the `.login()` method.\n\n    Returns:\n        The project object.\n\n    Example: Using this method\n        Retrieve the project from Synapse using ID\n\n            project = Project(id=\"syn123\").get()\n\n        Retrieve the project from Synapse using Name\n\n            project = Project(name=\"my_project\").get()\n\n    Raises:\n        ValueError: If the project ID or Name is not set.\n        SynapseNotFoundError: If the project is not found in Synapse.\n    \"\"\"\n    return self\n</code></pre>"},{"location":"reference/oop/models/#synapseclient.models.Project.store","title":"<code>store(failure_strategy=FailureStrategy.LOG_EXCEPTION, *, synapse_client=None)</code>","text":"<p>Store project, files, and folders to synapse. If you have any files or folders attached to this project they will be stored as well. You may attach files and folders to this project by setting the <code>files</code> and <code>folders</code> attributes.</p> <p>By default the store operation will non-destructively update the project if you have not already retrieved the project from Synapse. If you have already retrieved the project from Synapse then the store operation will be destructive and will overwrite the project with the current state of this object. See the <code>create_or_update</code> attribute for more information.</p> PARAMETER DESCRIPTION <code>failure_strategy</code> <p>Determines how to handle failures when storing attached Files and Folders under this Project and an exception occurs.</p> <p> TYPE: <code>FailureStrategy</code> DEFAULT: <code>LOG_EXCEPTION</code> </p> <code>synapse_client</code> <p>If not passed in or None this will use the last client from the <code>.login()</code> method.</p> <p> TYPE: <code>Optional[Synapse]</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>Project</code> <p>The project object.</p> Using this method to update the description <p>Store the project to Synapse using ID</p> <pre><code>project = Project(id=\"syn123\", description=\"new\").store()\n</code></pre> <p>Store the project to Synapse using Name</p> <pre><code>project = Project(name=\"my_project\", description=\"new\").store()\n</code></pre> RAISES DESCRIPTION <code>ValueError</code> <p>If the project name is not set.</p> Source code in <code>synapseclient/models/protocols/project_protocol.py</code> <pre><code>def store(\n    self,\n    failure_strategy: FailureStrategy = FailureStrategy.LOG_EXCEPTION,\n    *,\n    synapse_client: Optional[Synapse] = None,\n) -&gt; \"Project\":\n    \"\"\"\n    Store project, files, and folders to synapse. If you have any files or folders\n    attached to this project they will be stored as well. You may attach files\n    and folders to this project by setting the `files` and `folders` attributes.\n\n    By default the store operation will non-destructively update the project if\n    you have not already retrieved the project from Synapse. If you have already\n    retrieved the project from Synapse then the store operation will be destructive\n    and will overwrite the project with the current state of this object. See the\n    `create_or_update` attribute for more information.\n\n    Arguments:\n        failure_strategy: Determines how to handle failures when storing attached\n            Files and Folders under this Project and an exception occurs.\n        synapse_client: If not passed in or None this will use the last client from\n            the `.login()` method.\n\n    Returns:\n        The project object.\n\n    Example: Using this method to update the description\n        Store the project to Synapse using ID\n\n            project = Project(id=\"syn123\", description=\"new\").store()\n\n        Store the project to Synapse using Name\n\n            project = Project(name=\"my_project\", description=\"new\").store()\n\n    Raises:\n        ValueError: If the project name is not set.\n    \"\"\"\n    return self\n</code></pre>"},{"location":"reference/oop/models/#synapseclient.models.Project.delete","title":"<code>delete(*, synapse_client=None)</code>","text":"<p>Delete the project from Synapse.</p> PARAMETER DESCRIPTION <code>synapse_client</code> <p>If not passed in or None this will use the last client from the <code>.login()</code> method.</p> <p> TYPE: <code>Optional[Synapse]</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>None</code> <p>None</p> Using this method <p>Delete the project from Synapse using ID</p> <pre><code>Project(id=\"syn123\").delete()\n</code></pre> <p>Delete the project from Synapse using Name</p> <pre><code>Project(name=\"my_project\").delete()\n</code></pre> RAISES DESCRIPTION <code>ValueError</code> <p>If the project ID or Name is not set.</p> <code>SynapseNotFoundError</code> <p>If the project is not found in Synapse.</p> Source code in <code>synapseclient/models/protocols/project_protocol.py</code> <pre><code>def delete(self, *, synapse_client: Optional[Synapse] = None) -&gt; None:\n    \"\"\"Delete the project from Synapse.\n\n    Arguments:\n        synapse_client: If not passed in or None this will use the last client from\n            the `.login()` method.\n\n    Returns:\n        None\n\n    Example: Using this method\n        Delete the project from Synapse using ID\n\n            Project(id=\"syn123\").delete()\n\n        Delete the project from Synapse using Name\n\n            Project(name=\"my_project\").delete()\n\n    Raises:\n        ValueError: If the project ID or Name is not set.\n        SynapseNotFoundError: If the project is not found in Synapse.\n    \"\"\"\n    return None\n</code></pre>"},{"location":"reference/oop/models/#synapseclient.models.Project.sync_from_synapse","title":"<code>sync_from_synapse(path=None, recursive=True, download_file=True, if_collision=COLLISION_OVERWRITE_LOCAL, failure_strategy=FailureStrategy.LOG_EXCEPTION, *, synapse_client=None)</code>","text":"<p>Sync this container and all possible sub-folders from Synapse. By default this will download the files that are found and it will populate the <code>files</code> and <code>folders</code> attributes with the found files and folders. If you only want to retrieve the full tree of metadata about your container specify <code>download_file</code> as False.</p> <p>This works similar to synapseutils.syncFromSynapse, however, this does not currently support the writing of data to a manifest TSV file. This will be a future enhancement.</p> <p>Only Files and Folders are supported at this time to be synced from synapse.</p> PARAMETER DESCRIPTION <code>path</code> <p>An optional path where the file hierarchy will be reproduced. If not specified the files will by default be placed in the synapseCache.</p> <p> TYPE: <code>Optional[str]</code> DEFAULT: <code>None</code> </p> <code>recursive</code> <p>Whether or not to recursively get the entire hierarchy of the folder and sub-folders.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> <code>download_file</code> <p>Whether to download the files found or not.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> <code>if_collision</code> <p>Determines how to handle file collisions. May be</p> <ul> <li><code>overwrite.local</code></li> <li><code>keep.local</code></li> <li><code>keep.both</code></li> </ul> <p> TYPE: <code>str</code> DEFAULT: <code>COLLISION_OVERWRITE_LOCAL</code> </p> <code>failure_strategy</code> <p>Determines how to handle failures when retrieving children under this Folder and an exception occurs.</p> <p> TYPE: <code>FailureStrategy</code> DEFAULT: <code>LOG_EXCEPTION</code> </p> <code>synapse_client</code> <p>If not passed in or None this will use the last client from the <code>.login()</code> method.</p> <p> TYPE: <code>Optional[Synapse]</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>Self</code> <p>The object that was called on. This will be the same object that was called on to start the sync.</p> Using this function <p>Suppose I want to walk the immediate children of a folder without downloading the files:</p> <pre><code>from synapseclient import Synapse\nfrom synapseclient.models import Folder\n\nsyn = Synapse()\nsyn.login()\n\nmy_folder = Folder(id=\"syn12345\")\nmy_folder.sync_from_synapse(download_file=False, recursive=False)\n\nfor folder in my_folder.folders:\n    print(folder.name)\n\nfor file in my_folder.files:\n    print(file.name)\n</code></pre> <p>Suppose I want to download the immediate children of a folder:</p> <pre><code>from synapseclient import Synapse\nfrom synapseclient.models import Folder\n\nsyn = Synapse()\nsyn.login()\n\nmy_folder = Folder(id=\"syn12345\")\nmy_folder.sync_from_synapse(path=\"/path/to/folder\", recursive=False)\n\nfor folder in my_folder.folders:\n    print(folder.name)\n\nfor file in my_folder.files:\n    print(file.name)\n</code></pre> <p>Suppose I want to download the immediate all children of a Project and all sub-folders and files:</p> <pre><code>from synapseclient import Synapse\nfrom synapseclient.models import Project\n\nsyn = Synapse()\nsyn.login()\n\nmy_project = Project(id=\"syn12345\")\nmy_project.sync_from_synapse(path=\"/path/to/folder\")\n</code></pre> RAISES DESCRIPTION <code>ValueError</code> <p>If the folder does not have an id set.</p> <p>A sequence diagram for this method is as follows:</p> <pre><code>sequenceDiagram\n    autonumber\n    participant project_or_folder\n    activate project_or_folder\n    project_or_folder-&gt;&gt;sync_from_synapse: Recursive search and download files\n    activate sync_from_synapse\n        opt Current instance not retrieved from Synapse\n            sync_from_synapse-&gt;&gt;project_or_folder: Call `.get()` method\n            project_or_folder--&gt;&gt;sync_from_synapse: .\n        end\n\n        loop For each return of the generator\n            sync_from_synapse-&gt;&gt;client: call `.getChildren()` method\n            client--&gt;&gt;sync_from_synapse: .\n            note over sync_from_synapse: Append to a running list\n        end\n\n        loop For each child\n            note over sync_from_synapse: Create all `pending_tasks` at current depth\n\n            alt Child is File\n                note over sync_from_synapse: Append `file.get()` method\n            else Child is Folder\n                note over sync_from_synapse: Append `folder.get()` method\n                alt Recursive is True\n                    note over sync_from_synapse: Append `folder.sync_from_synapse()` method\n                end\n            end\n        end\n\n        loop For each task in pending_tasks\n            par `file.get()`\n                sync_from_synapse-&gt;&gt;File: Retrieve File metadata and Optionally download\n                File-&gt;&gt;client: `.get()`\n                client--&gt;&gt;File: .\n                File--&gt;&gt;sync_from_synapse: .\n            and `folder.get()`\n                sync_from_synapse-&gt;&gt;Folder: Retrieve Folder metadataa\n                Folder-&gt;&gt;client: `.get()`\n                client--&gt;&gt;Folder: .\n                Folder--&gt;&gt;sync_from_synapse: .\n            and `folder.sync_from_synapse()`\n                note over sync_from_synapse: This is a recursive call to `sync_from_synapse`\n                sync_from_synapse-&gt;&gt;sync_from_synapse: Recursive call to `.sync_from_synapse()`\n            end\n        end\n\n    deactivate sync_from_synapse\n    deactivate project_or_folder</code></pre> Source code in <code>synapseclient/models/protocols/storable_container_protocol.py</code> <pre><code>def sync_from_synapse(\n    self: Self,\n    path: Optional[str] = None,\n    recursive: bool = True,\n    download_file: bool = True,\n    if_collision: str = COLLISION_OVERWRITE_LOCAL,\n    failure_strategy: FailureStrategy = FailureStrategy.LOG_EXCEPTION,\n    *,\n    synapse_client: Optional[Synapse] = None,\n) -&gt; Self:\n    \"\"\"\n    Sync this container and all possible sub-folders from Synapse. By default this\n    will download the files that are found and it will populate the\n    `files` and `folders` attributes with the found files and folders. If you only\n    want to retrieve the full tree of metadata about your container specify\n    `download_file` as False.\n\n    This works similar to [synapseutils.syncFromSynapse][], however, this does not\n    currently support the writing of data to a manifest TSV file. This will be a\n    future enhancement.\n\n    Only Files and Folders are supported at this time to be synced from synapse.\n\n    Arguments:\n        path: An optional path where the file hierarchy will be reproduced. If not\n            specified the files will by default be placed in the synapseCache.\n        recursive: Whether or not to recursively get the entire hierarchy of the\n            folder and sub-folders.\n        download_file: Whether to download the files found or not.\n        if_collision: Determines how to handle file collisions. May be\n\n            - `overwrite.local`\n            - `keep.local`\n            - `keep.both`\n        failure_strategy: Determines how to handle failures when retrieving children\n            under this Folder and an exception occurs.\n        synapse_client: If not passed in or None this will use the last client from\n            the `.login()` method.\n\n    Returns:\n        The object that was called on. This will be the same object that was called on\n            to start the sync.\n\n    Example: Using this function\n        Suppose I want to walk the immediate children of a folder without downloading the files:\n\n            from synapseclient import Synapse\n            from synapseclient.models import Folder\n\n            syn = Synapse()\n            syn.login()\n\n            my_folder = Folder(id=\"syn12345\")\n            my_folder.sync_from_synapse(download_file=False, recursive=False)\n\n            for folder in my_folder.folders:\n                print(folder.name)\n\n            for file in my_folder.files:\n                print(file.name)\n\n        Suppose I want to download the immediate children of a folder:\n\n            from synapseclient import Synapse\n            from synapseclient.models import Folder\n\n            syn = Synapse()\n            syn.login()\n\n            my_folder = Folder(id=\"syn12345\")\n            my_folder.sync_from_synapse(path=\"/path/to/folder\", recursive=False)\n\n            for folder in my_folder.folders:\n                print(folder.name)\n\n            for file in my_folder.files:\n                print(file.name)\n\n\n        Suppose I want to download the immediate all children of a Project and all sub-folders and files:\n\n            from synapseclient import Synapse\n            from synapseclient.models import Project\n\n            syn = Synapse()\n            syn.login()\n\n            my_project = Project(id=\"syn12345\")\n            my_project.sync_from_synapse(path=\"/path/to/folder\")\n\n\n    Raises:\n        ValueError: If the folder does not have an id set.\n\n\n    A sequence diagram for this method is as follows:\n\n    ```mermaid\n    sequenceDiagram\n        autonumber\n        participant project_or_folder\n        activate project_or_folder\n        project_or_folder-&gt;&gt;sync_from_synapse: Recursive search and download files\n        activate sync_from_synapse\n            opt Current instance not retrieved from Synapse\n                sync_from_synapse-&gt;&gt;project_or_folder: Call `.get()` method\n                project_or_folder--&gt;&gt;sync_from_synapse: .\n            end\n\n            loop For each return of the generator\n                sync_from_synapse-&gt;&gt;client: call `.getChildren()` method\n                client--&gt;&gt;sync_from_synapse: .\n                note over sync_from_synapse: Append to a running list\n            end\n\n            loop For each child\n                note over sync_from_synapse: Create all `pending_tasks` at current depth\n\n                alt Child is File\n                    note over sync_from_synapse: Append `file.get()` method\n                else Child is Folder\n                    note over sync_from_synapse: Append `folder.get()` method\n                    alt Recursive is True\n                        note over sync_from_synapse: Append `folder.sync_from_synapse()` method\n                    end\n                end\n            end\n\n            loop For each task in pending_tasks\n                par `file.get()`\n                    sync_from_synapse-&gt;&gt;File: Retrieve File metadata and Optionally download\n                    File-&gt;&gt;client: `.get()`\n                    client--&gt;&gt;File: .\n                    File--&gt;&gt;sync_from_synapse: .\n                and `folder.get()`\n                    sync_from_synapse-&gt;&gt;Folder: Retrieve Folder metadataa\n                    Folder-&gt;&gt;client: `.get()`\n                    client--&gt;&gt;Folder: .\n                    Folder--&gt;&gt;sync_from_synapse: .\n                and `folder.sync_from_synapse()`\n                    note over sync_from_synapse: This is a recursive call to `sync_from_synapse`\n                    sync_from_synapse-&gt;&gt;sync_from_synapse: Recursive call to `.sync_from_synapse()`\n                end\n            end\n\n        deactivate sync_from_synapse\n        deactivate project_or_folder\n    ```\n\n    \"\"\"\n    return self\n</code></pre>"},{"location":"reference/oop/models/#synapseclient.models.Project.get_permissions","title":"<code>get_permissions(*, synapse_client=None)</code>","text":"<p>Get the permissions that the caller has on an Entity.</p> PARAMETER DESCRIPTION <code>synapse_client</code> <p>If not passed in or None this will use the last client from the <code>.login()</code> method.</p> <p> TYPE: <code>Optional[Synapse]</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>Permissions</code> <p>A Permissions object</p> Using this function: <p>Getting permissions for a Synapse Entity</p> <pre><code>permissions = File(id=\"syn123\").get_permissions()\n</code></pre> <p>Getting access types list from the Permissions object</p> <pre><code>permissions.access_types\n</code></pre> Source code in <code>synapseclient/models/protocols/access_control_protocol.py</code> <pre><code>def get_permissions(\n    self,\n    *,\n    synapse_client: Optional[Synapse] = None,\n) -&gt; \"Permissions\":\n    \"\"\"\n    Get the [permissions][synapseclient.core.models.permission.Permissions]\n    that the caller has on an Entity.\n\n    Arguments:\n        synapse_client: If not passed in or None this will use the last client\n            from the `.login()` method.\n\n    Returns:\n        A Permissions object\n\n\n    Example: Using this function:\n        Getting permissions for a Synapse Entity\n\n            permissions = File(id=\"syn123\").get_permissions()\n\n        Getting access types list from the Permissions object\n\n            permissions.access_types\n    \"\"\"\n    return self\n</code></pre>"},{"location":"reference/oop/models/#synapseclient.models.Project.get_acl","title":"<code>get_acl(principal_id=None, *, synapse_client=None)</code>","text":"<p>Get the ACL that a user or group has on an Entity.</p> PARAMETER DESCRIPTION <code>principal_id</code> <p>Identifier of a user or group (defaults to PUBLIC users)</p> <p> TYPE: <code>int</code> DEFAULT: <code>None</code> </p> <code>synapse_client</code> <p>If not passed in or None this will use the last client from the <code>.login()</code> method.</p> <p> TYPE: <code>Optional[Synapse]</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>List[str]</code> <p>An array containing some combination of ['READ', 'UPDATE', 'CREATE', 'DELETE', 'DOWNLOAD', 'MODERATE', 'CHANGE_PERMISSIONS', 'CHANGE_SETTINGS'] or an empty array</p> Source code in <code>synapseclient/models/protocols/access_control_protocol.py</code> <pre><code>def get_acl(\n    self, principal_id: int = None, *, synapse_client: Optional[Synapse] = None\n) -&gt; List[str]:\n    \"\"\"\n    Get the [ACL][synapseclient.core.models.permission.Permissions.access_types]\n    that a user or group has on an Entity.\n\n    Arguments:\n        principal_id: Identifier of a user or group (defaults to PUBLIC users)\n        synapse_client: If not passed in or None this will use the last client\n            from the `.login()` method.\n\n    Returns:\n        An array containing some combination of\n            ['READ', 'UPDATE', 'CREATE', 'DELETE', 'DOWNLOAD', 'MODERATE',\n            'CHANGE_PERMISSIONS', 'CHANGE_SETTINGS']\n            or an empty array\n    \"\"\"\n    return [\"\"]\n</code></pre>"},{"location":"reference/oop/models/#synapseclient.models.Project.set_permissions","title":"<code>set_permissions(principal_id=None, access_type=None, modify_benefactor=False, warn_if_inherits=True, overwrite=True, *, synapse_client=None)</code>","text":"<p>Sets permission that a user or group has on an Entity. An Entity may have its own ACL or inherit its ACL from a benefactor.</p> PARAMETER DESCRIPTION <code>principal_id</code> <p>Identifier of a user or group. <code>273948</code> is for all registered Synapse users and <code>273949</code> is for public access. None implies public access.</p> <p> TYPE: <code>int</code> DEFAULT: <code>None</code> </p> <code>access_type</code> <p>Type of permission to be granted. One or more of CREATE, READ, DOWNLOAD, UPDATE, DELETE, CHANGE_PERMISSIONS.</p> <p>Defaults to ['READ', 'DOWNLOAD']</p> <p> TYPE: <code>List[str]</code> DEFAULT: <code>None</code> </p> <code>modify_benefactor</code> <p>Set as True when modifying a benefactor's ACL</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>warn_if_inherits</code> <p>Set as False, when creating a new ACL. Trying to modify the ACL of an Entity that inherits its ACL will result in a warning</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> <code>overwrite</code> <p>By default this function overwrites existing permissions for the specified user. Set this flag to False to add new permissions non-destructively.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> <code>synapse_client</code> <p>If not passed in or None this will use the last client from the <code>.login()</code> method.</p> <p> TYPE: <code>Optional[Synapse]</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>Dict[str, Union[str, list]]</code> <p>An Access Control List object</p> Setting permissions <p>Grant all registered users download access</p> <pre><code>File(id=\"syn123\").set_permissions(principal_id=273948, access_type=['READ','DOWNLOAD'])\n</code></pre> <p>Grant the public view access</p> <pre><code>File(id=\"syn123\").set_permissions(principal_id=273949, access_type=['READ'])\n</code></pre> Source code in <code>synapseclient/models/protocols/access_control_protocol.py</code> <pre><code>def set_permissions(\n    self,\n    principal_id: int = None,\n    access_type: List[str] = None,\n    modify_benefactor: bool = False,\n    warn_if_inherits: bool = True,\n    overwrite: bool = True,\n    *,\n    synapse_client: Optional[Synapse] = None,\n) -&gt; Dict[str, Union[str, list]]:\n    \"\"\"\n    Sets permission that a user or group has on an Entity.\n    An Entity may have its own ACL or inherit its ACL from a benefactor.\n\n    Arguments:\n        principal_id: Identifier of a user or group. `273948` is for all\n            registered Synapse users and `273949` is for public access.\n            None implies public access.\n        access_type: Type of permission to be granted. One or more of CREATE,\n            READ, DOWNLOAD, UPDATE, DELETE, CHANGE_PERMISSIONS.\n\n            **Defaults to ['READ', 'DOWNLOAD']**\n        modify_benefactor: Set as True when modifying a benefactor's ACL\n        warn_if_inherits: Set as False, when creating a new ACL. Trying to modify\n            the ACL of an Entity that inherits its ACL will result in a warning\n        overwrite: By default this function overwrites existing permissions for\n            the specified user. Set this flag to False to add new permissions\n            non-destructively.\n        synapse_client: If not passed in or None this will use the last client\n            from the `.login()` method.\n\n    Returns:\n        An Access Control List object\n\n    Example: Setting permissions\n        Grant all registered users download access\n\n            File(id=\"syn123\").set_permissions(principal_id=273948, access_type=['READ','DOWNLOAD'])\n\n        Grant the public view access\n\n            File(id=\"syn123\").set_permissions(principal_id=273949, access_type=['READ'])\n    \"\"\"\n    return {}\n</code></pre>"},{"location":"reference/oop/models/#synapseclient.models.Folder","title":"<code>synapseclient.models.Folder</code>  <code>dataclass</code>","text":"<p>               Bases: <code>FolderSynchronousProtocol</code>, <code>AccessControllable</code>, <code>StorableContainer</code></p> <p>Folder is a hierarchical container for organizing data in Synapse.</p> ATTRIBUTE DESCRIPTION <code>id</code> <p>The unique immutable ID for this folder. A new ID will be generated for new Folders. Once issued, this ID is guaranteed to never change or be re-issued.</p> <p> TYPE: <code>Optional[str]</code> </p> <code>name</code> <p>The name of this folder. Must be 256 characters or less. Names may only contain: letters, numbers, spaces, underscores, hyphens, periods, plus signs, apostrophes, and parentheses.</p> <p> TYPE: <code>Optional[str]</code> </p> <code>parent_id</code> <p>The ID of the Project or Folder that is the parent of this Folder.</p> <p> TYPE: <code>Optional[str]</code> </p> <code>description</code> <p>The description of this entity. Must be 1000 characters or less.</p> <p> TYPE: <code>Optional[str]</code> </p> <code>etag</code> <p>(Read Only) Synapse employs an Optimistic Concurrency Control (OCC) scheme to handle concurrent updates. Since the E-Tag changes every time an entity is updated it is used to detect when a client's current representation of an entity is out-of-date.</p> <p> TYPE: <code>Optional[str]</code> </p> <code>created_on</code> <p>(Read Only) The date this entity was created.</p> <p> TYPE: <code>Optional[str]</code> </p> <code>modified_on</code> <p>(Read Only) The date this entity was last modified.</p> <p> TYPE: <code>Optional[str]</code> </p> <code>created_by</code> <p>(Read Only) The ID of the user that created this entity.</p> <p> TYPE: <code>Optional[str]</code> </p> <code>modified_by</code> <p>(Read Only) The ID of the user that last modified this entity.</p> <p> TYPE: <code>Optional[str]</code> </p> <code>files</code> <p>Files that exist within this folder.</p> <p> TYPE: <code>List[File]</code> </p> <code>folders</code> <p>Folders that exist within this folder.</p> <p> TYPE: <code>List[Folder]</code> </p> <code>annotations</code> <p>Additional metadata associated with the folder. The key is the name of your desired annotations. The value is an object containing a list of values (use empty list to represent no values for key) and the value type associated with all values in the list. To remove all annotations set this to an empty dict <code>{}</code> or None and store the entity.</p> <p> TYPE: <code>Optional[Dict[str, Union[List[str], List[bool], List[float], List[int], List[date], List[datetime]]]]</code> </p> <code>create_or_update</code> <p>(Store only) Indicates whether the method should automatically perform an update if the resource conflicts with an existing Synapse object. When True this means that any changes to the resource will be non-destructive.</p> <p>This boolean is ignored if you've already stored or retrieved the resource from Synapse for this instance at least once. Any changes to the resource will be destructive in this case. For example if you want to delete the content for a field you will need to call <code>.get()</code> and then modify the field.</p> <p> TYPE: <code>bool</code> </p> Source code in <code>synapseclient/models/folder.py</code> <pre><code>@dataclass()\n@async_to_sync\nclass Folder(FolderSynchronousProtocol, AccessControllable, StorableContainer):\n    \"\"\"Folder is a hierarchical container for organizing data in Synapse.\n\n    Attributes:\n        id: The unique immutable ID for this folder. A new ID will be generated for new\n            Folders. Once issued, this ID is guaranteed to never change or be re-issued.\n        name: The name of this folder. Must be 256 characters or less. Names may only\n            contain: letters, numbers, spaces, underscores, hyphens, periods, plus\n            signs, apostrophes, and parentheses.\n        parent_id: The ID of the Project or Folder that is the parent of this Folder.\n        description: The description of this entity. Must be 1000 characters or less.\n        etag: (Read Only)\n            Synapse employs an Optimistic Concurrency Control (OCC) scheme to handle\n            concurrent updates. Since the E-Tag changes every time an entity is updated\n            it is used to detect when a client's current representation of an entity is\n            out-of-date.\n        created_on: (Read Only) The date this entity was created.\n        modified_on: (Read Only) The date this entity was last modified.\n        created_by: (Read Only) The ID of the user that created this entity.\n        modified_by: (Read Only) The ID of the user that last modified this entity.\n        files: Files that exist within this folder.\n        folders: Folders that exist within this folder.\n        annotations: Additional metadata associated with the folder. The key is the name\n            of your desired annotations. The value is an object containing a list of\n            values (use empty list to represent no values for key) and the value type\n            associated with all values in the list. To remove all annotations set this\n            to an empty dict `{}` or None and store the entity.\n        create_or_update: (Store only) Indicates whether the method should\n            automatically perform an update if the resource conflicts with an existing\n            Synapse object. When True this means that any changes to the resource will\n            be non-destructive.\n\n            This boolean is ignored if you've already stored or retrieved the resource\n            from Synapse for this instance at least once. Any changes to the resource\n            will be destructive in this case. For example if you want to delete the\n            content for a field you will need to call `.get()` and then modify the\n            field.\n    \"\"\"\n\n    id: Optional[str] = None\n    \"\"\"The unique immutable ID for this folder. A new ID will be generated for new\n    Folders. Once issued, this ID is guaranteed to never change or be re-issued\"\"\"\n\n    name: Optional[str] = None\n    \"\"\"The name of this folder. Must be 256 characters or less. Names may only contain:\n    letters, numbers, spaces, underscores, hyphens, periods, plus signs, apostrophes,\n    and parentheses\"\"\"\n\n    parent_id: Optional[str] = None\n    \"\"\"The ID of the Project or Folder that is the parent of this Folder.\"\"\"\n\n    description: Optional[str] = None\n    \"\"\"The description of this entity. Must be 1000 characters or less.\"\"\"\n\n    etag: Optional[str] = None\n    \"\"\"(Read Only)\n    Synapse employs an Optimistic Concurrency Control (OCC) scheme to handle\n    concurrent updates. Since the E-Tag changes every time an entity is updated it\n    is used to detect when a client's current representation of an entity\n    is out-of-date.\"\"\"\n\n    created_on: Optional[str] = None\n    \"\"\"(Read Only) The date this entity was created.\"\"\"\n\n    modified_on: Optional[str] = None\n    \"\"\"(Read Only) The date this entity was last modified.\"\"\"\n\n    created_by: Optional[str] = None\n    \"\"\"(Read Only) The ID of the user that created this entity.\"\"\"\n\n    modified_by: Optional[str] = None\n    \"\"\"(Read Only) The ID of the user that last modified this entity.\"\"\"\n\n    files: List[\"File\"] = field(default_factory=list, compare=False)\n    \"\"\"Files that exist within this folder.\"\"\"\n\n    folders: List[\"Folder\"] = field(default_factory=list, compare=False)\n    \"\"\"Folders that exist within this folder.\"\"\"\n\n    annotations: Optional[\n        Dict[\n            str,\n            Union[\n                List[str],\n                List[bool],\n                List[float],\n                List[int],\n                List[date],\n                List[datetime],\n            ],\n        ]\n    ] = field(default_factory=dict, compare=False)\n    \"\"\"Additional metadata associated with the folder. The key is the name of your\n    desired annotations. The value is an object containing a list of values\n    (use empty list to represent no values for key) and the value type associated with\n    all values in the list. To remove all annotations set this to an empty dict `{}`\n    or None and store the entity.\"\"\"\n\n    is_restricted: bool = field(default=False, repr=False)\n    \"\"\"\n    (Store only)\n\n    If set to true, an email will be sent to the Synapse access control team to start\n    the process of adding terms-of-use or review board approval for this entity.\n    You will be contacted with regards to the specific data being restricted and the\n    requirements of access.\n    \"\"\"\n\n    create_or_update: bool = field(default=True, repr=False)\n    \"\"\"\n    (Store only)\n\n    Indicates whether the method should automatically perform an update if the resource\n    conflicts with an existing Synapse object. When True this means that any changes\n    to the resource will be non-destructive.\n\n    This boolean is ignored if you've already stored or retrieved the resource from\n    Synapse for this instance at least once. Any changes to the resource will be\n    destructive in this case. For example if you want to delete the content for a field\n    you will need to call `.get()` and then modify the field.\n    \"\"\"\n\n    _last_persistent_instance: Optional[\"Folder\"] = field(\n        default=None, repr=False, compare=False\n    )\n    \"\"\"The last persistent instance of this object. This is used to determine if the\n    object has been changed and needs to be updated in Synapse.\"\"\"\n\n    @property\n    def has_changed(self) -&gt; bool:\n        \"\"\"Determines if the object has been changed and needs to be updated in Synapse.\"\"\"\n        return (\n            not self._last_persistent_instance or self._last_persistent_instance != self\n        )\n\n    def _set_last_persistent_instance(self) -&gt; None:\n        \"\"\"Stash the last time this object interacted with Synapse. This is used to\n        determine if the object has been changed and needs to be updated in Synapse.\"\"\"\n        del self._last_persistent_instance\n        self._last_persistent_instance = replace(self)\n        self._last_persistent_instance.annotations = (\n            deepcopy(self.annotations) if self.annotations else {}\n        )\n\n    def fill_from_dict(\n        self, synapse_folder: Synapse_Folder, set_annotations: bool = True\n    ) -&gt; \"Folder\":\n        \"\"\"\n        Converts a response from the REST API into this dataclass.\n\n        Arguments:\n            synapse_file: The response from the REST API.\n            set_annotations: Whether to set the annotations from the response.\n\n        Returns:\n            The Folder object.\n        \"\"\"\n        self.id = synapse_folder.get(\"id\", None)\n        self.name = synapse_folder.get(\"name\", None)\n        self.parent_id = synapse_folder.get(\"parentId\", None)\n        self.description = synapse_folder.get(\"description\", None)\n        self.etag = synapse_folder.get(\"etag\", None)\n        self.created_on = synapse_folder.get(\"createdOn\", None)\n        self.modified_on = synapse_folder.get(\"modifiedOn\", None)\n        self.created_by = synapse_folder.get(\"createdBy\", None)\n        self.modified_by = synapse_folder.get(\"modifiedBy\", None)\n        if set_annotations:\n            self.annotations = Annotations.from_dict(\n                synapse_folder.get(\"annotations\", None)\n            )\n        return self\n\n    @otel_trace_method(\n        method_to_trace_name=lambda self, **kwargs: f\"Folder_Store: {self.name}\"\n    )\n    async def store_async(\n        self,\n        parent: Optional[Union[\"Folder\", \"Project\"]] = None,\n        failure_strategy: FailureStrategy = FailureStrategy.LOG_EXCEPTION,\n        *,\n        synapse_client: Optional[Synapse] = None,\n    ) -&gt; \"Folder\":\n        \"\"\"Store folders and files to synapse. If you have any files or folders attached\n        to this folder they will be stored as well. You may attach files and folders\n        to this folder by setting the `files` and `folders` attributes.\n\n        By default the store operation will non-destructively update the folder if\n        you have not already retrieved the folder from Synapse. If you have already\n        retrieved the folder from Synapse then the store operation will be destructive\n        and will overwrite the folder with the current state of this object. See the\n        `create_or_update` attribute for more information.\n\n        Arguments:\n            parent: The parent folder or project to store the folder in.\n            failure_strategy: Determines how to handle failures when storing attached\n                Files and Folders under this Folder and an exception occurs.\n            synapse_client: If not passed in or None this will use the last client from\n                the `.login()` method.\n\n        Returns:\n            The folder object.\n\n        Raises:\n            ValueError: If the folder does not have an id or a\n                (name and (`parent_id` or parent with an id)) set.\n        \"\"\"\n        parent_id = parent.id if parent else self.parent_id\n        if not (self.id or (self.name and parent_id)):\n            raise ValueError(\n                \"The folder must have an id or a \"\n                \"(name and (`parent_id` or parent with an id)) set.\"\n            )\n        self.parent_id = parent_id\n\n        if (\n            self.create_or_update\n            and not self._last_persistent_instance\n            and (\n                existing_folder_id := await get_id(\n                    entity=self, failure_strategy=None, synapse_client=synapse_client\n                )\n            )\n            and (existing_folder := await Folder(id=existing_folder_id).get_async())\n        ):\n            merge_dataclass_entities(source=existing_folder, destination=self)\n        trace.get_current_span().set_attributes(\n            {\n                \"synapse.name\": self.name or \"\",\n                \"synapse.id\": self.id or \"\",\n            }\n        )\n        if self.has_changed:\n            loop = asyncio.get_event_loop()\n            synapse_folder = Synapse_Folder(\n                id=self.id,\n                name=self.name,\n                parent=parent_id,\n                etag=self.etag,\n                description=self.description,\n            )\n            delete_none_keys(synapse_folder)\n            current_context = context.get_current()\n            entity = await loop.run_in_executor(\n                None,\n                lambda: run_and_attach_otel_context(\n                    lambda: Synapse.get_client(synapse_client=synapse_client).store(\n                        obj=synapse_folder,\n                        set_annotations=False,\n                        isRestricted=self.is_restricted,\n                        createOrUpdate=False,\n                    ),\n                    current_context,\n                ),\n            )\n\n            self.fill_from_dict(synapse_folder=entity, set_annotations=False)\n\n        await store_entity_components(\n            root_resource=self,\n            failure_strategy=failure_strategy,\n            synapse_client=synapse_client,\n        )\n        self._set_last_persistent_instance()\n        Synapse.get_client(synapse_client=synapse_client).logger.debug(\n            f\"Saved Folder {self.name}, id: {self.id}: parent: {self.parent_id}\"\n        )\n\n        return self\n\n    @otel_trace_method(\n        method_to_trace_name=lambda self, **kwargs: f\"Folder_Get: {self.id}\"\n    )\n    async def get_async(\n        self,\n        parent: Optional[Union[\"Folder\", \"Project\"]] = None,\n        *,\n        synapse_client: Optional[Synapse] = None,\n    ) -&gt; \"Folder\":\n        \"\"\"Get the folder metadata from Synapse. You are able to find a folder by\n        either the id or the name and parent_id.\n\n        Arguments:\n            parent: The parent folder or project this folder exists under.\n            synapse_client: If not passed in or None this will use the last client from\n                the `.login()` method.\n\n        Returns:\n            The folder object.\n\n        Raises:\n            ValueError: If the folder does not have an id or a\n                (name and (`parent_id` or parent with an id)) set.\n        \"\"\"\n        parent_id = parent.id if parent else self.parent_id\n        if not (self.id or (self.name and parent_id)):\n            raise ValueError(\n                \"The folder must have an id or a \"\n                \"(name and (`parent_id` or parent with an id)) set.\"\n            )\n        self.parent_id = parent_id\n\n        entity_id = await get_id(entity=self, synapse_client=synapse_client)\n\n        await get_from_entity_factory(\n            entity_to_update=self,\n            synapse_id_or_path=entity_id,\n        )\n\n        self._set_last_persistent_instance()\n        return self\n\n    @otel_trace_method(\n        method_to_trace_name=lambda self, **kwargs: f\"Folder_Delete: {self.id}\"\n    )\n    async def delete_async(self, *, synapse_client: Optional[Synapse] = None) -&gt; None:\n        \"\"\"Delete the folder from Synapse by its id.\n\n        Arguments:\n            synapse_client: If not passed in or None this will use the last client from\n                the `.login()` method.\n\n        Returns:\n            None\n\n        Raises:\n            ValueError: If the folder does not have an id set.\n        \"\"\"\n        if not self.id:\n            raise ValueError(\"The folder must have an id set.\")\n        loop = asyncio.get_event_loop()\n        current_context = context.get_current()\n        await loop.run_in_executor(\n            None,\n            lambda: run_and_attach_otel_context(\n                lambda: Synapse.get_client(synapse_client=synapse_client).delete(\n                    obj=self.id,\n                ),\n                current_context=current_context,\n            ),\n        )\n\n    @otel_trace_method(\n        method_to_trace_name=lambda self, **kwargs: f\"Folder_Copy: {self.id}\"\n    )\n    async def copy_async(\n        self,\n        parent_id: str,\n        copy_annotations: bool = True,\n        exclude_types: Optional[List[str]] = None,\n        file_update_existing: bool = False,\n        file_copy_activity: Union[str, None] = \"traceback\",\n        *,\n        synapse_client: Optional[Synapse] = None,\n    ) -&gt; \"Folder\":\n        \"\"\"\n        Copy the folder to another Synapse location. This will recursively copy all\n        Tables, Links, Files, and Folders within the folder.\n\n        Arguments:\n            parent_id: Synapse ID of a folder/project that the copied entity is\n                being copied to\n            copy_annotations: True to copy the annotations.\n            exclude_types: A list of entity types ['file', 'table', 'link'] which\n                determines which entity types to not copy. Defaults to an empty list.\n            file_update_existing: When the destination has a file that has the same name,\n                users can choose to update that file.\n            file_copy_activity: Has three options to set the activity of the copied file:\n\n                    - traceback: Creates a copy of the source files Activity.\n                    - existing: Link to the source file's original Activity (if it exists)\n                    - None: No activity is set\n            synapse_client: If not passed in or None this will use the last client from\n                the `.login()` method.\n\n        Returns:\n            The copied folder object.\n\n        Example: Using this function\n            Assuming you have a folder with the ID \"syn123\" and you want to copy it to a\n            project with the ID \"syn456\":\n\n                new_folder_instance = await Folder(id=\"syn123\").copy_async(parent_id=\"syn456\")\n\n            Copy the folder but do not persist annotations:\n\n                new_folder_instance = await Folder(id=\"syn123\").copy_async(parent_id=\"syn456\", copy_annotations=False)\n\n        Raises:\n            ValueError: If the folder does not have an ID and parent_id to copy.\n        \"\"\"\n        if not self.id or not parent_id:\n            raise ValueError(\"The folder must have an ID and parent_id to copy.\")\n\n        loop = asyncio.get_event_loop()\n\n        current_context = context.get_current()\n        syn = Synapse.get_client(synapse_client=synapse_client)\n        source_and_destination = await loop.run_in_executor(\n            None,\n            lambda: run_and_attach_otel_context(\n                lambda: copy(\n                    syn=syn,\n                    entity=self.id,\n                    destinationId=parent_id,\n                    excludeTypes=exclude_types or [],\n                    skipCopyAnnotations=not copy_annotations,\n                    updateExisting=file_update_existing,\n                    setProvenance=file_copy_activity,\n                ),\n                current_context,\n            ),\n        )\n\n        new_folder_id = source_and_destination.get(self.id, None)\n        if not new_folder_id:\n            raise SynapseError(\"Failed to copy folder.\")\n        folder_copy = await (\n            await Folder(id=new_folder_id).get_async()\n        ).sync_from_synapse_async(\n            download_file=False,\n            synapse_client=synapse_client,\n        )\n        Synapse.get_client(synapse_client=synapse_client).logger.debug(\n            f\"Copied from folder {self.id} to {parent_id} with new id of {folder_copy.id}\"\n        )\n        return folder_copy\n</code></pre>"},{"location":"reference/oop/models/#synapseclient.models.Folder-functions","title":"Functions","text":""},{"location":"reference/oop/models/#synapseclient.models.Folder.get","title":"<code>get(parent=None, *, synapse_client=None)</code>","text":"<p>Get the folder metadata from Synapse. You are able to find a folder by either the id or the name and parent_id.</p> PARAMETER DESCRIPTION <code>parent</code> <p>The parent folder or project this folder exists under.</p> <p> TYPE: <code>Optional[Union[Folder, Project]]</code> DEFAULT: <code>None</code> </p> <code>synapse_client</code> <p>If not passed in or None this will use the last client from the <code>.login()</code> method.</p> <p> TYPE: <code>Optional[Synapse]</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>Folder</code> <p>The folder object.</p> RAISES DESCRIPTION <code>ValueError</code> <p>If the folder does not have an id or a (name and (<code>parent_id</code> or parent with an id)) set.</p> Source code in <code>synapseclient/models/protocols/folder_protocol.py</code> <pre><code>def get(\n    self,\n    parent: Optional[Union[\"Folder\", \"Project\"]] = None,\n    *,\n    synapse_client: Optional[Synapse] = None,\n) -&gt; \"Folder\":\n    \"\"\"Get the folder metadata from Synapse. You are able to find a folder by\n    either the id or the name and parent_id.\n\n    Arguments:\n        parent: The parent folder or project this folder exists under.\n        synapse_client: If not passed in or None this will use the last client from\n            the `.login()` method.\n\n    Returns:\n        The folder object.\n\n    Raises:\n        ValueError: If the folder does not have an id or a\n            (name and (`parent_id` or parent with an id)) set.\n    \"\"\"\n    return self\n</code></pre>"},{"location":"reference/oop/models/#synapseclient.models.Folder.store","title":"<code>store(parent=None, failure_strategy=FailureStrategy.LOG_EXCEPTION, *, synapse_client=None)</code>","text":"<p>Store folders and files to synapse. If you have any files or folders attached to this folder they will be stored as well. You may attach files and folders to this folder by setting the <code>files</code> and <code>folders</code> attributes.</p> <p>By default the store operation will non-destructively update the folder if you have not already retrieved the folder from Synapse. If you have already retrieved the folder from Synapse then the store operation will be destructive and will overwrite the folder with the current state of this object. See the <code>create_or_update</code> attribute for more information.</p> PARAMETER DESCRIPTION <code>parent</code> <p>The parent folder or project to store the folder in.</p> <p> TYPE: <code>Optional[Union[Folder, Project]]</code> DEFAULT: <code>None</code> </p> <code>failure_strategy</code> <p>Determines how to handle failures when storing attached Files and Folders under this Folder and an exception occurs.</p> <p> TYPE: <code>FailureStrategy</code> DEFAULT: <code>LOG_EXCEPTION</code> </p> <code>synapse_client</code> <p>If not passed in or None this will use the last client from the <code>.login()</code> method.</p> <p> TYPE: <code>Optional[Synapse]</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>Folder</code> <p>The folder object.</p> RAISES DESCRIPTION <code>ValueError</code> <p>If the folder does not have an id or a (name and (<code>parent_id</code> or parent with an id)) set.</p> Source code in <code>synapseclient/models/protocols/folder_protocol.py</code> <pre><code>def store(\n    self,\n    parent: Optional[Union[\"Folder\", \"Project\"]] = None,\n    failure_strategy: FailureStrategy = FailureStrategy.LOG_EXCEPTION,\n    *,\n    synapse_client: Optional[Synapse] = None,\n) -&gt; \"Folder\":\n    \"\"\"Store folders and files to synapse. If you have any files or folders attached\n    to this folder they will be stored as well. You may attach files and folders\n    to this folder by setting the `files` and `folders` attributes.\n\n    By default the store operation will non-destructively update the folder if\n    you have not already retrieved the folder from Synapse. If you have already\n    retrieved the folder from Synapse then the store operation will be destructive\n    and will overwrite the folder with the current state of this object. See the\n    `create_or_update` attribute for more information.\n\n    Arguments:\n        parent: The parent folder or project to store the folder in.\n        failure_strategy: Determines how to handle failures when storing attached\n            Files and Folders under this Folder and an exception occurs.\n        synapse_client: If not passed in or None this will use the last client from\n            the `.login()` method.\n\n    Returns:\n        The folder object.\n\n    Raises:\n        ValueError: If the folder does not have an id or a\n            (name and (`parent_id` or parent with an id)) set.\n    \"\"\"\n    return self\n</code></pre>"},{"location":"reference/oop/models/#synapseclient.models.Folder.delete","title":"<code>delete(*, synapse_client=None)</code>","text":"<p>Delete the folder from Synapse by its id.</p> PARAMETER DESCRIPTION <code>synapse_client</code> <p>If not passed in or None this will use the last client from the <code>.login()</code> method.</p> <p> TYPE: <code>Optional[Synapse]</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>None</code> <p>None</p> RAISES DESCRIPTION <code>ValueError</code> <p>If the folder does not have an id set.</p> Source code in <code>synapseclient/models/protocols/folder_protocol.py</code> <pre><code>def delete(self, *, synapse_client: Optional[Synapse] = None) -&gt; None:\n    \"\"\"Delete the folder from Synapse by its id.\n\n    Arguments:\n        synapse_client: If not passed in or None this will use the last client from\n            the `.login()` method.\n\n    Returns:\n        None\n\n    Raises:\n        ValueError: If the folder does not have an id set.\n    \"\"\"\n    return None\n</code></pre>"},{"location":"reference/oop/models/#synapseclient.models.Folder.copy","title":"<code>copy(parent_id, copy_annotations=True, exclude_types=None, file_update_existing=False, file_copy_activity='traceback', *, synapse_client=None)</code>","text":"<p>Copy the folder to another Synapse location. This will recursively copy all Tables, Links, Files, and Folders within the folder.</p> PARAMETER DESCRIPTION <code>parent_id</code> <p>Synapse ID of a folder/project that the copied entity is being copied to</p> <p> TYPE: <code>str</code> </p> <code>copy_annotations</code> <p>True to copy the annotations.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> <code>exclude_types</code> <p>A list of entity types ['file', 'table', 'link'] which determines which entity types to not copy. Defaults to an empty list.</p> <p> TYPE: <code>Optional[List[str]]</code> DEFAULT: <code>None</code> </p> <code>file_update_existing</code> <p>When the destination has a file that has the same name, users can choose to update that file.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>file_copy_activity</code> <p>Has three options to set the activity of the copied file:</p> <pre><code>- traceback: Creates a copy of the source files Activity.\n- existing: Link to the source file's original Activity (if it exists)\n- None: No activity is set\n</code></pre> <p> TYPE: <code>Union[str, None]</code> DEFAULT: <code>'traceback'</code> </p> <code>synapse_client</code> <p>If not passed in or None this will use the last client from the <code>.login()</code> method.</p> <p> TYPE: <code>Optional[Synapse]</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>Folder</code> <p>The copied folder object.</p> Using this function <p>Assuming you have a folder with the ID \"syn123\" and you want to copy it to a project with the ID \"syn456\":</p> <pre><code>new_folder_instance = await Folder(id=\"syn123\").copy(parent_id=\"syn456\")\n</code></pre> <p>Copy the folder but do not persist annotations:</p> <pre><code>new_folder_instance = await Folder(id=\"syn123\").copy(parent_id=\"syn456\", copy_annotations=False)\n</code></pre> RAISES DESCRIPTION <code>ValueError</code> <p>If the folder does not have an ID and parent_id to copy.</p> Source code in <code>synapseclient/models/protocols/folder_protocol.py</code> <pre><code>def copy(\n    self,\n    parent_id: str,\n    copy_annotations: bool = True,\n    exclude_types: Optional[List[str]] = None,\n    file_update_existing: bool = False,\n    file_copy_activity: Union[str, None] = \"traceback\",\n    *,\n    synapse_client: Optional[Synapse] = None,\n) -&gt; \"Folder\":\n    \"\"\"\n    Copy the folder to another Synapse location. This will recursively copy all\n    Tables, Links, Files, and Folders within the folder.\n\n    Arguments:\n        parent_id: Synapse ID of a folder/project that the copied entity is\n            being copied to\n        copy_annotations: True to copy the annotations.\n        exclude_types: A list of entity types ['file', 'table', 'link'] which\n            determines which entity types to not copy. Defaults to an empty list.\n        file_update_existing: When the destination has a file that has the same name,\n            users can choose to update that file.\n        file_copy_activity: Has three options to set the activity of the copied file:\n\n                - traceback: Creates a copy of the source files Activity.\n                - existing: Link to the source file's original Activity (if it exists)\n                - None: No activity is set\n        synapse_client: If not passed in or None this will use the last client from\n            the `.login()` method.\n\n    Returns:\n        The copied folder object.\n\n    Example: Using this function\n        Assuming you have a folder with the ID \"syn123\" and you want to copy it to a\n        project with the ID \"syn456\":\n\n            new_folder_instance = await Folder(id=\"syn123\").copy(parent_id=\"syn456\")\n\n        Copy the folder but do not persist annotations:\n\n            new_folder_instance = await Folder(id=\"syn123\").copy(parent_id=\"syn456\", copy_annotations=False)\n\n    Raises:\n        ValueError: If the folder does not have an ID and parent_id to copy.\n    \"\"\"\n    return self\n</code></pre>"},{"location":"reference/oop/models/#synapseclient.models.Folder.sync_from_synapse","title":"<code>sync_from_synapse(path=None, recursive=True, download_file=True, if_collision=COLLISION_OVERWRITE_LOCAL, failure_strategy=FailureStrategy.LOG_EXCEPTION, *, synapse_client=None)</code>","text":"<p>Sync this container and all possible sub-folders from Synapse. By default this will download the files that are found and it will populate the <code>files</code> and <code>folders</code> attributes with the found files and folders. If you only want to retrieve the full tree of metadata about your container specify <code>download_file</code> as False.</p> <p>This works similar to synapseutils.syncFromSynapse, however, this does not currently support the writing of data to a manifest TSV file. This will be a future enhancement.</p> <p>Only Files and Folders are supported at this time to be synced from synapse.</p> PARAMETER DESCRIPTION <code>path</code> <p>An optional path where the file hierarchy will be reproduced. If not specified the files will by default be placed in the synapseCache.</p> <p> TYPE: <code>Optional[str]</code> DEFAULT: <code>None</code> </p> <code>recursive</code> <p>Whether or not to recursively get the entire hierarchy of the folder and sub-folders.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> <code>download_file</code> <p>Whether to download the files found or not.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> <code>if_collision</code> <p>Determines how to handle file collisions. May be</p> <ul> <li><code>overwrite.local</code></li> <li><code>keep.local</code></li> <li><code>keep.both</code></li> </ul> <p> TYPE: <code>str</code> DEFAULT: <code>COLLISION_OVERWRITE_LOCAL</code> </p> <code>failure_strategy</code> <p>Determines how to handle failures when retrieving children under this Folder and an exception occurs.</p> <p> TYPE: <code>FailureStrategy</code> DEFAULT: <code>LOG_EXCEPTION</code> </p> <code>synapse_client</code> <p>If not passed in or None this will use the last client from the <code>.login()</code> method.</p> <p> TYPE: <code>Optional[Synapse]</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>Self</code> <p>The object that was called on. This will be the same object that was called on to start the sync.</p> Using this function <p>Suppose I want to walk the immediate children of a folder without downloading the files:</p> <pre><code>from synapseclient import Synapse\nfrom synapseclient.models import Folder\n\nsyn = Synapse()\nsyn.login()\n\nmy_folder = Folder(id=\"syn12345\")\nmy_folder.sync_from_synapse(download_file=False, recursive=False)\n\nfor folder in my_folder.folders:\n    print(folder.name)\n\nfor file in my_folder.files:\n    print(file.name)\n</code></pre> <p>Suppose I want to download the immediate children of a folder:</p> <pre><code>from synapseclient import Synapse\nfrom synapseclient.models import Folder\n\nsyn = Synapse()\nsyn.login()\n\nmy_folder = Folder(id=\"syn12345\")\nmy_folder.sync_from_synapse(path=\"/path/to/folder\", recursive=False)\n\nfor folder in my_folder.folders:\n    print(folder.name)\n\nfor file in my_folder.files:\n    print(file.name)\n</code></pre> <p>Suppose I want to download the immediate all children of a Project and all sub-folders and files:</p> <pre><code>from synapseclient import Synapse\nfrom synapseclient.models import Project\n\nsyn = Synapse()\nsyn.login()\n\nmy_project = Project(id=\"syn12345\")\nmy_project.sync_from_synapse(path=\"/path/to/folder\")\n</code></pre> RAISES DESCRIPTION <code>ValueError</code> <p>If the folder does not have an id set.</p> <p>A sequence diagram for this method is as follows:</p> <pre><code>sequenceDiagram\n    autonumber\n    participant project_or_folder\n    activate project_or_folder\n    project_or_folder-&gt;&gt;sync_from_synapse: Recursive search and download files\n    activate sync_from_synapse\n        opt Current instance not retrieved from Synapse\n            sync_from_synapse-&gt;&gt;project_or_folder: Call `.get()` method\n            project_or_folder--&gt;&gt;sync_from_synapse: .\n        end\n\n        loop For each return of the generator\n            sync_from_synapse-&gt;&gt;client: call `.getChildren()` method\n            client--&gt;&gt;sync_from_synapse: .\n            note over sync_from_synapse: Append to a running list\n        end\n\n        loop For each child\n            note over sync_from_synapse: Create all `pending_tasks` at current depth\n\n            alt Child is File\n                note over sync_from_synapse: Append `file.get()` method\n            else Child is Folder\n                note over sync_from_synapse: Append `folder.get()` method\n                alt Recursive is True\n                    note over sync_from_synapse: Append `folder.sync_from_synapse()` method\n                end\n            end\n        end\n\n        loop For each task in pending_tasks\n            par `file.get()`\n                sync_from_synapse-&gt;&gt;File: Retrieve File metadata and Optionally download\n                File-&gt;&gt;client: `.get()`\n                client--&gt;&gt;File: .\n                File--&gt;&gt;sync_from_synapse: .\n            and `folder.get()`\n                sync_from_synapse-&gt;&gt;Folder: Retrieve Folder metadataa\n                Folder-&gt;&gt;client: `.get()`\n                client--&gt;&gt;Folder: .\n                Folder--&gt;&gt;sync_from_synapse: .\n            and `folder.sync_from_synapse()`\n                note over sync_from_synapse: This is a recursive call to `sync_from_synapse`\n                sync_from_synapse-&gt;&gt;sync_from_synapse: Recursive call to `.sync_from_synapse()`\n            end\n        end\n\n    deactivate sync_from_synapse\n    deactivate project_or_folder</code></pre> Source code in <code>synapseclient/models/protocols/storable_container_protocol.py</code> <pre><code>def sync_from_synapse(\n    self: Self,\n    path: Optional[str] = None,\n    recursive: bool = True,\n    download_file: bool = True,\n    if_collision: str = COLLISION_OVERWRITE_LOCAL,\n    failure_strategy: FailureStrategy = FailureStrategy.LOG_EXCEPTION,\n    *,\n    synapse_client: Optional[Synapse] = None,\n) -&gt; Self:\n    \"\"\"\n    Sync this container and all possible sub-folders from Synapse. By default this\n    will download the files that are found and it will populate the\n    `files` and `folders` attributes with the found files and folders. If you only\n    want to retrieve the full tree of metadata about your container specify\n    `download_file` as False.\n\n    This works similar to [synapseutils.syncFromSynapse][], however, this does not\n    currently support the writing of data to a manifest TSV file. This will be a\n    future enhancement.\n\n    Only Files and Folders are supported at this time to be synced from synapse.\n\n    Arguments:\n        path: An optional path where the file hierarchy will be reproduced. If not\n            specified the files will by default be placed in the synapseCache.\n        recursive: Whether or not to recursively get the entire hierarchy of the\n            folder and sub-folders.\n        download_file: Whether to download the files found or not.\n        if_collision: Determines how to handle file collisions. May be\n\n            - `overwrite.local`\n            - `keep.local`\n            - `keep.both`\n        failure_strategy: Determines how to handle failures when retrieving children\n            under this Folder and an exception occurs.\n        synapse_client: If not passed in or None this will use the last client from\n            the `.login()` method.\n\n    Returns:\n        The object that was called on. This will be the same object that was called on\n            to start the sync.\n\n    Example: Using this function\n        Suppose I want to walk the immediate children of a folder without downloading the files:\n\n            from synapseclient import Synapse\n            from synapseclient.models import Folder\n\n            syn = Synapse()\n            syn.login()\n\n            my_folder = Folder(id=\"syn12345\")\n            my_folder.sync_from_synapse(download_file=False, recursive=False)\n\n            for folder in my_folder.folders:\n                print(folder.name)\n\n            for file in my_folder.files:\n                print(file.name)\n\n        Suppose I want to download the immediate children of a folder:\n\n            from synapseclient import Synapse\n            from synapseclient.models import Folder\n\n            syn = Synapse()\n            syn.login()\n\n            my_folder = Folder(id=\"syn12345\")\n            my_folder.sync_from_synapse(path=\"/path/to/folder\", recursive=False)\n\n            for folder in my_folder.folders:\n                print(folder.name)\n\n            for file in my_folder.files:\n                print(file.name)\n\n\n        Suppose I want to download the immediate all children of a Project and all sub-folders and files:\n\n            from synapseclient import Synapse\n            from synapseclient.models import Project\n\n            syn = Synapse()\n            syn.login()\n\n            my_project = Project(id=\"syn12345\")\n            my_project.sync_from_synapse(path=\"/path/to/folder\")\n\n\n    Raises:\n        ValueError: If the folder does not have an id set.\n\n\n    A sequence diagram for this method is as follows:\n\n    ```mermaid\n    sequenceDiagram\n        autonumber\n        participant project_or_folder\n        activate project_or_folder\n        project_or_folder-&gt;&gt;sync_from_synapse: Recursive search and download files\n        activate sync_from_synapse\n            opt Current instance not retrieved from Synapse\n                sync_from_synapse-&gt;&gt;project_or_folder: Call `.get()` method\n                project_or_folder--&gt;&gt;sync_from_synapse: .\n            end\n\n            loop For each return of the generator\n                sync_from_synapse-&gt;&gt;client: call `.getChildren()` method\n                client--&gt;&gt;sync_from_synapse: .\n                note over sync_from_synapse: Append to a running list\n            end\n\n            loop For each child\n                note over sync_from_synapse: Create all `pending_tasks` at current depth\n\n                alt Child is File\n                    note over sync_from_synapse: Append `file.get()` method\n                else Child is Folder\n                    note over sync_from_synapse: Append `folder.get()` method\n                    alt Recursive is True\n                        note over sync_from_synapse: Append `folder.sync_from_synapse()` method\n                    end\n                end\n            end\n\n            loop For each task in pending_tasks\n                par `file.get()`\n                    sync_from_synapse-&gt;&gt;File: Retrieve File metadata and Optionally download\n                    File-&gt;&gt;client: `.get()`\n                    client--&gt;&gt;File: .\n                    File--&gt;&gt;sync_from_synapse: .\n                and `folder.get()`\n                    sync_from_synapse-&gt;&gt;Folder: Retrieve Folder metadataa\n                    Folder-&gt;&gt;client: `.get()`\n                    client--&gt;&gt;Folder: .\n                    Folder--&gt;&gt;sync_from_synapse: .\n                and `folder.sync_from_synapse()`\n                    note over sync_from_synapse: This is a recursive call to `sync_from_synapse`\n                    sync_from_synapse-&gt;&gt;sync_from_synapse: Recursive call to `.sync_from_synapse()`\n                end\n            end\n\n        deactivate sync_from_synapse\n        deactivate project_or_folder\n    ```\n\n    \"\"\"\n    return self\n</code></pre>"},{"location":"reference/oop/models/#synapseclient.models.Folder.get_permissions","title":"<code>get_permissions(*, synapse_client=None)</code>","text":"<p>Get the permissions that the caller has on an Entity.</p> PARAMETER DESCRIPTION <code>synapse_client</code> <p>If not passed in or None this will use the last client from the <code>.login()</code> method.</p> <p> TYPE: <code>Optional[Synapse]</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>Permissions</code> <p>A Permissions object</p> Using this function: <p>Getting permissions for a Synapse Entity</p> <pre><code>permissions = File(id=\"syn123\").get_permissions()\n</code></pre> <p>Getting access types list from the Permissions object</p> <pre><code>permissions.access_types\n</code></pre> Source code in <code>synapseclient/models/protocols/access_control_protocol.py</code> <pre><code>def get_permissions(\n    self,\n    *,\n    synapse_client: Optional[Synapse] = None,\n) -&gt; \"Permissions\":\n    \"\"\"\n    Get the [permissions][synapseclient.core.models.permission.Permissions]\n    that the caller has on an Entity.\n\n    Arguments:\n        synapse_client: If not passed in or None this will use the last client\n            from the `.login()` method.\n\n    Returns:\n        A Permissions object\n\n\n    Example: Using this function:\n        Getting permissions for a Synapse Entity\n\n            permissions = File(id=\"syn123\").get_permissions()\n\n        Getting access types list from the Permissions object\n\n            permissions.access_types\n    \"\"\"\n    return self\n</code></pre>"},{"location":"reference/oop/models/#synapseclient.models.Folder.get_acl","title":"<code>get_acl(principal_id=None, *, synapse_client=None)</code>","text":"<p>Get the ACL that a user or group has on an Entity.</p> PARAMETER DESCRIPTION <code>principal_id</code> <p>Identifier of a user or group (defaults to PUBLIC users)</p> <p> TYPE: <code>int</code> DEFAULT: <code>None</code> </p> <code>synapse_client</code> <p>If not passed in or None this will use the last client from the <code>.login()</code> method.</p> <p> TYPE: <code>Optional[Synapse]</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>List[str]</code> <p>An array containing some combination of ['READ', 'UPDATE', 'CREATE', 'DELETE', 'DOWNLOAD', 'MODERATE', 'CHANGE_PERMISSIONS', 'CHANGE_SETTINGS'] or an empty array</p> Source code in <code>synapseclient/models/protocols/access_control_protocol.py</code> <pre><code>def get_acl(\n    self, principal_id: int = None, *, synapse_client: Optional[Synapse] = None\n) -&gt; List[str]:\n    \"\"\"\n    Get the [ACL][synapseclient.core.models.permission.Permissions.access_types]\n    that a user or group has on an Entity.\n\n    Arguments:\n        principal_id: Identifier of a user or group (defaults to PUBLIC users)\n        synapse_client: If not passed in or None this will use the last client\n            from the `.login()` method.\n\n    Returns:\n        An array containing some combination of\n            ['READ', 'UPDATE', 'CREATE', 'DELETE', 'DOWNLOAD', 'MODERATE',\n            'CHANGE_PERMISSIONS', 'CHANGE_SETTINGS']\n            or an empty array\n    \"\"\"\n    return [\"\"]\n</code></pre>"},{"location":"reference/oop/models/#synapseclient.models.Folder.set_permissions","title":"<code>set_permissions(principal_id=None, access_type=None, modify_benefactor=False, warn_if_inherits=True, overwrite=True, *, synapse_client=None)</code>","text":"<p>Sets permission that a user or group has on an Entity. An Entity may have its own ACL or inherit its ACL from a benefactor.</p> PARAMETER DESCRIPTION <code>principal_id</code> <p>Identifier of a user or group. <code>273948</code> is for all registered Synapse users and <code>273949</code> is for public access. None implies public access.</p> <p> TYPE: <code>int</code> DEFAULT: <code>None</code> </p> <code>access_type</code> <p>Type of permission to be granted. One or more of CREATE, READ, DOWNLOAD, UPDATE, DELETE, CHANGE_PERMISSIONS.</p> <p>Defaults to ['READ', 'DOWNLOAD']</p> <p> TYPE: <code>List[str]</code> DEFAULT: <code>None</code> </p> <code>modify_benefactor</code> <p>Set as True when modifying a benefactor's ACL</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>warn_if_inherits</code> <p>Set as False, when creating a new ACL. Trying to modify the ACL of an Entity that inherits its ACL will result in a warning</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> <code>overwrite</code> <p>By default this function overwrites existing permissions for the specified user. Set this flag to False to add new permissions non-destructively.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> <code>synapse_client</code> <p>If not passed in or None this will use the last client from the <code>.login()</code> method.</p> <p> TYPE: <code>Optional[Synapse]</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>Dict[str, Union[str, list]]</code> <p>An Access Control List object</p> Setting permissions <p>Grant all registered users download access</p> <pre><code>File(id=\"syn123\").set_permissions(principal_id=273948, access_type=['READ','DOWNLOAD'])\n</code></pre> <p>Grant the public view access</p> <pre><code>File(id=\"syn123\").set_permissions(principal_id=273949, access_type=['READ'])\n</code></pre> Source code in <code>synapseclient/models/protocols/access_control_protocol.py</code> <pre><code>def set_permissions(\n    self,\n    principal_id: int = None,\n    access_type: List[str] = None,\n    modify_benefactor: bool = False,\n    warn_if_inherits: bool = True,\n    overwrite: bool = True,\n    *,\n    synapse_client: Optional[Synapse] = None,\n) -&gt; Dict[str, Union[str, list]]:\n    \"\"\"\n    Sets permission that a user or group has on an Entity.\n    An Entity may have its own ACL or inherit its ACL from a benefactor.\n\n    Arguments:\n        principal_id: Identifier of a user or group. `273948` is for all\n            registered Synapse users and `273949` is for public access.\n            None implies public access.\n        access_type: Type of permission to be granted. One or more of CREATE,\n            READ, DOWNLOAD, UPDATE, DELETE, CHANGE_PERMISSIONS.\n\n            **Defaults to ['READ', 'DOWNLOAD']**\n        modify_benefactor: Set as True when modifying a benefactor's ACL\n        warn_if_inherits: Set as False, when creating a new ACL. Trying to modify\n            the ACL of an Entity that inherits its ACL will result in a warning\n        overwrite: By default this function overwrites existing permissions for\n            the specified user. Set this flag to False to add new permissions\n            non-destructively.\n        synapse_client: If not passed in or None this will use the last client\n            from the `.login()` method.\n\n    Returns:\n        An Access Control List object\n\n    Example: Setting permissions\n        Grant all registered users download access\n\n            File(id=\"syn123\").set_permissions(principal_id=273948, access_type=['READ','DOWNLOAD'])\n\n        Grant the public view access\n\n            File(id=\"syn123\").set_permissions(principal_id=273949, access_type=['READ'])\n    \"\"\"\n    return {}\n</code></pre>"},{"location":"reference/oop/models/#synapseclient.models.File","title":"<code>synapseclient.models.File</code>  <code>dataclass</code>","text":"<p>               Bases: <code>FileSynchronousProtocol</code>, <code>AccessControllable</code></p> <p>A file within Synapse.</p> ATTRIBUTE DESCRIPTION <code>id</code> <p>The unique immutable ID for this file. A new ID will be generated for new Files. Once issued, this ID is guaranteed to never change or be re-issued.</p> <p> TYPE: <code>Optional[str]</code> </p> <code>name</code> <p>The name of this entity. Must be 256 characters or less. Names may only contain: letters, numbers, spaces, underscores, hyphens, periods, plus signs, apostrophes, and parentheses. If not specified, the name will be derived from the file name.</p> <p> TYPE: <code>Optional[str]</code> </p> <code>path</code> <p>The path to the file on disk.</p> <p> TYPE: <code>Optional[str]</code> </p> <code>description</code> <p>The description of this file. Must be 1000 characters or less.</p> <p> TYPE: <code>Optional[str]</code> </p> <code>parent_id</code> <p>The ID of the Entity that is the parent of this Entity. Setting this to a new value and storing it will move this File under the new parent.</p> <p> TYPE: <code>Optional[str]</code> </p> <code>version_label</code> <p>The version label for this entity. Updates to the entity will increment the version number.</p> <p> TYPE: <code>Optional[str]</code> </p> <code>version_comment</code> <p>The version comment for this entity</p> <p> TYPE: <code>Optional[str]</code> </p> <code>data_file_handle_id</code> <p>ID of the file associated with this entity. You may define an existing data_file_handle_id to use the existing data_file_handle_id. The creator of the file must also be the owner of the data_file_handle_id to have permission to store the file.</p> <p> TYPE: <code>Optional[str]</code> </p> <code>external_url</code> <p>The external URL of this file. If this is set AND <code>synapse_store</code> is False, only a reference to this URL and the file metadata will be stored in Synapse. The file itself will not be uploaded. If this attribute is set it will override the <code>path</code>.</p> <p> TYPE: <code>Optional[str]</code> </p> <code>activity</code> <p>The Activity model represents the main record of Provenance in Synapse. It is analygous to the Activity defined in the W3C Specification on Provenance. Activity cannot be removed during a store operation by setting it to None. You must use: synapseclient.models.Activity.delete_async or synapseclient.models.Activity.disassociate_from_entity_async.</p> <p> TYPE: <code>Optional[Activity]</code> </p> <code>annotations</code> <p>Additional metadata associated with the folder. The key is the name of your desired annotations. The value is an object containing a list of values (use empty list to represent no values for key) and the value type associated with all values in the list. To remove all annotations set this to an empty dict <code>{}</code> or None and store the entity.</p> <p> TYPE: <code>Optional[Dict[str, Union[List[str], List[bool], List[float], List[int], List[date], List[datetime]]]]</code> </p> ATTRIBUTE DESCRIPTION <code>content_type</code> <p>(New Upload Only) Used to manually specify Content-type header, for example 'application/png' or 'application/json; charset=UTF-8'. If not specified, the content type will be derived from the file extension.</p> <p>This can be specified only during the initial store of this file or any time there is a new file to upload. In order to change this after the File has been created use synapseclient.models.File.change_metadata.</p> <p> TYPE: <code>Optional[str]</code> </p> <code>content_size</code> <p>(New Upload Only) The size of the file in bytes. This can be specified only during the initial creation of the File. This is also only applicable to files not uploaded to Synapse. ie: <code>synapse_store</code> is False.</p> <p> TYPE: <code>Optional[int]</code> </p> ATTRIBUTE DESCRIPTION <code>content_md5</code> <p>(Store only) The MD5 of the file is known. If not supplied this will be computed in the client is possible. If supplied for a file entity already stored in Synapse it will be calculated again to check if a new upload needs to occur. This will not be filled in during a read for data. It is only used during a store operation. To retrieve the md5 of the file after read from synapse use the <code>.file_handle.content_md5</code> attribute.</p> <p> TYPE: <code>Optional[str]</code> </p> <code>create_or_update</code> <p>(Store only) Indicates whether the method should automatically perform an update if the <code>file</code> conflicts with an existing Synapse object.</p> <p> TYPE: <code>bool</code> </p> <code>force_version</code> <p>(Store only) Indicates whether the method should increment the version of the object if something within the entity has changed. For example updating the description or name. You may set this to False and an update to the entity will not increment the version.</p> <p>Updating the <code>version_label</code> attribute will also cause a version update regardless  of this flag.</p> <p>An update to the MD5 of the file will force a version update regardless of this  flag.</p> <p> TYPE: <code>bool</code> </p> <code>is_restricted</code> <p>(Store only) If set to true, an email will be sent to the Synapse access control team to start the process of adding terms-of-use or review board approval for this entity. You will be contacted with regards to the specific data being restricted and the requirements of access.</p> <p>This may be used only by an administrator of the specified file.</p> <p> TYPE: <code>bool</code> </p> <code>merge_existing_annotations</code> <p>(Store only) Works in conjunction with <code>create_or_update</code> in that this is only evaluated if <code>create_or_update</code> is True. If this entity exists in Synapse that has annotations that are not present in a store operation, these annotations will be added to the entity. If this is False any annotations that are not present within a store operation will be removed from this entity. This allows one to complete a destructive update of annotations on an entity.</p> <p> TYPE: <code>bool</code> </p> <code>associate_activity_to_new_version</code> <p>(Store only) Works in conjunction with <code>create_or_update</code> in that this is only evaluated if <code>create_or_update</code> is True. When true an activity already attached to the current version of this entity will be associated the new version during a store operation if the version was updated. This is useful if you are updating the entity and want to ensure that the activity is persisted onto the new version the entity.</p> <p> TYPE: <code>bool</code> </p> <code>synapse_store</code> <p>(Store only) Whether the File should be uploaded or if false: only the path should be stored when synapseclient.models.File.store is called.</p> <p> TYPE: <code>bool</code> </p> ATTRIBUTE DESCRIPTION <code>download_file</code> <p>(Get only) If True the file will be downloaded.</p> <p> TYPE: <code>bool</code> </p> <code>download_location</code> <p>(Get only) The location to download the file to.</p> <p> TYPE: <code>str</code> </p> <code>if_collision</code> <p>(Get only) Determines how to handle file collisions. Defaults to \"keep.both\". May be:</p> <ul> <li><code>overwrite.local</code></li> <li><code>keep.local</code></li> <li><code>keep.both</code></li> </ul> <p> TYPE: <code>str</code> </p> <code>synapse_container_limit</code> <p>(Get only) A Synanpse ID used to limit the search in Synapse if file is specified as a local file. That is, if the file is stored in multiple locations in Synapse only the ones in the specified folder/project will be returned.</p> <p> TYPE: <code>Optional[str]</code> </p> ATTRIBUTE DESCRIPTION <code>etag</code> <p>(Read Only) Synapse employs an Optimistic Concurrency Control (OCC) scheme to handle concurrent updates. Since the E-Tag changes every time an entity is updated it is used to detect when a client's current representation of an entity is out-of-date.</p> <p> TYPE: <code>Optional[str]</code> </p> <code>created_on</code> <p>(Read Only) The date this entity was created.</p> <p> TYPE: <code>Optional[str]</code> </p> <code>modified_on</code> <p>(Read Only) The date this entity was last modified.</p> <p> TYPE: <code>Optional[str]</code> </p> <code>created_by</code> <p>(Read Only) The ID of the user that created this entity.</p> <p> TYPE: <code>Optional[str]</code> </p> <code>modified_by</code> <p>(Read Only) The ID of the user that last modified this entity.</p> <p> TYPE: <code>Optional[str]</code> </p> <code>version_number</code> <p>(Read Only) The version number issued to this version on the object.</p> <p> TYPE: <code>Optional[int]</code> </p> <code>is_latest_version</code> <p>(Read Only) If this is the latest version of the object.</p> <p> TYPE: <code>Optional[bool]</code> </p> <code>file_handle</code> <p>(Read Only) The file handle associated with this entity.</p> <p> TYPE: <code>Optional[FileHandle]</code> </p> Source code in <code>synapseclient/models/file.py</code> <pre><code>@dataclass()\n@async_to_sync\nclass File(FileSynchronousProtocol, AccessControllable):\n    \"\"\"A file within Synapse.\n\n    Attributes:\n        id: The unique immutable ID for this file. A new ID will be generated for new\n            Files. Once issued, this ID is guaranteed to never change or be re-issued.\n        name: The name of this entity. Must be 256 characters or less. Names may only\n            contain: letters, numbers, spaces, underscores, hyphens, periods, plus\n            signs, apostrophes, and parentheses. If not specified, the name will be\n            derived from the file name.\n        path: The path to the file on disk.\n        description: The description of this file. Must be 1000 characters or less.\n        parent_id: The ID of the Entity that is the parent of this Entity. Setting this\n            to a new value and storing it will move this File under the new parent.\n        version_label: The version label for this entity. Updates to the entity will\n            increment the version number.\n        version_comment: The version comment for this entity\n        data_file_handle_id: ID of the file associated with this entity. You may define\n            an existing data_file_handle_id to use the existing data_file_handle_id. The\n            creator of the file must also be the owner of the data_file_handle_id to\n            have permission to store the file.\n        external_url: The external URL of this file. If this is set AND `synapse_store`\n            is False, only a reference to this URL and the file metadata will be stored\n            in Synapse. The file itself will not be uploaded. If this attribute is set\n            it will override the `path`.\n        activity: The Activity model represents the main record of Provenance in\n            Synapse. It is analygous to the Activity defined in the\n            [W3C Specification](https://www.w3.org/TR/prov-n/) on Provenance. Activity\n            cannot be removed during a store operation by setting it to None. You must\n            use: [synapseclient.models.Activity.delete_async][] or\n            [synapseclient.models.Activity.disassociate_from_entity_async][].\n        annotations: Additional metadata associated with the folder. The key is the name\n            of your desired annotations. The value is an object containing a list of\n            values (use empty list to represent no values for key) and the value type\n            associated with all values in the list. To remove all annotations set this\n            to an empty dict `{}` or None and store the entity.\n\n    Attributes:\n        content_type: (New Upload Only)\n            Used to manually specify Content-type header, for example\n            'application/png' or 'application/json; charset=UTF-8'. If not specified,\n            the content type will be derived from the file extension.\n\n\n            This can be specified only during the initial store of this file or any time\n            there is a new file to upload.\n            In order to change this after the File has been created use\n            [synapseclient.models.File.change_metadata][].\n        content_size: (New Upload Only)\n            The size of the file in bytes. This can be specified only during the initial\n            creation of the File. This is also only applicable to files not uploaded to\n            Synapse. ie: `synapse_store` is False.\n\n    Attributes:\n        content_md5: (Store only) The MD5 of the file is known. If not supplied this\n            will be computed in the client is possible. If supplied for a file entity\n            already stored in Synapse it will be calculated again to check if a new\n            upload needs to occur. This will not be filled in during a read for data. It\n            is only used during a store operation. To retrieve the md5 of the file after\n            read from synapse use the `.file_handle.content_md5` attribute.\n        create_or_update: (Store only)\n            Indicates whether the method should automatically perform an\n            update if the `file` conflicts with an existing Synapse object.\n        force_version: (Store only)\n            Indicates whether the method should increment the version of the object if\n            something within the entity has changed. For example updating the\n            description or name. You may set this to False and an update to the\n            entity will not increment the version.\n\n            Updating the `version_label` attribute will also cause a version update\n            regardless  of this flag.\n\n            An update to the MD5 of the file will force a version update regardless of\n            this  flag.\n        is_restricted: (Store only)\n            If set to true, an email will be sent to the Synapse access control\n            team to start the process of adding terms-of-use or review board approval\n            for this entity. You will be contacted with regards to the specific data\n            being restricted and the requirements of access.\n\n            This may be used only by an administrator of the specified file.\n        merge_existing_annotations: (Store only)\n            Works in conjunction with `create_or_update` in that this is only evaluated\n            if `create_or_update` is True. If this entity exists in Synapse that has\n            annotations that are not present in a store operation, these annotations\n            will be added to the entity. If this is False any annotations that are not\n            present within a store operation will be removed from this entity. This\n            allows one to complete a destructive update of annotations on an entity.\n        associate_activity_to_new_version: (Store only)\n            Works in conjunction with `create_or_update` in that this is only evaluated\n            if `create_or_update` is True. When true an activity already attached to the\n            current version of this entity will be associated the new version during a\n            store operation if the version was updated. This is useful if you are\n            updating the entity and want to ensure that the activity is persisted onto\n            the new version the entity.\n        synapse_store: (Store only)\n            Whether the File should be uploaded or if false: only the path should\n            be stored when [synapseclient.models.File.store][] is called.\n\n    Attributes:\n        download_file: (Get only) If True the file will be downloaded.\n        download_location: (Get only) The location to download the file to.\n        if_collision: (Get only)\n            Determines how to handle file collisions. Defaults to \"keep.both\". May be:\n\n            - `overwrite.local`\n            - `keep.local`\n            - `keep.both`\n        synapse_container_limit: (Get only)\n            A Synanpse ID used to limit the search in Synapse if\n            file is specified as a local file. That is, if the file is stored in\n            multiple locations in Synapse only the ones in the specified folder/project\n            will be returned.\n\n    Attributes:\n        etag: (Read Only) Synapse employs an Optimistic Concurrency Control (OCC) scheme\n            to handle concurrent updates. Since the E-Tag changes every time an entity\n            is updated it is used to detect when a client's current representation of an\n            entity is out-of-date.\n        created_on: (Read Only) The date this entity was created.\n        modified_on: (Read Only) The date this entity was last modified.\n        created_by: (Read Only) The ID of the user that created this entity.\n        modified_by: (Read Only) The ID of the user that last modified this entity.\n        version_number: (Read Only) The version number issued to this version on the\n            object.\n        is_latest_version: (Read Only) If this is the latest version of the object.\n        file_handle: (Read Only) The file handle associated with this entity.\n    \"\"\"\n\n    id: Optional[str] = None\n    \"\"\"The unique immutable ID for this file. A new ID will be generated for new Files.\n    Once issued, this ID is guaranteed to never change or be re-issued.\"\"\"\n\n    name: Optional[str] = None\n    \"\"\"\n    The name of this entity. Must be 256 characters or less.\n    Names may only contain: letters, numbers, spaces, underscores, hyphens, periods,\n    plus signs, apostrophes, and parentheses. If not specified, the name will be\n    derived from the file name.\n    \"\"\"\n\n    path: Optional[str] = field(default=None, compare=False)\n    \"\"\"The path to the file on disk.\"\"\"\n\n    description: Optional[str] = None\n    \"\"\"The description of this file. Must be 1000 characters or less.\"\"\"\n\n    parent_id: Optional[str] = None\n    \"\"\"The ID of the Entity that is the parent of this Entity. Setting this to a new\n    value and storing it will move this File under the new parent.\"\"\"\n\n    version_label: Optional[str] = None\n    \"\"\"The version label for this entity. Updates to the entity will increment the\n    version number.\"\"\"\n\n    version_comment: Optional[str] = None\n    \"\"\"The version comment for this entity.\"\"\"\n\n    data_file_handle_id: Optional[str] = None\n    \"\"\"\n    ID of the file handle associated with this entity. You may define an existing\n    data_file_handle_id to use the existing data_file_handle_id. The creator of the\n    file must also be the owner of the data_file_handle_id to have permission to\n    store the file.\n    \"\"\"\n\n    external_url: Optional[str] = field(default=None, compare=False)\n    \"\"\"\n    The external URL of this file. If this is set AND `synapse_store` is False, only\n    a reference to this URL and the file metadata will be stored in Synapse. The file\n    itself will not be uploaded. If this attribute is set it will override the `path`.\n    \"\"\"\n\n    activity: Optional[Activity] = field(default=None, compare=False)\n    \"\"\"The Activity model represents the main record of Provenance in Synapse.  It is\n    analygous to the Activity defined in the\n    [W3C Specification](https://www.w3.org/TR/prov-n/) on Provenance. Activity cannot\n    be removed during a store operation by setting it to None. You must use:\n    [synapseclient.models.Activity.delete_async][] or\n    [synapseclient.models.Activity.disassociate_from_entity_async][].\n    \"\"\"\n\n    annotations: Optional[\n        Dict[\n            str,\n            Union[\n                List[str],\n                List[bool],\n                List[float],\n                List[int],\n                List[date],\n                List[datetime],\n            ],\n        ]\n    ] = field(default_factory=dict, compare=False)\n    \"\"\"Additional metadata associated with the folder. The key is the name of your\n    desired annotations. The value is an object containing a list of values\n    (use empty list to represent no values for key) and the value type associated with\n    all values in the list. To remove all annotations set this to an empty dict `{}`.\"\"\"\n\n    content_type: Optional[str] = None\n    \"\"\"\n    (New Upload Only)\n    Used to manually specify Content-type header, for example 'application/png'\n    or 'application/json; charset=UTF-8'. If not specified, the content type will be\n    derived from the file extension.\n\n    This can be specified only during the initial store of this file. In order to change\n    this after the File has been created use\n    [synapseclient.models.File.change_metadata][].\n    \"\"\"\n\n    content_size: Optional[int] = None\n    \"\"\"\n    (New Upload Only)\n    The size of the file in bytes. This can be specified only during the initial\n    creation of the File. This is also only applicable to files not uploaded to Synapse.\n    ie: `synapse_store` is False.\n    \"\"\"\n\n    content_md5: Optional[str] = field(default=None, compare=False)\n    \"\"\"\n    (Store only)\n    The MD5 of the file is known. If not supplied this will be computed in the client\n    is possible. If supplied for a file entity already stored in Synapse it will be\n    calculated again to check if a new upload needs to occur. This will not be filled\n    in during a read for data. It is only used during a store operation. To retrieve\n    the md5 of the file after read from synapse use the `.file_handle.content_md5`\n    attribute.\n    \"\"\"\n\n    create_or_update: bool = field(default=True, repr=False, compare=False)\n    \"\"\"\n    (Store only)\n\n    Indicates whether the method should automatically perform an update if the file\n    conflicts with an existing Synapse object.\n    \"\"\"\n\n    force_version: bool = field(default=True, repr=False, compare=False)\n    \"\"\"\n    (Store only)\n\n    Indicates whether the method should increment the version of the object if something\n    within the entity has changed. For example updating the description or name.\n    You may set this to False and an update to the entity will not increment the\n    version.\n\n    Updating the `version_label` attribute will also cause a version update regardless\n    of this flag.\n\n    An update to the MD5 of the file will force a version update regardless of this\n    flag.\n    \"\"\"\n\n    is_restricted: bool = field(default=False, repr=False)\n    \"\"\"\n    (Store only)\n\n    If set to true, an email will be sent to the Synapse access control team to start\n    the process of adding terms-of-use or review board approval for this entity.\n    You will be contacted with regards to the specific data being restricted and the\n    requirements of access.\n\n    This may be used only by an administrator of the specified file.\n    \"\"\"\n\n    merge_existing_annotations: bool = field(default=True, repr=False, compare=False)\n    \"\"\"\n    (Store only)\n\n    Works in conjunction with `create_or_update` in that this is only evaluated if\n    `create_or_update` is True. If this entity exists in Synapse that has annotations\n    that are not present in a store operation, these annotations will be added to the\n    entity. If this is False any annotations that are not present within a store\n    operation will be removed from this entity. This allows one to complete a\n    destructive update of annotations on an entity.\n    \"\"\"\n\n    associate_activity_to_new_version: bool = field(\n        default=False, repr=False, compare=False\n    )\n    \"\"\"\n    (Store only)\n\n    Works in conjunction with `create_or_update` in that this is only evaluated if\n    `create_or_update` is True. When true an activity already attached to the current\n    version of this entity will be associated the new version during a store operation\n    if the version was updated. This is useful if you are updating the entity and want\n    to ensure that the activity is persisted onto the new version the entity.\n\n    When this is False the activity will not be associated to the new version of the\n    entity during a store operation.\n\n    Regardless of this setting, if you have an Activity object on the entity it will be\n    persisted onto the new version. This is only used when you don't have an Activity\n    object on the entity.\n    \"\"\"\n\n    _present_manifest_fields: List[str] = field(default=None, repr=False, compare=False)\n    \"\"\"Hidden attribute to pass along what columns were present in a manifest upload.\"\"\"\n\n    synapse_store: bool = field(default=True, repr=False)\n    \"\"\"\n    (Store only)\n\n    Whether the File should be uploaded or if false: only the path should be stored when\n    [synapseclient.models.File.store][] is called.\n    \"\"\"\n\n    download_file: bool = field(default=True, repr=False, compare=False)\n    \"\"\"\n    (Get only)\n\n    If True the file will be downloaded.\"\"\"\n\n    download_location: str = field(default=None, repr=False, compare=False)\n    \"\"\"\n    (Get only)\n\n    The location to download the file to.\"\"\"\n\n    if_collision: str = field(default=\"keep.both\", repr=False, compare=False)\n    \"\"\"\n    (Get only)\n\n    Determines how to handle file collisions. Defaults to \"keep.both\".\n            May be\n\n            - `overwrite.local`\n            - `keep.local`\n            - `keep.both`\n    \"\"\"\n\n    synapse_container_limit: Optional[str] = field(\n        default=None, repr=False, compare=False\n    )\n    \"\"\"A Synanpse ID used to limit the search in Synapse if file is specified as a local\n    file. That is, if the file is stored in multiple locations in Synapse only the\n    ones in the specified folder/project will be returned.\"\"\"\n\n    etag: Optional[str] = field(default=None, compare=False)\n    \"\"\"\n    (Read Only)\n    Synapse employs an Optimistic Concurrency Control (OCC) scheme to handle\n    concurrent updates. Since the E-Tag changes every time an entity is updated it is\n    used to detect when a client's current representation of an entity is out-of-date.\n    \"\"\"\n\n    created_on: Optional[str] = field(default=None, compare=False)\n    \"\"\"(Read Only) The date this entity was created.\"\"\"\n\n    modified_on: Optional[str] = field(default=None, compare=False)\n    \"\"\"(Read Only) The date this entity was last modified.\"\"\"\n\n    created_by: Optional[str] = field(default=None, compare=False)\n    \"\"\"(Read Only) The ID of the user that created this entity.\"\"\"\n\n    modified_by: Optional[str] = field(default=None, compare=False)\n    \"\"\"(Read Only) The ID of the user that last modified this entity.\"\"\"\n\n    version_number: Optional[int] = field(default=None, compare=False)\n    \"\"\"(Read Only) The version number issued to this version on the object.\"\"\"\n\n    is_latest_version: Optional[bool] = field(default=None, compare=False)\n    \"\"\"(Read Only) If this is the latest version of the object.\"\"\"\n\n    file_handle: Optional[FileHandle] = field(default=None, compare=False)\n    \"\"\"(Read Only) The file handle associated with this entity.\"\"\"\n\n    _last_persistent_instance: Optional[\"File\"] = field(\n        default=None, repr=False, compare=False\n    )\n    \"\"\"The last persistent instance of this object. This is used to determine if the\n    object has been changed and needs to be updated in Synapse.\"\"\"\n\n    @property\n    def has_changed(self) -&gt; bool:\n        \"\"\"Determines if the object has been changed and needs to be updated in Synapse.\"\"\"\n        return (\n            not self._last_persistent_instance or self._last_persistent_instance != self\n        )\n\n    def _set_last_persistent_instance(self) -&gt; None:\n        \"\"\"Stash the last time this object interacted with Synapse. This is used to\n        determine if the object has been changed and needs to be updated in Synapse.\"\"\"\n        del self._last_persistent_instance\n        self._last_persistent_instance = dataclasses.replace(self)\n        self._last_persistent_instance.activity = (\n            dataclasses.replace(self.activity) if self.activity else None\n        )\n        self._last_persistent_instance.annotations = (\n            deepcopy(self.annotations) if self.annotations else {}\n        )\n\n    def _fill_from_file_handle(self) -&gt; None:\n        \"\"\"Fill the file object from the file handle.\"\"\"\n        if self.file_handle:\n            self.data_file_handle_id = self.file_handle.id\n            self.content_type = self.file_handle.content_type\n            self.content_size = self.file_handle.content_size\n            self.external_url = self.file_handle.external_url\n\n    def fill_from_dict(\n        self,\n        synapse_file: Union[Synapse_File, Dict[str, Union[bool, str, int]]],\n        set_annotations: bool = True,\n    ) -&gt; \"File\":\n        \"\"\"\n        Converts a response from the REST API into this dataclass.\n\n        Arguments:\n            synapse_file: The response from the REST API.\n            set_annotations: Whether to set the annotations from the response.\n\n        Returns:\n            The File object.\n        \"\"\"\n        self.id = synapse_file.get(\"id\", None)\n        self.name = synapse_file.get(\"name\", None)\n        self.description = synapse_file.get(\"description\", None)\n        self.etag = synapse_file.get(\"etag\", None)\n        self.created_on = synapse_file.get(\"createdOn\", None)\n        self.modified_on = synapse_file.get(\"modifiedOn\", None)\n        self.created_by = synapse_file.get(\"createdBy\", None)\n        self.modified_by = synapse_file.get(\"modifiedBy\", None)\n        self.parent_id = synapse_file.get(\"parentId\", None)\n        self.version_number = synapse_file.get(\"versionNumber\", None)\n        self.version_label = synapse_file.get(\"versionLabel\", None)\n        self.version_comment = synapse_file.get(\"versionComment\", None)\n        self.is_latest_version = synapse_file.get(\"isLatestVersion\", False)\n        self.data_file_handle_id = synapse_file.get(\"dataFileHandleId\", None)\n        self.path = synapse_file.get(\"path\", self.path)\n        synapse_file_handle = synapse_file.get(\"_file_handle\", None)\n        if synapse_file_handle:\n            file_handle = self.file_handle or FileHandle()\n            self.file_handle = file_handle.fill_from_dict(\n                synapse_instance=synapse_file_handle\n            )\n            self._fill_from_file_handle()\n\n        if set_annotations:\n            self.annotations = Annotations.from_dict(\n                synapse_file.get(\"annotations\", {})\n            )\n        return self\n\n    def _cannot_store(self) -&gt; bool:\n        \"\"\"Determines based on some guard conditions if we are unable to continue with\n        a store operation.\"\"\"\n        return (\n            not (\n                self.id is not None\n                and (self.path is not None or self.data_file_handle_id is not None)\n            )\n            and not (self.path is not None and self.parent_id is not None)\n            and not (\n                self.parent_id is not None and self.data_file_handle_id is not None\n            )\n        )\n\n    async def _load_local_md5(self) -&gt; None:\n        \"\"\"Load the MD5 of the file if it's a local file and we have not already loaded\n        it.\"\"\"\n        if not self.content_md5 and self.path and os.path.isfile(self.path):\n            self.content_md5 = utils.md5_for_file_hex(filename=self.path)\n\n    async def _find_existing_file(\n        self, *, synapse_client: Optional[Synapse] = None\n    ) -&gt; Union[\"File\", None]:\n        \"\"\"Determines if the file already exists in Synapse. If it does it will return\n        the file object, otherwise it will return None. This is used to determine if the\n        file should be updated or created.\"\"\"\n\n        async def get_file(existing_id: str) -&gt; \"File\":\n            \"\"\"Small wrapper to retrieve a file instance without raising an error if it\n            does not exist.\n\n            Arguments:\n                existing_id: The ID of the file to retrieve.\n\n            Returns:\n                The file object if it exists, otherwise None.\n            \"\"\"\n            try:\n                file_copy = File(\n                    id=existing_id,\n                    download_file=False,\n                    version_number=self.version_number,\n                    synapse_container_limit=self.synapse_container_limit,\n                    parent_id=self.parent_id,\n                )\n                return await file_copy.get_async(\n                    synapse_client=synapse_client,\n                    include_activity=self.activity is not None\n                    or self.associate_activity_to_new_version,\n                )\n            except SynapseFileNotFoundError:\n                return None\n\n        if (\n            self.create_or_update\n            and not self._last_persistent_instance\n            and (\n                existing_file_id := await get_id(\n                    entity=self,\n                    failure_strategy=None,\n                    synapse_client=synapse_client,\n                )\n            )\n            and (existing_file := await get_file(existing_file_id))\n        ):\n            return existing_file\n        return None\n\n    def _determine_fields_to_ignore_in_merge(self) -&gt; List[str]:\n        \"\"\"This is used to determine what fields should not be merged when merging two\n        entities. This allows for a fine tuned destructive update of an entity.\n\n        This also has special handling during a manifest upload of files. If a manifest\n        is specifying fields we'll use those values rather than copying them from the\n        existing entity. This is to allow for a destructive update of an entity.\n\n        \"\"\"\n        fields_to_not_merge = []\n        if not self.merge_existing_annotations:\n            fields_to_not_merge.append(\"annotations\")\n\n        if not self.associate_activity_to_new_version:\n            fields_to_not_merge.append(\"activity\")\n\n        if self._present_manifest_fields:\n            if \"name\" in self._present_manifest_fields:\n                fields_to_not_merge.append(\"name\")\n\n            if \"contentType\" in self._present_manifest_fields:\n                fields_to_not_merge.append(\"content_type\")\n\n        return fields_to_not_merge\n\n    @otel_trace_method(\n        method_to_trace_name=lambda self, **kwargs: f\"File_Store: {self.path if self.path else self.id}\"\n    )\n    async def store_async(\n        self,\n        parent: Optional[Union[\"Folder\", \"Project\"]] = None,\n        *,\n        synapse_client: Optional[Synapse] = None,\n    ) -&gt; \"File\":\n        \"\"\"\n        Store the file in Synapse. With this method you may:\n\n        - Upload a file into Synapse\n        - Update the metadata of a file in Synapse\n        - Store a File object in Synapse without updating a file by setting\n            `synapse_store` to False.\n        - Change the name of a file in Synapse by setting the `name` attribute of the\n            File object. Also see the [synapseclient.models.File.change_metadata][]\n            method for changing the name of the downloaded file.\n        - Moving a file to a new parent by setting the `parent_id` attribute of the\n            File object.\n\n        If no Name is specified this will be derived from the file name. This is the\n        reccommended way to store a file in Synapse.\n\n        Please note:\n        The file, as it appears on disk, will be the file that is downloaded from\n        Synapse. The name of the actual File is different from the name of the File\n        Entity in Synapse. It is generally not reccommended to specify a different\n        name for the Entity and the file as it will cause confusion and potential\n        conflicts later on.\n\n        Arguments:\n            parent: The parent folder or project to store the file in. May also be\n                specified in the File object. If both are provided the parent passed\n                into `store` will take precedence.\n            synapse_client: If not passed in or None this will use the last client from\n                the `.login()` method.\n\n        Returns:\n            The file object.\n\n        Raises:\n            ValueError: If the file does not have an ID and a path, or a path and a\n                parent ID, or a data file handle ID and a parent ID.\n\n        Example: Using this function\n            File with the ID `syn123` at path `path/to/file.txt`:\n\n                file_instance = await File(id=\"syn123\", path=\"path/to/file.txt\").store_async()\n\n            File at the path `path/to/file.txt` and a parent folder with the ID `syn456`:\n\n                file_instance = await File(path=\"path/to/file.txt\", parent_id=\"syn456\").store_async()\n\n            File at the path `path/to/file.txt` and a parent folder with the ID `syn456`:\n\n                file_instance = await File(path=\"path/to/file.txt\").store_async(parent=Folder(id=\"syn456\"))\n\n            File with a parent and existing file handle (This allows multiple entities to reference the underlying file):\n\n                file_instance = await File(data_file_handle_id=\"123\", parent_id=\"syn456\").store_async()\n\n            Rename a file (Does not update the file on disk or the name of the downloaded file):\n\n                file_instance = await File(id=\"syn123\", download_file=False).get_async()\n                print(file_instance.name)  ## prints, e.g., \"my_file.txt\"\n                await file_instance.change_metadata_async(name=\"my_new_name_file.txt\")\n\n            Rename a file, and the name of the file as downloaded\n                (Does not update the file on disk). Is is reccommended that `name` and\n                `download_as` match to prevent confusion later on:\n\n                file_instance = await File(id=\"syn123\", download_file=False).get_async()\n                print(file_instance.name)  ## prints, e.g., \"my_file.txt\"\n                await file_instance.change_metadata_async(name=\"my_new_name_file.txt\", download_as=\"my_new_name_file.txt\")\n\n        \"\"\"\n        self.parent_id = parent.id if parent else self.parent_id\n        if self._cannot_store():\n            raise ValueError(\n                \"The file must have an (ID with a (path or `data_file_handle_id`)), or a \"\n                \"(path with a (`parent_id` or parent with an id)), or a \"\n                \"(data_file_handle_id with a (`parent_id` or parent with an id)) to store.\"\n            )\n        self.name = self.name or (guess_file_name(self.path) if self.path else None)\n        client = Synapse.get_client(synapse_client=synapse_client)\n\n        if existing_file := await self._find_existing_file(synapse_client=client):\n            merge_dataclass_entities(\n                source=existing_file,\n                destination=self,\n                fields_to_ignore=self._determine_fields_to_ignore_in_merge(),\n            )\n\n        if self.path:\n            self.path = os.path.expanduser(self.path)\n            async with client._get_parallel_file_transfer_semaphore(\n                asyncio_event_loop=asyncio.get_running_loop()\n            ):\n                await self._upload_file(synapse_client=client)\n        elif self.data_file_handle_id:\n            self.path = client.cache.get(file_handle_id=self.data_file_handle_id)\n\n        if self.has_changed:\n            synapse_file = Synapse_File(\n                id=self.id,\n                path=self.path,\n                description=self.description,\n                etag=self.etag,\n                name=self.name,\n                parent=parent.id if parent else self.parent_id,\n                contentType=self.content_type,\n                contentSize=self.content_size,\n                dataFileHandleId=self.data_file_handle_id,\n                synapseStore=self.synapse_store,\n                modifiedOn=self.modified_on,\n                versionLabel=self.version_label,\n                versionNumber=self.version_number,\n                versionComment=self.version_comment,\n            )\n            delete_none_keys(synapse_file)\n\n            entity = await store_entity(\n                resource=self, entity=synapse_file, synapse_client=client\n            )\n\n            self.fill_from_dict(synapse_file=entity, set_annotations=False)\n\n        re_read_required = await store_entity_components(\n            root_resource=self, synapse_client=client\n        )\n        if re_read_required:\n            before_download_file = self.download_file\n            self.download_file = False\n            await self.get_async(\n                synapse_client=client,\n            )\n            self.download_file = before_download_file\n\n        self._set_last_persistent_instance()\n\n        client.logger.debug(f\"Stored File {self.name}, id: {self.id}: {self.path}\")\n        # Clear the content_md5 so that it is recalculated if the file is updated\n        self.content_md5 = None\n        return self\n\n    @otel_trace_method(\n        method_to_trace_name=lambda self, **kwargs: f\"File_Change_Metadata: {self.id}\"\n    )\n    async def change_metadata_async(\n        self,\n        name: Optional[str] = None,\n        download_as: Optional[str] = None,\n        content_type: Optional[str] = None,\n        *,\n        synapse_client: Optional[Synapse] = None,\n    ) -&gt; \"File\":\n        \"\"\"\n        Change File Entity metadata for properties that are immutable after creation\n        through the store method.\n\n        Arguments:\n            name: Specify to change the filename of a file as seen on Synapse.\n            download_as: Specify filename to change the filename of a filehandle.\n            content_type: Specify content type to change the content type of a\n                filehandle.\n            synapse_client: If not passed in or None this will use the last client from\n                the `.login()` method.\n\n        Returns:\n            The file object.\n\n        Example: Using this function\n            Can be used to change the filename, the filename when the file is\n            downloaded, or the file content-type without downloading:\n\n                file_entity = await File(id=\"syn123\", download_file=False).get_async()\n                print(os.path.basename(file_entity.path))  ## prints, e.g., \"my_file.txt\"\n                file_entity = await file_entity.change_metadata_async(name=\"my_new_name_file.txt\", download_as=\"my_new_downloadAs_name_file.txt\", content_type=\"text/plain\")\n                print(os.path.basename(file_entity.path))  ## prints, \"my_new_downloadAs_name_file.txt\"\n                print(file_entity.name) ## prints, \"my_new_name_file.txt\"\n\n        Raises:\n            ValueError: If the file does not have an ID to change metadata.\n        \"\"\"\n        if not self.id:\n            raise ValueError(\"The file must have an ID to change metadata.\")\n        from synapseutils.copy_functions import changeFileMetaData\n\n        loop = asyncio.get_event_loop()\n\n        current_context = context.get_current()\n        syn = Synapse.get_client(synapse_client=synapse_client)\n        entity = await loop.run_in_executor(\n            None,\n            lambda: run_and_attach_otel_context(\n                lambda: changeFileMetaData(\n                    syn=syn,\n                    entity=self.id,\n                    name=name,\n                    downloadAs=download_as,\n                    contentType=content_type,\n                    forceVersion=self.force_version,\n                ),\n                current_context,\n            ),\n        )\n\n        self.fill_from_dict(synapse_file=entity, set_annotations=True)\n        self._set_last_persistent_instance()\n        Synapse.get_client(synapse_client=synapse_client).logger.debug(\n            f\"Change metadata for file {self.name}, id: {self.id}: {self.path}\"\n        )\n        return self\n\n    @otel_trace_method(\n        method_to_trace_name=lambda self, **kwargs: f\"File_Get: {self.id}, {self.path}\"\n    )\n    async def get_async(\n        self,\n        include_activity: bool = False,\n        *,\n        synapse_client: Optional[Synapse] = None,\n    ) -&gt; \"File\":\n        \"\"\"\n        Get the file from Synapse. You may retrieve a File entity by either:\n\n        - id\n        - path\n\n\n        If you specify both, the `id` will take precedence.\n\n\n        If you specify the `path` and the file is stored in multiple locations in\n        Synapse only the first one found will be returned. The other matching files\n        will be printed to the console.\n\n\n        You may also specify a `version_number` to get a specific version of the file.\n\n        Arguments:\n            include_activity: If True the activity will be included in the file\n                if it exists.\n            synapse_client: If not passed in or None this will use the last client from\n                the `.login()` method.\n\n        Returns:\n            The file object.\n\n        Raises:\n            ValueError: If the file does not have an ID or path to get.\n\n\n        Example: Using this function\n            Assuming you have a file with the ID \"syn123\":\n\n                file_instance = await File(id=\"syn123\").get_async()\n\n            Assuming you have a file at the path \"path/to/file.txt\":\n\n                file_instance = await File(path=\"path/to/file.txt\").get_async()\n        \"\"\"\n        if not self.id and not self.path:\n            raise ValueError(\"The file must have an ID or path to get.\")\n        syn = Synapse.get_client(synapse_client=synapse_client)\n\n        await self._load_local_md5()\n\n        await get_from_entity_factory(\n            entity_to_update=self,\n            synapse_id_or_path=self.id or self.path,\n            version=self.version_number,\n            if_collision=self.if_collision,\n            limit_search=self.synapse_container_limit or self.parent_id,\n            download_file=self.download_file,\n            download_location=self.download_location,\n            md5=self.content_md5,\n        )\n\n        if (\n            not self.path\n            and self.data_file_handle_id\n            and (cached_path := syn.cache.get(file_handle_id=self.data_file_handle_id))\n        ):\n            self.path = cached_path\n\n        if include_activity:\n            self.activity = await Activity.from_parent_async(\n                parent=self, synapse_client=synapse_client\n            )\n\n        self._set_last_persistent_instance()\n        Synapse.get_client(synapse_client=synapse_client).logger.debug(\n            f\"Got file {self.name}, id: {self.id}, path: {self.path}\"\n        )\n        return self\n\n    @classmethod\n    async def from_id_async(\n        cls,\n        synapse_id: str,\n        *,\n        synapse_client: Optional[Synapse] = None,\n    ) -&gt; \"File\":\n        \"\"\"Wrapper for [synapseclient.models.File.get][].\n\n        Arguments:\n            synapse_id: The ID of the file in Synapse.\n            synapse_client: If not passed in or None this will use the last client\n                from the `.login()` method.\n\n        Returns:\n            The file object.\n\n        Example: Using this function\n            Assuming you have a file with the ID \"syn123\":\n\n                file_instance = await File.from_id_async(synapse_id=\"syn123\")\n        \"\"\"\n        return await cls(id=synapse_id).get_async(\n            synapse_client=synapse_client,\n        )\n\n    @classmethod\n    async def from_path_async(\n        cls,\n        path: str,\n        *,\n        synapse_client: Optional[Synapse] = None,\n    ) -&gt; \"File\":\n        \"\"\"Get the file from Synapse. If the path of the file matches multiple files\n        within Synapse the first one found will be returned. The other matching\n        files will be printed to the console.\n\n\n        Wrapper for [synapseclient.models.File.get][].\n\n        Arguments:\n            path: The path to the file on disk.\n            synapse_client: If not passed in or None this will use the last client\n                from the `.login()` method.\n\n        Returns:\n            The file object.\n\n        Example: Using this function\n            Assuming you have a file at the path \"path/to/file.txt\":\n\n                file_instance = await File.from_path_async(path=\"path/to/file.txt\")\n        \"\"\"\n        return await cls(path=path).get_async(\n            synapse_client=synapse_client,\n        )\n\n    @otel_trace_method(\n        method_to_trace_name=lambda self, **kwargs: f\"File_Delete: {self.id}\"\n    )\n    async def delete_async(\n        self,\n        version_only: Optional[bool] = False,\n        *,\n        synapse_client: Optional[Synapse] = None,\n    ) -&gt; None:\n        \"\"\"\n        Delete the file from Synapse using the ID of the file.\n\n        Arguments:\n            version_only: If True only the version specified in the `version_number`\n                attribute of the file will be deleted. If False the entire file will\n                be deleted.\n            synapse_client: If not passed in or None this will use the last client from\n                the `.login()` method.\n\n        Returns:\n            None\n\n        Raises:\n            ValueError: If the file does not have an ID to delete.\n            ValueError: If the file does not have a version number to delete a version,\n                and `version_only` is True.\n\n        Example: Using this function\n            Assuming you have a file with the ID \"syn123\":\n\n                await File(id=\"syn123\").delete_async()\n        \"\"\"\n        if not self.id:\n            raise ValueError(\"The file must have an ID to delete.\")\n        if version_only and not self.version_number:\n            raise ValueError(\"The file must have a version number to delete a version.\")\n\n        loop = asyncio.get_event_loop()\n        current_context = context.get_current()\n        await loop.run_in_executor(\n            None,\n            lambda: run_and_attach_otel_context(\n                lambda: Synapse.get_client(synapse_client=synapse_client).delete(\n                    obj=self.id,\n                    version=self.version_number if version_only else None,\n                ),\n                current_context,\n            ),\n        )\n        Synapse.get_client(synapse_client=synapse_client).logger.debug(\n            f\"Deleted file {self.id}\"\n        )\n\n    @otel_trace_method(\n        method_to_trace_name=lambda self, **kwargs: f\"File_Copy: {self.id}\"\n    )\n    async def copy_async(\n        self,\n        parent_id: str,\n        update_existing: bool = False,\n        copy_annotations: bool = True,\n        copy_activity: Union[str, None] = \"traceback\",\n        *,\n        synapse_client: Optional[Synapse] = None,\n    ) -&gt; \"File\":\n        \"\"\"\n        Copy the file to another Synapse location. Defaults to the latest version of the\n        file, or the version_number specified in the instance.\n\n        Arguments:\n            parent_id: Synapse ID of a folder/project that the copied entity is being\n                copied to\n            update_existing: When the destination has a file that has the same name,\n                users can choose to update that file.\n            copy_annotations: True to copy the annotations.\n            copy_activity: Has three options to set the activity of the copied file:\n\n                    - traceback: Creates a copy of the source files Activity.\n                    - existing: Link to the source file's original Activity (if it exists)\n                    - None: No activity is set\n            synapse_client: If not passed in or None this will use the last client from\n                the `.login()` method.\n\n        Returns:\n            The copied file object.\n\n        Example: Using this function\n            Assuming you have a file with the ID \"syn123\" and you want to copy it to a folder with the ID \"syn456\":\n\n                new_file_instance = await File(id=\"syn123\").copy_async(parent_id=\"syn456\")\n\n            Copy the file but do not persist annotations or activity:\n\n                new_file_instance = await File(id=\"syn123\").copy_async(parent_id=\"syn456\", copy_annotations=False, copy_activity=None)\n\n        Raises:\n            ValueError: If the file does not have an ID and parent_id to copy.\n        \"\"\"\n        if not self.id or not parent_id:\n            raise ValueError(\"The file must have an ID and parent_id to copy.\")\n        from synapseutils.copy_functions import copy\n\n        loop = asyncio.get_event_loop()\n\n        current_context = context.get_current()\n        syn = Synapse.get_client(synapse_client=synapse_client)\n        source_and_destination = await loop.run_in_executor(\n            None,\n            lambda: run_and_attach_otel_context(\n                lambda: copy(\n                    syn=syn,\n                    version=self.version_number,\n                    entity=self.id,\n                    destinationId=parent_id,\n                    skipCopyAnnotations=not copy_annotations,\n                    updateExisting=update_existing,\n                    setProvenance=copy_activity,\n                ),\n                current_context,\n            ),\n        )\n\n        parent_id = source_and_destination.get(self.id, None)\n        if not parent_id:\n            raise SynapseError(\"Failed to copy file.\")\n        file_copy = await File(id=parent_id, download_file=False).get_async(\n            synapse_client=synapse_client\n        )\n        file_copy.download_file = True\n        Synapse.get_client(synapse_client=synapse_client).logger.debug(\n            f\"Copied from file {self.id} to {parent_id} with new id of {file_copy.id}\"\n        )\n        return file_copy\n\n    async def _needs_upload(self, syn: Synapse) -&gt; bool:\n        \"\"\"\n        Determines if a file needs to be uploaded to Synapse. The following conditions\n        apply:\n\n        - The file exists and is an ExternalFileHandle and the url has changed\n        - The file exists and is a local file and the MD5 has changed\n        - The file is not present in Synapse\n\n        If the file is already specifying a data_file_handle_id then it is assumed that\n        the file is already uploaded to Synapse. It does not need to be uploaded and\n        the only thing that will occur is the File metadata will be added to Synapse\n        outside of this upload process.\n\n        Arguments:\n            syn: If not passed in or None this will use the last client from\n                the `.login()` method.\n\n        Returns:\n            True if the file needs to be uploaded, otherwise False.\n        \"\"\"\n        needs_upload = False\n        # Check if the file should be uploaded\n        if self._last_persistent_instance is not None:\n            if (\n                self.file_handle\n                and self.file_handle.concrete_type\n                == \"org.sagebionetworks.repo.model.file.ExternalFileHandle\"\n            ):\n                # switching away from ExternalFileHandle or the url was updated\n                needs_upload = self.synapse_store or (\n                    self.file_handle.external_url != self.external_url\n                )\n            else:\n                # Check if we need to upload a new version of an existing\n                # file. If the file referred to by entity['path'] has been\n                # modified, we want to upload the new version.\n                # If synapeStore is false then we must upload a ExternalFileHandle\n                needs_upload = (\n                    not self.synapse_store\n                    or not self.file_handle\n                    or not (\n                        exists_in_cache := syn.cache.contains(\n                            self.file_handle.id, self.path\n                        )\n                    )\n                )\n\n                md5_stored_in_synapse = (\n                    self.file_handle.content_md5 if self.file_handle else None\n                )\n\n                # Check if we got an MD5 checksum from Synapse and compare it to the local file\n                if (\n                    self.synapse_store\n                    and needs_upload\n                    and os.path.isfile(self.path)\n                    and md5_stored_in_synapse\n                ):\n                    await self._load_local_md5()\n                    if md5_stored_in_synapse == (\n                        local_file_md5_hex := self.content_md5\n                    ):\n                        needs_upload = False\n\n                    # If we had a cache miss, but already uploaded to Synapse we\n                    # can add the file to the cache.\n                    if (\n                        not exists_in_cache\n                        and self.file_handle\n                        and self.file_handle.id\n                        and local_file_md5_hex\n                    ):\n                        syn.cache.add(\n                            file_handle_id=self.file_handle.id,\n                            path=self.path,\n                            md5=local_file_md5_hex,\n                        )\n        elif self.data_file_handle_id is not None:\n            needs_upload = False\n        else:\n            needs_upload = True\n        return needs_upload\n\n    async def _upload_file(\n        self,\n        *,\n        synapse_client: Optional[Synapse] = None,\n    ) -&gt; \"File\":\n        \"\"\"The upload process for a file. This will upload the file to Synapse if it\n        needs to be uploaded. If the file does not need to be uploaded the file\n        metadata will be added to Synapse outside of this upload process.\n\n        Arguments:\n            synapse_client: If not passed in or None this will use the last client from\n                the `.login()` method.\n\n        Returns:\n            The file object.\n        \"\"\"\n        syn = Synapse.get_client(synapse_client=synapse_client)\n\n        needs_upload = await self._needs_upload(syn=syn)\n\n        if needs_upload:\n            parent_id_for_upload = self.parent_id\n\n            if not parent_id_for_upload:\n                raise SynapseMalformedEntityError(\n                    \"Entities of type File must have a parentId.\"\n                )\n\n            updated_file_handle = await upload_file_handle(\n                syn=syn,\n                parent_entity_id=parent_id_for_upload,\n                path=(\n                    self.path\n                    if (self.synapse_store or self.external_url is None)\n                    else self.external_url\n                ),\n                synapse_store=self.synapse_store,\n                md5=self.content_md5,\n                file_size=self.content_size,\n                mimetype=self.content_type,\n            )\n\n            self.file_handle = FileHandle().fill_from_dict(updated_file_handle)\n            self._fill_from_file_handle()\n\n        return self\n\n    def _convert_into_legacy_file(self) -&gt; SynapseFile:\n        \"\"\"Convert the file object into a SynapseFile object.\"\"\"\n        return_data = SynapseFile(\n            id=self.id,\n            name=self.name,\n            description=self.description,\n            etag=self.etag,\n            createdOn=self.created_on,\n            modifiedOn=self.modified_on,\n            createdBy=self.created_by,\n            modifiedBy=self.modified_by,\n            parentId=self.parent_id,\n            versionNumber=self.version_number,\n            versionLabel=self.version_label,\n            versionComment=self.version_comment,\n            dataFileHandleId=self.data_file_handle_id,\n            path=self.path,\n            properties={\n                \"isLatestVersion\": self.is_latest_version,\n            },\n            _file_handle=(\n                self.file_handle._convert_into_legacy_file_handle()\n                if self.file_handle\n                else None\n            ),\n            annotations=self.annotations,\n        )\n        delete_none_keys(return_data)\n        return return_data\n</code></pre>"},{"location":"reference/oop/models/#synapseclient.models.File-functions","title":"Functions","text":""},{"location":"reference/oop/models/#synapseclient.models.File.get","title":"<code>get(include_activity=False, *, synapse_client=None)</code>","text":"<p>Get the file from Synapse. You may retrieve a File entity by either:</p> <ul> <li>id</li> <li>path</li> </ul> <p>If you specify both, the <code>id</code> will take precedence.</p> <p>If you specify the <code>path</code> and the file is stored in multiple locations in Synapse only the first one found will be returned. The other matching files will be printed to the console.</p> <p>You may also specify a <code>version_number</code> to get a specific version of the file.</p> PARAMETER DESCRIPTION <code>include_activity</code> <p>If True the activity will be included in the file if it exists.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>synapse_client</code> <p>If not passed in or None this will use the last client from the <code>.login()</code> method.</p> <p> TYPE: <code>Optional[Synapse]</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>File</code> <p>The file object.</p> RAISES DESCRIPTION <code>ValueError</code> <p>If the file does not have an ID or path to get.</p> Using this function <p>Assuming you have a file with the ID \"syn123\":</p> <pre><code>file_instance = File(id=\"syn123\").get()\n</code></pre> <p>Assuming you have a file at the path \"path/to/file.txt\":</p> <pre><code>file_instance = File(path=\"path/to/file.txt\").get()\n</code></pre> Source code in <code>synapseclient/models/protocols/file_protocol.py</code> <pre><code>def get(\n    self,\n    include_activity: bool = False,\n    *,\n    synapse_client: Optional[Synapse] = None,\n) -&gt; \"File\":\n    \"\"\"\n    Get the file from Synapse. You may retrieve a File entity by either:\n\n    - id\n    - path\n\n\n    If you specify both, the `id` will take precedence.\n\n\n    If you specify the `path` and the file is stored in multiple locations in Synapse\n    only the first one found will be returned. The other matching files will be\n    printed to the console.\n\n\n    You may also specify a `version_number` to get a specific version of the file.\n\n    Arguments:\n        include_activity: If True the activity will be included in the file if it exists.\n        synapse_client: If not passed in or None this will use the last client from\n            the `.login()` method.\n\n    Returns:\n        The file object.\n\n    Raises:\n        ValueError: If the file does not have an ID or path to get.\n\n\n    Example: Using this function\n        Assuming you have a file with the ID \"syn123\":\n\n            file_instance = File(id=\"syn123\").get()\n\n        Assuming you have a file at the path \"path/to/file.txt\":\n\n            file_instance = File(path=\"path/to/file.txt\").get()\n    \"\"\"\n    return self\n</code></pre>"},{"location":"reference/oop/models/#synapseclient.models.File.store","title":"<code>store(parent=None, *, synapse_client=None)</code>","text":"<p>Store the file in Synapse. With this method you may:</p> <ul> <li>Upload a file into Synapse</li> <li>Update the metadata of a file in Synapse</li> <li>Store a File object in Synapse without updating a file by setting     <code>synapse_store</code> to False.</li> <li>Change the name of a file in Synapse by setting the <code>name</code> attribute of the     File object. Also see the synapseclient.models.File.change_metadata     method for changing the name of the downloaded file.</li> <li>Moving a file to a new parent by setting the <code>parent_id</code> attribute of the     File object.</li> </ul> PARAMETER DESCRIPTION <code>parent</code> <p>The parent folder or project to store the file in. May also be specified in the File object. If both are provided the parent passed into <code>store</code> will take precedence.</p> <p> TYPE: <code>Optional[Union[Folder, Project]]</code> DEFAULT: <code>None</code> </p> <code>synapse_client</code> <p>If not passed in or None this will use the last client from the <code>.login()</code> method.</p> <p> TYPE: <code>Optional[Synapse]</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>File</code> <p>The file object.</p> Using this function <p>File with the ID <code>syn123</code> at path <code>path/to/file.txt</code>:</p> <pre><code>file_instance = File(id=\"syn123\", path=\"path/to/file.txt\").store()\n</code></pre> <p>File at the path <code>path/to/file.txt</code> and a parent folder with the ID <code>syn456</code>:</p> <pre><code>file_instance = File(path=\"path/to/file.txt\", parent_id=\"syn456\").store()\n</code></pre> <p>File at the path <code>path/to/file.txt</code> and a parent folder with the ID <code>syn456</code>:</p> <pre><code>file_instance = File(path=\"path/to/file.txt\").store(parent=Folder(id=\"syn456\"))\n</code></pre> <p>Rename a file (Does not update the file on disk or the name of the downloaded file):</p> <pre><code>file_instance = File(id=\"syn123\", download_file=False).get()\nprint(file_instance.name)  ## prints, e.g., \"my_file.txt\"\nfile_instance.change_metadata(name=\"my_new_name_file.txt\")\n</code></pre> <p>Rename a file, and the name of the file as downloaded (Does not update the file on disk):</p> <pre><code>file_instance = File(id=\"syn123\", download_file=False).get()\nprint(file_instance.name)  ## prints, e.g., \"my_file.txt\"\nfile_instance.change_metadata(name=\"my_new_name_file.txt\", download_as=\"my_new_name_file.txt\")\n</code></pre> Source code in <code>synapseclient/models/protocols/file_protocol.py</code> <pre><code>def store(\n    self,\n    parent: Optional[Union[\"Folder\", \"Project\"]] = None,\n    *,\n    synapse_client: Optional[Synapse] = None,\n) -&gt; \"File\":\n    \"\"\"\n    Store the file in Synapse. With this method you may:\n\n    - Upload a file into Synapse\n    - Update the metadata of a file in Synapse\n    - Store a File object in Synapse without updating a file by setting\n        `synapse_store` to False.\n    - Change the name of a file in Synapse by setting the `name` attribute of the\n        File object. Also see the [synapseclient.models.File.change_metadata][]\n        method for changing the name of the downloaded file.\n    - Moving a file to a new parent by setting the `parent_id` attribute of the\n        File object.\n\n    Arguments:\n        parent: The parent folder or project to store the file in. May also be\n            specified in the File object. If both are provided the parent passed\n            into `store` will take precedence.\n        synapse_client: If not passed in or None this will use the last client from\n            the `.login()` method.\n\n    Returns:\n        The file object.\n\n\n    Example: Using this function\n        File with the ID `syn123` at path `path/to/file.txt`:\n\n            file_instance = File(id=\"syn123\", path=\"path/to/file.txt\").store()\n\n        File at the path `path/to/file.txt` and a parent folder with the ID `syn456`:\n\n            file_instance = File(path=\"path/to/file.txt\", parent_id=\"syn456\").store()\n\n        File at the path `path/to/file.txt` and a parent folder with the ID `syn456`:\n\n            file_instance = File(path=\"path/to/file.txt\").store(parent=Folder(id=\"syn456\"))\n\n        Rename a file (Does not update the file on disk or the name of the downloaded file):\n\n            file_instance = File(id=\"syn123\", download_file=False).get()\n            print(file_instance.name)  ## prints, e.g., \"my_file.txt\"\n            file_instance.change_metadata(name=\"my_new_name_file.txt\")\n\n        Rename a file, and the name of the file as downloaded (Does not update the file on disk):\n\n            file_instance = File(id=\"syn123\", download_file=False).get()\n            print(file_instance.name)  ## prints, e.g., \"my_file.txt\"\n            file_instance.change_metadata(name=\"my_new_name_file.txt\", download_as=\"my_new_name_file.txt\")\n\n    \"\"\"\n    return self\n</code></pre>"},{"location":"reference/oop/models/#synapseclient.models.File.copy","title":"<code>copy(parent_id, update_existing=False, copy_annotations=True, copy_activity='traceback', *, synapse_client=None)</code>","text":"<p>Copy the file to another Synapse location. Defaults to the latest version of the file, or the version_number specified in the instance.</p> PARAMETER DESCRIPTION <code>parent_id</code> <p>Synapse ID of a folder/project that the copied entity is being copied to</p> <p> TYPE: <code>str</code> </p> <code>update_existing</code> <p>When the destination has a file that has the same name, users can choose to update that file.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>copy_annotations</code> <p>True to copy the annotations.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> <code>copy_activity</code> <p>Has three options to set the activity of the copied file:</p> <pre><code>- traceback: Creates a copy of the source files Activity.\n- existing: Link to the source file's original Activity (if it exists)\n- None: No activity is set\n</code></pre> <p> TYPE: <code>Union[str, None]</code> DEFAULT: <code>'traceback'</code> </p> <code>synapse_client</code> <p>If not passed in or None this will use the last client from the <code>.login()</code> method.</p> <p> TYPE: <code>Optional[Synapse]</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>File</code> <p>The copied file object.</p> Using this function <p>Assuming you have a file with the ID \"syn123\" and you want to copy it to a folder with the ID \"syn456\":</p> <pre><code>new_file_instance = File(id=\"syn123\").copy(parent_id=\"syn456\")\n</code></pre> <p>Copy the file but do not persist annotations or activity:</p> <pre><code>new_file_instance = File(id=\"syn123\").copy(parent_id=\"syn456\", copy_annotations=False, copy_activity=None)\n</code></pre> RAISES DESCRIPTION <code>ValueError</code> <p>If the file does not have an ID and parent_id to copy.</p> Source code in <code>synapseclient/models/protocols/file_protocol.py</code> <pre><code>def copy(\n    self,\n    parent_id: str,\n    update_existing: bool = False,\n    copy_annotations: bool = True,\n    copy_activity: Union[str, None] = \"traceback\",\n    *,\n    synapse_client: Optional[Synapse] = None,\n) -&gt; \"File\":\n    \"\"\"\n    Copy the file to another Synapse location. Defaults to the latest version of the\n    file, or the version_number specified in the instance.\n\n    Arguments:\n        parent_id: Synapse ID of a folder/project that the copied entity is being\n            copied to\n        update_existing: When the destination has a file that has the same name,\n            users can choose to update that file.\n        copy_annotations: True to copy the annotations.\n        copy_activity: Has three options to set the activity of the copied file:\n\n                - traceback: Creates a copy of the source files Activity.\n                - existing: Link to the source file's original Activity (if it exists)\n                - None: No activity is set\n        synapse_client: If not passed in or None this will use the last client from\n            the `.login()` method.\n\n    Returns:\n        The copied file object.\n\n    Example: Using this function\n        Assuming you have a file with the ID \"syn123\" and you want to copy it to a folder with the ID \"syn456\":\n\n            new_file_instance = File(id=\"syn123\").copy(parent_id=\"syn456\")\n\n        Copy the file but do not persist annotations or activity:\n\n            new_file_instance = File(id=\"syn123\").copy(parent_id=\"syn456\", copy_annotations=False, copy_activity=None)\n\n    Raises:\n        ValueError: If the file does not have an ID and parent_id to copy.\n    \"\"\"\n    from synapseclient.models import File\n\n    return File()\n</code></pre>"},{"location":"reference/oop/models/#synapseclient.models.File.delete","title":"<code>delete(version_only=False, *, synapse_client=None)</code>","text":"<p>Delete the file from Synapse.</p> PARAMETER DESCRIPTION <code>version_only</code> <p>If True only the version specified in the <code>version_number</code> attribute of the file will be deleted. If False the entire file will be deleted.</p> <p> TYPE: <code>Optional[bool]</code> DEFAULT: <code>False</code> </p> <code>synapse_client</code> <p>If not passed in or None this will use the last client from the <code>.login()</code> method.</p> <p> TYPE: <code>Optional[Synapse]</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>None</code> <p>None</p> RAISES DESCRIPTION <code>ValueError</code> <p>If the file does not have an ID to delete.</p> <code>ValueError</code> <p>If the file does not have a version number to delete a version, and <code>version_only</code> is True.</p> Using this function <p>Assuming you have a file with the ID \"syn123\":</p> <pre><code>File(id=\"syn123\").delete()\n</code></pre> Source code in <code>synapseclient/models/protocols/file_protocol.py</code> <pre><code>def delete(\n    self,\n    version_only: Optional[bool] = False,\n    *,\n    synapse_client: Optional[Synapse] = None,\n) -&gt; None:\n    \"\"\"Delete the file from Synapse.\n\n    Arguments:\n        version_only: If True only the version specified in the `version_number`\n            attribute of the file will be deleted. If False the entire file will\n            be deleted.\n        synapse_client: If not passed in or None this will use the last client from\n            the `.login()` method.\n\n    Returns:\n        None\n\n    Raises:\n        ValueError: If the file does not have an ID to delete.\n        ValueError: If the file does not have a version number to delete a version,\n            and `version_only` is True.\n\n    Example: Using this function\n        Assuming you have a file with the ID \"syn123\":\n\n            File(id=\"syn123\").delete()\n    \"\"\"\n    return None\n</code></pre>"},{"location":"reference/oop/models/#synapseclient.models.File.from_id","title":"<code>from_id(synapse_id, *, synapse_client=None)</code>  <code>classmethod</code>","text":"<p>Wrapper for synapseclient.models.File.get.</p> PARAMETER DESCRIPTION <code>synapse_id</code> <p>The ID of the file in Synapse.</p> <p> TYPE: <code>str</code> </p> <code>synapse_client</code> <p>If not passed in or None this will use the last client from the <code>.login()</code> method.</p> <p> TYPE: <code>Optional[Synapse]</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>File</code> <p>The file object.</p> Using this function <p>Assuming you have a file with the ID \"syn123\":</p> <pre><code>file_instance = File.from_id(synapse_id=\"syn123\")\n</code></pre> Source code in <code>synapseclient/models/protocols/file_protocol.py</code> <pre><code>@classmethod\ndef from_id(\n    cls,\n    synapse_id: str,\n    *,\n    synapse_client: Optional[Synapse] = None,\n) -&gt; \"File\":\n    \"\"\"Wrapper for [synapseclient.models.File.get][].\n\n    Arguments:\n        synapse_id: The ID of the file in Synapse.\n        synapse_client: If not passed in or None this will use the last client\n            from the `.login()` method.\n\n    Returns:\n        The file object.\n\n    Example: Using this function\n        Assuming you have a file with the ID \"syn123\":\n\n            file_instance = File.from_id(synapse_id=\"syn123\")\n    \"\"\"\n    from synapseclient.models import File\n\n    return File()\n</code></pre>"},{"location":"reference/oop/models/#synapseclient.models.File.from_path","title":"<code>from_path(path, *, synapse_client=None)</code>  <code>classmethod</code>","text":"<p>Get the file from Synapse. If the path of the file matches multiple files within Synapse the first one found will be returned. The other matching files will be printed to the console.</p> <p>Wrapper for synapseclient.models.File.get.</p> PARAMETER DESCRIPTION <code>path</code> <p>The path to the file on disk.</p> <p> TYPE: <code>str</code> </p> <code>synapse_client</code> <p>If not passed in or None this will use the last client from the <code>.login()</code> method.</p> <p> TYPE: <code>Optional[Synapse]</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>File</code> <p>The file object.</p> Using this function <p>Assuming you have a file at the path \"path/to/file.txt\":</p> <pre><code>file_instance = File.from_path(path=\"path/to/file.txt\")\n</code></pre> Source code in <code>synapseclient/models/protocols/file_protocol.py</code> <pre><code>@classmethod\ndef from_path(\n    cls,\n    path: str,\n    *,\n    synapse_client: Optional[Synapse] = None,\n) -&gt; \"File\":\n    \"\"\"Get the file from Synapse. If the path of the file matches multiple files\n    within Synapse the first one found will be returned. The other matching\n    files will be printed to the console.\n\n\n    Wrapper for [synapseclient.models.File.get][].\n\n    Arguments:\n        path: The path to the file on disk.\n        synapse_client: If not passed in or None this will use the last client\n            from the `.login()` method.\n\n    Returns:\n        The file object.\n\n    Example: Using this function\n        Assuming you have a file at the path \"path/to/file.txt\":\n\n            file_instance = File.from_path(path=\"path/to/file.txt\")\n    \"\"\"\n    from synapseclient.models import File\n\n    return File()\n</code></pre>"},{"location":"reference/oop/models/#synapseclient.models.File.change_metadata","title":"<code>change_metadata(name=None, download_as=None, content_type=None, *, synapse_client=None)</code>","text":"<p>Change File Entity metadata for properties that are immutable after creation through the store method.</p> PARAMETER DESCRIPTION <code>name</code> <p>Specify to change the filename of a file as seen on Synapse.</p> <p> TYPE: <code>Optional[str]</code> DEFAULT: <code>None</code> </p> <code>download_as</code> <p>Specify filename to change the filename of a filehandle.</p> <p> TYPE: <code>Optional[str]</code> DEFAULT: <code>None</code> </p> <code>content_type</code> <p>Specify content type to change the content type of a filehandle.</p> <p> TYPE: <code>Optional[str]</code> DEFAULT: <code>None</code> </p> <code>synapse_client</code> <p>If not passed in or None this will use the last client from the <code>.login()</code> method.</p> <p> TYPE: <code>Optional[Synapse]</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>File</code> <p>The file object.</p> Using this function <p>Can be used to change the filename, the filename when the file is downloaded, or the file content-type without downloading:</p> <pre><code>file_entity = File(id=\"syn123\", download_file=False).get()\nprint(os.path.basename(file_entity.path))  ## prints, e.g., \"my_file.txt\"\nfile_entity = file_entity.change_metadata(name=\"my_new_name_file.txt\", download_as=\"my_new_downloadAs_name_file.txt\", content_type=\"text/plain\")\nprint(os.path.basename(file_entity.path))  ## prints, \"my_new_downloadAs_name_file.txt\"\nprint(file_entity.name) ## prints, \"my_new_name_file.txt\"\n</code></pre> RAISES DESCRIPTION <code>ValueError</code> <p>If the file does not have an ID to change metadata.</p> Source code in <code>synapseclient/models/protocols/file_protocol.py</code> <pre><code>def change_metadata(\n    self,\n    name: Optional[str] = None,\n    download_as: Optional[str] = None,\n    content_type: Optional[str] = None,\n    *,\n    synapse_client: Optional[Synapse] = None,\n) -&gt; \"File\":\n    \"\"\"\n    Change File Entity metadata for properties that are immutable after creation\n    through the store method.\n\n    Arguments:\n        name: Specify to change the filename of a file as seen on Synapse.\n        download_as: Specify filename to change the filename of a filehandle.\n        content_type: Specify content type to change the content type of a\n            filehandle.\n        synapse_client: If not passed in or None this will use the last client from\n            the `.login()` method.\n\n    Returns:\n        The file object.\n\n    Example: Using this function\n        Can be used to change the filename, the filename when the file is downloaded, or the file content-type without downloading:\n\n            file_entity = File(id=\"syn123\", download_file=False).get()\n            print(os.path.basename(file_entity.path))  ## prints, e.g., \"my_file.txt\"\n            file_entity = file_entity.change_metadata(name=\"my_new_name_file.txt\", download_as=\"my_new_downloadAs_name_file.txt\", content_type=\"text/plain\")\n            print(os.path.basename(file_entity.path))  ## prints, \"my_new_downloadAs_name_file.txt\"\n            print(file_entity.name) ## prints, \"my_new_name_file.txt\"\n\n    Raises:\n        ValueError: If the file does not have an ID to change metadata.\n    \"\"\"\n    return self\n</code></pre>"},{"location":"reference/oop/models/#synapseclient.models.File.get_permissions","title":"<code>get_permissions(*, synapse_client=None)</code>","text":"<p>Get the permissions that the caller has on an Entity.</p> PARAMETER DESCRIPTION <code>synapse_client</code> <p>If not passed in or None this will use the last client from the <code>.login()</code> method.</p> <p> TYPE: <code>Optional[Synapse]</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>Permissions</code> <p>A Permissions object</p> Using this function: <p>Getting permissions for a Synapse Entity</p> <pre><code>permissions = File(id=\"syn123\").get_permissions()\n</code></pre> <p>Getting access types list from the Permissions object</p> <pre><code>permissions.access_types\n</code></pre> Source code in <code>synapseclient/models/protocols/access_control_protocol.py</code> <pre><code>def get_permissions(\n    self,\n    *,\n    synapse_client: Optional[Synapse] = None,\n) -&gt; \"Permissions\":\n    \"\"\"\n    Get the [permissions][synapseclient.core.models.permission.Permissions]\n    that the caller has on an Entity.\n\n    Arguments:\n        synapse_client: If not passed in or None this will use the last client\n            from the `.login()` method.\n\n    Returns:\n        A Permissions object\n\n\n    Example: Using this function:\n        Getting permissions for a Synapse Entity\n\n            permissions = File(id=\"syn123\").get_permissions()\n\n        Getting access types list from the Permissions object\n\n            permissions.access_types\n    \"\"\"\n    return self\n</code></pre>"},{"location":"reference/oop/models/#synapseclient.models.File.get_acl","title":"<code>get_acl(principal_id=None, *, synapse_client=None)</code>","text":"<p>Get the ACL that a user or group has on an Entity.</p> PARAMETER DESCRIPTION <code>principal_id</code> <p>Identifier of a user or group (defaults to PUBLIC users)</p> <p> TYPE: <code>int</code> DEFAULT: <code>None</code> </p> <code>synapse_client</code> <p>If not passed in or None this will use the last client from the <code>.login()</code> method.</p> <p> TYPE: <code>Optional[Synapse]</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>List[str]</code> <p>An array containing some combination of ['READ', 'UPDATE', 'CREATE', 'DELETE', 'DOWNLOAD', 'MODERATE', 'CHANGE_PERMISSIONS', 'CHANGE_SETTINGS'] or an empty array</p> Source code in <code>synapseclient/models/protocols/access_control_protocol.py</code> <pre><code>def get_acl(\n    self, principal_id: int = None, *, synapse_client: Optional[Synapse] = None\n) -&gt; List[str]:\n    \"\"\"\n    Get the [ACL][synapseclient.core.models.permission.Permissions.access_types]\n    that a user or group has on an Entity.\n\n    Arguments:\n        principal_id: Identifier of a user or group (defaults to PUBLIC users)\n        synapse_client: If not passed in or None this will use the last client\n            from the `.login()` method.\n\n    Returns:\n        An array containing some combination of\n            ['READ', 'UPDATE', 'CREATE', 'DELETE', 'DOWNLOAD', 'MODERATE',\n            'CHANGE_PERMISSIONS', 'CHANGE_SETTINGS']\n            or an empty array\n    \"\"\"\n    return [\"\"]\n</code></pre>"},{"location":"reference/oop/models/#synapseclient.models.File.set_permissions","title":"<code>set_permissions(principal_id=None, access_type=None, modify_benefactor=False, warn_if_inherits=True, overwrite=True, *, synapse_client=None)</code>","text":"<p>Sets permission that a user or group has on an Entity. An Entity may have its own ACL or inherit its ACL from a benefactor.</p> PARAMETER DESCRIPTION <code>principal_id</code> <p>Identifier of a user or group. <code>273948</code> is for all registered Synapse users and <code>273949</code> is for public access. None implies public access.</p> <p> TYPE: <code>int</code> DEFAULT: <code>None</code> </p> <code>access_type</code> <p>Type of permission to be granted. One or more of CREATE, READ, DOWNLOAD, UPDATE, DELETE, CHANGE_PERMISSIONS.</p> <p>Defaults to ['READ', 'DOWNLOAD']</p> <p> TYPE: <code>List[str]</code> DEFAULT: <code>None</code> </p> <code>modify_benefactor</code> <p>Set as True when modifying a benefactor's ACL</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>warn_if_inherits</code> <p>Set as False, when creating a new ACL. Trying to modify the ACL of an Entity that inherits its ACL will result in a warning</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> <code>overwrite</code> <p>By default this function overwrites existing permissions for the specified user. Set this flag to False to add new permissions non-destructively.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> <code>synapse_client</code> <p>If not passed in or None this will use the last client from the <code>.login()</code> method.</p> <p> TYPE: <code>Optional[Synapse]</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>Dict[str, Union[str, list]]</code> <p>An Access Control List object</p> Setting permissions <p>Grant all registered users download access</p> <pre><code>File(id=\"syn123\").set_permissions(principal_id=273948, access_type=['READ','DOWNLOAD'])\n</code></pre> <p>Grant the public view access</p> <pre><code>File(id=\"syn123\").set_permissions(principal_id=273949, access_type=['READ'])\n</code></pre> Source code in <code>synapseclient/models/protocols/access_control_protocol.py</code> <pre><code>def set_permissions(\n    self,\n    principal_id: int = None,\n    access_type: List[str] = None,\n    modify_benefactor: bool = False,\n    warn_if_inherits: bool = True,\n    overwrite: bool = True,\n    *,\n    synapse_client: Optional[Synapse] = None,\n) -&gt; Dict[str, Union[str, list]]:\n    \"\"\"\n    Sets permission that a user or group has on an Entity.\n    An Entity may have its own ACL or inherit its ACL from a benefactor.\n\n    Arguments:\n        principal_id: Identifier of a user or group. `273948` is for all\n            registered Synapse users and `273949` is for public access.\n            None implies public access.\n        access_type: Type of permission to be granted. One or more of CREATE,\n            READ, DOWNLOAD, UPDATE, DELETE, CHANGE_PERMISSIONS.\n\n            **Defaults to ['READ', 'DOWNLOAD']**\n        modify_benefactor: Set as True when modifying a benefactor's ACL\n        warn_if_inherits: Set as False, when creating a new ACL. Trying to modify\n            the ACL of an Entity that inherits its ACL will result in a warning\n        overwrite: By default this function overwrites existing permissions for\n            the specified user. Set this flag to False to add new permissions\n            non-destructively.\n        synapse_client: If not passed in or None this will use the last client\n            from the `.login()` method.\n\n    Returns:\n        An Access Control List object\n\n    Example: Setting permissions\n        Grant all registered users download access\n\n            File(id=\"syn123\").set_permissions(principal_id=273948, access_type=['READ','DOWNLOAD'])\n\n        Grant the public view access\n\n            File(id=\"syn123\").set_permissions(principal_id=273949, access_type=['READ'])\n    \"\"\"\n    return {}\n</code></pre>"},{"location":"reference/oop/models/#synapseclient.models.file.FileHandle","title":"<code>synapseclient.models.file.FileHandle</code>  <code>dataclass</code>","text":"<p>A file handle is a pointer to a file stored in a specific location.</p> ATTRIBUTE DESCRIPTION <code>id</code> <p>The ID of this FileHandle. All references to this FileHandle will use this ID. Synapse will generate this ID when the FileHandle is created.</p> <p> TYPE: <code>Optional[str]</code> </p> <code>etag</code> <p>FileHandles are immutable from the perspective of the API. The only field that can be change is the previewId. When a new previewId is set, the etag will change.</p> <p> TYPE: <code>Optional[str]</code> </p> <code>created_by</code> <p>The ID Of the user that created this file.</p> <p> TYPE: <code>Optional[str]</code> </p> <code>created_on</code> <p>The date when this file was uploaded.</p> <p> TYPE: <code>Optional[str]</code> </p> <code>modified_on</code> <p>The date when the file was modified. This is handled by the backend and cannot be modified.</p> <p> TYPE: <code>Optional[str]</code> </p> <code>concrete_type</code> <p>This is used to indicate the implementation of this interface. For example, an S3FileHandle should be set to: org.sagebionetworks.repo.model.file.S3FileHandle</p> <p> TYPE: <code>Optional[str]</code> </p> <code>content_type</code> <p>Must be: http://en.wikipedia.org/wiki/Internet_media_type.</p> <p> TYPE: <code>Optional[str]</code> </p> <code>content_md5</code> <p>The file's content MD5.</p> <p> TYPE: <code>Optional[str]</code> </p> <code>file_name</code> <p>The short, user visible name for this file.</p> <p> TYPE: <code>Optional[str]</code> </p> <code>storage_location_id</code> <p>The optional storage location descriptor.</p> <p> TYPE: <code>Optional[int]</code> </p> <code>content_size</code> <p>The size of the file in bytes.</p> <p> TYPE: <code>Optional[int]</code> </p> <code>status</code> <p>The status of the file handle as computed by the backend. This value cannot be changed, any file handle that is not AVAILABLE should not be used.</p> <p> TYPE: <code>Optional[str]</code> </p> <code>bucket_name</code> <p>The name of the bucket where this file resides.</p> <p> TYPE: <code>Optional[str]</code> </p> <code>key</code> <p>The path or resource name for this object.</p> <p> TYPE: <code>Optional[str]</code> </p> <code>preview_id</code> <p>If this file has a preview, then this will be the file ID of the preview.</p> <p> TYPE: <code>Optional[str]</code> </p> <code>is_preview</code> <p>Whether or not this is a preview of another file.</p> <p> TYPE: <code>Optional[bool]</code> </p> <code>external_url</code> <p>The URL of the file if it is stored externally.</p> <p> TYPE: <code>Optional[str]</code> </p> Source code in <code>synapseclient/models/file.py</code> <pre><code>@dataclass()\nclass FileHandle:\n    \"\"\"A file handle is a pointer to a file stored in a specific location.\n\n    Attributes:\n        id: The ID of this FileHandle. All references to this FileHandle will use this\n            ID. Synapse will generate this ID when the FileHandle is created.\n        etag: FileHandles are immutable from the perspective of the API. The only field\n            that can be change is the previewId. When a new previewId is set, the\n            etag will change.\n        created_by: The ID Of the user that created this file.\n        created_on: The date when this file was uploaded.\n        modified_on: The date when the file was modified. This is handled by the backend\n            and cannot be modified.\n        concrete_type: This is used to indicate the implementation of this interface.\n            For example, an S3FileHandle should be set to:\n            org.sagebionetworks.repo.model.file.S3FileHandle\n        content_type: Must be: &lt;http://en.wikipedia.org/wiki/Internet_media_type&gt;.\n        content_md5: The file's content MD5.\n        file_name: The short, user visible name for this file.\n        storage_location_id: The optional storage location descriptor.\n        content_size: The size of the file in bytes.\n        status: The status of the file handle as computed by the backend. This value\n            cannot be changed, any file handle that is not AVAILABLE should not be used.\n        bucket_name: The name of the bucket where this file resides.\n        key: The path or resource name for this object.\n        preview_id: If this file has a preview, then this will be the file ID of the\n            preview.\n        is_preview: Whether or not this is a preview of another file.\n        external_url: The URL of the file if it is stored externally.\n    \"\"\"\n\n    id: Optional[str] = None\n    \"\"\"The ID of this FileHandle. All references to this FileHandle will use this ID.\n        Synapse will generate this ID when the FileHandle is created.\"\"\"\n\n    etag: Optional[str] = None\n    \"\"\"\n    FileHandles are immutable from the perspective of the API. The only field that can\n    be change is the previewId. When a new previewId is set, the etag will change.\n    \"\"\"\n\n    created_by: Optional[str] = None\n    \"\"\"The ID Of the user that created this file.\"\"\"\n\n    created_on: Optional[str] = None\n    \"\"\"The date when this file was uploaded.\"\"\"\n\n    modified_on: Optional[str] = None\n    \"\"\"The date when the file was modified. This is handled by the backend and cannot\n    be modified.\"\"\"\n\n    concrete_type: Optional[str] = None\n    \"\"\"\n    This is used to indicate the implementation of this interface. For example,\n    an S3FileHandle should be set to: org.sagebionetworks.repo.model.file.S3FileHandle\n    \"\"\"\n\n    content_type: Optional[str] = None\n    \"\"\"Must be: &lt;http://en.wikipedia.org/wiki/Internet_media_type&gt;.\"\"\"\n\n    content_md5: Optional[str] = None\n    \"\"\"The file's content MD5.\"\"\"\n\n    file_name: Optional[str] = None\n    \"\"\"The short, user visible name for this file.\"\"\"\n\n    storage_location_id: Optional[int] = None\n    \"\"\"The optional storage location descriptor.\"\"\"\n\n    content_size: Optional[int] = None\n    \"\"\"The size of the file in bytes.\"\"\"\n\n    status: Optional[str] = None\n    \"\"\"The status of the file handle as computed by the backend. This value cannot be\n    changed, any file handle that is not AVAILABLE should not be used.\"\"\"\n\n    bucket_name: Optional[str] = None\n    \"\"\"The name of the bucket where this file resides.\"\"\"\n\n    key: Optional[str] = None\n    \"\"\"The path or resource name for this object.\"\"\"\n\n    preview_id: Optional[str] = None\n    \"\"\"If this file has a preview, then this will be the file ID of the preview.\"\"\"\n\n    is_preview: Optional[bool] = None\n    \"\"\"Whether or not this is a preview of another file.\"\"\"\n\n    external_url: Optional[str] = None\n    \"\"\"The URL of the file if it is stored externally.\"\"\"\n\n    def fill_from_dict(\n        self, synapse_instance: Dict[str, Union[bool, str, int]]\n    ) -&gt; \"FileHandle\":\n        \"\"\"\n        Converts a response from the REST API into this dataclass.\n\n        Arguments:\n            synapse_instance: The response from the REST API.\n            set_annotations: Whether to set the annotations from the response.\n\n        Returns:\n            The File object.\n        \"\"\"\n        file_handle = self or FileHandle()\n        file_handle.id = synapse_instance.get(\"id\", None)\n        file_handle.etag = synapse_instance.get(\"etag\", None)\n        file_handle.created_by = synapse_instance.get(\"createdBy\", None)\n        file_handle.created_on = synapse_instance.get(\"createdOn\", None)\n        file_handle.modified_on = synapse_instance.get(\"modifiedOn\", None)\n        file_handle.concrete_type = synapse_instance.get(\"concreteType\", None)\n        file_handle.content_type = synapse_instance.get(\"contentType\", None)\n        file_handle.content_md5 = synapse_instance.get(\"contentMd5\", None)\n        file_handle.file_name = synapse_instance.get(\"fileName\", None)\n        file_handle.storage_location_id = synapse_instance.get(\n            \"storageLocationId\", None\n        )\n        file_handle.content_size = synapse_instance.get(\"contentSize\", None)\n        file_handle.status = synapse_instance.get(\"status\", None)\n        file_handle.bucket_name = synapse_instance.get(\"bucketName\", None)\n        file_handle.key = synapse_instance.get(\"key\", None)\n        file_handle.preview_id = synapse_instance.get(\"previewId\", None)\n        file_handle.is_preview = synapse_instance.get(\"isPreview\", None)\n        file_handle.external_url = synapse_instance.get(\"externalURL\", None)\n\n        return self\n\n    def _convert_into_legacy_file_handle(self) -&gt; Dict[str, Union[str, bool, int]]:\n        \"\"\"Convert the file handle object into a legacy File Handle object.\"\"\"\n        return_data = {\n            \"id\": self.id,\n            \"etag\": self.etag,\n            \"createdBy\": self.created_by,\n            \"createdOn\": self.created_on,\n            \"modifiedOn\": self.modified_on,\n            \"concreteType\": self.concrete_type,\n            \"contentType\": self.content_type,\n            \"contentMd5\": self.content_md5,\n            \"fileName\": self.file_name,\n            \"storageLocationId\": self.storage_location_id,\n            \"contentSize\": self.content_size,\n            \"status\": self.status,\n            \"bucketName\": self.bucket_name,\n            \"key\": self.key,\n            \"previewId\": self.preview_id,\n            \"isPreview\": self.is_preview,\n            \"externalURL\": self.external_url,\n        }\n        delete_none_keys(return_data)\n        return return_data\n</code></pre>"},{"location":"reference/oop/models/#synapseclient.models.Table","title":"<code>synapseclient.models.Table</code>  <code>dataclass</code>","text":"<p>               Bases: <code>TableSynchronousProtocol</code>, <code>AccessControllable</code></p> <p>A Table represents the metadata of a table.</p> ATTRIBUTE DESCRIPTION <code>id</code> <p>The unique immutable ID for this table. A new ID will be generated for new Tables. Once issued, this ID is guaranteed to never change or be re-issued</p> <p> TYPE: <code>Optional[str]</code> </p> <code>name</code> <p>The name of this table. Must be 256 characters or less. Names may only contain: letters, numbers, spaces, underscores, hyphens, periods, plus signs, apostrophes, and parentheses</p> <p> TYPE: <code>Optional[str]</code> </p> <code>parent_id</code> <p>The ID of the Entity that is the parent of this table.</p> <p> TYPE: <code>Optional[str]</code> </p> <code>columns</code> <p>The columns of this table.</p> <p> TYPE: <code>Optional[List[Column]]</code> </p> <code>description</code> <p>The description of this entity. Must be 1000 characters or less.</p> <p> TYPE: <code>Optional[List[Column]]</code> </p> <code>etag</code> <p>Synapse employs an Optimistic Concurrency Control (OCC) scheme to handle concurrent updates. Since the E-Tag changes every time an entity is updated it is used to detect when a client's current representation of an entity is out-of-date.</p> <p> TYPE: <code>Optional[str]</code> </p> <code>created_on</code> <p>The date this table was created.</p> <p> TYPE: <code>Optional[str]</code> </p> <code>created_by</code> <p>The ID of the user that created this table.</p> <p> TYPE: <code>Optional[str]</code> </p> <code>modified_on</code> <p>The date this table was last modified. In YYYY-MM-DD-Thh:mm:ss.sssZ format</p> <p> TYPE: <code>Optional[str]</code> </p> <code>modified_by</code> <p>The ID of the user that last modified this table.</p> <p> TYPE: <code>Optional[str]</code> </p> <code>version_number</code> <p>The version number issued to this version on the object.</p> <p> TYPE: <code>Optional[int]</code> </p> <code>version_label</code> <p>The version label for this table</p> <p> TYPE: <code>Optional[str]</code> </p> <code>version_comment</code> <p>The version comment for this table</p> <p> TYPE: <code>Optional[str]</code> </p> <code>is_latest_version</code> <p>If this is the latest version of the object.</p> <p> TYPE: <code>Optional[bool]</code> </p> <code>is_search_enabled</code> <p>When creating or updating a table or view specifies if full text search should be enabled. Note that enabling full text search might slow down the indexing of the table or view.</p> <p> TYPE: <code>Optional[bool]</code> </p> <code>activity</code> <p>The Activity model represents the main record of Provenance in Synapse. It is analygous to the Activity defined in the W3C Specification on Provenance. Activity cannot be removed during a store operation by setting it to None. You must use: synapseclient.models.Activity.delete_async or synapseclient.models.Activity.disassociate_from_entity_async.</p> <p> TYPE: <code>Optional[Activity]</code> </p> <code>annotations</code> <p>Additional metadata associated with the table. The key is the name of your desired annotations. The value is an object containing a list of values (use empty list to represent no values for key) and the value type associated with all values in the list. To remove all annotations set this to an empty dict <code>{}</code> or None and store the entity.</p> <p> TYPE: <code>Optional[Dict[str, Union[List[str], List[bool], List[float], List[int], List[date], List[datetime]]]]</code> </p> Source code in <code>synapseclient/models/table.py</code> <pre><code>@dataclass()\n@async_to_sync\nclass Table(TableSynchronousProtocol, AccessControllable):\n    \"\"\"A Table represents the metadata of a table.\n\n    Attributes:\n        id: The unique immutable ID for this table. A new ID will be generated for new\n            Tables. Once issued, this ID is guaranteed to never change or be re-issued\n        name: The name of this table. Must be 256 characters or less. Names may only\n            contain: letters, numbers, spaces, underscores, hyphens, periods, plus\n            signs, apostrophes, and parentheses\n        parent_id: The ID of the Entity that is the parent of this table.\n        columns: The columns of this table.\n        description: The description of this entity. Must be 1000 characters or less.\n        etag: Synapse employs an Optimistic Concurrency Control (OCC) scheme to handle\n            concurrent updates. Since the E-Tag changes every time an entity is updated\n            it is used to detect when a client's current representation of an entity is\n            out-of-date.\n        created_on: The date this table was created.\n        created_by: The ID of the user that created this table.\n        modified_on: The date this table was last modified.\n            In YYYY-MM-DD-Thh:mm:ss.sssZ format\n        modified_by: The ID of the user that last modified this table.\n        version_number: The version number issued to this version on the object.\n        version_label: The version label for this table\n        version_comment: The version comment for this table\n        is_latest_version: If this is the latest version of the object.\n        is_search_enabled: When creating or updating a table or view specifies if full\n            text search should be enabled. Note that enabling full text search might\n            slow down the indexing of the table or view.\n        activity: The Activity model represents the main record of Provenance in\n            Synapse. It is analygous to the Activity defined in the\n            [W3C Specification](https://www.w3.org/TR/prov-n/) on Provenance. Activity\n            cannot be removed during a store operation by setting it to None. You must\n            use: [synapseclient.models.Activity.delete_async][] or\n            [synapseclient.models.Activity.disassociate_from_entity_async][].\n        annotations: Additional metadata associated with the table. The key is the name\n            of your desired annotations. The value is an object containing a list of\n            values (use empty list to represent no values for key) and the value type\n            associated with all values in the list. To remove all annotations set this\n            to an empty dict `{}` or None and store the entity.\n\n    \"\"\"\n\n    id: Optional[str] = None\n    \"\"\"The unique immutable ID for this table. A new ID will be generated for new\n    Tables. Once issued, this ID is guaranteed to never change or be re-issued\"\"\"\n\n    name: Optional[str] = None\n    \"\"\"The name of this table. Must be 256 characters or less. Names may only\n    contain: letters, numbers, spaces, underscores, hyphens, periods, plus signs,\n    apostrophes, and parentheses\"\"\"\n\n    parent_id: Optional[str] = None\n    \"\"\"The ID of the Entity that is the parent of this table.\"\"\"\n\n    columns: Optional[List[Column]] = None\n\n    # TODO: Description doesn't seem to be returned from the API. Look into why.\n    # description: Optional[str] = None\n    # \"\"\"The description of this entity. Must be 1000 characters or less.\"\"\"\n\n    etag: Optional[str] = None\n    \"\"\"\n    Synapse employs an Optimistic Concurrency Control (OCC) scheme to handle\n    concurrent updates. Since the E-Tag changes every time an entity is updated it is\n    used to detect when a client's current representation of an entity is out-of-date.\n    \"\"\"\n\n    created_on: Optional[str] = None\n    \"\"\"The date this table was created.\"\"\"\n\n    created_by: Optional[str] = None\n    \"\"\"The ID of the user that created this table.\"\"\"\n\n    modified_on: Optional[str] = None\n    \"\"\"The date this table was last modified. In YYYY-MM-DD-Thh:mm:ss.sssZ format\"\"\"\n\n    modified_by: Optional[str] = None\n    \"\"\"The ID of the user that last modified this table.\"\"\"\n\n    version_number: Optional[int] = None\n    \"\"\"The version number issued to this version on the object.\"\"\"\n\n    version_label: Optional[str] = None\n    \"\"\"The version label for this table\"\"\"\n\n    version_comment: Optional[str] = None\n    \"\"\"The version comment for this table\"\"\"\n\n    is_latest_version: Optional[bool] = None\n    \"\"\"If this is the latest version of the object.\"\"\"\n\n    is_search_enabled: Optional[bool] = None\n    \"\"\"When creating or updating a table or view specifies if full text search\n    should be enabled. Note that enabling full text search might slow down the\n    indexing of the table or view.\"\"\"\n\n    activity: Optional[Activity] = None\n    \"\"\"The Activity model represents the main record of Provenance in Synapse.  It is\n    analygous to the Activity defined in the\n    [W3C Specification](https://www.w3.org/TR/prov-n/) on Provenance. Activity cannot\n    be removed during a store operation by setting it to None. You must use:\n    [synapseclient.models.Activity.delete_async][] or\n    [synapseclient.models.Activity.disassociate_from_entity_async][].\n    \"\"\"\n\n    annotations: Optional[\n        Dict[\n            str,\n            Union[\n                List[str],\n                List[bool],\n                List[float],\n                List[int],\n                List[date],\n                List[datetime],\n            ],\n        ]\n    ] = field(default_factory=dict)\n    \"\"\"Additional metadata associated with the table. The key is the name of your\n    desired annotations. The value is an object containing a list of values\n    (use empty list to represent no values for key) and the value type associated with\n    all values in the list. To remove all annotations set this to an empty dict `{}`\n    or None and store the entity.\"\"\"\n\n    def fill_from_dict(\n        self, synapse_table: Synapse_Table, set_annotations: bool = True\n    ) -&gt; \"Table\":\n        \"\"\"Converts the data coming from the Synapse API into this datamodel.\n\n        :param synapse_table: The data coming from the Synapse API\n        \"\"\"\n        self.id = synapse_table.get(\"id\", None)\n        self.name = synapse_table.get(\"name\", None)\n        self.parent_id = synapse_table.get(\"parentId\", None)\n        # TODO: Description doesn't seem to be returned from the API. Look into why.\n        # self.description = synapse_table.description\n        self.etag = synapse_table.get(\"etag\", None)\n        self.created_on = synapse_table.get(\"createdOn\", None)\n        self.created_by = synapse_table.get(\"createdBy\", None)\n        self.modified_on = synapse_table.get(\"modifiedOn\", None)\n        self.modified_by = synapse_table.get(\"modifiedBy\", None)\n        self.version_number = synapse_table.get(\"versionNumber\", None)\n        self.version_label = synapse_table.get(\"versionLabel\", None)\n        self.version_comment = synapse_table.get(\"versionComment\", None)\n        self.is_latest_version = synapse_table.get(\"isLatestVersion\", None)\n        self.is_search_enabled = synapse_table.get(\"isSearchEnabled\", False)\n        self.columns = [\n            Column(id=columnId, name=None, column_type=None)\n            for columnId in synapse_table.get(\"columnIds\", [])\n        ]\n        if set_annotations:\n            self.annotations = Annotations.from_dict(\n                synapse_table.get(\"annotations\", {})\n            )\n        return self\n\n    @otel_trace_method(\n        method_to_trace_name=lambda _, **kwargs: f\"Store_rows_by_csv: {kwargs.get('csv_path', None)}\"\n    )\n    async def store_rows_from_csv_async(\n        self, csv_path: str, *, synapse_client: Optional[Synapse] = None\n    ) -&gt; str:\n        \"\"\"Takes in a path to a CSV and stores the rows to Synapse.\n\n        Arguments:\n            csv_path: The path to the CSV to store.\n            synapse_client: If not passed in or None this will use the last client\n                from the `.login()` method.\n\n        Returns:\n            The path to the CSV that was stored.\n        \"\"\"\n        synapse_table = Synapse_Table(schema=self.id, values=csv_path)\n        loop = asyncio.get_event_loop()\n        current_context = context.get_current()\n        entity = await loop.run_in_executor(\n            None,\n            lambda: run_and_attach_otel_context(\n                lambda: Synapse.get_client(synapse_client=synapse_client).store(\n                    obj=synapse_table\n                ),\n                current_context,\n            ),\n        )\n        print(entity)\n        # TODO: What should this return?\n        return csv_path\n\n    @otel_trace_method(\n        method_to_trace_name=lambda self, **kwargs: f\"Delete_rows: {self.name}\"\n    )\n    async def delete_rows_async(\n        self, rows: List[Row], *, synapse_client: Optional[Synapse] = None\n    ) -&gt; None:\n        \"\"\"Delete rows from a table.\n\n        Arguments:\n            rows: The rows to delete.\n            synapse_client: If not passed in or None this will use the last client\n                from the `.login()` method.\n\n        Returns:\n            None\n        \"\"\"\n        rows_to_delete = []\n        for row in rows:\n            rows_to_delete.append([row.row_id, row.version_number])\n        loop = asyncio.get_event_loop()\n        current_context = context.get_current()\n        await loop.run_in_executor(\n            None,\n            lambda: run_and_attach_otel_context(\n                lambda: delete_rows(\n                    syn=Synapse.get_client(synapse_client=synapse_client),\n                    table_id=self.id,\n                    row_id_vers_list=rows_to_delete,\n                ),\n                current_context,\n            ),\n        )\n\n    @otel_trace_method(\n        method_to_trace_name=lambda self, **kwargs: f\"Table_Schema_Store: {self.name}\"\n    )\n    async def store_schema_async(\n        self, *, synapse_client: Optional[Synapse] = None\n    ) -&gt; \"Table\":\n        \"\"\"Store non-row information about a table including the columns and annotations.\n\n        Arguments:\n            synapse_client: If not passed in or None this will use the last client\n                from the `.login()` method.\n\n        Returns:\n            The Table instance stored in synapse.\n        \"\"\"\n        tasks = []\n        if self.columns:\n            # TODO: When a table is retrieved via `.get()` we create Column objects but\n            # TODO: We only have the ID attribute. THis is causing this if check to eval\n            # TODO: To True, however, we aren't actually modifying the column.\n            # TODO: Perhaps we should have a `has_changed` boolean on all dataclasses\n            # TODO: That we can check to see if we need to store the data.\n            tasks.extend(\n                column.store_async(synapse_client=synapse_client)\n                for column in self.columns\n            )\n            try:\n                results = await asyncio.gather(*tasks, return_exceptions=True)\n\n                # TODO: Proper exception handling\n                for result in results:\n                    if isinstance(result, Column):\n                        print(f\"Stored {result.name}\")\n                    else:\n                        if isinstance(result, BaseException):\n                            raise result\n                        raise ValueError(f\"Unknown type: {type(result)}\", result)\n            except Exception as ex:\n                Synapse.get_client(synapse_client=synapse_client).logger.exception(ex)\n                print(\"I hit an exception\")\n\n        synapse_schema = Synapse_Schema(\n            name=self.name,\n            columns=self.columns,\n            parent=self.parent_id,\n        )\n        trace.get_current_span().set_attributes(\n            {\n                \"synapse.name\": self.name or \"\",\n                \"synapse.id\": self.id or \"\",\n            }\n        )\n        loop = asyncio.get_event_loop()\n        current_context = context.get_current()\n        entity = await loop.run_in_executor(\n            None,\n            lambda: run_and_attach_otel_context(\n                lambda: Synapse.get_client(synapse_client=synapse_client).store(\n                    obj=synapse_schema\n                ),\n                current_context,\n            ),\n        )\n\n        self.fill_from_dict(synapse_table=entity, set_annotations=False)\n\n        re_read_required = await store_entity_components(\n            root_resource=self, synapse_client=synapse_client\n        )\n        if re_read_required:\n            await self.get_async(\n                synapse_client=synapse_client,\n            )\n\n        return self\n\n    @otel_trace_method(\n        method_to_trace_name=lambda self, **kwargs: f\"Table_Get: {self.name}\"\n    )\n    async def get_async(self, *, synapse_client: Optional[Synapse] = None) -&gt; \"Table\":\n        \"\"\"Get the metadata about the table from synapse.\n\n        Arguments:\n            synapse_client: If not passed in or None this will use the last client\n                from the `.login()` method.\n\n        Returns:\n            The Table instance stored in synapse.\n        \"\"\"\n        # TODO: How do we want to support retriving the table? Do we want to support by name, and parent?\n        loop = asyncio.get_event_loop()\n        current_context = context.get_current()\n        entity = await loop.run_in_executor(\n            None,\n            lambda: run_and_attach_otel_context(\n                lambda: Synapse.get_client(synapse_client=synapse_client).get(\n                    entity=self.id\n                ),\n                current_context,\n            ),\n        )\n        self.fill_from_dict(synapse_table=entity, set_annotations=True)\n        return self\n\n    @otel_trace_method(\n        method_to_trace_name=lambda self, **kwargs: f\"Table_Delete: {self.name}\"\n    )\n    # TODO: Synapse allows immediate deletion of entities, but the Synapse Client does not\n    # TODO: Should we support immediate deletion?\n    async def delete_async(self, *, synapse_client: Optional[Synapse] = None) -&gt; None:\n        \"\"\"Delete the table from synapse.\n\n        Arguments:\n            synapse_client: If not passed in or None this will use the last client\n                from the `.login()` method.\n\n        Returns:\n            None\n        \"\"\"\n        loop = asyncio.get_event_loop()\n        current_context = context.get_current()\n        await loop.run_in_executor(\n            None,\n            lambda: run_and_attach_otel_context(\n                lambda: Synapse.get_client(synapse_client=synapse_client).delete(\n                    obj=self.id\n                ),\n                current_context,\n            ),\n        )\n\n    @classmethod\n    async def query_async(\n        cls,\n        query: str,\n        result_format: Union[CsvResultFormat, RowsetResultFormat] = CsvResultFormat(),\n        *,\n        synapse_client: Optional[Synapse] = None,\n    ) -&gt; Union[Synapse_CsvFileTable, Synaspe_TableQueryResult]:\n        \"\"\"Query for data on a table stored in Synapse.\n\n        Arguments:\n            query: The query to run.\n            result_format: The format of the results. Defaults to CsvResultFormat().\n            synapse_client: If not passed in or None this will use the last client\n                from the `.login()` method.\n\n        Returns:\n            The results of the query.\n        \"\"\"\n        loop = asyncio.get_event_loop()\n        current_context = context.get_current()\n\n        # TODO: Future Idea - We stream back a CSV, and let those reading this to handle the CSV however they want\n        results = await loop.run_in_executor(\n            None,\n            lambda: run_and_attach_otel_context(\n                lambda: Synapse.get_client(synapse_client=synapse_client).tableQuery(\n                    query=query,\n                    **result_format.to_dict(),\n                ),\n                current_context,\n            ),\n        )\n        print(results)\n        return results\n</code></pre>"},{"location":"reference/oop/models/#synapseclient.models.Table-functions","title":"Functions","text":""},{"location":"reference/oop/models/#synapseclient.models.Table.get","title":"<code>get(*, synapse_client=None)</code>","text":"<p>Get the metadata about the table from synapse.</p> PARAMETER DESCRIPTION <code>synapse_client</code> <p>If not passed in or None this will use the last client from the <code>.login()</code> method.</p> <p> TYPE: <code>Optional[Synapse]</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>Table</code> <p>The Table instance stored in synapse.</p> Source code in <code>synapseclient/models/protocols/table_protocol.py</code> <pre><code>def get(self, *, synapse_client: Optional[Synapse] = None) -&gt; \"Table\":\n    \"\"\"Get the metadata about the table from synapse.\n\n    Arguments:\n        synapse_client: If not passed in or None this will use the last client\n            from the `.login()` method.\n\n    Returns:\n        The Table instance stored in synapse.\n    \"\"\"\n    return self\n</code></pre>"},{"location":"reference/oop/models/#synapseclient.models.Table.store_schema","title":"<code>store_schema(*, synapse_client=None)</code>","text":"<p>Store non-row information about a table including the columns and annotations.</p> PARAMETER DESCRIPTION <code>synapse_client</code> <p>If not passed in or None this will use the last client from the <code>.login()</code> method.</p> <p> TYPE: <code>Optional[Synapse]</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>Table</code> <p>The Table instance stored in synapse.</p> Source code in <code>synapseclient/models/protocols/table_protocol.py</code> <pre><code>def store_schema(self, *, synapse_client: Optional[Synapse] = None) -&gt; \"Table\":\n    \"\"\"Store non-row information about a table including the columns and annotations.\n\n    Arguments:\n        synapse_client: If not passed in or None this will use the last client\n            from the `.login()` method.\n\n    Returns:\n        The Table instance stored in synapse.\n    \"\"\"\n    return self\n</code></pre>"},{"location":"reference/oop/models/#synapseclient.models.Table.store_rows_from_csv","title":"<code>store_rows_from_csv(csv_path, *, synapse_client=None)</code>","text":"<p>Takes in a path to a CSV and stores the rows to Synapse.</p> PARAMETER DESCRIPTION <code>csv_path</code> <p>The path to the CSV to store.</p> <p> TYPE: <code>str</code> </p> <code>synapse_client</code> <p>If not passed in or None this will use the last client from the <code>.login()</code> method.</p> <p> TYPE: <code>Optional[Synapse]</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>str</code> <p>The path to the CSV that was stored.</p> Source code in <code>synapseclient/models/protocols/table_protocol.py</code> <pre><code>def store_rows_from_csv(\n    self, csv_path: str, *, synapse_client: Optional[Synapse] = None\n) -&gt; str:\n    \"\"\"Takes in a path to a CSV and stores the rows to Synapse.\n\n    Arguments:\n        csv_path: The path to the CSV to store.\n        synapse_client: If not passed in or None this will use the last client\n            from the `.login()` method.\n\n    Returns:\n        The path to the CSV that was stored.\n    \"\"\"\n    return \"\"\n</code></pre>"},{"location":"reference/oop/models/#synapseclient.models.Table.delete_rows","title":"<code>delete_rows(rows, *, synapse_client=None)</code>","text":"<p>Delete rows from a table.</p> PARAMETER DESCRIPTION <code>rows</code> <p>The rows to delete.</p> <p> TYPE: <code>List[Row]</code> </p> <code>synapse_client</code> <p>If not passed in or None this will use the last client from the <code>.login()</code> method.</p> <p> TYPE: <code>Optional[Synapse]</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>None</code> <p>None</p> Source code in <code>synapseclient/models/protocols/table_protocol.py</code> <pre><code>def delete_rows(\n    self, rows: List[\"Row\"], *, synapse_client: Optional[Synapse] = None\n) -&gt; None:\n    \"\"\"Delete rows from a table.\n\n    Arguments:\n        rows: The rows to delete.\n        synapse_client: If not passed in or None this will use the last client\n            from the `.login()` method.\n\n    Returns:\n        None\n    \"\"\"\n    return None\n</code></pre>"},{"location":"reference/oop/models/#synapseclient.models.Table.query","title":"<code>query(query, result_format=None, *, synapse_client=None)</code>  <code>classmethod</code>","text":"<p>Query for data on a table stored in Synapse.</p> PARAMETER DESCRIPTION <code>query</code> <p>The query to run.</p> <p> TYPE: <code>str</code> </p> <code>result_format</code> <p>The format of the results. Defaults to CsvResultFormat().</p> <p> TYPE: <code>Union[CsvResultFormat, RowsetResultFormat]</code> DEFAULT: <code>None</code> </p> <code>synapse_client</code> <p>If not passed in or None this will use the last client from the <code>.login()</code> method.</p> <p> TYPE: <code>Optional[Synapse]</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>Union[CsvFileTable, TableQueryResult, None]</code> <p>The results of the query.</p> Source code in <code>synapseclient/models/protocols/table_protocol.py</code> <pre><code>@classmethod\ndef query(\n    cls,\n    query: str,\n    result_format: Union[\"CsvResultFormat\", \"RowsetResultFormat\"] = None,\n    *,\n    synapse_client: Optional[Synapse] = None,\n) -&gt; Union[Synapse_CsvFileTable, Synaspe_TableQueryResult, None]:\n    \"\"\"Query for data on a table stored in Synapse.\n\n    Arguments:\n        query: The query to run.\n        result_format: The format of the results. Defaults to CsvResultFormat().\n        synapse_client: If not passed in or None this will use the last client\n            from the `.login()` method.\n\n    Returns:\n        The results of the query.\n    \"\"\"\n    return None\n</code></pre>"},{"location":"reference/oop/models/#synapseclient.models.Table.delete","title":"<code>delete(*, synapse_client=None)</code>","text":"<p>Delete the table from synapse.</p> PARAMETER DESCRIPTION <code>synapse_client</code> <p>If not passed in or None this will use the last client from the <code>.login()</code> method.</p> <p> TYPE: <code>Optional[Synapse]</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>None</code> <p>None</p> Source code in <code>synapseclient/models/protocols/table_protocol.py</code> <pre><code>def delete(self, *, synapse_client: Optional[Synapse] = None) -&gt; None:\n    \"\"\"Delete the table from synapse.\n\n    Arguments:\n        synapse_client: If not passed in or None this will use the last client\n            from the `.login()` method.\n\n    Returns:\n        None\n    \"\"\"\n    return None\n</code></pre>"},{"location":"reference/oop/models/#synapseclient.models.Table.get_permissions","title":"<code>get_permissions(*, synapse_client=None)</code>","text":"<p>Get the permissions that the caller has on an Entity.</p> PARAMETER DESCRIPTION <code>synapse_client</code> <p>If not passed in or None this will use the last client from the <code>.login()</code> method.</p> <p> TYPE: <code>Optional[Synapse]</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>Permissions</code> <p>A Permissions object</p> Using this function: <p>Getting permissions for a Synapse Entity</p> <pre><code>permissions = File(id=\"syn123\").get_permissions()\n</code></pre> <p>Getting access types list from the Permissions object</p> <pre><code>permissions.access_types\n</code></pre> Source code in <code>synapseclient/models/protocols/access_control_protocol.py</code> <pre><code>def get_permissions(\n    self,\n    *,\n    synapse_client: Optional[Synapse] = None,\n) -&gt; \"Permissions\":\n    \"\"\"\n    Get the [permissions][synapseclient.core.models.permission.Permissions]\n    that the caller has on an Entity.\n\n    Arguments:\n        synapse_client: If not passed in or None this will use the last client\n            from the `.login()` method.\n\n    Returns:\n        A Permissions object\n\n\n    Example: Using this function:\n        Getting permissions for a Synapse Entity\n\n            permissions = File(id=\"syn123\").get_permissions()\n\n        Getting access types list from the Permissions object\n\n            permissions.access_types\n    \"\"\"\n    return self\n</code></pre>"},{"location":"reference/oop/models/#synapseclient.models.Table.get_acl","title":"<code>get_acl(principal_id=None, *, synapse_client=None)</code>","text":"<p>Get the ACL that a user or group has on an Entity.</p> PARAMETER DESCRIPTION <code>principal_id</code> <p>Identifier of a user or group (defaults to PUBLIC users)</p> <p> TYPE: <code>int</code> DEFAULT: <code>None</code> </p> <code>synapse_client</code> <p>If not passed in or None this will use the last client from the <code>.login()</code> method.</p> <p> TYPE: <code>Optional[Synapse]</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>List[str]</code> <p>An array containing some combination of ['READ', 'UPDATE', 'CREATE', 'DELETE', 'DOWNLOAD', 'MODERATE', 'CHANGE_PERMISSIONS', 'CHANGE_SETTINGS'] or an empty array</p> Source code in <code>synapseclient/models/protocols/access_control_protocol.py</code> <pre><code>def get_acl(\n    self, principal_id: int = None, *, synapse_client: Optional[Synapse] = None\n) -&gt; List[str]:\n    \"\"\"\n    Get the [ACL][synapseclient.core.models.permission.Permissions.access_types]\n    that a user or group has on an Entity.\n\n    Arguments:\n        principal_id: Identifier of a user or group (defaults to PUBLIC users)\n        synapse_client: If not passed in or None this will use the last client\n            from the `.login()` method.\n\n    Returns:\n        An array containing some combination of\n            ['READ', 'UPDATE', 'CREATE', 'DELETE', 'DOWNLOAD', 'MODERATE',\n            'CHANGE_PERMISSIONS', 'CHANGE_SETTINGS']\n            or an empty array\n    \"\"\"\n    return [\"\"]\n</code></pre>"},{"location":"reference/oop/models/#synapseclient.models.Table.set_permissions","title":"<code>set_permissions(principal_id=None, access_type=None, modify_benefactor=False, warn_if_inherits=True, overwrite=True, *, synapse_client=None)</code>","text":"<p>Sets permission that a user or group has on an Entity. An Entity may have its own ACL or inherit its ACL from a benefactor.</p> PARAMETER DESCRIPTION <code>principal_id</code> <p>Identifier of a user or group. <code>273948</code> is for all registered Synapse users and <code>273949</code> is for public access. None implies public access.</p> <p> TYPE: <code>int</code> DEFAULT: <code>None</code> </p> <code>access_type</code> <p>Type of permission to be granted. One or more of CREATE, READ, DOWNLOAD, UPDATE, DELETE, CHANGE_PERMISSIONS.</p> <p>Defaults to ['READ', 'DOWNLOAD']</p> <p> TYPE: <code>List[str]</code> DEFAULT: <code>None</code> </p> <code>modify_benefactor</code> <p>Set as True when modifying a benefactor's ACL</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>warn_if_inherits</code> <p>Set as False, when creating a new ACL. Trying to modify the ACL of an Entity that inherits its ACL will result in a warning</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> <code>overwrite</code> <p>By default this function overwrites existing permissions for the specified user. Set this flag to False to add new permissions non-destructively.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> <code>synapse_client</code> <p>If not passed in or None this will use the last client from the <code>.login()</code> method.</p> <p> TYPE: <code>Optional[Synapse]</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>Dict[str, Union[str, list]]</code> <p>An Access Control List object</p> Setting permissions <p>Grant all registered users download access</p> <pre><code>File(id=\"syn123\").set_permissions(principal_id=273948, access_type=['READ','DOWNLOAD'])\n</code></pre> <p>Grant the public view access</p> <pre><code>File(id=\"syn123\").set_permissions(principal_id=273949, access_type=['READ'])\n</code></pre> Source code in <code>synapseclient/models/protocols/access_control_protocol.py</code> <pre><code>def set_permissions(\n    self,\n    principal_id: int = None,\n    access_type: List[str] = None,\n    modify_benefactor: bool = False,\n    warn_if_inherits: bool = True,\n    overwrite: bool = True,\n    *,\n    synapse_client: Optional[Synapse] = None,\n) -&gt; Dict[str, Union[str, list]]:\n    \"\"\"\n    Sets permission that a user or group has on an Entity.\n    An Entity may have its own ACL or inherit its ACL from a benefactor.\n\n    Arguments:\n        principal_id: Identifier of a user or group. `273948` is for all\n            registered Synapse users and `273949` is for public access.\n            None implies public access.\n        access_type: Type of permission to be granted. One or more of CREATE,\n            READ, DOWNLOAD, UPDATE, DELETE, CHANGE_PERMISSIONS.\n\n            **Defaults to ['READ', 'DOWNLOAD']**\n        modify_benefactor: Set as True when modifying a benefactor's ACL\n        warn_if_inherits: Set as False, when creating a new ACL. Trying to modify\n            the ACL of an Entity that inherits its ACL will result in a warning\n        overwrite: By default this function overwrites existing permissions for\n            the specified user. Set this flag to False to add new permissions\n            non-destructively.\n        synapse_client: If not passed in or None this will use the last client\n            from the `.login()` method.\n\n    Returns:\n        An Access Control List object\n\n    Example: Setting permissions\n        Grant all registered users download access\n\n            File(id=\"syn123\").set_permissions(principal_id=273948, access_type=['READ','DOWNLOAD'])\n\n        Grant the public view access\n\n            File(id=\"syn123\").set_permissions(principal_id=273949, access_type=['READ'])\n    \"\"\"\n    return {}\n</code></pre>"},{"location":"reference/oop/models/#synapseclient.models.Activity","title":"<code>synapseclient.models.Activity</code>  <code>dataclass</code>","text":"<p>               Bases: <code>ActivitySynchronousProtocol</code></p> <p>An activity is a Synapse object that helps to keep track of what objects were used in an analysis step, as well as what objects were generated. Thus, all relationships between Synapse objects and an activity are governed by dependencies. That is, an activity needs to know what it <code>used</code>, and outputs need to know what activity they were <code>generatedBy</code>.</p> ATTRIBUTE DESCRIPTION <code>id</code> <p>The unique immutable ID for this actvity.</p> <p> TYPE: <code>Optional[str]</code> </p> <code>name</code> <p>A name for this Activity.</p> <p> TYPE: <code>Optional[str]</code> </p> <code>description</code> <p>A description for this Activity.</p> <p> TYPE: <code>Optional[str]</code> </p> <code>etag</code> <p>Synapse employs an Optimistic Concurrency Control (OCC) scheme to handle concurrent updates. Since the E-Tag changes every time an entity is updated it is used to detect when a client's current representation of an entity is out-of-date.</p> <p> TYPE: <code>Optional[str]</code> </p> <code>created_on</code> <p>The date this object was created.</p> <p> TYPE: <code>Optional[str]</code> </p> <code>modified_on</code> <p>The date this object was last modified.</p> <p> TYPE: <code>Optional[str]</code> </p> <code>created_by</code> <p>The user that created this object.</p> <p> TYPE: <code>Optional[str]</code> </p> <code>modified_by</code> <p>The user that last modified this object.</p> <p> TYPE: <code>Optional[str]</code> </p> <code>used</code> <p>The entities or URLs used by this Activity.</p> <p> TYPE: <code>List[Union[UsedEntity, UsedURL]]</code> </p> <code>executed</code> <p>The entities or URLs executed by this Activity.</p> <p> TYPE: <code>List[Union[UsedEntity, UsedURL]]</code> </p> Source code in <code>synapseclient/models/activity.py</code> <pre><code>@dataclass\n@async_to_sync\nclass Activity(ActivitySynchronousProtocol):\n    \"\"\"\n    An activity is a Synapse object that helps to keep track of what objects were used\n    in an analysis step, as well as what objects were generated. Thus, all relationships\n    between Synapse objects and an activity are governed by dependencies. That is, an\n    activity needs to know what it `used`, and outputs need to know what activity\n    they were `generatedBy`.\n\n    Attributes:\n        id: The unique immutable ID for this actvity.\n        name: A name for this Activity.\n        description: A description for this Activity.\n        etag: Synapse employs an Optimistic Concurrency Control (OCC) scheme to handle\n            concurrent updates. Since the E-Tag changes every time an entity is updated\n            it is used to detect when a client's current representation of an entity is\n            out-of-date.\n        created_on: The date this object was created.\n        modified_on: The date this object was last modified.\n        created_by: The user that created this object.\n        modified_by: The user that last modified this object.\n        used: The entities or URLs used by this Activity.\n        executed: The entities or URLs executed by this Activity.\n    \"\"\"\n\n    id: Optional[str] = None\n    \"\"\"The unique immutable ID for this actvity.\"\"\"\n\n    name: Optional[str] = None\n    \"\"\"A name for this Activity.\"\"\"\n\n    description: Optional[str] = None\n    \"\"\"A description for this Activity.\"\"\"\n\n    etag: Optional[str] = None\n    \"\"\"\n    Synapse employs an Optimistic Concurrency Control (OCC) scheme to handle\n    concurrent updates. Since the E-Tag changes every time an entity is updated it is\n    used to detect when a client's current representation of an entity is out-of-date.\n    \"\"\"\n\n    created_on: Optional[str] = None\n    \"\"\"The date this object was created.\"\"\"\n\n    modified_on: Optional[str] = None\n    \"\"\"The date this object was last modified.\"\"\"\n\n    created_by: Optional[str] = None\n    \"\"\"The user that created this object.\"\"\"\n\n    modified_by: Optional[str] = None\n    \"\"\"The user that last modified this object.\"\"\"\n\n    used: List[Union[UsedEntity, UsedURL]] = field(default_factory=list)\n    \"\"\"The entities used by this Activity.\"\"\"\n\n    executed: List[Union[UsedEntity, UsedURL]] = field(default_factory=list)\n    \"\"\"The entities executed by this Activity.\"\"\"\n\n    def fill_from_dict(\n        self, synapse_activity: Union[Synapse_Activity, Dict]\n    ) -&gt; \"Activity\":\n        \"\"\"\n        Converts a response from the REST API into this dataclass.\n\n        Arguments:\n            synapse_activity: The response from the REST API.\n\n        Returns:\n            The Activity object.\n        \"\"\"\n        if not synapse_activity:\n            synapse_activity = {}\n        self.id = synapse_activity.get(\"id\", None)\n        self.name = synapse_activity.get(\"name\", None)\n        self.description = synapse_activity.get(\"description\", None)\n        self.etag = synapse_activity.get(\"etag\", None)\n        self.created_on = synapse_activity.get(\"createdOn\", None)\n        self.modified_on = synapse_activity.get(\"modifiedOn\", None)\n        self.created_by = synapse_activity.get(\"createdBy\", None)\n        self.modified_by = synapse_activity.get(\"modifiedBy\", None)\n        self.executed = []\n        self.used = []\n        for used in synapse_activity.get(\"used\", []):\n            concrete_type = used.get(\"concreteType\", None)\n            if USED_URL == concrete_type:\n                used_url = UsedURL(\n                    name=used.get(\"name\", None),\n                    url=used.get(\"url\", None),\n                )\n\n                if used.get(\"wasExecuted\", False):\n                    self.executed.append(used_url)\n                else:\n                    self.used.append(used_url)\n            elif USED_ENTITY == concrete_type:\n                reference = used.get(\"reference\", {})\n                used_entity = UsedEntity(\n                    target_id=reference.get(\"targetId\", None),\n                    target_version_number=reference.get(\"targetVersionNumber\", None),\n                )\n\n                if used.get(\"wasExecuted\", False):\n                    self.executed.append(used_entity)\n                else:\n                    self.used.append(used_entity)\n\n        return self\n\n    def _create_used_and_executed_synapse_activities(\n        self,\n    ) -&gt; UsedAndExecutedSynapseActivities:\n        \"\"\"\n        Helper function to create the used and executed activities for the\n        Synapse Activity.\n\n        Returns:\n            A tuple of the used and executed activities.\n        \"\"\"\n        synapse_activity_used = []\n        synapse_activity_executed = []\n\n        for used in self.used:\n            if isinstance(used, UsedEntity):\n                synapse_activity_used.append(\n                    {\n                        \"reference\": {\n                            \"targetId\": used.target_id,\n                            \"targetVersionNumber\": used.target_version_number,\n                        }\n                    }\n                )\n            elif isinstance(used, UsedURL):\n                synapse_activity_used.append(\n                    {\n                        \"name\": used.name,\n                        \"url\": used.url,\n                    }\n                )\n\n        for executed in self.executed:\n            if isinstance(executed, UsedEntity):\n                synapse_activity_executed.append(\n                    {\n                        \"reference\": {\n                            \"targetId\": executed.target_id,\n                            \"targetVersionNumber\": executed.target_version_number,\n                        },\n                        \"wasExecuted\": True,\n                    }\n                )\n            elif isinstance(executed, UsedURL):\n                synapse_activity_executed.append(\n                    {\"name\": executed.name, \"url\": executed.url, \"wasExecuted\": True}\n                )\n        return UsedAndExecutedSynapseActivities(\n            used=synapse_activity_used, executed=synapse_activity_executed\n        )\n\n    @otel_trace_method(\n        method_to_trace_name=lambda self, **kwargs: f\"Activity_store: {self.name}\"\n    )\n    async def store_async(\n        self,\n        parent: Optional[Union[\"Table\", \"File\"]] = None,\n        *,\n        synapse_client: Optional[Synapse] = None,\n    ) -&gt; \"Activity\":\n        \"\"\"\n        Store the Activity in Synapse.\n\n        Arguments:\n            parent: The parent entity to associate this activity with.\n            synapse_client: If not passed in or None this will use the last client\n                from the `.login()` method.\n\n        Returns:\n            The activity object.\n\n        Raises:\n            ValueError: Raised if both of the following are true:\n\n                - If the parent does not have an ID.\n                - If the Activity does not have an ID and ETag.\n        \"\"\"\n        # TODO: Input validation: SYNPY-1400\n        used_and_executed_activities = (\n            self._create_used_and_executed_synapse_activities()\n        )\n\n        synapse_activity = Synapse_Activity(\n            name=self.name,\n            description=self.description,\n            used=used_and_executed_activities.used,\n            executed=used_and_executed_activities.executed,\n        )\n\n        loop = asyncio.get_event_loop()\n        current_context = context.get_current()\n        if self.id:\n            # Despite init in `Synapse_Activity` not accepting an ID/ETAG the\n            # `updateActivity` method expects that it exists on the dict\n            # and `setProvenance` accepts it as well.\n            synapse_activity[\"id\"] = self.id\n            synapse_activity[\"etag\"] = self.etag\n        if parent:\n            saved_activity = await loop.run_in_executor(\n                None,\n                lambda: run_and_attach_otel_context(\n                    lambda: Synapse.get_client(\n                        synapse_client=synapse_client\n                    ).setProvenance(\n                        entity=parent.id,\n                        activity=synapse_activity,\n                    ),\n                    current_context,\n                ),\n            )\n        else:\n            saved_activity = await loop.run_in_executor(\n                None,\n                lambda: run_and_attach_otel_context(\n                    lambda: Synapse.get_client(\n                        synapse_client=synapse_client\n                    ).updateActivity(\n                        activity=synapse_activity,\n                    ),\n                    current_context,\n                ),\n            )\n        self.fill_from_dict(synapse_activity=saved_activity)\n        Synapse.get_client(synapse_client=synapse_client).logger.debug(\n            f\"Stored activity {self.id}\"\n        )\n\n        return self\n\n    @classmethod\n    async def from_parent_async(\n        cls,\n        parent: Union[\"Table\", \"File\"],\n        *,\n        synapse_client: Optional[Synapse] = None,\n    ) -&gt; Union[\"Activity\", None]:\n        \"\"\"\n        Get the Activity from Synapse based on the parent entity.\n\n        Arguments:\n            parent: The parent entity this activity is associated with. The parent may\n                also have a version_number. Gets the most recent version if version is\n                omitted.\n            synapse_client: If not passed in or None this will use the last client\n                from the `.login()` method.\n\n        Returns:\n            The activity object or None if it does not exist.\n\n        Raises:\n            ValueError: If the parent does not have an ID.\n        \"\"\"\n        # TODO: Input validation: SYNPY-1400\n        with tracer.start_as_current_span(name=f\"Activity_get: Parent_ID: {parent.id}\"):\n            loop = asyncio.get_event_loop()\n            current_context = context.get_current()\n            try:\n                synapse_activity = await loop.run_in_executor(\n                    None,\n                    lambda: run_and_attach_otel_context(\n                        lambda: Synapse.get_client(\n                            synapse_client=synapse_client\n                        ).getProvenance(\n                            entity=parent.id,\n                            version=parent.version_number,\n                        ),\n                        current_context,\n                    ),\n                )\n            except SynapseHTTPError as ex:\n                if ex.response.status_code == 404:\n                    return None\n                else:\n                    raise ex\n            if synapse_activity:\n                return cls().fill_from_dict(synapse_activity=synapse_activity)\n            else:\n                return None\n\n    @classmethod\n    async def delete_async(\n        cls,\n        parent: Union[\"Table\", \"File\"],\n        *,\n        synapse_client: Optional[Synapse] = None,\n    ) -&gt; None:\n        \"\"\"\n        Delete the Activity from Synapse. The Activity must be disassociated from\n        all entities before it can be deleted. The first step of this delete call\n        is to disassociate the Activity from the parent entity. If you have other\n        entities that are associated with this Activity you must disassociate them\n        by calling this method on them as well. You'll receive an error for all entities\n        until the last one which will delete the Activity.\n\n        Arguments:\n            parent: The parent entity this activity is associated with.\n            synapse_client: If not passed in or None this will use the last client\n                from the `.login()` method.\n\n        Raises:\n            ValueError: If the parent does not have an ID.\n        \"\"\"\n        # TODO: Input validation: SYNPY-1400\n        with tracer.start_as_current_span(\n            name=f\"Activity_delete: Parent_ID: {parent.id}\"\n        ):\n            loop = asyncio.get_event_loop()\n            current_context = context.get_current()\n            await loop.run_in_executor(\n                None,\n                lambda: run_and_attach_otel_context(\n                    lambda: Synapse.get_client(\n                        synapse_client=synapse_client\n                    ).deleteProvenance(\n                        entity=parent.id,\n                    ),\n                    current_context,\n                ),\n            )\n            parent.activity = None\n\n    @classmethod\n    async def disassociate_from_entity_async(\n        cls,\n        parent: Union[\"Table\", \"File\"],\n        *,\n        synapse_client: Optional[Synapse] = None,\n    ) -&gt; None:\n        \"\"\"\n        Disassociate the Activity from the parent entity. This is the first step in\n        deleting the Activity. If you have other entities that are associated with this\n        Activity you must disassociate them by calling this method on them as well.\n\n        Arguments:\n            parent: The parent entity this activity is associated with.\n            synapse_client: If not passed in or None this will use the last client\n                from the `.login()` method.\n\n        Raises:\n            ValueError: If the parent does not have an ID.\n        \"\"\"\n        # TODO: Input validation: SYNPY-1400\n        with tracer.start_as_current_span(\n            name=f\"Activity_disassociate: Parent_ID: {parent.id}\"\n        ):\n            await delete_entity_generated_by(\n                entity_id=parent.id, synapse_client=synapse_client\n            )\n            parent.activity = None\n</code></pre>"},{"location":"reference/oop/models/#synapseclient.models.UsedEntity","title":"<code>synapseclient.models.UsedEntity</code>  <code>dataclass</code>","text":"<p>Reference to a Synapse entity that was used or executed by an Activity.</p> ATTRIBUTE DESCRIPTION <code>target_id</code> <p>The ID of the entity to which this reference refers.</p> <p> TYPE: <code>Optional[str]</code> </p> <code>target_version_number</code> <p>The version number of the entity to which this reference refers.</p> <p> TYPE: <code>Optional[int]</code> </p> Source code in <code>synapseclient/models/activity.py</code> <pre><code>@dataclass\nclass UsedEntity:\n    \"\"\"\n    Reference to a Synapse entity that was used or executed by an Activity.\n\n    Attributes:\n        target_id: The ID of the entity to which this reference refers.\n        target_version_number: The version number of the entity to which this reference refers.\n    \"\"\"\n\n    target_id: Optional[str] = None\n    \"\"\"The the id of the entity to which this reference refers.\"\"\"\n\n    target_version_number: Optional[int] = None\n    \"\"\"The version number of the entity to which this reference refers.\"\"\"\n\n    def format_for_manifest(self) -&gt; str:\n        \"\"\"\n        Format the content of this data class to be written to a manifest file.\n\n        Returns:\n            The formatted string.\n        \"\"\"\n        return_value = f\"{self.target_id}\"\n        if self.target_version_number is not None:\n            return_value += f\".{self.target_version_number}\"\n        return return_value\n</code></pre>"},{"location":"reference/oop/models/#synapseclient.models.UsedURL","title":"<code>synapseclient.models.UsedURL</code>  <code>dataclass</code>","text":"<p>URL that was used or executed by an Activity such as a link to a GitHub commit or a link to a specific version of a software tool.</p> ATTRIBUTE DESCRIPTION <code>name</code> <p>The name of the URL.</p> <p> TYPE: <code>Optional[str]</code> </p> <code>url</code> <p>The external URL of the file that was used such as a link to a GitHub commit or a link to a specific version of a software tool.</p> <p> TYPE: <code>Optional[str]</code> </p> Source code in <code>synapseclient/models/activity.py</code> <pre><code>@dataclass\nclass UsedURL:\n    \"\"\"\n    URL that was used or executed by an Activity such as a link to a\n    GitHub commit or a link to a specific version of a software tool.\n\n    Attributes:\n        name: The name of the URL.\n        url: The external URL of the file that was used such as a link to a\n            GitHub commit or a link to a specific version of a software tool.\n    \"\"\"\n\n    name: Optional[str] = None\n    \"\"\"The name of the URL.\"\"\"\n\n    url: Optional[str] = None\n    \"\"\"The external URL of the file that was used such as a link to a GitHub commit\n    or a link to a specific version of a software tool.\"\"\"\n\n    def format_for_manifest(self) -&gt; str:\n        \"\"\"\n        Format the content of this data class to be written to a manifest file.\n\n        Returns:\n            The formatted string.\n        \"\"\"\n        if self.name:\n            return_value = self.name\n        else:\n            return_value = self.url\n\n        return return_value\n</code></pre>"},{"location":"reference/oop/models/#synapseclient.models.Team","title":"<code>synapseclient.models.Team</code>  <code>dataclass</code>","text":"<p>               Bases: <code>TeamSynchronousProtocol</code></p> <p>Represents a Synapse Team. User definable fields are:</p> ATTRIBUTE DESCRIPTION <code>id</code> <p>The ID of the team</p> <p> TYPE: <code>Optional[int]</code> </p> <code>name</code> <p>The name of the team</p> <p> TYPE: <code>Optional[str]</code> </p> <code>description</code> <p>A short description of the team</p> <p> TYPE: <code>Optional[str]</code> </p> <code>icon</code> <p>A file handle ID for the icon image of the team</p> <p> TYPE: <code>Optional[str]</code> </p> <code>can_public_join</code> <p>True if members can join without an invitation or approval</p> <p> TYPE: <code>Optional[bool]</code> </p> <code>can_request_membership</code> <p>True if users can create a membership request to join</p> <p> TYPE: <code>Optional[bool]</code> </p> <code>etag</code> <p>Synapse employs an Optimistic Concurrency Control (OCC) scheme to handle concurrent updates Since the E-Tag changes every time an entity is updated it is used to detect when a client's current representation of an entity is out-of-date.</p> <p> TYPE: <code>Optional[str]</code> </p> <code>created_on</code> <p>The date this team was created</p> <p> TYPE: <code>Optional[str]</code> </p> <code>modified_on</code> <p>The date this team was last modified</p> <p> TYPE: <code>Optional[str]</code> </p> <code>created_by</code> <p>The ID of the user that created this team</p> <p> TYPE: <code>Optional[str]</code> </p> <code>modified_by</code> <p>The ID of the user that last modified this team</p> <p> TYPE: <code>Optional[str]</code> </p> Source code in <code>synapseclient/models/team.py</code> <pre><code>@dataclass\n@async_to_sync\nclass Team(TeamSynchronousProtocol):\n    \"\"\"\n    Represents a [Synapse Team](https://rest-docs.synapse.org/rest/org/sagebionetworks/repo/model/Team.html).\n    User definable fields are:\n\n    Attributes:\n        id: The ID of the team\n        name: The name of the team\n        description: A short description of the team\n        icon: A file handle ID for the icon image of the team\n        can_public_join: True if members can join without an invitation or approval\n        can_request_membership: True if users can create a membership request to join\n        etag: Synapse employs an Optimistic Concurrency Control (OCC) scheme to handle\n            concurrent updates Since the E-Tag changes every time an entity is updated\n            it is used to detect when a client's current representation of an entity\n            is out-of-date.\n        created_on: The date this team was created\n        modified_on: The date this team was last modified\n        created_by: The ID of the user that created this team\n        modified_by: The ID of the user that last modified this team\n    \"\"\"\n\n    id: Optional[int] = None\n    \"\"\"The ID of the team\"\"\"\n\n    name: Optional[str] = None\n    \"\"\"The name of the team\"\"\"\n\n    description: Optional[str] = None\n    \"\"\"A short description of the team\"\"\"\n\n    icon: Optional[str] = None\n    \"\"\"A file handle ID for the icon image of the team\"\"\"\n\n    can_public_join: Optional[bool] = False\n    \"\"\"True if members can join without an invitation or approval\"\"\"\n\n    can_request_membership: Optional[bool] = True\n    \"\"\"True if users can create a membership request to join\"\"\"\n\n    etag: Optional[str] = None\n    \"\"\"\n    Synapse employs an Optimistic Concurrency Control (OCC) scheme to handle\n    concurrent updates Since the E-Tag changes every time an entity is updated it is\n    used to detect when a client's current representation of an entity is out-of-date.\n    \"\"\"\n\n    created_on: Optional[str] = None\n    \"\"\"The date this team was created\"\"\"\n\n    modified_on: Optional[str] = None\n    \"\"\"The date this team was last modified\"\"\"\n\n    created_by: Optional[str] = None\n    \"\"\"The ID of the user that created this team\"\"\"\n\n    modified_by: Optional[str] = None\n    \"\"\"The ID of the user that last modified this team\"\"\"\n\n    def fill_from_dict(\n        self, synapse_team: Union[Synapse_Team, Dict[str, str]]\n    ) -&gt; \"Team\":\n        \"\"\"\n        Converts a response from the REST API into this dataclass.\n\n        Arguments:\n            synapse_team: The response from the REST API.\n\n        Returns:\n            The Team object.\n        \"\"\"\n        self.id = (\n            int(synapse_team.get(\"id\", None)) if synapse_team.get(\"id\", None) else None\n        )\n        self.name = synapse_team.get(\"name\", None)\n        self.description = synapse_team.get(\"description\", None)\n        self.icon = synapse_team.get(\"icon\", None)\n        self.can_public_join = synapse_team.get(\"canPublicJoin\", False)\n        self.can_request_membership = synapse_team.get(\"canRequestMembership\", True)\n        self.etag = synapse_team.get(\"etag\", None)\n        self.created_on = synapse_team.get(\"createdOn\", None)\n        self.modified_on = synapse_team.get(\"modifiedOn\", None)\n        self.created_by = synapse_team.get(\"createdBy\", None)\n        self.modified_by = synapse_team.get(\"modifiedBy\", None)\n        return self\n\n    @otel_trace_method(\n        method_to_trace_name=lambda self, **kwargs: f\"Team_Create: {self.name}\"\n    )\n    async def create_async(self, *, synapse_client: Optional[Synapse] = None) -&gt; \"Team\":\n        \"\"\"Creates a new team on Synapse.\n\n        Arguments:\n            synapse_client: If not passed in or None this will use the last client\n                from the `.login()` method.\n\n        Returns:\n            Team: The Team object.\n        \"\"\"\n        loop = asyncio.get_event_loop()\n        current_context = context.get_current()\n        trace.get_current_span().set_attributes(\n            {\n                \"synapse.name\": self.name or \"\",\n                \"synapse.id\": self.id or \"\",\n            }\n        )\n        team = await loop.run_in_executor(\n            None,\n            lambda: run_and_attach_otel_context(\n                lambda: Synapse.get_client(synapse_client=synapse_client).create_team(\n                    name=self.name,\n                    description=self.description,\n                    icon=self.icon,\n                    can_public_join=self.can_public_join,\n                    can_request_membership=self.can_request_membership,\n                ),\n                current_context,\n            ),\n        )\n        self.fill_from_dict(synapse_team=team)\n        return self\n\n    @otel_trace_method(\n        method_to_trace_name=lambda self, **kwargs: f\"Team_Delete: {self.id}\"\n    )\n    async def delete_async(self, *, synapse_client: Optional[Synapse] = None) -&gt; None:\n        \"\"\"Deletes a team from Synapse.\n\n        Arguments:\n            synapse_client: If not passed in or None this will use the last client\n                from the `.login()` method.\n\n        Returns:\n            None\n        \"\"\"\n        loop = asyncio.get_event_loop()\n        current_context = context.get_current()\n        await loop.run_in_executor(\n            None,\n            lambda: run_and_attach_otel_context(\n                lambda: Synapse.get_client(synapse_client=synapse_client).delete_team(\n                    id=self.id,\n                ),\n                current_context,\n            ),\n        )\n\n    @otel_trace_method(\n        method_to_trace_name=lambda self, **kwargs: f\"Team_Get: {self.id if self.id else self.name}\"\n    )\n    async def get_async(self, *, synapse_client: Optional[Synapse] = None) -&gt; \"Team\":\n        \"\"\"\n        Gets a Team from Synapse by ID or Name. If both are added to the Team instance\n        it will use the ID.\n\n        Arguments:\n            synapse_client: If not passed in or None this will use the last client\n                from the `.login()` method.\n\n        Raises:\n            ValueError: If the Team object has neither an id nor a name.\n\n        Returns:\n            Team: The Team object.\n        \"\"\"\n        if self.id:\n            loop = asyncio.get_event_loop()\n            current_context = context.get_current()\n            api_team = await loop.run_in_executor(\n                None,\n                lambda: run_and_attach_otel_context(\n                    lambda: Synapse.get_client(synapse_client=synapse_client).getTeam(\n                        id=self.id,\n                    ),\n                    current_context,\n                ),\n            )\n            return self.fill_from_dict(api_team)\n        elif self.name:\n            loop = asyncio.get_event_loop()\n            current_context = context.get_current()\n            api_team = await loop.run_in_executor(\n                None,\n                lambda: run_and_attach_otel_context(\n                    lambda: Synapse.get_client(synapse_client=synapse_client).getTeam(\n                        id=self.name,\n                    ),\n                    current_context,\n                ),\n            )\n            return self.fill_from_dict(api_team)\n        raise ValueError(\"Team must have either an id or a name\")\n\n    @classmethod\n    @otel_trace_method(\n        method_to_trace_name=lambda cls, id, **kwargs: f\"Team_From_Id: {id}\"\n    )\n    async def from_id_async(\n        cls, id: int, *, synapse_client: Optional[Synapse] = None\n    ) -&gt; \"Team\":\n        \"\"\"Gets Team object using its integer id.\n\n        Arguments:\n            id: The id of the team.\n            synapse_client: If not passed in or None this will use the last client\n                from the `.login()` method.\n\n        Returns:\n            Team: The Team object.\n        \"\"\"\n\n        return await cls(id=id).get_async(synapse_client=synapse_client)\n\n    @classmethod\n    @otel_trace_method(\n        method_to_trace_name=lambda cls, name, **kwargs: f\"Team_From_Name: {name}\"\n    )\n    async def from_name_async(\n        cls, name: str, *, synapse_client: Optional[Synapse] = None\n    ) -&gt; \"Team\":\n        \"\"\"Gets Team object using its string name.\n\n        *** You will be unable to retrieve a team by name immediately after its\n        creation because the fragment service is eventually consistent. If you need to\n        retrieve a team immediately following creation you should use the\n        [from_id][synapseclient.models.Team.from_id] method. ***\n\n        Arguments:\n            name: The name of the team.\n            synapse_client: If not passed in or None this will use the last client\n                from the `.login()` method.\n\n        Returns:\n            Team: The Team object.\n        \"\"\"\n        return await cls(name=name).get_async(synapse_client=synapse_client)\n\n    @otel_trace_method(\n        method_to_trace_name=lambda self, **kwargs: f\"Team_Members: {self.name}\"\n    )\n    async def members_async(\n        self, *, synapse_client: Optional[Synapse] = None\n    ) -&gt; List[TeamMember]:\n        \"\"\"\n        Gets the TeamMembers associated with a team given the ID field on the\n        Team instance.\n\n        Arguments:\n            synapse_client: If not passed in or None this will use the last client\n                from the `.login()` method.\n\n        Returns:\n            List[TeamMember]: A List of TeamMember objects.\n        \"\"\"\n        loop = asyncio.get_event_loop()\n        current_context = context.get_current()\n        team_members = await loop.run_in_executor(\n            None,\n            lambda: run_and_attach_otel_context(\n                lambda: Synapse.get_client(\n                    synapse_client=synapse_client\n                ).getTeamMembers(team=self),\n                current_context,\n            ),\n        )\n        team_member_list = [\n            TeamMember().fill_from_dict(synapse_team_member=member)\n            for member in team_members\n        ]\n        return team_member_list\n\n    @otel_trace_method(\n        method_to_trace_name=lambda self, **kwargs: f\"Team_Invite: {self.name}\"\n    )\n    async def invite_async(\n        self,\n        user: str,\n        message: str,\n        force: bool = True,\n        *,\n        synapse_client: Optional[Synapse] = None,\n    ) -&gt; Dict[str, str]:\n        \"\"\"Invites a user to a team given the ID field on the Team instance.\n\n        Arguments:\n            user: The username of the user to invite.\n            message: The message to send.\n            synapse_client: If not passed in or None this will use the last client\n                from the `.login()` method.\n\n        Returns:\n            dict: The invite response.\n        \"\"\"\n        loop = asyncio.get_event_loop()\n        current_context = context.get_current()\n        invite = await loop.run_in_executor(\n            None,\n            lambda: run_and_attach_otel_context(\n                lambda: Synapse.get_client(\n                    synapse_client=synapse_client\n                ).invite_to_team(\n                    team=self,\n                    user=user,\n                    message=message,\n                    force=force,\n                ),\n                current_context,\n            ),\n        )\n        return invite\n\n    @otel_trace_method(\n        method_to_trace_name=lambda self, **kwargs: f\"Team_Open_Invitations: {self.name}\"\n    )\n    async def open_invitations_async(\n        self, *, synapse_client: Optional[Synapse] = None\n    ) -&gt; List[Dict[str, str]]:\n        \"\"\"Gets all open invitations for a team given the ID field on the Team instance.\n\n        Arguments:\n            synapse_client: If not passed in or None this will use the last client\n                from the `.login()` method.\n\n        Returns:\n            List[dict]: A list of invitations.\n        \"\"\"\n        loop = asyncio.get_event_loop()\n        current_context = context.get_current()\n        invitations = await loop.run_in_executor(\n            None,\n            lambda: run_and_attach_otel_context(\n                lambda: Synapse.get_client(\n                    synapse_client=synapse_client\n                ).get_team_open_invitations(\n                    team=self,\n                ),\n                current_context,\n            ),\n        )\n        return list(invitations)\n</code></pre>"},{"location":"reference/oop/models/#synapseclient.models.UserProfile","title":"<code>synapseclient.models.UserProfile</code>  <code>dataclass</code>","text":"<p>               Bases: <code>UserProfileSynchronousProtocol</code></p> <p>UserProfile represents a user's profile in the system.</p> ATTRIBUTE DESCRIPTION <code>id</code> <p>A foreign key to the ID of the 'principal' object for the user.</p> <p> TYPE: <code>Optional[int]</code> </p> <code>etag</code> <p>Synapse employs an Optimistic Concurrency Control (OCC) scheme to handle concurrent updates. Since the E-Tag changes every time an entity is updated it is used to detect when a client's currentrepresentation of an entity is out-of-date.</p> <p> TYPE: <code>Optional[str]</code> </p> <code>first_name</code> <p>This person's given name (forename)</p> <p> TYPE: <code>Optional[str]</code> </p> <code>last_name</code> <p>This person's family name (surname)</p> <p> TYPE: <code>Optional[str]</code> </p> <code>emails</code> <p>The list of user email addresses registered to this user.</p> <p> TYPE: <code>List[str]</code> </p> <code>open_ids</code> <p>The list of OpenIds bound to this user's account.</p> <p> TYPE: <code>List[str]</code> </p> <code>username</code> <p>A name chosen by the user that uniquely identifies them.</p> <p> TYPE: <code>Optional[str]</code> </p> <code>display_name</code> <p>This field is deprecated and will always be null.</p> <p> TYPE: <code>Optional[str]</code> </p> <code>r_studio_url</code> <p>URL for RStudio server assigned to the user.</p> <p> TYPE: <code>Optional[str]</code> </p> <code>summary</code> <p>A summary description about this person.</p> <p> TYPE: <code>Optional[str]</code> </p> <code>position</code> <p>This person's current position title.</p> <p> TYPE: <code>Optional[str]</code> </p> <code>location</code> <p>This person's location.</p> <p> TYPE: <code>Optional[str]</code> </p> <code>industry</code> <p>The industry/discipline that this person is associated with.</p> <p> TYPE: <code>Optional[str]</code> </p> <code>company</code> <p>This person's current affiliation.</p> <p> TYPE: <code>Optional[str]</code> </p> <code>profile_picure_file_handle_id</code> <p>The File Handle id of the user's profile picture.</p> <p> TYPE: <code>Optional[str]</code> </p> <code>url</code> <p>A link to more information about this person.</p> <p> TYPE: <code>Optional[str]</code> </p> <code>team_name</code> <p>This person's default team name.</p> <p> TYPE: <code>Optional[str]</code> </p> <code>notification_settings</code> <p>Contains a user's notification settings.</p> <p> TYPE: <code>Optional[str]</code> </p> <code>preferences</code> <p>User preferences</p> <p> TYPE: <code>Optional[List[UserPreference]]</code> </p> <code>created_on</code> <p>The date this profile was created.</p> <p> TYPE: <code>Optional[str]</code> </p> Source code in <code>synapseclient/models/user.py</code> <pre><code>@dataclass()\n@async_to_sync\nclass UserProfile(UserProfileSynchronousProtocol):\n    \"\"\"\n    UserProfile represents a user's profile in the system.\n\n    Attributes:\n        id: A foreign key to the ID of the 'principal' object for the user.\n        etag: Synapse employs an Optimistic Concurrency Control (OCC) scheme to handle\n            concurrent updates. Since the E-Tag changes every time an entity is updated\n            it is used to detect when a client's currentrepresentation of an entity is\n            out-of-date.\n        first_name: This person's given name (forename)\n        last_name: This person's family name (surname)\n        emails: The list of user email addresses registered to this user.\n        open_ids: The list of OpenIds bound to this user's account.\n        username: A name chosen by the user that uniquely identifies them.\n        display_name: This field is deprecated and will always be null.\n        r_studio_url: URL for RStudio server assigned to the user.\n        summary: A summary description about this person.\n        position: This person's current position title.\n        location: This person's location.\n        industry: The industry/discipline that this person is associated with.\n        company: This person's current affiliation.\n        profile_picure_file_handle_id: The File Handle id of the user's profile picture.\n        url: A link to more information about this person.\n        team_name: This person's default team name.\n        notification_settings: Contains a user's notification settings.\n        preferences: User preferences\n        created_on: The date this profile was created.\n    \"\"\"\n\n    id: Optional[int] = None\n    \"\"\"A foreign key to the ID of the 'principal' object for the user.\"\"\"\n\n    username: Optional[str] = None\n    \"\"\"A name chosen by the user that uniquely identifies them.\"\"\"\n\n    etag: Optional[str] = None\n    \"\"\"\n    Synapse employs an Optimistic Concurrency Control (OCC) scheme to handle\n    concurrent updates. Since the E-Tag changes every time an entity is updated it is\n    used to detect when a client's current representation of an entity is out-of-date.\n    \"\"\"\n\n    first_name: Optional[str] = None\n    \"\"\"This person's given name (forename)\"\"\"\n\n    last_name: Optional[str] = None\n    \"\"\"This person's family name (surname)\"\"\"\n\n    emails: List[str] = field(default_factory=list)\n    \"\"\"The list of user email addresses registered to this user.\"\"\"\n\n    open_ids: List[str] = field(default_factory=list)\n    \"\"\"The list of OpenIds bound to this user's account.\"\"\"\n\n    r_studio_url: Optional[str] = None\n    \"\"\"URL for RStudio server assigned to the user\"\"\"\n\n    summary: Optional[str] = None\n    \"\"\"A summary description about this person\"\"\"\n\n    position: Optional[str] = None\n    \"\"\"This person's current position title\"\"\"\n\n    location: Optional[str] = None\n    \"\"\"This person's location\"\"\"\n\n    industry: Optional[str] = None\n    \"\"\"The industry/discipline that this person is associated with\"\"\"\n\n    company: Optional[str] = None\n    \"\"\"This person's current affiliation\"\"\"\n\n    profile_picure_file_handle_id: Optional[str] = None\n    \"\"\"The File Handle id of the user's profile picture\"\"\"\n\n    url: Optional[str] = None\n    \"\"\"A link to more information about this person\"\"\"\n\n    team_name: Optional[str] = None\n    \"\"\"This person's default team name\"\"\"\n\n    send_email_notifications: Optional[bool] = True\n    \"\"\"Should the user receive email notifications? Default true.\"\"\"\n\n    mark_emailed_messages_as_read: Optional[bool] = False\n    \"\"\"Should messages that are emailed to the user be marked as\n    READ in Synapse? Default false.\"\"\"\n\n    preferences: Optional[List[UserPreference]] = field(default_factory=list)\n    \"\"\"User preferences\"\"\"\n\n    created_on: Optional[str] = None\n    \"\"\"The date this profile was created.\"\"\"\n\n    def fill_from_dict(\n        self, synapse_user_profile: Union[Synapse_UserProfile, Dict]\n    ) -&gt; \"UserProfile\":\n        \"\"\"Fills the UserProfile object from a dictionary.\n\n        Arguments:\n            synapse_user_profile: The dictionary to fill the UserProfile object from.\n                Typically filled from a\n                [Synapse UserProfile](https://rest-docs.synapse.org/rest/org/sagebionetworks/repo/model/UserProfile.html) object.\n        \"\"\"\n        self.id = (\n            int(synapse_user_profile.get(\"ownerId\", None))\n            if synapse_user_profile.get(\"ownerId\", None)\n            else None\n        )\n        self.etag = synapse_user_profile.get(\"etag\", None)\n        self.first_name = synapse_user_profile.get(\"firstName\", None)\n        self.last_name = synapse_user_profile.get(\"lastName\", None)\n        self.emails = synapse_user_profile.get(\"emails\", [])\n        self.open_ids = synapse_user_profile.get(\"openIds\", [])\n        self.username = synapse_user_profile.get(\"userName\", None)\n        self.r_studio_url = synapse_user_profile.get(\"rStudioUrl\", None)\n        self.summary = synapse_user_profile.get(\"summary\", None)\n        self.position = synapse_user_profile.get(\"position\", None)\n        self.location = synapse_user_profile.get(\"location\", None)\n        self.industry = synapse_user_profile.get(\"industry\", None)\n        self.company = synapse_user_profile.get(\"company\", None)\n        self.profile_picure_file_handle_id = synapse_user_profile.get(\n            \"profilePicureFileHandleId\", None\n        )\n        self.url = synapse_user_profile.get(\"url\", None)\n        self.team_name = synapse_user_profile.get(\"teamName\", None)\n        notification_settings = synapse_user_profile.get(\"notificationSettings\", {})\n        self.send_email_notifications = notification_settings.get(\n            \"sendEmailNotifications\", True\n        )\n        self.mark_emailed_messages_as_read = notification_settings.get(\n            \"markEmailedMessagesAsRead\", False\n        )\n        synapse_preferences_list = synapse_user_profile.get(\"preferences\", [])\n        preferences = []\n        for preference in synapse_preferences_list:\n            preferences.append(\n                UserPreference(\n                    name=preference.get(\"name\", None),\n                    value=preference.get(\"value\", None),\n                )\n            )\n        self.preferences = preferences\n        self.created_on = synapse_user_profile.get(\"createdOn\", None)\n\n        return self\n\n    @otel_trace_method(\n        method_to_trace_name=lambda self, **kwargs: f\"Profile_Get: Username: {self.username}, id: {self.id}\"\n    )\n    async def get_async(\n        self,\n        *,\n        synapse_client: Optional[Synapse] = None,\n    ) -&gt; \"UserProfile\":\n        \"\"\"\n        Gets a UserProfile object using its id or username in that order. If an id\n        and username is not specified this will retrieve the current user's profile.\n\n        Arguments:\n            synapse_client: If not passed in or None this will use the last client\n                from the `.login()` method.\n\n        Returns:\n            The UserProfile object.\n\n        \"\"\"\n        loop = asyncio.get_event_loop()\n\n        current_context = context.get_current()\n        if self.id:\n            synapse_user_profile = await loop.run_in_executor(\n                None,\n                lambda: run_and_attach_otel_context(\n                    lambda: Synapse.get_client(\n                        synapse_client=synapse_client\n                    ).get_user_profile_by_id(id=self.id),\n                    current_context,\n                ),\n            )\n        elif self.username:\n            synapse_user_profile = await loop.run_in_executor(\n                None,\n                lambda: run_and_attach_otel_context(\n                    lambda: Synapse.get_client(\n                        synapse_client=synapse_client\n                    ).get_user_profile_by_username(username=self.username),\n                    current_context,\n                ),\n            )\n        else:\n            synapse_user_profile = await loop.run_in_executor(\n                None,\n                lambda: run_and_attach_otel_context(\n                    lambda: Synapse.get_client(\n                        synapse_client=synapse_client\n                    ).get_user_profile_by_username(),\n                    current_context,\n                ),\n            )\n\n        self.fill_from_dict(synapse_user_profile=synapse_user_profile)\n        return self\n\n    @classmethod\n    @otel_trace_method(\n        method_to_trace_name=lambda cls, user_id, **kwargs: f\"Profile_From_Id: {user_id}\"\n    )\n    async def from_id_async(\n        cls, user_id: int, *, synapse_client: Optional[Synapse] = None\n    ) -&gt; \"UserProfile\":\n        \"\"\"Gets UserProfile object using its integer id. Wrapper for the\n        [get][synapseclient.models.UserProfile.get] method.\n\n        Arguments:\n            user_id: The id of the user.\n            synapse_client: If not passed in or None this will use the last client\n                from the `.login()` method.\n\n        Returns:\n            The UserProfile object.\n        \"\"\"\n\n        return await cls(id=user_id).get_async(synapse_client=synapse_client)\n\n    @classmethod\n    @otel_trace_method(\n        method_to_trace_name=lambda cls, username, **kwargs: f\"Profile_From_Username: {username}\"\n    )\n    async def from_username_async(\n        cls, username: str, *, synapse_client: Optional[Synapse] = None\n    ) -&gt; \"UserProfile\":\n        \"\"\"\n        Gets UserProfile object using its string name. Wrapper for the\n        [get][synapseclient.models.UserProfile.get] method.\n\n        Arguments:\n            username: A name chosen by the user that uniquely identifies them.\n            synapse_client: If not passed in or None this will use the last client\n                from the `.login()` method.\n\n        Returns:\n            The UserProfile object.\n        \"\"\"\n        return await cls(username=username).get_async(synapse_client=synapse_client)\n\n    @otel_trace_method(\n        method_to_trace_name=lambda self, **kwargs: f\"Profile_is_certified: Username: {self.username}, id: {self.id}\"\n    )\n    async def is_certified_async(\n        self,\n        *,\n        synapse_client: Optional[Synapse] = None,\n    ) -&gt; \"bool\":\n        \"\"\"\n        Determine whether a user is certified.\n\n        Arguments:\n            synapse_client: If not passed in or None this will use the last client\n                from the `.login()` method.\n\n        Returns:\n            True if the user is certified, False otherwise.\n\n        Raises:\n            ValueError: If id nor username is specified.\n        \"\"\"\n        loop = asyncio.get_event_loop()\n\n        current_context = context.get_current()\n        if self.id or self.username:\n            is_certified = await loop.run_in_executor(\n                None,\n                lambda: run_and_attach_otel_context(\n                    lambda: Synapse.get_client(\n                        synapse_client=synapse_client\n                    ).is_certified(user=self.id or self.username),\n                    current_context,\n                ),\n            )\n        else:\n            raise ValueError(\"Must specify either id or username\")\n\n        return is_certified\n</code></pre>"},{"location":"reference/oop/models/#synapseclient.models.UserPreference","title":"<code>synapseclient.models.UserPreference</code>  <code>dataclass</code>","text":"<p>A UserPreference represents a user preference in the system.</p> ATTRIBUTE DESCRIPTION <code>name</code> <p>The name of the user preference.</p> <p> TYPE: <code>Optional[str]</code> </p> <code>value</code> <p>The value of the user preference.</p> <p> TYPE: <code>Optional[bool]</code> </p> Source code in <code>synapseclient/models/user.py</code> <pre><code>@dataclass()\nclass UserPreference:\n    \"\"\"\n    A UserPreference represents a user preference in the system.\n\n    Attributes:\n        name: The name of the user preference.\n        value: The value of the user preference.\n    \"\"\"\n\n    name: Optional[str] = None\n    \"\"\"The name of the user preference.\"\"\"\n\n    value: Optional[bool] = None\n    \"\"\"The value of the user preference.\"\"\"\n</code></pre>"},{"location":"reference/oop/models/#synapseclient.models.UserPreference-attributes","title":"Attributes","text":""},{"location":"reference/oop/models/#synapseclient.models.UserPreference.name","title":"<code>name: Optional[str] = None</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The name of the user preference.</p>"},{"location":"reference/oop/models/#synapseclient.models.UserPreference.value","title":"<code>value: Optional[bool] = None</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The value of the user preference.</p>"},{"location":"reference/oop/models/#synapseclient.models.Annotations","title":"<code>synapseclient.models.Annotations</code>  <code>dataclass</code>","text":"<p>               Bases: <code>AnnotationsSynchronousProtocol</code></p> <p>Annotations that can be applied to a number of Synapse resources to provide additional information.</p> ATTRIBUTE DESCRIPTION <code>annotations</code> <p>Additional metadata associated with the object. The key is the name of your desired annotations. The value is an object containing a list of string values (use empty list to represent no values for key) and the value type associated with all values in the list.</p> <p> TYPE: <code>Union[Dict[str, Union[List[str], List[bool], List[float], List[int], List[date], List[datetime]]], None]</code> </p> <code>id</code> <p>ID of the object to which this annotation belongs. Not required if being used as a member variable on another class.</p> <p> TYPE: <code>Optional[str]</code> </p> <code>etag</code> <p>Etag of the object to which this annotation belongs. This field must match the current etag on the object. Not required if being used as a member variable on another class.</p> <p> TYPE: <code>Optional[str]</code> </p> Source code in <code>synapseclient/models/annotations.py</code> <pre><code>@dataclass()\n@async_to_sync\nclass Annotations(AnnotationsSynchronousProtocol):\n    \"\"\"Annotations that can be applied to a number of Synapse resources to provide\n    additional information.\n\n    Attributes:\n        annotations: Additional metadata associated with the object. The key is the name\n            of your desired annotations. The value is an object containing a list of\n            string values (use empty list to represent no values for key) and the value\n            type associated with all values in the list.\n        id: ID of the object to which this annotation belongs. Not required if being\n            used as a member variable on another class.\n        etag: Etag of the object to which this annotation belongs. This field must match\n            the current etag on the object. Not required if being used as a member\n            variable on another class.\n    \"\"\"\n\n    annotations: Union[\n        Dict[\n            str,\n            Union[\n                List[str],\n                List[bool],\n                List[float],\n                List[int],\n                List[date],\n                List[datetime],\n            ],\n        ],\n        None,\n    ] = field(default_factory=dict)\n    \"\"\"Additional metadata associated with the object. The key is the name of your\n    desired annotations. The value is an object containing a list of string values\n    (use empty list to represent no values for key) and the value type associated with\n    all values in the list.\n    \"\"\"\n\n    id: Optional[str] = None\n    \"\"\"ID of the object to which this annotation belongs. Not required if being used as\n    a member variable on another class.\"\"\"\n\n    etag: Optional[str] = None\n    \"\"\" Etag of the object to which this annotation belongs. To update an AnnotationV2,\n    this field must match the current etag on the object. Not required if being used as\n    a member variable on another class.\"\"\"\n\n    async def store_async(\n        self,\n        *,\n        synapse_client: Optional[Synapse] = None,\n    ) -&gt; \"Annotations\":\n        \"\"\"Storing annotations to synapse.\n\n        Arguments:\n            synapse_client: If not passed in or None this will use the last client\n                from the `.login()` method.\n\n        Returns:\n            The stored annotations.\n\n        Raises:\n            ValueError: If the id or etag are not set.\n        \"\"\"\n        if self.id is None or self.etag is None:\n            raise ValueError(\"id and etag are required to store annotations.\")\n\n        result = await set_annotations_async(\n            annotations=self,\n            synapse_client=synapse_client,\n        )\n        self.annotations = Annotations.from_dict(result)\n        self.etag = result[\"etag\"]\n        Synapse.get_client(synapse_client=synapse_client).logger.debug(\n            f\"Annotations stored for {self.id}\"\n        )\n        return self\n\n    @classmethod\n    def from_dict(\n        cls, synapse_annotations: dict\n    ) -&gt; Union[\n        Dict[\n            str,\n            Union[\n                List[str],\n                List[bool],\n                List[float],\n                List[int],\n                List[date],\n                List[datetime],\n            ],\n        ],\n        None,\n    ]:\n        \"\"\"Convert the annotations from the format the synapse rest API works in -\n        to the format used by this class.\n\n        Arguments:\n            synapse_annotations: The annotations from the synapse rest API.\n\n        Returns:\n            The annotations in python class format or None.\n        \"\"\"\n        if synapse_annotations is None:\n            return None\n        annotations = {}\n        dict_to_convert = (\n            synapse_annotations[\"annotations\"]\n            if \"annotations\" in synapse_annotations\n            else synapse_annotations\n        )\n        for key in dict_to_convert:\n            if isinstance(dict_to_convert[key], dict):\n                conversion_func = ANNO_TYPE_TO_FUNC[dict_to_convert[key][\"type\"]]\n                annotations[key] = [\n                    conversion_func(v) for v in dict_to_convert[key][\"value\"]\n                ]\n            else:\n                annotations[key] = dict_to_convert[key]\n\n        return annotations\n</code></pre>"},{"location":"reference/oop/models/#synapseclient.models.Annotations-functions","title":"Functions","text":""},{"location":"reference/oop/models/#synapseclient.models.Annotations.from_dict","title":"<code>from_dict(synapse_annotations)</code>  <code>classmethod</code>","text":"<p>Convert the annotations from the format the synapse rest API works in - to the format used by this class.</p> PARAMETER DESCRIPTION <code>synapse_annotations</code> <p>The annotations from the synapse rest API.</p> <p> TYPE: <code>dict</code> </p> RETURNS DESCRIPTION <code>Union[Dict[str, Union[List[str], List[bool], List[float], List[int], List[date], List[datetime]]], None]</code> <p>The annotations in python class format or None.</p> Source code in <code>synapseclient/models/annotations.py</code> <pre><code>@classmethod\ndef from_dict(\n    cls, synapse_annotations: dict\n) -&gt; Union[\n    Dict[\n        str,\n        Union[\n            List[str],\n            List[bool],\n            List[float],\n            List[int],\n            List[date],\n            List[datetime],\n        ],\n    ],\n    None,\n]:\n    \"\"\"Convert the annotations from the format the synapse rest API works in -\n    to the format used by this class.\n\n    Arguments:\n        synapse_annotations: The annotations from the synapse rest API.\n\n    Returns:\n        The annotations in python class format or None.\n    \"\"\"\n    if synapse_annotations is None:\n        return None\n    annotations = {}\n    dict_to_convert = (\n        synapse_annotations[\"annotations\"]\n        if \"annotations\" in synapse_annotations\n        else synapse_annotations\n    )\n    for key in dict_to_convert:\n        if isinstance(dict_to_convert[key], dict):\n            conversion_func = ANNO_TYPE_TO_FUNC[dict_to_convert[key][\"type\"]]\n            annotations[key] = [\n                conversion_func(v) for v in dict_to_convert[key][\"value\"]\n            ]\n        else:\n            annotations[key] = dict_to_convert[key]\n\n    return annotations\n</code></pre>"},{"location":"reference/oop/models/#synapseclient.models.mixins.AccessControllable","title":"<code>synapseclient.models.mixins.AccessControllable</code>","text":"<p>               Bases: <code>AccessControllableSynchronousProtocol</code></p> <p>Mixin for objects that can be controlled by an Access Control List (ACL).</p> <p>In order to use this mixin, the class must have an <code>id</code> attribute.</p> Source code in <code>synapseclient/models/mixins/access_control.py</code> <pre><code>@async_to_sync\nclass AccessControllable(AccessControllableSynchronousProtocol):\n    \"\"\"\n    Mixin for objects that can be controlled by an Access Control List (ACL).\n\n    In order to use this mixin, the class must have an `id` attribute.\n    \"\"\"\n\n    id: Optional[str] = None\n    \"\"\"The unique immutable ID for this entity. A new ID will be generated for new Files.\n    Once issued, this ID is guaranteed to never change or be re-issued.\"\"\"\n\n    async def get_permissions_async(\n        self,\n        *,\n        synapse_client: Optional[Synapse] = None,\n    ) -&gt; \"Permissions\":\n        \"\"\"\n        Get the [permissions][synapseclient.core.models.permission.Permissions]\n        that the caller has on an Entity.\n\n        Arguments:\n            synapse_client: If not passed in or None this will use the last client\n                from the `.login()` method.\n\n        Returns:\n            A Permissions object\n\n\n        Example: Using this function:\n            Getting permissions for a Synapse Entity\n\n                permissions = await File(id=\"syn123\").get_permissions_async()\n\n            Getting access types list from the Permissions object\n\n                permissions.access_types\n        \"\"\"\n        loop = asyncio.get_event_loop()\n        current_context = context.get_current()\n\n        return await loop.run_in_executor(\n            None,\n            lambda: run_and_attach_otel_context(\n                lambda: Synapse.get_client(\n                    synapse_client=synapse_client\n                ).get_permissions(entity=self.id),\n                current_context,\n            ),\n        )\n\n    async def get_acl_async(\n        self, principal_id: int = None, *, synapse_client: Optional[Synapse] = None\n    ) -&gt; List[str]:\n        \"\"\"\n        Get the [ACL][synapseclient.core.models.permission.Permissions.access_types]\n        that a user or group has on an Entity.\n\n        Arguments:\n            principal_id: Identifier of a user or group (defaults to PUBLIC users)\n            synapse_client: If not passed in or None this will use the last client\n                from the `.login()` method.\n\n        Returns:\n            An array containing some combination of\n                ['READ', 'UPDATE', 'CREATE', 'DELETE', 'DOWNLOAD', 'MODERATE',\n                'CHANGE_PERMISSIONS', 'CHANGE_SETTINGS']\n                or an empty array\n        \"\"\"\n        loop = asyncio.get_event_loop()\n        current_context = context.get_current()\n\n        return await loop.run_in_executor(\n            None,\n            lambda: run_and_attach_otel_context(\n                lambda: Synapse.get_client(synapse_client=synapse_client).get_acl(\n                    entity=self.id, principal_id=principal_id\n                ),\n                current_context,\n            ),\n        )\n\n    async def set_permissions_async(\n        self,\n        principal_id: int = None,\n        access_type: List[str] = None,\n        modify_benefactor: bool = False,\n        warn_if_inherits: bool = True,\n        overwrite: bool = True,\n        *,\n        synapse_client: Optional[Synapse] = None,\n    ) -&gt; Dict[str, Union[str, list]]:\n        \"\"\"\n        Sets permission that a user or group has on an Entity.\n        An Entity may have its own ACL or inherit its ACL from a benefactor.\n\n        Arguments:\n            principal_id: Identifier of a user or group. `273948` is for all\n                registered Synapse users and `273949` is for public access.\n                None implies public access.\n            access_type: Type of permission to be granted. One or more of CREATE,\n                READ, DOWNLOAD, UPDATE, DELETE, CHANGE_PERMISSIONS.\n\n                **Defaults to ['READ', 'DOWNLOAD']**\n            modify_benefactor: Set as True when modifying a benefactor's ACL\n            warn_if_inherits: Set as False, when creating a new ACL. Trying to modify\n                the ACL of an Entity that inherits its ACL will result in a warning\n            overwrite: By default this function overwrites existing permissions for\n                the specified user. Set this flag to False to add new permissions\n                non-destructively.\n            synapse_client: If not passed in or None this will use the last client\n                from the `.login()` method.\n\n        Returns:\n            An Access Control List object\n\n        Example: Setting permissions\n            Grant all registered users download access\n\n                await File(id=\"syn123\").set_permissions_async(principal_id=273948, access_type=['READ','DOWNLOAD'])\n\n            Grant the public view access\n\n                await File(id=\"syn123\").set_permissions_async(principal_id=273949, access_type=['READ'])\n        \"\"\"\n        if access_type is None:\n            access_type = [\"READ\", \"DOWNLOAD\"]\n        loop = asyncio.get_event_loop()\n        current_context = context.get_current()\n\n        return await loop.run_in_executor(\n            None,\n            lambda: run_and_attach_otel_context(\n                lambda: Synapse.get_client(\n                    synapse_client=synapse_client\n                ).setPermissions(\n                    entity=self.id,\n                    principalId=principal_id,\n                    accessType=access_type,\n                    modify_benefactor=modify_benefactor,\n                    warn_if_inherits=warn_if_inherits,\n                    overwrite=overwrite,\n                ),\n                current_context,\n            ),\n        )\n</code></pre>"},{"location":"reference/oop/models/#synapseclient.models.mixins.AccessControllable-attributes","title":"Attributes","text":""},{"location":"reference/oop/models/#synapseclient.models.mixins.AccessControllable.id","title":"<code>id: Optional[str] = None</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The unique immutable ID for this entity. A new ID will be generated for new Files. Once issued, this ID is guaranteed to never change or be re-issued.</p>"},{"location":"reference/oop/models/#synapseclient.models.mixins.AccessControllable-functions","title":"Functions","text":""},{"location":"reference/oop/models/#synapseclient.models.mixins.AccessControllable.get_permissions_async","title":"<code>get_permissions_async(*, synapse_client=None)</code>  <code>async</code>","text":"<p>Get the permissions that the caller has on an Entity.</p> PARAMETER DESCRIPTION <code>synapse_client</code> <p>If not passed in or None this will use the last client from the <code>.login()</code> method.</p> <p> TYPE: <code>Optional[Synapse]</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>Permissions</code> <p>A Permissions object</p> Using this function: <p>Getting permissions for a Synapse Entity</p> <pre><code>permissions = await File(id=\"syn123\").get_permissions_async()\n</code></pre> <p>Getting access types list from the Permissions object</p> <pre><code>permissions.access_types\n</code></pre> Source code in <code>synapseclient/models/mixins/access_control.py</code> <pre><code>async def get_permissions_async(\n    self,\n    *,\n    synapse_client: Optional[Synapse] = None,\n) -&gt; \"Permissions\":\n    \"\"\"\n    Get the [permissions][synapseclient.core.models.permission.Permissions]\n    that the caller has on an Entity.\n\n    Arguments:\n        synapse_client: If not passed in or None this will use the last client\n            from the `.login()` method.\n\n    Returns:\n        A Permissions object\n\n\n    Example: Using this function:\n        Getting permissions for a Synapse Entity\n\n            permissions = await File(id=\"syn123\").get_permissions_async()\n\n        Getting access types list from the Permissions object\n\n            permissions.access_types\n    \"\"\"\n    loop = asyncio.get_event_loop()\n    current_context = context.get_current()\n\n    return await loop.run_in_executor(\n        None,\n        lambda: run_and_attach_otel_context(\n            lambda: Synapse.get_client(\n                synapse_client=synapse_client\n            ).get_permissions(entity=self.id),\n            current_context,\n        ),\n    )\n</code></pre>"},{"location":"reference/oop/models/#synapseclient.models.mixins.AccessControllable.get_acl_async","title":"<code>get_acl_async(principal_id=None, *, synapse_client=None)</code>  <code>async</code>","text":"<p>Get the ACL that a user or group has on an Entity.</p> PARAMETER DESCRIPTION <code>principal_id</code> <p>Identifier of a user or group (defaults to PUBLIC users)</p> <p> TYPE: <code>int</code> DEFAULT: <code>None</code> </p> <code>synapse_client</code> <p>If not passed in or None this will use the last client from the <code>.login()</code> method.</p> <p> TYPE: <code>Optional[Synapse]</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>List[str]</code> <p>An array containing some combination of ['READ', 'UPDATE', 'CREATE', 'DELETE', 'DOWNLOAD', 'MODERATE', 'CHANGE_PERMISSIONS', 'CHANGE_SETTINGS'] or an empty array</p> Source code in <code>synapseclient/models/mixins/access_control.py</code> <pre><code>async def get_acl_async(\n    self, principal_id: int = None, *, synapse_client: Optional[Synapse] = None\n) -&gt; List[str]:\n    \"\"\"\n    Get the [ACL][synapseclient.core.models.permission.Permissions.access_types]\n    that a user or group has on an Entity.\n\n    Arguments:\n        principal_id: Identifier of a user or group (defaults to PUBLIC users)\n        synapse_client: If not passed in or None this will use the last client\n            from the `.login()` method.\n\n    Returns:\n        An array containing some combination of\n            ['READ', 'UPDATE', 'CREATE', 'DELETE', 'DOWNLOAD', 'MODERATE',\n            'CHANGE_PERMISSIONS', 'CHANGE_SETTINGS']\n            or an empty array\n    \"\"\"\n    loop = asyncio.get_event_loop()\n    current_context = context.get_current()\n\n    return await loop.run_in_executor(\n        None,\n        lambda: run_and_attach_otel_context(\n            lambda: Synapse.get_client(synapse_client=synapse_client).get_acl(\n                entity=self.id, principal_id=principal_id\n            ),\n            current_context,\n        ),\n    )\n</code></pre>"},{"location":"reference/oop/models/#synapseclient.models.mixins.AccessControllable.set_permissions_async","title":"<code>set_permissions_async(principal_id=None, access_type=None, modify_benefactor=False, warn_if_inherits=True, overwrite=True, *, synapse_client=None)</code>  <code>async</code>","text":"<p>Sets permission that a user or group has on an Entity. An Entity may have its own ACL or inherit its ACL from a benefactor.</p> PARAMETER DESCRIPTION <code>principal_id</code> <p>Identifier of a user or group. <code>273948</code> is for all registered Synapse users and <code>273949</code> is for public access. None implies public access.</p> <p> TYPE: <code>int</code> DEFAULT: <code>None</code> </p> <code>access_type</code> <p>Type of permission to be granted. One or more of CREATE, READ, DOWNLOAD, UPDATE, DELETE, CHANGE_PERMISSIONS.</p> <p>Defaults to ['READ', 'DOWNLOAD']</p> <p> TYPE: <code>List[str]</code> DEFAULT: <code>None</code> </p> <code>modify_benefactor</code> <p>Set as True when modifying a benefactor's ACL</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>warn_if_inherits</code> <p>Set as False, when creating a new ACL. Trying to modify the ACL of an Entity that inherits its ACL will result in a warning</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> <code>overwrite</code> <p>By default this function overwrites existing permissions for the specified user. Set this flag to False to add new permissions non-destructively.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> <code>synapse_client</code> <p>If not passed in or None this will use the last client from the <code>.login()</code> method.</p> <p> TYPE: <code>Optional[Synapse]</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>Dict[str, Union[str, list]]</code> <p>An Access Control List object</p> Setting permissions <p>Grant all registered users download access</p> <pre><code>await File(id=\"syn123\").set_permissions_async(principal_id=273948, access_type=['READ','DOWNLOAD'])\n</code></pre> <p>Grant the public view access</p> <pre><code>await File(id=\"syn123\").set_permissions_async(principal_id=273949, access_type=['READ'])\n</code></pre> Source code in <code>synapseclient/models/mixins/access_control.py</code> <pre><code>async def set_permissions_async(\n    self,\n    principal_id: int = None,\n    access_type: List[str] = None,\n    modify_benefactor: bool = False,\n    warn_if_inherits: bool = True,\n    overwrite: bool = True,\n    *,\n    synapse_client: Optional[Synapse] = None,\n) -&gt; Dict[str, Union[str, list]]:\n    \"\"\"\n    Sets permission that a user or group has on an Entity.\n    An Entity may have its own ACL or inherit its ACL from a benefactor.\n\n    Arguments:\n        principal_id: Identifier of a user or group. `273948` is for all\n            registered Synapse users and `273949` is for public access.\n            None implies public access.\n        access_type: Type of permission to be granted. One or more of CREATE,\n            READ, DOWNLOAD, UPDATE, DELETE, CHANGE_PERMISSIONS.\n\n            **Defaults to ['READ', 'DOWNLOAD']**\n        modify_benefactor: Set as True when modifying a benefactor's ACL\n        warn_if_inherits: Set as False, when creating a new ACL. Trying to modify\n            the ACL of an Entity that inherits its ACL will result in a warning\n        overwrite: By default this function overwrites existing permissions for\n            the specified user. Set this flag to False to add new permissions\n            non-destructively.\n        synapse_client: If not passed in or None this will use the last client\n            from the `.login()` method.\n\n    Returns:\n        An Access Control List object\n\n    Example: Setting permissions\n        Grant all registered users download access\n\n            await File(id=\"syn123\").set_permissions_async(principal_id=273948, access_type=['READ','DOWNLOAD'])\n\n        Grant the public view access\n\n            await File(id=\"syn123\").set_permissions_async(principal_id=273949, access_type=['READ'])\n    \"\"\"\n    if access_type is None:\n        access_type = [\"READ\", \"DOWNLOAD\"]\n    loop = asyncio.get_event_loop()\n    current_context = context.get_current()\n\n    return await loop.run_in_executor(\n        None,\n        lambda: run_and_attach_otel_context(\n            lambda: Synapse.get_client(\n                synapse_client=synapse_client\n            ).setPermissions(\n                entity=self.id,\n                principalId=principal_id,\n                accessType=access_type,\n                modify_benefactor=modify_benefactor,\n                warn_if_inherits=warn_if_inherits,\n                overwrite=overwrite,\n            ),\n            current_context,\n        ),\n    )\n</code></pre>"},{"location":"reference/oop/models/#synapseclient.models.mixins.StorableContainer","title":"<code>synapseclient.models.mixins.StorableContainer</code>","text":"<p>               Bases: <code>StorableContainerSynchronousProtocol</code></p> <p>Mixin for objects that can have Folders and Files stored in them.</p> <p>In order to use this mixin, the class must have the following attributes:</p> <ul> <li><code>id</code></li> <li><code>files</code></li> <li><code>folders</code></li> <li><code>_last_persistent_instance</code></li> </ul> <p>The class must have the following method:</p> <ul> <li><code>get</code></li> </ul> Source code in <code>synapseclient/models/mixins/storable_container.py</code> <pre><code>@async_to_sync\nclass StorableContainer(StorableContainerSynchronousProtocol):\n    \"\"\"\n    Mixin for objects that can have Folders and Files stored in them.\n\n    In order to use this mixin, the class must have the following attributes:\n\n    - `id`\n    - `files`\n    - `folders`\n    - `_last_persistent_instance`\n\n    The class must have the following method:\n\n    - `get`\n    \"\"\"\n\n    id: None = None\n    name: None = None\n    files: \"File\" = None\n    folders: \"Folder\" = None\n    _last_persistent_instance: None = None\n\n    async def get_async(self, *, synapse_client: Optional[Synapse] = None) -&gt; None:\n        \"\"\"Used to satisfy the usage in this mixin from the parent class.\"\"\"\n\n    @otel_trace_method(\n        method_to_trace_name=lambda self, **kwargs: f\"{self.__class__.__name__}_sync_from_synapse: {self.id}\"\n    )\n    async def sync_from_synapse_async(\n        self: Self,\n        path: Optional[str] = None,\n        recursive: bool = True,\n        download_file: bool = True,\n        if_collision: str = COLLISION_OVERWRITE_LOCAL,\n        failure_strategy: FailureStrategy = FailureStrategy.LOG_EXCEPTION,\n        include_activity: bool = True,\n        follow_link: bool = False,\n        link_hops: int = 1,\n        *,\n        synapse_client: Optional[Synapse] = None,\n    ) -&gt; Self:\n        \"\"\"\n        Sync this container and all possible sub-folders from Synapse. By default this\n        will download the files that are found and it will populate the\n        `files` and `folders` attributes with the found files and folders. If you only\n        want to retrieve the full tree of metadata about your container specify\n        `download_file` as False.\n\n        This works similar to [synapseutils.syncFromSynapse][], however, this does not\n        currently support the writing of data to a manifest TSV file. This will be a\n        future enhancement.\n\n        Only Files and Folders are supported at this time to be synced from synapse.\n\n        Arguments:\n            path: An optional path where the file hierarchy will be reproduced. If not\n                specified the files will by default be placed in the synapseCache.\n            recursive: Whether or not to recursively get the entire hierarchy of the\n                folder and sub-folders.\n            download_file: Whether to download the files found or not.\n            if_collision: Determines how to handle file collisions. May be\n\n                - `overwrite.local`\n                - `keep.local`\n                - `keep.both`\n            failure_strategy: Determines how to handle failures when retrieving children\n                under this Folder and an exception occurs.\n            include_activity: Whether to include the activity of the files.\n            follow_link: Whether to follow a link entity or not. Links can be used to\n                point at other Synapse entities.\n            link_hops: The number of hops to follow the link. A number of 1 is used to\n                prevent circular references. There is nothing in place to prevent\n                infinite loops. Be careful if setting this above 1.\n            synapse_client: If not passed in or None this will use the last client from\n                the `.login()` method.\n\n        Returns:\n            The object that was called on. This will be the same object that was called on\n                to start the sync.\n\n        Example: Using this function\n            Suppose I want to walk the immediate children of a folder without downloading the files:\n\n                from synapseclient import Synapse\n                from synapseclient.models import Folder\n\n                syn = Synapse()\n                syn.login()\n\n                my_folder = Folder(id=\"syn12345\")\n                await my_folder.sync_from_synapse_async(download_file=False, recursive=False)\n\n                for folder in my_folder.folders:\n                    print(folder.name)\n\n                for file in my_folder.files:\n                    print(file.name)\n\n            Suppose I want to download the immediate children of a folder:\n\n                from synapseclient import Synapse\n                from synapseclient.models import Folder\n\n                syn = Synapse()\n                syn.login()\n\n                my_folder = Folder(id=\"syn12345\")\n                await my_folder.sync_from_synapse_async(path=\"/path/to/folder\", recursive=False)\n\n                for folder in my_folder.folders:\n                    print(folder.name)\n\n                for file in my_folder.files:\n                    print(file.name)\n\n\n            Suppose I want to download the immediate all children of a Project and all sub-folders and files:\n\n                from synapseclient import Synapse\n                from synapseclient.models import Project\n\n                syn = Synapse()\n                syn.login()\n\n                my_project = Project(id=\"syn12345\")\n                await my_project.sync_from_synapse_async(path=\"/path/to/folder\")\n\n\n        Raises:\n            ValueError: If the folder does not have an id set.\n\n\n        A sequence diagram for this method is as follows:\n\n        ```mermaid\n        sequenceDiagram\n            autonumber\n            participant project_or_folder\n            activate project_or_folder\n            project_or_folder-&gt;&gt;sync_from_synapse: Recursive search and download files\n            activate sync_from_synapse\n                opt Current instance not retrieved from Synapse\n                    sync_from_synapse-&gt;&gt;project_or_folder: Call `.get()` method\n                    project_or_folder--&gt;&gt;sync_from_synapse: .\n                end\n\n                loop For each return of the generator\n                    sync_from_synapse-&gt;&gt;client: call `.getChildren()` method\n                    client--&gt;&gt;sync_from_synapse: .\n                    note over sync_from_synapse: Append to a running list\n                end\n\n                loop For each child\n                    note over sync_from_synapse: Create all `pending_tasks` at current depth\n\n                    alt Child is File\n                        note over sync_from_synapse: Append `file.get()` method\n                    else Child is Folder\n                        note over sync_from_synapse: Append `folder.get()` method\n                        alt Recursive is True\n                            note over sync_from_synapse: Append `folder.sync_from_synapse()` method\n                        end\n                    else Child is Link and hops &gt; 0\n                        note over sync_from_synapse: Append task to follow link\n                    end\n                end\n\n                loop For each task in pending_tasks\n                    par `file.get()`\n                        sync_from_synapse-&gt;&gt;File: Retrieve File metadata and Optionally download\n                        File-&gt;&gt;client: `.get()`\n                        client--&gt;&gt;File: .\n                        File--&gt;&gt;sync_from_synapse: .\n                    and `folder.get()`\n                        sync_from_synapse-&gt;&gt;Folder: Retrieve Folder metadataa\n                        Folder-&gt;&gt;client: `.get()`\n                        client--&gt;&gt;Folder: .\n                        Folder--&gt;&gt;sync_from_synapse: .\n                    and `folder.sync_from_synapse_async()`\n                        note over sync_from_synapse: This is a recursive call to `sync_from_synapse`\n                        sync_from_synapse-&gt;&gt;sync_from_synapse: Recursive call to `.sync_from_synapse_async()`\n                    and `_follow_link`\n                        sync_from_synapse -&gt;&gt;client: call `get_entity_id_bundle2` function\n                        client--&gt;sync_from_synapse: .\n                        note over sync_from_synapse: Do nothing if not link\n                        note over sync_from_synapse: call `_create_task_for_child` and execute\n                    end\n                end\n\n            deactivate sync_from_synapse\n            deactivate project_or_folder\n        ```\n\n        \"\"\"\n        if not self._last_persistent_instance:\n            await self.get_async(synapse_client=synapse_client)\n        Synapse.get_client(synapse_client=synapse_client).logger.info(\n            f\"Syncing {self.__class__.__name__} ({self.id}:{self.name}) from Synapse.\"\n        )\n        path = os.path.expanduser(path) if path else None\n\n        loop = asyncio.get_event_loop()\n        current_context = context.get_current()\n        children = await loop.run_in_executor(\n            None,\n            lambda: run_and_attach_otel_context(\n                lambda: self._retrieve_children(\n                    follow_link=follow_link,\n                    synapse_client=synapse_client,\n                ),\n                current_context,\n            ),\n        )\n\n        pending_tasks = []\n        self.folders = []\n        self.files = []\n\n        for child in children:\n            pending_tasks.extend(\n                self._create_task_for_child(\n                    child=child,\n                    recursive=recursive,\n                    path=path,\n                    download_file=download_file,\n                    if_collision=if_collision,\n                    failure_strategy=failure_strategy,\n                    synapse_client=synapse_client,\n                    include_activity=include_activity,\n                    follow_link=follow_link,\n                    link_hops=link_hops,\n                )\n            )\n\n        for task in asyncio.as_completed(pending_tasks):\n            result = await task\n            self._resolve_sync_from_synapse_result(\n                result=result,\n                failure_strategy=failure_strategy,\n                synapse_client=synapse_client,\n            )\n        return self\n\n    def flatten_file_list(self) -&gt; List[\"File\"]:\n        \"\"\"\n        Recursively loop over all of the already retrieved files and folders and return\n        a list of all files in the container.\n\n        Returns:\n            A list of all files in the container.\n        \"\"\"\n        files = []\n        for file in self.files:\n            files.append(file)\n        for folder in self.folders:\n            files.extend(folder.flatten_file_list())\n        return files\n\n    def map_directory_to_all_contained_files(\n        self, root_path: str\n    ) -&gt; Dict[str, List[\"File\"]]:\n        \"\"\"\n        Recursively loop over all of the already retrieved files and folders. Then\n        return back a dictionary where the key is the path to the directory at each\n        level. The value is a list of all files in that directory AND all files in\n        the child directories.\n\n        This is used during the creation of the manifest TSV file during the\n        syncFromSynapse utility function.\n\n        Example: Using this function\n           Returning back a dict with 2 keys:\n\n                Given:\n                root_folder\n                \u251c\u2500\u2500 sub_folder\n                \u2502   \u251c\u2500\u2500 file1.txt\n                \u2502   \u2514\u2500\u2500 file2.txt\n\n                Returns:\n                {\n                    \"root_folder\": [file1, file2],\n                    \"root_folder/sub_folder\": [file1, file2]\n                }\n\n\n           Returning back a dict with 3 keys:\n\n                Given:\n                root_folder\n                \u251c\u2500\u2500 sub_folder_1\n                \u2502   \u251c\u2500\u2500 file1.txt\n                \u251c\u2500\u2500 sub_folder_2\n                \u2502   \u2514\u2500\u2500 file2.txt\n\n                Returns:\n                {\n                    \"root_folder\": [file1, file2],\n                    \"root_folder/sub_folder_1\": [file1]\n                    \"root_folder/sub_folder_2\": [file2]\n                }\n\n        Arguments:\n            root_path: The root path where the top level files are stored.\n\n        Returns:\n            A dictionary where the key is the path to the directory at each level. The\n                value is a list of all files in that directory AND all files in the child\n                directories.\n        \"\"\"\n        directory_map = {}\n        directory_map.update({root_path: self.flatten_file_list()})\n\n        for folder in self.folders:\n            directory_map.update(\n                **folder.map_directory_to_all_contained_files(\n                    root_path=os.path.join(root_path, folder.name)\n                )\n            )\n\n        return directory_map\n\n    def _retrieve_children(\n        self,\n        follow_link: bool,\n        *,\n        synapse_client: Optional[Synapse] = None,\n    ) -&gt; List:\n        \"\"\"\n        This wraps the `getChildren` generator to return back a list of children.\n\n        Arguments:\n            follow_link: Whether to follow a link entity or not. Links can be used to\n                point at other Synapse entities.\n            synapse_client: If not passed in or None this will use the last client from\n                the `.login()` method.\n        \"\"\"\n        include_types = [\"folder\", \"file\"]\n        if follow_link:\n            include_types.append(\"link\")\n        children_objects = Synapse.get_client(\n            synapse_client=synapse_client\n        ).getChildren(\n            parent=self.id,\n            includeTypes=include_types,\n        )\n        children = []\n        for child in children_objects:\n            children.append(child)\n        return children\n\n    async def _wrap_recursive_get_children(\n        self,\n        folder: \"Folder\",\n        recursive: bool = False,\n        path: Optional[str] = None,\n        download_file: bool = False,\n        if_collision: str = COLLISION_OVERWRITE_LOCAL,\n        failure_strategy: FailureStrategy = FailureStrategy.LOG_EXCEPTION,\n        include_activity: bool = True,\n        follow_link: bool = False,\n        link_hops: int = 1,\n        *,\n        synapse_client: Optional[Synapse] = None,\n    ) -&gt; None:\n        \"\"\"\n        Wrap the recursive get children method to return nothing. We are updating\n        the folder object in place. We do not want to cause the result of this\n        method to cause any folder of file objects to be added to this level of the\n        hierarchy.\n        \"\"\"\n        new_resolved_path = (\n            os.path.join(path, folder.name) if path and folder.name else None\n        )\n        if new_resolved_path and not os.path.exists(new_resolved_path):\n            os.makedirs(new_resolved_path)\n        await folder.sync_from_synapse_async(\n            recursive=recursive,\n            download_file=download_file,\n            path=new_resolved_path,\n            if_collision=if_collision,\n            failure_strategy=failure_strategy,\n            include_activity=include_activity,\n            follow_link=follow_link,\n            link_hops=link_hops,\n            synapse_client=synapse_client,\n        )\n\n    def _create_task_for_child(\n        self,\n        child,\n        recursive: bool = False,\n        path: Optional[str] = None,\n        download_file: bool = False,\n        if_collision: str = COLLISION_OVERWRITE_LOCAL,\n        failure_strategy: FailureStrategy = FailureStrategy.LOG_EXCEPTION,\n        include_activity: bool = True,\n        follow_link: bool = False,\n        link_hops: int = 1,\n        *,\n        synapse_client: Optional[Synapse] = None,\n    ) -&gt; List[asyncio.Task]:\n        \"\"\"\n        Determines based off the type of child which tasks should be created to handle\n        the child. This will return a list of tasks that will be executed in parallel\n        to handle the child. The tasks will retrieve the File and Folder objects from\n        Synapse. In the case of a Folder object, it will also retrieve the children of\n        that folder if `recursive` is set to True.\n\n\n        Arguments:\n            recursive: Whether or not to recursively get the entire hierarchy of the\n                folder and sub-folders.\n            download_file: Whether to download the files found or not.\n            path: An optional path where the file hierarchy will be reproduced. If not\n                specified the files will by default be placed in the synapseCache.\n            if_collision: Determines how to handle file collisions. May be\n\n                - `overwrite.local`\n                - `keep.local`\n                - `keep.both`\n            failure_strategy: Determines how to handle failures when retrieving children\n                under this Folder and an exception occurs.\n            include_activity: Whether to include the activity of the files.\n            follow_link: Whether to follow a link entity or not. Links can be used to\n                point at other Synapse entities.\n            link_hops: The number of hops to follow the link. A number of 1 is used to\n                prevent circular references. There is nothing in place to prevent\n                infinite loops. Be careful if setting this above 1.\n            synapse_client: If not passed in or None this will use the last client from\n                the `.login()` method.\n\n        \"\"\"\n\n        pending_tasks = []\n        synapse_id = child.get(\"id\", None)\n        child_type = child.get(\"type\", None)\n        name = child.get(\"name\", None)\n        if synapse_id and child_type == FOLDER_ENTITY:\n            # Lazy import to avoid circular import\n            from synapseclient.models import Folder\n\n            folder = Folder(id=synapse_id, name=name)\n            self.folders.append(folder)\n\n            if recursive:\n                pending_tasks.append(\n                    asyncio.create_task(\n                        self._wrap_recursive_get_children(\n                            folder=folder,\n                            recursive=recursive,\n                            path=path,\n                            download_file=download_file,\n                            if_collision=if_collision,\n                            failure_strategy=failure_strategy,\n                            include_activity=include_activity,\n                            follow_link=follow_link,\n                            link_hops=link_hops,\n                            synapse_client=synapse_client,\n                        )\n                    )\n                )\n            else:\n                pending_tasks.append(\n                    asyncio.create_task(wrap_coroutine(folder.get_async()))\n                )\n\n        elif synapse_id and child_type == FILE_ENTITY:\n            # Lazy import to avoid circular import\n            from synapseclient.models import File\n\n            file = File(id=synapse_id, name=name, download_file=download_file)\n            self.files.append(file)\n            if path:\n                file.download_location = path\n            if if_collision:\n                file.if_collision = if_collision\n\n            pending_tasks.append(\n                asyncio.create_task(\n                    wrap_coroutine(file.get_async(include_activity=include_activity))\n                )\n            )\n        elif link_hops &gt; 0 and synapse_id and child_type == LINK_ENTITY:\n            pending_tasks.append(\n                asyncio.create_task(\n                    wrap_coroutine(\n                        self._follow_link(\n                            child=child,\n                            recursive=recursive,\n                            path=path,\n                            download_file=download_file,\n                            if_collision=if_collision,\n                            failure_strategy=failure_strategy,\n                            synapse_client=synapse_client,\n                            include_activity=include_activity,\n                            follow_link=follow_link,\n                            link_hops=link_hops - 1,\n                        )\n                    )\n                )\n            )\n\n        return pending_tasks\n\n    async def _follow_link(\n        self,\n        child,\n        recursive: bool = False,\n        path: Optional[str] = None,\n        download_file: bool = False,\n        if_collision: str = COLLISION_OVERWRITE_LOCAL,\n        failure_strategy: FailureStrategy = FailureStrategy.LOG_EXCEPTION,\n        include_activity: bool = True,\n        follow_link: bool = False,\n        link_hops: int = 0,\n        *,\n        synapse_client: Optional[Synapse] = None,\n    ) -&gt; None:\n        \"\"\"Follow a link to get a target entity.\n\n        Arguments in this function are all supplied in order to recursively traverse\n        the container hierarchy.\n\n        Returns:\n            None\n        \"\"\"\n\n        synapse_id = child.get(\"id\", None)\n        # TODO: Until Link is an official Model dataclass this logic will suffice for\n        # the purpose of following a link to potentially download a File or open another\n        # Folder.\n        entity_bundle = await get_entity_id_bundle2(\n            entity_id=synapse_id,\n            request={\"includeEntity\": True},\n            synapse_client=synapse_client,\n        )\n\n        if (\n            entity_bundle is None\n            or not (entity := entity_bundle.get(\"entity\", None))\n            or not (links_to := entity.get(\"linksTo\", None))\n            or not (link_class_name := entity.get(\"linksToClassName\", None))\n            or not (link_target_id := links_to.get(\"targetId\", None))\n        ):\n            return\n\n        pending_tasks = self._create_task_for_child(\n            child={\n                \"id\": link_target_id,\n                \"type\": link_class_name,\n            },\n            recursive=recursive,\n            path=path,\n            download_file=download_file,\n            if_collision=if_collision,\n            failure_strategy=failure_strategy,\n            include_activity=include_activity,\n            follow_link=follow_link,\n            link_hops=link_hops,\n            synapse_client=synapse_client,\n        )\n        for task in asyncio.as_completed(pending_tasks):\n            result = await task\n            self._resolve_sync_from_synapse_result(\n                result=result,\n                failure_strategy=failure_strategy,\n                synapse_client=synapse_client,\n            )\n\n    def _resolve_sync_from_synapse_result(\n        self,\n        result: Union[None, \"Folder\", \"File\", BaseException],\n        failure_strategy: FailureStrategy,\n        *,\n        synapse_client: Union[None, Synapse],\n    ) -&gt; None:\n        \"\"\"\n        Handle what to do based on what was returned from the latest task to complete.\n        We are updating the object in place and appending the returned Folder/Files to\n        the appropriate list.\n\n        Arguments:\n            result: The result of the task that was completed.\n            failure_strategy: Determines how to handle failures when retrieving children\n                under this Folder and an exception occurs.\n            synapse_client: If not passed in or None this will use the last client from\n                the `.login()` method.\n        \"\"\"\n        if result is None:\n            # We will recieve None when executing `_wrap_recursive_get_children` as\n            # it will internally be recursively calling this method and setting the\n            # appropriate folder/file objects in place.\n            pass\n        elif (\n            result.__class__.__name__ == \"Folder\" or result.__class__.__name__ == \"File\"\n        ):\n            # Do nothing as the objects are updated in place and the container has\n            # already been updated to append the new objects.\n            pass\n        elif isinstance(result, BaseException):\n            Synapse.get_client(synapse_client=synapse_client).logger.exception(result)\n\n            if failure_strategy == FailureStrategy.RAISE_EXCEPTION:\n                raise result\n        else:\n            exception = SynapseError(\n                f\"Unknown failure retrieving children of Folder ({self.id}): {type(result)}\",\n                result,\n            )\n            Synapse.get_client(synapse_client=synapse_client).logger.exception(\n                exception\n            )\n            if failure_strategy == FailureStrategy.RAISE_EXCEPTION:\n                raise exception\n</code></pre>"},{"location":"reference/oop/models/#synapseclient.models.mixins.StorableContainer-functions","title":"Functions","text":""},{"location":"reference/oop/models/#synapseclient.models.mixins.StorableContainer.get_async","title":"<code>get_async(*, synapse_client=None)</code>  <code>async</code>","text":"<p>Used to satisfy the usage in this mixin from the parent class.</p> Source code in <code>synapseclient/models/mixins/storable_container.py</code> <pre><code>async def get_async(self, *, synapse_client: Optional[Synapse] = None) -&gt; None:\n    \"\"\"Used to satisfy the usage in this mixin from the parent class.\"\"\"\n</code></pre>"},{"location":"reference/oop/models/#synapseclient.models.mixins.StorableContainer.sync_from_synapse_async","title":"<code>sync_from_synapse_async(path=None, recursive=True, download_file=True, if_collision=COLLISION_OVERWRITE_LOCAL, failure_strategy=FailureStrategy.LOG_EXCEPTION, include_activity=True, follow_link=False, link_hops=1, *, synapse_client=None)</code>  <code>async</code>","text":"<p>Sync this container and all possible sub-folders from Synapse. By default this will download the files that are found and it will populate the <code>files</code> and <code>folders</code> attributes with the found files and folders. If you only want to retrieve the full tree of metadata about your container specify <code>download_file</code> as False.</p> <p>This works similar to synapseutils.syncFromSynapse, however, this does not currently support the writing of data to a manifest TSV file. This will be a future enhancement.</p> <p>Only Files and Folders are supported at this time to be synced from synapse.</p> PARAMETER DESCRIPTION <code>path</code> <p>An optional path where the file hierarchy will be reproduced. If not specified the files will by default be placed in the synapseCache.</p> <p> TYPE: <code>Optional[str]</code> DEFAULT: <code>None</code> </p> <code>recursive</code> <p>Whether or not to recursively get the entire hierarchy of the folder and sub-folders.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> <code>download_file</code> <p>Whether to download the files found or not.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> <code>if_collision</code> <p>Determines how to handle file collisions. May be</p> <ul> <li><code>overwrite.local</code></li> <li><code>keep.local</code></li> <li><code>keep.both</code></li> </ul> <p> TYPE: <code>str</code> DEFAULT: <code>COLLISION_OVERWRITE_LOCAL</code> </p> <code>failure_strategy</code> <p>Determines how to handle failures when retrieving children under this Folder and an exception occurs.</p> <p> TYPE: <code>FailureStrategy</code> DEFAULT: <code>LOG_EXCEPTION</code> </p> <code>include_activity</code> <p>Whether to include the activity of the files.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> <code>follow_link</code> <p>Whether to follow a link entity or not. Links can be used to point at other Synapse entities.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>link_hops</code> <p>The number of hops to follow the link. A number of 1 is used to prevent circular references. There is nothing in place to prevent infinite loops. Be careful if setting this above 1.</p> <p> TYPE: <code>int</code> DEFAULT: <code>1</code> </p> <code>synapse_client</code> <p>If not passed in or None this will use the last client from the <code>.login()</code> method.</p> <p> TYPE: <code>Optional[Synapse]</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>Self</code> <p>The object that was called on. This will be the same object that was called on to start the sync.</p> Using this function <p>Suppose I want to walk the immediate children of a folder without downloading the files:</p> <pre><code>from synapseclient import Synapse\nfrom synapseclient.models import Folder\n\nsyn = Synapse()\nsyn.login()\n\nmy_folder = Folder(id=\"syn12345\")\nawait my_folder.sync_from_synapse_async(download_file=False, recursive=False)\n\nfor folder in my_folder.folders:\n    print(folder.name)\n\nfor file in my_folder.files:\n    print(file.name)\n</code></pre> <p>Suppose I want to download the immediate children of a folder:</p> <pre><code>from synapseclient import Synapse\nfrom synapseclient.models import Folder\n\nsyn = Synapse()\nsyn.login()\n\nmy_folder = Folder(id=\"syn12345\")\nawait my_folder.sync_from_synapse_async(path=\"/path/to/folder\", recursive=False)\n\nfor folder in my_folder.folders:\n    print(folder.name)\n\nfor file in my_folder.files:\n    print(file.name)\n</code></pre> <p>Suppose I want to download the immediate all children of a Project and all sub-folders and files:</p> <pre><code>from synapseclient import Synapse\nfrom synapseclient.models import Project\n\nsyn = Synapse()\nsyn.login()\n\nmy_project = Project(id=\"syn12345\")\nawait my_project.sync_from_synapse_async(path=\"/path/to/folder\")\n</code></pre> RAISES DESCRIPTION <code>ValueError</code> <p>If the folder does not have an id set.</p> <p>A sequence diagram for this method is as follows:</p> <pre><code>sequenceDiagram\n    autonumber\n    participant project_or_folder\n    activate project_or_folder\n    project_or_folder-&gt;&gt;sync_from_synapse: Recursive search and download files\n    activate sync_from_synapse\n        opt Current instance not retrieved from Synapse\n            sync_from_synapse-&gt;&gt;project_or_folder: Call `.get()` method\n            project_or_folder--&gt;&gt;sync_from_synapse: .\n        end\n\n        loop For each return of the generator\n            sync_from_synapse-&gt;&gt;client: call `.getChildren()` method\n            client--&gt;&gt;sync_from_synapse: .\n            note over sync_from_synapse: Append to a running list\n        end\n\n        loop For each child\n            note over sync_from_synapse: Create all `pending_tasks` at current depth\n\n            alt Child is File\n                note over sync_from_synapse: Append `file.get()` method\n            else Child is Folder\n                note over sync_from_synapse: Append `folder.get()` method\n                alt Recursive is True\n                    note over sync_from_synapse: Append `folder.sync_from_synapse()` method\n                end\n            else Child is Link and hops &gt; 0\n                note over sync_from_synapse: Append task to follow link\n            end\n        end\n\n        loop For each task in pending_tasks\n            par `file.get()`\n                sync_from_synapse-&gt;&gt;File: Retrieve File metadata and Optionally download\n                File-&gt;&gt;client: `.get()`\n                client--&gt;&gt;File: .\n                File--&gt;&gt;sync_from_synapse: .\n            and `folder.get()`\n                sync_from_synapse-&gt;&gt;Folder: Retrieve Folder metadataa\n                Folder-&gt;&gt;client: `.get()`\n                client--&gt;&gt;Folder: .\n                Folder--&gt;&gt;sync_from_synapse: .\n            and `folder.sync_from_synapse_async()`\n                note over sync_from_synapse: This is a recursive call to `sync_from_synapse`\n                sync_from_synapse-&gt;&gt;sync_from_synapse: Recursive call to `.sync_from_synapse_async()`\n            and `_follow_link`\n                sync_from_synapse -&gt;&gt;client: call `get_entity_id_bundle2` function\n                client--&gt;sync_from_synapse: .\n                note over sync_from_synapse: Do nothing if not link\n                note over sync_from_synapse: call `_create_task_for_child` and execute\n            end\n        end\n\n    deactivate sync_from_synapse\n    deactivate project_or_folder</code></pre> Source code in <code>synapseclient/models/mixins/storable_container.py</code> <pre><code>@otel_trace_method(\n    method_to_trace_name=lambda self, **kwargs: f\"{self.__class__.__name__}_sync_from_synapse: {self.id}\"\n)\nasync def sync_from_synapse_async(\n    self: Self,\n    path: Optional[str] = None,\n    recursive: bool = True,\n    download_file: bool = True,\n    if_collision: str = COLLISION_OVERWRITE_LOCAL,\n    failure_strategy: FailureStrategy = FailureStrategy.LOG_EXCEPTION,\n    include_activity: bool = True,\n    follow_link: bool = False,\n    link_hops: int = 1,\n    *,\n    synapse_client: Optional[Synapse] = None,\n) -&gt; Self:\n    \"\"\"\n    Sync this container and all possible sub-folders from Synapse. By default this\n    will download the files that are found and it will populate the\n    `files` and `folders` attributes with the found files and folders. If you only\n    want to retrieve the full tree of metadata about your container specify\n    `download_file` as False.\n\n    This works similar to [synapseutils.syncFromSynapse][], however, this does not\n    currently support the writing of data to a manifest TSV file. This will be a\n    future enhancement.\n\n    Only Files and Folders are supported at this time to be synced from synapse.\n\n    Arguments:\n        path: An optional path where the file hierarchy will be reproduced. If not\n            specified the files will by default be placed in the synapseCache.\n        recursive: Whether or not to recursively get the entire hierarchy of the\n            folder and sub-folders.\n        download_file: Whether to download the files found or not.\n        if_collision: Determines how to handle file collisions. May be\n\n            - `overwrite.local`\n            - `keep.local`\n            - `keep.both`\n        failure_strategy: Determines how to handle failures when retrieving children\n            under this Folder and an exception occurs.\n        include_activity: Whether to include the activity of the files.\n        follow_link: Whether to follow a link entity or not. Links can be used to\n            point at other Synapse entities.\n        link_hops: The number of hops to follow the link. A number of 1 is used to\n            prevent circular references. There is nothing in place to prevent\n            infinite loops. Be careful if setting this above 1.\n        synapse_client: If not passed in or None this will use the last client from\n            the `.login()` method.\n\n    Returns:\n        The object that was called on. This will be the same object that was called on\n            to start the sync.\n\n    Example: Using this function\n        Suppose I want to walk the immediate children of a folder without downloading the files:\n\n            from synapseclient import Synapse\n            from synapseclient.models import Folder\n\n            syn = Synapse()\n            syn.login()\n\n            my_folder = Folder(id=\"syn12345\")\n            await my_folder.sync_from_synapse_async(download_file=False, recursive=False)\n\n            for folder in my_folder.folders:\n                print(folder.name)\n\n            for file in my_folder.files:\n                print(file.name)\n\n        Suppose I want to download the immediate children of a folder:\n\n            from synapseclient import Synapse\n            from synapseclient.models import Folder\n\n            syn = Synapse()\n            syn.login()\n\n            my_folder = Folder(id=\"syn12345\")\n            await my_folder.sync_from_synapse_async(path=\"/path/to/folder\", recursive=False)\n\n            for folder in my_folder.folders:\n                print(folder.name)\n\n            for file in my_folder.files:\n                print(file.name)\n\n\n        Suppose I want to download the immediate all children of a Project and all sub-folders and files:\n\n            from synapseclient import Synapse\n            from synapseclient.models import Project\n\n            syn = Synapse()\n            syn.login()\n\n            my_project = Project(id=\"syn12345\")\n            await my_project.sync_from_synapse_async(path=\"/path/to/folder\")\n\n\n    Raises:\n        ValueError: If the folder does not have an id set.\n\n\n    A sequence diagram for this method is as follows:\n\n    ```mermaid\n    sequenceDiagram\n        autonumber\n        participant project_or_folder\n        activate project_or_folder\n        project_or_folder-&gt;&gt;sync_from_synapse: Recursive search and download files\n        activate sync_from_synapse\n            opt Current instance not retrieved from Synapse\n                sync_from_synapse-&gt;&gt;project_or_folder: Call `.get()` method\n                project_or_folder--&gt;&gt;sync_from_synapse: .\n            end\n\n            loop For each return of the generator\n                sync_from_synapse-&gt;&gt;client: call `.getChildren()` method\n                client--&gt;&gt;sync_from_synapse: .\n                note over sync_from_synapse: Append to a running list\n            end\n\n            loop For each child\n                note over sync_from_synapse: Create all `pending_tasks` at current depth\n\n                alt Child is File\n                    note over sync_from_synapse: Append `file.get()` method\n                else Child is Folder\n                    note over sync_from_synapse: Append `folder.get()` method\n                    alt Recursive is True\n                        note over sync_from_synapse: Append `folder.sync_from_synapse()` method\n                    end\n                else Child is Link and hops &gt; 0\n                    note over sync_from_synapse: Append task to follow link\n                end\n            end\n\n            loop For each task in pending_tasks\n                par `file.get()`\n                    sync_from_synapse-&gt;&gt;File: Retrieve File metadata and Optionally download\n                    File-&gt;&gt;client: `.get()`\n                    client--&gt;&gt;File: .\n                    File--&gt;&gt;sync_from_synapse: .\n                and `folder.get()`\n                    sync_from_synapse-&gt;&gt;Folder: Retrieve Folder metadataa\n                    Folder-&gt;&gt;client: `.get()`\n                    client--&gt;&gt;Folder: .\n                    Folder--&gt;&gt;sync_from_synapse: .\n                and `folder.sync_from_synapse_async()`\n                    note over sync_from_synapse: This is a recursive call to `sync_from_synapse`\n                    sync_from_synapse-&gt;&gt;sync_from_synapse: Recursive call to `.sync_from_synapse_async()`\n                and `_follow_link`\n                    sync_from_synapse -&gt;&gt;client: call `get_entity_id_bundle2` function\n                    client--&gt;sync_from_synapse: .\n                    note over sync_from_synapse: Do nothing if not link\n                    note over sync_from_synapse: call `_create_task_for_child` and execute\n                end\n            end\n\n        deactivate sync_from_synapse\n        deactivate project_or_folder\n    ```\n\n    \"\"\"\n    if not self._last_persistent_instance:\n        await self.get_async(synapse_client=synapse_client)\n    Synapse.get_client(synapse_client=synapse_client).logger.info(\n        f\"Syncing {self.__class__.__name__} ({self.id}:{self.name}) from Synapse.\"\n    )\n    path = os.path.expanduser(path) if path else None\n\n    loop = asyncio.get_event_loop()\n    current_context = context.get_current()\n    children = await loop.run_in_executor(\n        None,\n        lambda: run_and_attach_otel_context(\n            lambda: self._retrieve_children(\n                follow_link=follow_link,\n                synapse_client=synapse_client,\n            ),\n            current_context,\n        ),\n    )\n\n    pending_tasks = []\n    self.folders = []\n    self.files = []\n\n    for child in children:\n        pending_tasks.extend(\n            self._create_task_for_child(\n                child=child,\n                recursive=recursive,\n                path=path,\n                download_file=download_file,\n                if_collision=if_collision,\n                failure_strategy=failure_strategy,\n                synapse_client=synapse_client,\n                include_activity=include_activity,\n                follow_link=follow_link,\n                link_hops=link_hops,\n            )\n        )\n\n    for task in asyncio.as_completed(pending_tasks):\n        result = await task\n        self._resolve_sync_from_synapse_result(\n            result=result,\n            failure_strategy=failure_strategy,\n            synapse_client=synapse_client,\n        )\n    return self\n</code></pre>"},{"location":"reference/oop/models/#synapseclient.models.mixins.StorableContainer.flatten_file_list","title":"<code>flatten_file_list()</code>","text":"<p>Recursively loop over all of the already retrieved files and folders and return a list of all files in the container.</p> RETURNS DESCRIPTION <code>List[File]</code> <p>A list of all files in the container.</p> Source code in <code>synapseclient/models/mixins/storable_container.py</code> <pre><code>def flatten_file_list(self) -&gt; List[\"File\"]:\n    \"\"\"\n    Recursively loop over all of the already retrieved files and folders and return\n    a list of all files in the container.\n\n    Returns:\n        A list of all files in the container.\n    \"\"\"\n    files = []\n    for file in self.files:\n        files.append(file)\n    for folder in self.folders:\n        files.extend(folder.flatten_file_list())\n    return files\n</code></pre>"},{"location":"reference/oop/models/#synapseclient.models.mixins.StorableContainer.map_directory_to_all_contained_files","title":"<code>map_directory_to_all_contained_files(root_path)</code>","text":"<p>Recursively loop over all of the already retrieved files and folders. Then return back a dictionary where the key is the path to the directory at each level. The value is a list of all files in that directory AND all files in the child directories.</p> <p>This is used during the creation of the manifest TSV file during the syncFromSynapse utility function.</p> Using this function <p>Returning back a dict with 2 keys:</p> <pre><code> Given:\n root_folder\n \u251c\u2500\u2500 sub_folder\n \u2502   \u251c\u2500\u2500 file1.txt\n \u2502   \u2514\u2500\u2500 file2.txt\n\n Returns:\n {\n     \"root_folder\": [file1, file2],\n     \"root_folder/sub_folder\": [file1, file2]\n }\n</code></pre> <p>Returning back a dict with 3 keys:</p> <pre><code> Given:\n root_folder\n \u251c\u2500\u2500 sub_folder_1\n \u2502   \u251c\u2500\u2500 file1.txt\n \u251c\u2500\u2500 sub_folder_2\n \u2502   \u2514\u2500\u2500 file2.txt\n\n Returns:\n {\n     \"root_folder\": [file1, file2],\n     \"root_folder/sub_folder_1\": [file1]\n     \"root_folder/sub_folder_2\": [file2]\n }\n</code></pre> PARAMETER DESCRIPTION <code>root_path</code> <p>The root path where the top level files are stored.</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>Dict[str, List[File]]</code> <p>A dictionary where the key is the path to the directory at each level. The value is a list of all files in that directory AND all files in the child directories.</p> Source code in <code>synapseclient/models/mixins/storable_container.py</code> <pre><code>def map_directory_to_all_contained_files(\n    self, root_path: str\n) -&gt; Dict[str, List[\"File\"]]:\n    \"\"\"\n    Recursively loop over all of the already retrieved files and folders. Then\n    return back a dictionary where the key is the path to the directory at each\n    level. The value is a list of all files in that directory AND all files in\n    the child directories.\n\n    This is used during the creation of the manifest TSV file during the\n    syncFromSynapse utility function.\n\n    Example: Using this function\n       Returning back a dict with 2 keys:\n\n            Given:\n            root_folder\n            \u251c\u2500\u2500 sub_folder\n            \u2502   \u251c\u2500\u2500 file1.txt\n            \u2502   \u2514\u2500\u2500 file2.txt\n\n            Returns:\n            {\n                \"root_folder\": [file1, file2],\n                \"root_folder/sub_folder\": [file1, file2]\n            }\n\n\n       Returning back a dict with 3 keys:\n\n            Given:\n            root_folder\n            \u251c\u2500\u2500 sub_folder_1\n            \u2502   \u251c\u2500\u2500 file1.txt\n            \u251c\u2500\u2500 sub_folder_2\n            \u2502   \u2514\u2500\u2500 file2.txt\n\n            Returns:\n            {\n                \"root_folder\": [file1, file2],\n                \"root_folder/sub_folder_1\": [file1]\n                \"root_folder/sub_folder_2\": [file2]\n            }\n\n    Arguments:\n        root_path: The root path where the top level files are stored.\n\n    Returns:\n        A dictionary where the key is the path to the directory at each level. The\n            value is a list of all files in that directory AND all files in the child\n            directories.\n    \"\"\"\n    directory_map = {}\n    directory_map.update({root_path: self.flatten_file_list()})\n\n    for folder in self.folders:\n        directory_map.update(\n            **folder.map_directory_to_all_contained_files(\n                root_path=os.path.join(root_path, folder.name)\n            )\n        )\n\n    return directory_map\n</code></pre>"},{"location":"reference/oop/models/#synapseclient.models.FailureStrategy","title":"<code>synapseclient.models.FailureStrategy</code>","text":"<p>               Bases: <code>Enum</code></p> <p>When storing a large number of items through bulk actions like <code>Project(id=\"syn123\").store()</code> or <code>Folder(id=\"syn456\").store()</code> individual failures may occur. Passing this ENUM will allow you to define how you want to respond to failures.</p> Source code in <code>synapseclient/models/services/storable_entity_components.py</code> <pre><code>class FailureStrategy(Enum):\n    \"\"\"\n    When storing a large number of items through bulk actions like\n    `Project(id=\"syn123\").store()` or `Folder(id=\"syn456\").store()` individual failures\n    may occur. Passing this ENUM will allow you to define how you want to respond to\n    failures.\n    \"\"\"\n\n    RAISE_EXCEPTION = \"RAISE_EXCEPTION\"\n    \"\"\"An exception is raised on the first failure and all tasks yet to be completed\n    are cancelled. The exception will also be logged.\"\"\"\n\n    LOG_EXCEPTION = \"LOG_EXCEPTION\"\n    \"\"\"An exception is logged and all tasks yet to be completed continue to be\n    processed.\"\"\"\n</code></pre>"},{"location":"reference/oop/models/#synapseclient.models.FailureStrategy-attributes","title":"Attributes","text":""},{"location":"reference/oop/models/#synapseclient.models.FailureStrategy.RAISE_EXCEPTION","title":"<code>RAISE_EXCEPTION = 'RAISE_EXCEPTION'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>An exception is raised on the first failure and all tasks yet to be completed are cancelled. The exception will also be logged.</p>"},{"location":"reference/oop/models/#synapseclient.models.FailureStrategy.LOG_EXCEPTION","title":"<code>LOG_EXCEPTION = 'LOG_EXCEPTION'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>An exception is logged and all tasks yet to be completed continue to be processed.</p>"},{"location":"reference/oop/models_async/","title":"Async Object-Orientated Models","text":"<p>Contained within this file are experimental interfaces for working with the Synapse Python Client. Unless otherwise noted these interfaces are subject to change at any time. Use at your own risk.</p> <p>These APIs also introduce AsyncIO to the client.</p>"},{"location":"reference/oop/models_async/#sample-scripts","title":"Sample Scripts:","text":"<p>See this page for sample scripts. The sample scripts are from a synchronous context, replace any of the method calls with the async counter-party and they will be functionally equivalent.</p>"},{"location":"reference/oop/models_async/#api-reference","title":"API reference","text":""},{"location":"reference/oop/models_async/#synapseclient.models.Project","title":"<code>synapseclient.models.Project</code>  <code>dataclass</code>","text":"<p>               Bases: <code>ProjectSynchronousProtocol</code>, <code>AccessControllable</code>, <code>StorableContainer</code></p> <p>A Project is a top-level container for organizing data in Synapse.</p> ATTRIBUTE DESCRIPTION <code>id</code> <p>The unique immutable ID for this project. A new ID will be generated for new Projects. Once issued, this ID is guaranteed to never change or be re-issued</p> <p> TYPE: <code>Optional[str]</code> </p> <code>name</code> <p>The name of this project. Must be 256 characters or less. Names may only contain: letters, numbers, spaces, underscores, hyphens, periods, plus signs, apostrophes, and parentheses</p> <p> TYPE: <code>Optional[str]</code> </p> <code>description</code> <p>The description of this entity. Must be 1000 characters or less.</p> <p> TYPE: <code>Optional[str]</code> </p> <code>etag</code> <p>Synapse employs an Optimistic Concurrency Control (OCC) scheme to handle concurrent updates. Since the E-Tag changes every time an entity is updated it is used to detect when a client's current representation of an entity is out-of-date.</p> <p> TYPE: <code>Optional[str]</code> </p> <code>created_on</code> <p>The date this entity was created.</p> <p> TYPE: <code>Optional[str]</code> </p> <code>modified_on</code> <p>The date this entity was last modified.</p> <p> TYPE: <code>Optional[str]</code> </p> <code>created_by</code> <p>The ID of the user that created this entity.</p> <p> TYPE: <code>Optional[str]</code> </p> <code>modified_by</code> <p>The ID of the user that last modified this entity.</p> <p> TYPE: <code>Optional[str]</code> </p> <code>alias</code> <p>The project alias for use in friendly project urls.</p> <p> TYPE: <code>Optional[str]</code> </p> <code>files</code> <p>Any files that are at the root directory of the project.</p> <p> TYPE: <code>List[File]</code> </p> <code>folders</code> <p>Any folders that are at the root directory of the project.</p> <p> TYPE: <code>List[Folder]</code> </p> <code>annotations</code> <p>Additional metadata associated with the folder. The key is the name of your desired annotations. The value is an object containing a list of values (use empty list to represent no values for key) and the value type associated with all values in the list. To remove all annotations set this to an empty dict <code>{}</code> or None and store the entity.</p> <p> TYPE: <code>Optional[Dict[str, Union[List[str], List[bool], List[float], List[int], List[date], List[datetime]]]]</code> </p> <code>create_or_update</code> <p>(Store only) Indicates whether the method should automatically perform an update if the resource conflicts with an existing Synapse object. When True this means that any changes to the resource will be non-destructive.</p> <p>This boolean is ignored if you've already stored or retrieved the resource from Synapse for this instance at least once. Any changes to the resource will be destructive in this case. For example if you want to delete the content for a field you will need to call <code>.get()</code> and then modify the field.</p> <p> TYPE: <code>bool</code> </p> <code>parent_id</code> <p>The parent ID of the project. In practice projects do not have a parent, but this is required for the inner workings of Synapse.</p> <p> TYPE: <code>Optional[str]</code> </p> Creating a project <p>This example shows how to create a project</p> <pre><code>from synapseclient.models import Project, File\nimport synapseclient\n\nsynapseclient.login()\n\nmy_annotations = {\n    \"my_single_key_string\": \"a\",\n    \"my_key_string\": [\"b\", \"a\", \"c\"],\n}\nproject = Project(\n    name=\"My unique project name\",\n    annotations=my_annotations,\n    description=\"This is a project with random data.\",\n)\n\nproject = project.store()\n\nprint(project)\n</code></pre> Storing several files to a project <p>This example shows how to store several files to a project</p> <pre><code>file_1 = File(\n    path=path_to_file_1,\n    name=name_of_file_1,\n)\nfile_2 = File(\n    path=path_to_file_2,\n    name=name_of_file_2,\n)\nproject.files = [file_1, file_2]\nproject = project.store()\n</code></pre> Source code in <code>synapseclient/models/project.py</code> <pre><code>@dataclass()\n@async_to_sync\nclass Project(ProjectSynchronousProtocol, AccessControllable, StorableContainer):\n    \"\"\"A Project is a top-level container for organizing data in Synapse.\n\n    Attributes:\n        id: The unique immutable ID for this project. A new ID will be generated for new\n            Projects. Once issued, this ID is guaranteed to never change or be re-issued\n        name: The name of this project. Must be 256 characters or less. Names may only\n            contain: letters, numbers, spaces, underscores, hyphens, periods, plus\n            signs, apostrophes, and parentheses\n        description: The description of this entity. Must be 1000 characters or less.\n        etag: Synapse employs an Optimistic Concurrency Control (OCC) scheme to handle\n            concurrent updates. Since the E-Tag changes every time an entity is updated\n            it is used to detect when a client's current representation of an entity\n            is out-of-date.\n        created_on: The date this entity was created.\n        modified_on: The date this entity was last modified.\n        created_by: The ID of the user that created this entity.\n        modified_by: The ID of the user that last modified this entity.\n        alias: The project alias for use in friendly project urls.\n        files: Any files that are at the root directory of the project.\n        folders: Any folders that are at the root directory of the project.\n        annotations: Additional metadata associated with the folder. The key is the name\n            of your desired annotations. The value is an object containing a list of\n            values (use empty list to represent no values for key) and the value type\n            associated with all values in the list. To remove all annotations set this\n            to an empty dict `{}` or None and store the entity.\n        create_or_update: (Store only) Indicates whether the method should\n            automatically perform an update if the resource conflicts with an existing\n            Synapse object. When True this means that any changes to the resource will\n            be non-destructive.\n\n            This boolean is ignored if you've already stored or retrieved the resource\n            from Synapse for this instance at least once. Any changes to the resource\n            will be destructive in this case. For example if you want to delete the\n            content for a field you will need to call `.get()` and then modify the\n            field.\n        parent_id: The parent ID of the project. In practice projects do not have a\n            parent, but this is required for the inner workings of Synapse.\n\n    Example: Creating a project\n        This example shows how to create a project\n\n            from synapseclient.models import Project, File\n            import synapseclient\n\n            synapseclient.login()\n\n            my_annotations = {\n                \"my_single_key_string\": \"a\",\n                \"my_key_string\": [\"b\", \"a\", \"c\"],\n            }\n            project = Project(\n                name=\"My unique project name\",\n                annotations=my_annotations,\n                description=\"This is a project with random data.\",\n            )\n\n            project = project.store()\n\n            print(project)\n\n    Example: Storing several files to a project\n        This example shows how to store several files to a project\n\n            file_1 = File(\n                path=path_to_file_1,\n                name=name_of_file_1,\n            )\n            file_2 = File(\n                path=path_to_file_2,\n                name=name_of_file_2,\n            )\n            project.files = [file_1, file_2]\n            project = project.store()\n\n    \"\"\"\n\n    id: Optional[str] = None\n    \"\"\"The unique immutable ID for this project. A new ID will be generated for new\n    Projects. Once issued, this ID is guaranteed to never change or be re-issued\"\"\"\n\n    name: Optional[str] = None\n    \"\"\"The name of this project. Must be 256 characters or less. Names may only contain:\n    letters, numbers, spaces, underscores, hyphens, periods, plus signs, apostrophes,\n    and parentheses\"\"\"\n\n    description: Optional[str] = None\n    \"\"\"The description of this entity. Must be 1000 characters or less.\"\"\"\n\n    etag: Optional[str] = None\n    \"\"\"Synapse employs an Optimistic Concurrency Control (OCC) scheme to handle\n    concurrent updates. Since the E-Tag changes every time an entity is updated it\n    is used to detect when a client's current representation of an entity is out-of-date.\"\"\"\n\n    created_on: Optional[str] = field(default=None, compare=False)\n    \"\"\"(Read Only) The date this entity was created.\"\"\"\n\n    modified_on: Optional[str] = field(default=None, compare=False)\n    \"\"\"(Read Only) The date this entity was last modified.\"\"\"\n\n    created_by: Optional[str] = field(default=None, compare=False)\n    \"\"\"(Read Only) The ID of the user that created this entity.\"\"\"\n\n    modified_by: Optional[str] = field(default=None, compare=False)\n    \"\"\"(Read Only) The ID of the user that last modified this entity.\"\"\"\n\n    alias: Optional[str] = None\n    \"\"\"The project alias for use in friendly project urls.\"\"\"\n\n    files: List[\"File\"] = field(default_factory=list, compare=False)\n    \"\"\"Any files that are at the root directory of the project.\"\"\"\n\n    folders: List[\"Folder\"] = field(default_factory=list, compare=False)\n    \"\"\"Any folders that are at the root directory of the project.\"\"\"\n\n    annotations: Optional[\n        Dict[\n            str,\n            Union[\n                List[str],\n                List[bool],\n                List[float],\n                List[int],\n                List[date],\n                List[datetime],\n            ],\n        ]\n    ] = field(default_factory=dict, compare=False)\n    \"\"\"Additional metadata associated with the folder. The key is the name of your\n    desired annotations. The value is an object containing a list of values\n    (use empty list to represent no values for key) and the value type associated with\n    all values in the list. To remove all annotations set this to an empty dict `{}`\n    or None and store the entity.\"\"\"\n\n    create_or_update: bool = field(default=True, repr=False)\n    \"\"\"\n    (Store only)\n\n    Indicates whether the method should automatically perform an update if the resource\n    conflicts with an existing Synapse object. When True this means that any changes\n    to the resource will be non-destructive.\n\n    This boolean is ignored if you've already stored or retrieved the resource from\n    Synapse for this instance at least once. Any changes to the resource will be\n    destructive in this case. For example if you want to delete the content for a field\n    you will need to call `.get()` and then modify the field.\n    \"\"\"\n\n    parent_id: Optional[str] = None\n    \"\"\"The parent ID of the project. In practice projects do not have a parent, but this\n    is required for the inner workings of Synapse.\"\"\"\n\n    _last_persistent_instance: Optional[\"Project\"] = field(\n        default=None, repr=False, compare=False\n    )\n    \"\"\"The last persistent instance of this object. This is used to determine if the\n    object has been changed and needs to be updated in Synapse.\"\"\"\n\n    @property\n    def has_changed(self) -&gt; bool:\n        \"\"\"Determines if the object has been changed and needs to be updated in Synapse.\"\"\"\n        return (\n            not self._last_persistent_instance or self._last_persistent_instance != self\n        )\n\n    def _set_last_persistent_instance(self) -&gt; None:\n        \"\"\"Stash the last time this object interacted with Synapse. This is used to\n        determine if the object has been changed and needs to be updated in Synapse.\"\"\"\n        del self._last_persistent_instance\n        self._last_persistent_instance = replace(self)\n        self._last_persistent_instance.annotations = (\n            deepcopy(self.annotations) if self.annotations else {}\n        )\n\n    def fill_from_dict(\n        self,\n        synapse_project: Union[Synapse_Project, Dict],\n        set_annotations: bool = True,\n    ) -&gt; \"Project\":\n        \"\"\"\n        Converts a response from the REST API into this dataclass.\n\n        Arguments:\n            synapse_project: The response from the REST API.\n\n        Returns:\n            The Project object.\n        \"\"\"\n        self.id = synapse_project.get(\"id\", None)\n        self.name = synapse_project.get(\"name\", None)\n        self.description = synapse_project.get(\"description\", None)\n        self.etag = synapse_project.get(\"etag\", None)\n        self.created_on = synapse_project.get(\"createdOn\", None)\n        self.modified_on = synapse_project.get(\"modifiedOn\", None)\n        self.created_by = synapse_project.get(\"createdBy\", None)\n        self.modified_by = synapse_project.get(\"modifiedBy\", None)\n        self.alias = synapse_project.get(\"alias\", None)\n        self.parent_id = synapse_project.get(\"parentId\", None)\n        if set_annotations:\n            self.annotations = Annotations.from_dict(\n                synapse_project.get(\"annotations\", {})\n            )\n        return self\n\n    @otel_trace_method(\n        method_to_trace_name=lambda self, **kwargs: f\"Project_Store: ID: {self.id}, Name: {self.name}\"\n    )\n    async def store_async(\n        self,\n        failure_strategy: FailureStrategy = FailureStrategy.LOG_EXCEPTION,\n        *,\n        synapse_client: Optional[Synapse] = None,\n    ) -&gt; \"Project\":\n        \"\"\"\n        Store project, files, and folders to synapse. If you have any files or folders\n        attached to this project they will be stored as well. You may attach files\n        and folders to this project by setting the `files` and `folders` attributes.\n\n        By default the store operation will non-destructively update the project if\n        you have not already retrieved the project from Synapse. If you have already\n        retrieved the project from Synapse then the store operation will be destructive\n        and will overwrite the project with the current state of this object. See the\n        `create_or_update` attribute for more information.\n\n        Arguments:\n            failure_strategy: Determines how to handle failures when storing attached\n                Files and Folders under this Project and an exception occurs.\n            synapse_client: If not passed in or None this will use the last client from\n                the `.login()` method.\n\n        Returns:\n            The project object.\n\n        Example: Using this method to update the description\n            Store the project to Synapse using ID\n\n                project = await Project(id=\"syn123\", description=\"new\").store_async()\n\n            Store the project to Synapse using Name\n\n                project = await Project(name=\"my_project\", description=\"new\").store_async()\n\n        Raises:\n            ValueError: If the project name is not set.\n        \"\"\"\n        if not self.name and not self.id:\n            raise ValueError(\"Project ID or Name is required\")\n\n        if (\n            self.create_or_update\n            and not self._last_persistent_instance\n            and (\n                existing_project_id := await get_id(\n                    entity=self, synapse_client=synapse_client, failure_strategy=None\n                )\n            )\n            and (\n                existing_project := await Project(id=existing_project_id).get_async(\n                    synapse_client=synapse_client\n                )\n            )\n        ):\n            merge_dataclass_entities(source=existing_project, destination=self)\n        trace.get_current_span().set_attributes(\n            {\n                \"synapse.name\": self.name or \"\",\n                \"synapse.id\": self.id or \"\",\n            }\n        )\n        if self.has_changed:\n            loop = asyncio.get_event_loop()\n            synapse_project = Synapse_Project(\n                id=self.id,\n                etag=self.etag,\n                name=self.name,\n                description=self.description,\n                alias=self.alias,\n                parentId=self.parent_id,\n            )\n            delete_none_keys(synapse_project)\n            current_context = context.get_current()\n            entity = await loop.run_in_executor(\n                None,\n                lambda: run_and_attach_otel_context(\n                    lambda: Synapse.get_client(synapse_client=synapse_client).store(\n                        obj=synapse_project,\n                        set_annotations=False,\n                        createOrUpdate=False,\n                    ),\n                    current_context,\n                ),\n            )\n            self.fill_from_dict(synapse_project=entity, set_annotations=False)\n\n        await store_entity_components(\n            root_resource=self,\n            failure_strategy=failure_strategy,\n            synapse_client=synapse_client,\n        )\n\n        self._set_last_persistent_instance()\n        Synapse.get_client(synapse_client=synapse_client).logger.debug(\n            f\"Saved Project {self.name}, id: {self.id}\"\n        )\n\n        return self\n\n    @otel_trace_method(\n        method_to_trace_name=lambda self, **kwargs: f\"Project_Get: ID: {self.id}, Name: {self.name}\"\n    )\n    async def get_async(\n        self,\n        *,\n        synapse_client: Optional[Synapse] = None,\n    ) -&gt; \"Project\":\n        \"\"\"Get the project metadata from Synapse.\n\n        Arguments:\n            synapse_client: If not passed in or None this will use the last client from\n                the `.login()` method.\n\n        Returns:\n            The project object.\n\n        Example: Using this method\n            Retrieve the project from Synapse using ID\n\n                project = await Project(id=\"syn123\").get_async()\n\n            Retrieve the project from Synapse using Name\n\n                project = await Project(name=\"my_project\").get_async()\n\n        Raises:\n            ValueError: If the project ID or Name is not set.\n            SynapseNotFoundError: If the project is not found in Synapse.\n        \"\"\"\n        entity_id = await get_id(entity=self, synapse_client=synapse_client)\n\n        await get_from_entity_factory(\n            entity_to_update=self,\n            synapse_id_or_path=entity_id,\n        )\n\n        self._set_last_persistent_instance()\n        return self\n\n    @otel_trace_method(\n        method_to_trace_name=lambda self, **kwargs: f\"Project_Delete: {self.id}, Name: {self.name}\"\n    )\n    async def delete_async(self, *, synapse_client: Optional[Synapse] = None) -&gt; None:\n        \"\"\"Delete the project from Synapse.\n\n        Arguments:\n            synapse_client: If not passed in or None this will use the last client from\n                the `.login()` method.\n\n        Returns:\n            None\n\n        Example: Using this method\n            Delete the project from Synapse using ID\n\n                await Project(id=\"syn123\").delete_async()\n\n            Delete the project from Synapse using Name\n\n                await Project(name=\"my_project\").delete_async()\n\n        Raises:\n            ValueError: If the project ID or Name is not set.\n            SynapseNotFoundError: If the project is not found in Synapse.\n        \"\"\"\n        entity_id = await get_id(entity=self, synapse_client=synapse_client)\n\n        loop = asyncio.get_event_loop()\n        current_context = context.get_current()\n        await loop.run_in_executor(\n            None,\n            lambda: run_and_attach_otel_context(\n                lambda: Synapse.get_client(synapse_client=synapse_client).delete(\n                    obj=entity_id,\n                ),\n                current_context,\n            ),\n        )\n\n    @otel_trace_method(\n        method_to_trace_name=lambda self, **kwargs: f\"Project_Copy: {self.id}\"\n    )\n    async def copy_async(\n        self,\n        destination_id: str,\n        copy_annotations: bool = True,\n        copy_wiki: bool = True,\n        exclude_types: Optional[List[str]] = None,\n        file_update_existing: bool = False,\n        file_copy_activity: Union[str, None] = \"traceback\",\n        *,\n        synapse_client: Optional[Synapse] = None,\n    ) -&gt; \"Project\":\n        \"\"\"\n        You must have already created the Project you will be copying to. It will have\n        it's own Synapse ID and unique name that you will use as the destination_id.\n\n\n        Copy the project to another Synapse project. This will recursively copy all\n        Tables, Links, Files, and Folders within the project.\n\n        Arguments:\n            destination_id: Synapse ID of a project to copy to.\n            copy_annotations: True to copy the annotations.\n            copy_wiki: True to copy the wiki pages.\n            exclude_types: A list of entity types ['file', 'table', 'link'] which\n                determines which entity types to not copy. Defaults to an empty list.\n            file_update_existing: When the destination has a file that has the same\n                name, users can choose to update that file.\n            file_copy_activity: Has three options to set the activity of the copied file:\n\n                    - traceback: Creates a copy of the source files Activity.\n                    - existing: Link to the source file's original Activity (if it exists)\n                    - None: No activity is set\n            synapse_client: If not passed in or None this will use the last client from\n                the `.login()` method.\n\n        Returns:\n            The copied project object.\n\n        Example: Using this function\n            Assuming you have a project with the ID \"syn123\" and you want to copy it to a\n            project with the ID \"syn456\":\n\n                new_instance = await Project(id=\"syn123\").copy_async(destination_id=\"syn456\")\n\n            Copy the project but do not persist annotations:\n\n                new_instance = await Project(id=\"syn123\").copy_async(destination_id=\"syn456\", copy_annotations=False)\n\n        Raises:\n            ValueError: If the project does not have an ID and destination_id to copy.\n        \"\"\"\n        if not self.id or not destination_id:\n            raise ValueError(\"The project must have an ID and destination_id to copy.\")\n\n        loop = asyncio.get_event_loop()\n\n        current_context = context.get_current()\n        syn = Synapse.get_client(synapse_client=synapse_client)\n        source_and_destination = await loop.run_in_executor(\n            None,\n            lambda: run_and_attach_otel_context(\n                lambda: copy(\n                    syn=syn,\n                    entity=self.id,\n                    destinationId=destination_id,\n                    excludeTypes=exclude_types or [],\n                    skipCopyAnnotations=not copy_annotations,\n                    skipCopyWikiPage=not copy_wiki,\n                    updateExisting=file_update_existing,\n                    setProvenance=file_copy_activity,\n                ),\n                current_context,\n            ),\n        )\n\n        new_project_id = source_and_destination.get(self.id, None)\n        if not new_project_id:\n            raise SynapseError(\"Failed to copy project.\")\n        project_copy = await (\n            await Project(id=new_project_id).get_async()\n        ).sync_from_synapse_async(\n            download_file=False,\n            synapse_client=synapse_client,\n        )\n        Synapse.get_client(synapse_client=synapse_client).logger.debug(\n            f\"Copied from project {self.id} to {destination_id}\"\n        )\n        return project_copy\n</code></pre>"},{"location":"reference/oop/models_async/#synapseclient.models.Project-functions","title":"Functions","text":""},{"location":"reference/oop/models_async/#synapseclient.models.Project.get_async","title":"<code>get_async(*, synapse_client=None)</code>  <code>async</code>","text":"<p>Get the project metadata from Synapse.</p> PARAMETER DESCRIPTION <code>synapse_client</code> <p>If not passed in or None this will use the last client from the <code>.login()</code> method.</p> <p> TYPE: <code>Optional[Synapse]</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>Project</code> <p>The project object.</p> Using this method <p>Retrieve the project from Synapse using ID</p> <pre><code>project = await Project(id=\"syn123\").get_async()\n</code></pre> <p>Retrieve the project from Synapse using Name</p> <pre><code>project = await Project(name=\"my_project\").get_async()\n</code></pre> RAISES DESCRIPTION <code>ValueError</code> <p>If the project ID or Name is not set.</p> <code>SynapseNotFoundError</code> <p>If the project is not found in Synapse.</p> Source code in <code>synapseclient/models/project.py</code> <pre><code>@otel_trace_method(\n    method_to_trace_name=lambda self, **kwargs: f\"Project_Get: ID: {self.id}, Name: {self.name}\"\n)\nasync def get_async(\n    self,\n    *,\n    synapse_client: Optional[Synapse] = None,\n) -&gt; \"Project\":\n    \"\"\"Get the project metadata from Synapse.\n\n    Arguments:\n        synapse_client: If not passed in or None this will use the last client from\n            the `.login()` method.\n\n    Returns:\n        The project object.\n\n    Example: Using this method\n        Retrieve the project from Synapse using ID\n\n            project = await Project(id=\"syn123\").get_async()\n\n        Retrieve the project from Synapse using Name\n\n            project = await Project(name=\"my_project\").get_async()\n\n    Raises:\n        ValueError: If the project ID or Name is not set.\n        SynapseNotFoundError: If the project is not found in Synapse.\n    \"\"\"\n    entity_id = await get_id(entity=self, synapse_client=synapse_client)\n\n    await get_from_entity_factory(\n        entity_to_update=self,\n        synapse_id_or_path=entity_id,\n    )\n\n    self._set_last_persistent_instance()\n    return self\n</code></pre>"},{"location":"reference/oop/models_async/#synapseclient.models.Project.store_async","title":"<code>store_async(failure_strategy=FailureStrategy.LOG_EXCEPTION, *, synapse_client=None)</code>  <code>async</code>","text":"<p>Store project, files, and folders to synapse. If you have any files or folders attached to this project they will be stored as well. You may attach files and folders to this project by setting the <code>files</code> and <code>folders</code> attributes.</p> <p>By default the store operation will non-destructively update the project if you have not already retrieved the project from Synapse. If you have already retrieved the project from Synapse then the store operation will be destructive and will overwrite the project with the current state of this object. See the <code>create_or_update</code> attribute for more information.</p> PARAMETER DESCRIPTION <code>failure_strategy</code> <p>Determines how to handle failures when storing attached Files and Folders under this Project and an exception occurs.</p> <p> TYPE: <code>FailureStrategy</code> DEFAULT: <code>LOG_EXCEPTION</code> </p> <code>synapse_client</code> <p>If not passed in or None this will use the last client from the <code>.login()</code> method.</p> <p> TYPE: <code>Optional[Synapse]</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>Project</code> <p>The project object.</p> Using this method to update the description <p>Store the project to Synapse using ID</p> <pre><code>project = await Project(id=\"syn123\", description=\"new\").store_async()\n</code></pre> <p>Store the project to Synapse using Name</p> <pre><code>project = await Project(name=\"my_project\", description=\"new\").store_async()\n</code></pre> RAISES DESCRIPTION <code>ValueError</code> <p>If the project name is not set.</p> Source code in <code>synapseclient/models/project.py</code> <pre><code>@otel_trace_method(\n    method_to_trace_name=lambda self, **kwargs: f\"Project_Store: ID: {self.id}, Name: {self.name}\"\n)\nasync def store_async(\n    self,\n    failure_strategy: FailureStrategy = FailureStrategy.LOG_EXCEPTION,\n    *,\n    synapse_client: Optional[Synapse] = None,\n) -&gt; \"Project\":\n    \"\"\"\n    Store project, files, and folders to synapse. If you have any files or folders\n    attached to this project they will be stored as well. You may attach files\n    and folders to this project by setting the `files` and `folders` attributes.\n\n    By default the store operation will non-destructively update the project if\n    you have not already retrieved the project from Synapse. If you have already\n    retrieved the project from Synapse then the store operation will be destructive\n    and will overwrite the project with the current state of this object. See the\n    `create_or_update` attribute for more information.\n\n    Arguments:\n        failure_strategy: Determines how to handle failures when storing attached\n            Files and Folders under this Project and an exception occurs.\n        synapse_client: If not passed in or None this will use the last client from\n            the `.login()` method.\n\n    Returns:\n        The project object.\n\n    Example: Using this method to update the description\n        Store the project to Synapse using ID\n\n            project = await Project(id=\"syn123\", description=\"new\").store_async()\n\n        Store the project to Synapse using Name\n\n            project = await Project(name=\"my_project\", description=\"new\").store_async()\n\n    Raises:\n        ValueError: If the project name is not set.\n    \"\"\"\n    if not self.name and not self.id:\n        raise ValueError(\"Project ID or Name is required\")\n\n    if (\n        self.create_or_update\n        and not self._last_persistent_instance\n        and (\n            existing_project_id := await get_id(\n                entity=self, synapse_client=synapse_client, failure_strategy=None\n            )\n        )\n        and (\n            existing_project := await Project(id=existing_project_id).get_async(\n                synapse_client=synapse_client\n            )\n        )\n    ):\n        merge_dataclass_entities(source=existing_project, destination=self)\n    trace.get_current_span().set_attributes(\n        {\n            \"synapse.name\": self.name or \"\",\n            \"synapse.id\": self.id or \"\",\n        }\n    )\n    if self.has_changed:\n        loop = asyncio.get_event_loop()\n        synapse_project = Synapse_Project(\n            id=self.id,\n            etag=self.etag,\n            name=self.name,\n            description=self.description,\n            alias=self.alias,\n            parentId=self.parent_id,\n        )\n        delete_none_keys(synapse_project)\n        current_context = context.get_current()\n        entity = await loop.run_in_executor(\n            None,\n            lambda: run_and_attach_otel_context(\n                lambda: Synapse.get_client(synapse_client=synapse_client).store(\n                    obj=synapse_project,\n                    set_annotations=False,\n                    createOrUpdate=False,\n                ),\n                current_context,\n            ),\n        )\n        self.fill_from_dict(synapse_project=entity, set_annotations=False)\n\n    await store_entity_components(\n        root_resource=self,\n        failure_strategy=failure_strategy,\n        synapse_client=synapse_client,\n    )\n\n    self._set_last_persistent_instance()\n    Synapse.get_client(synapse_client=synapse_client).logger.debug(\n        f\"Saved Project {self.name}, id: {self.id}\"\n    )\n\n    return self\n</code></pre>"},{"location":"reference/oop/models_async/#synapseclient.models.Project.delete_async","title":"<code>delete_async(*, synapse_client=None)</code>  <code>async</code>","text":"<p>Delete the project from Synapse.</p> PARAMETER DESCRIPTION <code>synapse_client</code> <p>If not passed in or None this will use the last client from the <code>.login()</code> method.</p> <p> TYPE: <code>Optional[Synapse]</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>None</code> <p>None</p> Using this method <p>Delete the project from Synapse using ID</p> <pre><code>await Project(id=\"syn123\").delete_async()\n</code></pre> <p>Delete the project from Synapse using Name</p> <pre><code>await Project(name=\"my_project\").delete_async()\n</code></pre> RAISES DESCRIPTION <code>ValueError</code> <p>If the project ID or Name is not set.</p> <code>SynapseNotFoundError</code> <p>If the project is not found in Synapse.</p> Source code in <code>synapseclient/models/project.py</code> <pre><code>@otel_trace_method(\n    method_to_trace_name=lambda self, **kwargs: f\"Project_Delete: {self.id}, Name: {self.name}\"\n)\nasync def delete_async(self, *, synapse_client: Optional[Synapse] = None) -&gt; None:\n    \"\"\"Delete the project from Synapse.\n\n    Arguments:\n        synapse_client: If not passed in or None this will use the last client from\n            the `.login()` method.\n\n    Returns:\n        None\n\n    Example: Using this method\n        Delete the project from Synapse using ID\n\n            await Project(id=\"syn123\").delete_async()\n\n        Delete the project from Synapse using Name\n\n            await Project(name=\"my_project\").delete_async()\n\n    Raises:\n        ValueError: If the project ID or Name is not set.\n        SynapseNotFoundError: If the project is not found in Synapse.\n    \"\"\"\n    entity_id = await get_id(entity=self, synapse_client=synapse_client)\n\n    loop = asyncio.get_event_loop()\n    current_context = context.get_current()\n    await loop.run_in_executor(\n        None,\n        lambda: run_and_attach_otel_context(\n            lambda: Synapse.get_client(synapse_client=synapse_client).delete(\n                obj=entity_id,\n            ),\n            current_context,\n        ),\n    )\n</code></pre>"},{"location":"reference/oop/models_async/#synapseclient.models.Project.sync_from_synapse_async","title":"<code>sync_from_synapse_async(path=None, recursive=True, download_file=True, if_collision=COLLISION_OVERWRITE_LOCAL, failure_strategy=FailureStrategy.LOG_EXCEPTION, include_activity=True, follow_link=False, link_hops=1, *, synapse_client=None)</code>  <code>async</code>","text":"<p>Sync this container and all possible sub-folders from Synapse. By default this will download the files that are found and it will populate the <code>files</code> and <code>folders</code> attributes with the found files and folders. If you only want to retrieve the full tree of metadata about your container specify <code>download_file</code> as False.</p> <p>This works similar to synapseutils.syncFromSynapse, however, this does not currently support the writing of data to a manifest TSV file. This will be a future enhancement.</p> <p>Only Files and Folders are supported at this time to be synced from synapse.</p> PARAMETER DESCRIPTION <code>path</code> <p>An optional path where the file hierarchy will be reproduced. If not specified the files will by default be placed in the synapseCache.</p> <p> TYPE: <code>Optional[str]</code> DEFAULT: <code>None</code> </p> <code>recursive</code> <p>Whether or not to recursively get the entire hierarchy of the folder and sub-folders.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> <code>download_file</code> <p>Whether to download the files found or not.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> <code>if_collision</code> <p>Determines how to handle file collisions. May be</p> <ul> <li><code>overwrite.local</code></li> <li><code>keep.local</code></li> <li><code>keep.both</code></li> </ul> <p> TYPE: <code>str</code> DEFAULT: <code>COLLISION_OVERWRITE_LOCAL</code> </p> <code>failure_strategy</code> <p>Determines how to handle failures when retrieving children under this Folder and an exception occurs.</p> <p> TYPE: <code>FailureStrategy</code> DEFAULT: <code>LOG_EXCEPTION</code> </p> <code>include_activity</code> <p>Whether to include the activity of the files.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> <code>follow_link</code> <p>Whether to follow a link entity or not. Links can be used to point at other Synapse entities.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>link_hops</code> <p>The number of hops to follow the link. A number of 1 is used to prevent circular references. There is nothing in place to prevent infinite loops. Be careful if setting this above 1.</p> <p> TYPE: <code>int</code> DEFAULT: <code>1</code> </p> <code>synapse_client</code> <p>If not passed in or None this will use the last client from the <code>.login()</code> method.</p> <p> TYPE: <code>Optional[Synapse]</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>Self</code> <p>The object that was called on. This will be the same object that was called on to start the sync.</p> Using this function <p>Suppose I want to walk the immediate children of a folder without downloading the files:</p> <pre><code>from synapseclient import Synapse\nfrom synapseclient.models import Folder\n\nsyn = Synapse()\nsyn.login()\n\nmy_folder = Folder(id=\"syn12345\")\nawait my_folder.sync_from_synapse_async(download_file=False, recursive=False)\n\nfor folder in my_folder.folders:\n    print(folder.name)\n\nfor file in my_folder.files:\n    print(file.name)\n</code></pre> <p>Suppose I want to download the immediate children of a folder:</p> <pre><code>from synapseclient import Synapse\nfrom synapseclient.models import Folder\n\nsyn = Synapse()\nsyn.login()\n\nmy_folder = Folder(id=\"syn12345\")\nawait my_folder.sync_from_synapse_async(path=\"/path/to/folder\", recursive=False)\n\nfor folder in my_folder.folders:\n    print(folder.name)\n\nfor file in my_folder.files:\n    print(file.name)\n</code></pre> <p>Suppose I want to download the immediate all children of a Project and all sub-folders and files:</p> <pre><code>from synapseclient import Synapse\nfrom synapseclient.models import Project\n\nsyn = Synapse()\nsyn.login()\n\nmy_project = Project(id=\"syn12345\")\nawait my_project.sync_from_synapse_async(path=\"/path/to/folder\")\n</code></pre> RAISES DESCRIPTION <code>ValueError</code> <p>If the folder does not have an id set.</p> <p>A sequence diagram for this method is as follows:</p> <pre><code>sequenceDiagram\n    autonumber\n    participant project_or_folder\n    activate project_or_folder\n    project_or_folder-&gt;&gt;sync_from_synapse: Recursive search and download files\n    activate sync_from_synapse\n        opt Current instance not retrieved from Synapse\n            sync_from_synapse-&gt;&gt;project_or_folder: Call `.get()` method\n            project_or_folder--&gt;&gt;sync_from_synapse: .\n        end\n\n        loop For each return of the generator\n            sync_from_synapse-&gt;&gt;client: call `.getChildren()` method\n            client--&gt;&gt;sync_from_synapse: .\n            note over sync_from_synapse: Append to a running list\n        end\n\n        loop For each child\n            note over sync_from_synapse: Create all `pending_tasks` at current depth\n\n            alt Child is File\n                note over sync_from_synapse: Append `file.get()` method\n            else Child is Folder\n                note over sync_from_synapse: Append `folder.get()` method\n                alt Recursive is True\n                    note over sync_from_synapse: Append `folder.sync_from_synapse()` method\n                end\n            else Child is Link and hops &gt; 0\n                note over sync_from_synapse: Append task to follow link\n            end\n        end\n\n        loop For each task in pending_tasks\n            par `file.get()`\n                sync_from_synapse-&gt;&gt;File: Retrieve File metadata and Optionally download\n                File-&gt;&gt;client: `.get()`\n                client--&gt;&gt;File: .\n                File--&gt;&gt;sync_from_synapse: .\n            and `folder.get()`\n                sync_from_synapse-&gt;&gt;Folder: Retrieve Folder metadataa\n                Folder-&gt;&gt;client: `.get()`\n                client--&gt;&gt;Folder: .\n                Folder--&gt;&gt;sync_from_synapse: .\n            and `folder.sync_from_synapse_async()`\n                note over sync_from_synapse: This is a recursive call to `sync_from_synapse`\n                sync_from_synapse-&gt;&gt;sync_from_synapse: Recursive call to `.sync_from_synapse_async()`\n            and `_follow_link`\n                sync_from_synapse -&gt;&gt;client: call `get_entity_id_bundle2` function\n                client--&gt;sync_from_synapse: .\n                note over sync_from_synapse: Do nothing if not link\n                note over sync_from_synapse: call `_create_task_for_child` and execute\n            end\n        end\n\n    deactivate sync_from_synapse\n    deactivate project_or_folder</code></pre> Source code in <code>synapseclient/models/mixins/storable_container.py</code> <pre><code>@otel_trace_method(\n    method_to_trace_name=lambda self, **kwargs: f\"{self.__class__.__name__}_sync_from_synapse: {self.id}\"\n)\nasync def sync_from_synapse_async(\n    self: Self,\n    path: Optional[str] = None,\n    recursive: bool = True,\n    download_file: bool = True,\n    if_collision: str = COLLISION_OVERWRITE_LOCAL,\n    failure_strategy: FailureStrategy = FailureStrategy.LOG_EXCEPTION,\n    include_activity: bool = True,\n    follow_link: bool = False,\n    link_hops: int = 1,\n    *,\n    synapse_client: Optional[Synapse] = None,\n) -&gt; Self:\n    \"\"\"\n    Sync this container and all possible sub-folders from Synapse. By default this\n    will download the files that are found and it will populate the\n    `files` and `folders` attributes with the found files and folders. If you only\n    want to retrieve the full tree of metadata about your container specify\n    `download_file` as False.\n\n    This works similar to [synapseutils.syncFromSynapse][], however, this does not\n    currently support the writing of data to a manifest TSV file. This will be a\n    future enhancement.\n\n    Only Files and Folders are supported at this time to be synced from synapse.\n\n    Arguments:\n        path: An optional path where the file hierarchy will be reproduced. If not\n            specified the files will by default be placed in the synapseCache.\n        recursive: Whether or not to recursively get the entire hierarchy of the\n            folder and sub-folders.\n        download_file: Whether to download the files found or not.\n        if_collision: Determines how to handle file collisions. May be\n\n            - `overwrite.local`\n            - `keep.local`\n            - `keep.both`\n        failure_strategy: Determines how to handle failures when retrieving children\n            under this Folder and an exception occurs.\n        include_activity: Whether to include the activity of the files.\n        follow_link: Whether to follow a link entity or not. Links can be used to\n            point at other Synapse entities.\n        link_hops: The number of hops to follow the link. A number of 1 is used to\n            prevent circular references. There is nothing in place to prevent\n            infinite loops. Be careful if setting this above 1.\n        synapse_client: If not passed in or None this will use the last client from\n            the `.login()` method.\n\n    Returns:\n        The object that was called on. This will be the same object that was called on\n            to start the sync.\n\n    Example: Using this function\n        Suppose I want to walk the immediate children of a folder without downloading the files:\n\n            from synapseclient import Synapse\n            from synapseclient.models import Folder\n\n            syn = Synapse()\n            syn.login()\n\n            my_folder = Folder(id=\"syn12345\")\n            await my_folder.sync_from_synapse_async(download_file=False, recursive=False)\n\n            for folder in my_folder.folders:\n                print(folder.name)\n\n            for file in my_folder.files:\n                print(file.name)\n\n        Suppose I want to download the immediate children of a folder:\n\n            from synapseclient import Synapse\n            from synapseclient.models import Folder\n\n            syn = Synapse()\n            syn.login()\n\n            my_folder = Folder(id=\"syn12345\")\n            await my_folder.sync_from_synapse_async(path=\"/path/to/folder\", recursive=False)\n\n            for folder in my_folder.folders:\n                print(folder.name)\n\n            for file in my_folder.files:\n                print(file.name)\n\n\n        Suppose I want to download the immediate all children of a Project and all sub-folders and files:\n\n            from synapseclient import Synapse\n            from synapseclient.models import Project\n\n            syn = Synapse()\n            syn.login()\n\n            my_project = Project(id=\"syn12345\")\n            await my_project.sync_from_synapse_async(path=\"/path/to/folder\")\n\n\n    Raises:\n        ValueError: If the folder does not have an id set.\n\n\n    A sequence diagram for this method is as follows:\n\n    ```mermaid\n    sequenceDiagram\n        autonumber\n        participant project_or_folder\n        activate project_or_folder\n        project_or_folder-&gt;&gt;sync_from_synapse: Recursive search and download files\n        activate sync_from_synapse\n            opt Current instance not retrieved from Synapse\n                sync_from_synapse-&gt;&gt;project_or_folder: Call `.get()` method\n                project_or_folder--&gt;&gt;sync_from_synapse: .\n            end\n\n            loop For each return of the generator\n                sync_from_synapse-&gt;&gt;client: call `.getChildren()` method\n                client--&gt;&gt;sync_from_synapse: .\n                note over sync_from_synapse: Append to a running list\n            end\n\n            loop For each child\n                note over sync_from_synapse: Create all `pending_tasks` at current depth\n\n                alt Child is File\n                    note over sync_from_synapse: Append `file.get()` method\n                else Child is Folder\n                    note over sync_from_synapse: Append `folder.get()` method\n                    alt Recursive is True\n                        note over sync_from_synapse: Append `folder.sync_from_synapse()` method\n                    end\n                else Child is Link and hops &gt; 0\n                    note over sync_from_synapse: Append task to follow link\n                end\n            end\n\n            loop For each task in pending_tasks\n                par `file.get()`\n                    sync_from_synapse-&gt;&gt;File: Retrieve File metadata and Optionally download\n                    File-&gt;&gt;client: `.get()`\n                    client--&gt;&gt;File: .\n                    File--&gt;&gt;sync_from_synapse: .\n                and `folder.get()`\n                    sync_from_synapse-&gt;&gt;Folder: Retrieve Folder metadataa\n                    Folder-&gt;&gt;client: `.get()`\n                    client--&gt;&gt;Folder: .\n                    Folder--&gt;&gt;sync_from_synapse: .\n                and `folder.sync_from_synapse_async()`\n                    note over sync_from_synapse: This is a recursive call to `sync_from_synapse`\n                    sync_from_synapse-&gt;&gt;sync_from_synapse: Recursive call to `.sync_from_synapse_async()`\n                and `_follow_link`\n                    sync_from_synapse -&gt;&gt;client: call `get_entity_id_bundle2` function\n                    client--&gt;sync_from_synapse: .\n                    note over sync_from_synapse: Do nothing if not link\n                    note over sync_from_synapse: call `_create_task_for_child` and execute\n                end\n            end\n\n        deactivate sync_from_synapse\n        deactivate project_or_folder\n    ```\n\n    \"\"\"\n    if not self._last_persistent_instance:\n        await self.get_async(synapse_client=synapse_client)\n    Synapse.get_client(synapse_client=synapse_client).logger.info(\n        f\"Syncing {self.__class__.__name__} ({self.id}:{self.name}) from Synapse.\"\n    )\n    path = os.path.expanduser(path) if path else None\n\n    loop = asyncio.get_event_loop()\n    current_context = context.get_current()\n    children = await loop.run_in_executor(\n        None,\n        lambda: run_and_attach_otel_context(\n            lambda: self._retrieve_children(\n                follow_link=follow_link,\n                synapse_client=synapse_client,\n            ),\n            current_context,\n        ),\n    )\n\n    pending_tasks = []\n    self.folders = []\n    self.files = []\n\n    for child in children:\n        pending_tasks.extend(\n            self._create_task_for_child(\n                child=child,\n                recursive=recursive,\n                path=path,\n                download_file=download_file,\n                if_collision=if_collision,\n                failure_strategy=failure_strategy,\n                synapse_client=synapse_client,\n                include_activity=include_activity,\n                follow_link=follow_link,\n                link_hops=link_hops,\n            )\n        )\n\n    for task in asyncio.as_completed(pending_tasks):\n        result = await task\n        self._resolve_sync_from_synapse_result(\n            result=result,\n            failure_strategy=failure_strategy,\n            synapse_client=synapse_client,\n        )\n    return self\n</code></pre>"},{"location":"reference/oop/models_async/#synapseclient.models.Project.get_permissions_async","title":"<code>get_permissions_async(*, synapse_client=None)</code>  <code>async</code>","text":"<p>Get the permissions that the caller has on an Entity.</p> PARAMETER DESCRIPTION <code>synapse_client</code> <p>If not passed in or None this will use the last client from the <code>.login()</code> method.</p> <p> TYPE: <code>Optional[Synapse]</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>Permissions</code> <p>A Permissions object</p> Using this function: <p>Getting permissions for a Synapse Entity</p> <pre><code>permissions = await File(id=\"syn123\").get_permissions_async()\n</code></pre> <p>Getting access types list from the Permissions object</p> <pre><code>permissions.access_types\n</code></pre> Source code in <code>synapseclient/models/mixins/access_control.py</code> <pre><code>async def get_permissions_async(\n    self,\n    *,\n    synapse_client: Optional[Synapse] = None,\n) -&gt; \"Permissions\":\n    \"\"\"\n    Get the [permissions][synapseclient.core.models.permission.Permissions]\n    that the caller has on an Entity.\n\n    Arguments:\n        synapse_client: If not passed in or None this will use the last client\n            from the `.login()` method.\n\n    Returns:\n        A Permissions object\n\n\n    Example: Using this function:\n        Getting permissions for a Synapse Entity\n\n            permissions = await File(id=\"syn123\").get_permissions_async()\n\n        Getting access types list from the Permissions object\n\n            permissions.access_types\n    \"\"\"\n    loop = asyncio.get_event_loop()\n    current_context = context.get_current()\n\n    return await loop.run_in_executor(\n        None,\n        lambda: run_and_attach_otel_context(\n            lambda: Synapse.get_client(\n                synapse_client=synapse_client\n            ).get_permissions(entity=self.id),\n            current_context,\n        ),\n    )\n</code></pre>"},{"location":"reference/oop/models_async/#synapseclient.models.Project.get_acl_async","title":"<code>get_acl_async(principal_id=None, *, synapse_client=None)</code>  <code>async</code>","text":"<p>Get the ACL that a user or group has on an Entity.</p> PARAMETER DESCRIPTION <code>principal_id</code> <p>Identifier of a user or group (defaults to PUBLIC users)</p> <p> TYPE: <code>int</code> DEFAULT: <code>None</code> </p> <code>synapse_client</code> <p>If not passed in or None this will use the last client from the <code>.login()</code> method.</p> <p> TYPE: <code>Optional[Synapse]</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>List[str]</code> <p>An array containing some combination of ['READ', 'UPDATE', 'CREATE', 'DELETE', 'DOWNLOAD', 'MODERATE', 'CHANGE_PERMISSIONS', 'CHANGE_SETTINGS'] or an empty array</p> Source code in <code>synapseclient/models/mixins/access_control.py</code> <pre><code>async def get_acl_async(\n    self, principal_id: int = None, *, synapse_client: Optional[Synapse] = None\n) -&gt; List[str]:\n    \"\"\"\n    Get the [ACL][synapseclient.core.models.permission.Permissions.access_types]\n    that a user or group has on an Entity.\n\n    Arguments:\n        principal_id: Identifier of a user or group (defaults to PUBLIC users)\n        synapse_client: If not passed in or None this will use the last client\n            from the `.login()` method.\n\n    Returns:\n        An array containing some combination of\n            ['READ', 'UPDATE', 'CREATE', 'DELETE', 'DOWNLOAD', 'MODERATE',\n            'CHANGE_PERMISSIONS', 'CHANGE_SETTINGS']\n            or an empty array\n    \"\"\"\n    loop = asyncio.get_event_loop()\n    current_context = context.get_current()\n\n    return await loop.run_in_executor(\n        None,\n        lambda: run_and_attach_otel_context(\n            lambda: Synapse.get_client(synapse_client=synapse_client).get_acl(\n                entity=self.id, principal_id=principal_id\n            ),\n            current_context,\n        ),\n    )\n</code></pre>"},{"location":"reference/oop/models_async/#synapseclient.models.Project.set_permissions_async","title":"<code>set_permissions_async(principal_id=None, access_type=None, modify_benefactor=False, warn_if_inherits=True, overwrite=True, *, synapse_client=None)</code>  <code>async</code>","text":"<p>Sets permission that a user or group has on an Entity. An Entity may have its own ACL or inherit its ACL from a benefactor.</p> PARAMETER DESCRIPTION <code>principal_id</code> <p>Identifier of a user or group. <code>273948</code> is for all registered Synapse users and <code>273949</code> is for public access. None implies public access.</p> <p> TYPE: <code>int</code> DEFAULT: <code>None</code> </p> <code>access_type</code> <p>Type of permission to be granted. One or more of CREATE, READ, DOWNLOAD, UPDATE, DELETE, CHANGE_PERMISSIONS.</p> <p>Defaults to ['READ', 'DOWNLOAD']</p> <p> TYPE: <code>List[str]</code> DEFAULT: <code>None</code> </p> <code>modify_benefactor</code> <p>Set as True when modifying a benefactor's ACL</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>warn_if_inherits</code> <p>Set as False, when creating a new ACL. Trying to modify the ACL of an Entity that inherits its ACL will result in a warning</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> <code>overwrite</code> <p>By default this function overwrites existing permissions for the specified user. Set this flag to False to add new permissions non-destructively.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> <code>synapse_client</code> <p>If not passed in or None this will use the last client from the <code>.login()</code> method.</p> <p> TYPE: <code>Optional[Synapse]</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>Dict[str, Union[str, list]]</code> <p>An Access Control List object</p> Setting permissions <p>Grant all registered users download access</p> <pre><code>await File(id=\"syn123\").set_permissions_async(principal_id=273948, access_type=['READ','DOWNLOAD'])\n</code></pre> <p>Grant the public view access</p> <pre><code>await File(id=\"syn123\").set_permissions_async(principal_id=273949, access_type=['READ'])\n</code></pre> Source code in <code>synapseclient/models/mixins/access_control.py</code> <pre><code>async def set_permissions_async(\n    self,\n    principal_id: int = None,\n    access_type: List[str] = None,\n    modify_benefactor: bool = False,\n    warn_if_inherits: bool = True,\n    overwrite: bool = True,\n    *,\n    synapse_client: Optional[Synapse] = None,\n) -&gt; Dict[str, Union[str, list]]:\n    \"\"\"\n    Sets permission that a user or group has on an Entity.\n    An Entity may have its own ACL or inherit its ACL from a benefactor.\n\n    Arguments:\n        principal_id: Identifier of a user or group. `273948` is for all\n            registered Synapse users and `273949` is for public access.\n            None implies public access.\n        access_type: Type of permission to be granted. One or more of CREATE,\n            READ, DOWNLOAD, UPDATE, DELETE, CHANGE_PERMISSIONS.\n\n            **Defaults to ['READ', 'DOWNLOAD']**\n        modify_benefactor: Set as True when modifying a benefactor's ACL\n        warn_if_inherits: Set as False, when creating a new ACL. Trying to modify\n            the ACL of an Entity that inherits its ACL will result in a warning\n        overwrite: By default this function overwrites existing permissions for\n            the specified user. Set this flag to False to add new permissions\n            non-destructively.\n        synapse_client: If not passed in or None this will use the last client\n            from the `.login()` method.\n\n    Returns:\n        An Access Control List object\n\n    Example: Setting permissions\n        Grant all registered users download access\n\n            await File(id=\"syn123\").set_permissions_async(principal_id=273948, access_type=['READ','DOWNLOAD'])\n\n        Grant the public view access\n\n            await File(id=\"syn123\").set_permissions_async(principal_id=273949, access_type=['READ'])\n    \"\"\"\n    if access_type is None:\n        access_type = [\"READ\", \"DOWNLOAD\"]\n    loop = asyncio.get_event_loop()\n    current_context = context.get_current()\n\n    return await loop.run_in_executor(\n        None,\n        lambda: run_and_attach_otel_context(\n            lambda: Synapse.get_client(\n                synapse_client=synapse_client\n            ).setPermissions(\n                entity=self.id,\n                principalId=principal_id,\n                accessType=access_type,\n                modify_benefactor=modify_benefactor,\n                warn_if_inherits=warn_if_inherits,\n                overwrite=overwrite,\n            ),\n            current_context,\n        ),\n    )\n</code></pre>"},{"location":"reference/oop/models_async/#synapseclient.models.Folder","title":"<code>synapseclient.models.Folder</code>  <code>dataclass</code>","text":"<p>               Bases: <code>FolderSynchronousProtocol</code>, <code>AccessControllable</code>, <code>StorableContainer</code></p> <p>Folder is a hierarchical container for organizing data in Synapse.</p> ATTRIBUTE DESCRIPTION <code>id</code> <p>The unique immutable ID for this folder. A new ID will be generated for new Folders. Once issued, this ID is guaranteed to never change or be re-issued.</p> <p> TYPE: <code>Optional[str]</code> </p> <code>name</code> <p>The name of this folder. Must be 256 characters or less. Names may only contain: letters, numbers, spaces, underscores, hyphens, periods, plus signs, apostrophes, and parentheses.</p> <p> TYPE: <code>Optional[str]</code> </p> <code>parent_id</code> <p>The ID of the Project or Folder that is the parent of this Folder.</p> <p> TYPE: <code>Optional[str]</code> </p> <code>description</code> <p>The description of this entity. Must be 1000 characters or less.</p> <p> TYPE: <code>Optional[str]</code> </p> <code>etag</code> <p>(Read Only) Synapse employs an Optimistic Concurrency Control (OCC) scheme to handle concurrent updates. Since the E-Tag changes every time an entity is updated it is used to detect when a client's current representation of an entity is out-of-date.</p> <p> TYPE: <code>Optional[str]</code> </p> <code>created_on</code> <p>(Read Only) The date this entity was created.</p> <p> TYPE: <code>Optional[str]</code> </p> <code>modified_on</code> <p>(Read Only) The date this entity was last modified.</p> <p> TYPE: <code>Optional[str]</code> </p> <code>created_by</code> <p>(Read Only) The ID of the user that created this entity.</p> <p> TYPE: <code>Optional[str]</code> </p> <code>modified_by</code> <p>(Read Only) The ID of the user that last modified this entity.</p> <p> TYPE: <code>Optional[str]</code> </p> <code>files</code> <p>Files that exist within this folder.</p> <p> TYPE: <code>List[File]</code> </p> <code>folders</code> <p>Folders that exist within this folder.</p> <p> TYPE: <code>List[Folder]</code> </p> <code>annotations</code> <p>Additional metadata associated with the folder. The key is the name of your desired annotations. The value is an object containing a list of values (use empty list to represent no values for key) and the value type associated with all values in the list. To remove all annotations set this to an empty dict <code>{}</code> or None and store the entity.</p> <p> TYPE: <code>Optional[Dict[str, Union[List[str], List[bool], List[float], List[int], List[date], List[datetime]]]]</code> </p> <code>create_or_update</code> <p>(Store only) Indicates whether the method should automatically perform an update if the resource conflicts with an existing Synapse object. When True this means that any changes to the resource will be non-destructive.</p> <p>This boolean is ignored if you've already stored or retrieved the resource from Synapse for this instance at least once. Any changes to the resource will be destructive in this case. For example if you want to delete the content for a field you will need to call <code>.get()</code> and then modify the field.</p> <p> TYPE: <code>bool</code> </p> Source code in <code>synapseclient/models/folder.py</code> <pre><code>@dataclass()\n@async_to_sync\nclass Folder(FolderSynchronousProtocol, AccessControllable, StorableContainer):\n    \"\"\"Folder is a hierarchical container for organizing data in Synapse.\n\n    Attributes:\n        id: The unique immutable ID for this folder. A new ID will be generated for new\n            Folders. Once issued, this ID is guaranteed to never change or be re-issued.\n        name: The name of this folder. Must be 256 characters or less. Names may only\n            contain: letters, numbers, spaces, underscores, hyphens, periods, plus\n            signs, apostrophes, and parentheses.\n        parent_id: The ID of the Project or Folder that is the parent of this Folder.\n        description: The description of this entity. Must be 1000 characters or less.\n        etag: (Read Only)\n            Synapse employs an Optimistic Concurrency Control (OCC) scheme to handle\n            concurrent updates. Since the E-Tag changes every time an entity is updated\n            it is used to detect when a client's current representation of an entity is\n            out-of-date.\n        created_on: (Read Only) The date this entity was created.\n        modified_on: (Read Only) The date this entity was last modified.\n        created_by: (Read Only) The ID of the user that created this entity.\n        modified_by: (Read Only) The ID of the user that last modified this entity.\n        files: Files that exist within this folder.\n        folders: Folders that exist within this folder.\n        annotations: Additional metadata associated with the folder. The key is the name\n            of your desired annotations. The value is an object containing a list of\n            values (use empty list to represent no values for key) and the value type\n            associated with all values in the list. To remove all annotations set this\n            to an empty dict `{}` or None and store the entity.\n        create_or_update: (Store only) Indicates whether the method should\n            automatically perform an update if the resource conflicts with an existing\n            Synapse object. When True this means that any changes to the resource will\n            be non-destructive.\n\n            This boolean is ignored if you've already stored or retrieved the resource\n            from Synapse for this instance at least once. Any changes to the resource\n            will be destructive in this case. For example if you want to delete the\n            content for a field you will need to call `.get()` and then modify the\n            field.\n    \"\"\"\n\n    id: Optional[str] = None\n    \"\"\"The unique immutable ID for this folder. A new ID will be generated for new\n    Folders. Once issued, this ID is guaranteed to never change or be re-issued\"\"\"\n\n    name: Optional[str] = None\n    \"\"\"The name of this folder. Must be 256 characters or less. Names may only contain:\n    letters, numbers, spaces, underscores, hyphens, periods, plus signs, apostrophes,\n    and parentheses\"\"\"\n\n    parent_id: Optional[str] = None\n    \"\"\"The ID of the Project or Folder that is the parent of this Folder.\"\"\"\n\n    description: Optional[str] = None\n    \"\"\"The description of this entity. Must be 1000 characters or less.\"\"\"\n\n    etag: Optional[str] = None\n    \"\"\"(Read Only)\n    Synapse employs an Optimistic Concurrency Control (OCC) scheme to handle\n    concurrent updates. Since the E-Tag changes every time an entity is updated it\n    is used to detect when a client's current representation of an entity\n    is out-of-date.\"\"\"\n\n    created_on: Optional[str] = None\n    \"\"\"(Read Only) The date this entity was created.\"\"\"\n\n    modified_on: Optional[str] = None\n    \"\"\"(Read Only) The date this entity was last modified.\"\"\"\n\n    created_by: Optional[str] = None\n    \"\"\"(Read Only) The ID of the user that created this entity.\"\"\"\n\n    modified_by: Optional[str] = None\n    \"\"\"(Read Only) The ID of the user that last modified this entity.\"\"\"\n\n    files: List[\"File\"] = field(default_factory=list, compare=False)\n    \"\"\"Files that exist within this folder.\"\"\"\n\n    folders: List[\"Folder\"] = field(default_factory=list, compare=False)\n    \"\"\"Folders that exist within this folder.\"\"\"\n\n    annotations: Optional[\n        Dict[\n            str,\n            Union[\n                List[str],\n                List[bool],\n                List[float],\n                List[int],\n                List[date],\n                List[datetime],\n            ],\n        ]\n    ] = field(default_factory=dict, compare=False)\n    \"\"\"Additional metadata associated with the folder. The key is the name of your\n    desired annotations. The value is an object containing a list of values\n    (use empty list to represent no values for key) and the value type associated with\n    all values in the list. To remove all annotations set this to an empty dict `{}`\n    or None and store the entity.\"\"\"\n\n    is_restricted: bool = field(default=False, repr=False)\n    \"\"\"\n    (Store only)\n\n    If set to true, an email will be sent to the Synapse access control team to start\n    the process of adding terms-of-use or review board approval for this entity.\n    You will be contacted with regards to the specific data being restricted and the\n    requirements of access.\n    \"\"\"\n\n    create_or_update: bool = field(default=True, repr=False)\n    \"\"\"\n    (Store only)\n\n    Indicates whether the method should automatically perform an update if the resource\n    conflicts with an existing Synapse object. When True this means that any changes\n    to the resource will be non-destructive.\n\n    This boolean is ignored if you've already stored or retrieved the resource from\n    Synapse for this instance at least once. Any changes to the resource will be\n    destructive in this case. For example if you want to delete the content for a field\n    you will need to call `.get()` and then modify the field.\n    \"\"\"\n\n    _last_persistent_instance: Optional[\"Folder\"] = field(\n        default=None, repr=False, compare=False\n    )\n    \"\"\"The last persistent instance of this object. This is used to determine if the\n    object has been changed and needs to be updated in Synapse.\"\"\"\n\n    @property\n    def has_changed(self) -&gt; bool:\n        \"\"\"Determines if the object has been changed and needs to be updated in Synapse.\"\"\"\n        return (\n            not self._last_persistent_instance or self._last_persistent_instance != self\n        )\n\n    def _set_last_persistent_instance(self) -&gt; None:\n        \"\"\"Stash the last time this object interacted with Synapse. This is used to\n        determine if the object has been changed and needs to be updated in Synapse.\"\"\"\n        del self._last_persistent_instance\n        self._last_persistent_instance = replace(self)\n        self._last_persistent_instance.annotations = (\n            deepcopy(self.annotations) if self.annotations else {}\n        )\n\n    def fill_from_dict(\n        self, synapse_folder: Synapse_Folder, set_annotations: bool = True\n    ) -&gt; \"Folder\":\n        \"\"\"\n        Converts a response from the REST API into this dataclass.\n\n        Arguments:\n            synapse_file: The response from the REST API.\n            set_annotations: Whether to set the annotations from the response.\n\n        Returns:\n            The Folder object.\n        \"\"\"\n        self.id = synapse_folder.get(\"id\", None)\n        self.name = synapse_folder.get(\"name\", None)\n        self.parent_id = synapse_folder.get(\"parentId\", None)\n        self.description = synapse_folder.get(\"description\", None)\n        self.etag = synapse_folder.get(\"etag\", None)\n        self.created_on = synapse_folder.get(\"createdOn\", None)\n        self.modified_on = synapse_folder.get(\"modifiedOn\", None)\n        self.created_by = synapse_folder.get(\"createdBy\", None)\n        self.modified_by = synapse_folder.get(\"modifiedBy\", None)\n        if set_annotations:\n            self.annotations = Annotations.from_dict(\n                synapse_folder.get(\"annotations\", None)\n            )\n        return self\n\n    @otel_trace_method(\n        method_to_trace_name=lambda self, **kwargs: f\"Folder_Store: {self.name}\"\n    )\n    async def store_async(\n        self,\n        parent: Optional[Union[\"Folder\", \"Project\"]] = None,\n        failure_strategy: FailureStrategy = FailureStrategy.LOG_EXCEPTION,\n        *,\n        synapse_client: Optional[Synapse] = None,\n    ) -&gt; \"Folder\":\n        \"\"\"Store folders and files to synapse. If you have any files or folders attached\n        to this folder they will be stored as well. You may attach files and folders\n        to this folder by setting the `files` and `folders` attributes.\n\n        By default the store operation will non-destructively update the folder if\n        you have not already retrieved the folder from Synapse. If you have already\n        retrieved the folder from Synapse then the store operation will be destructive\n        and will overwrite the folder with the current state of this object. See the\n        `create_or_update` attribute for more information.\n\n        Arguments:\n            parent: The parent folder or project to store the folder in.\n            failure_strategy: Determines how to handle failures when storing attached\n                Files and Folders under this Folder and an exception occurs.\n            synapse_client: If not passed in or None this will use the last client from\n                the `.login()` method.\n\n        Returns:\n            The folder object.\n\n        Raises:\n            ValueError: If the folder does not have an id or a\n                (name and (`parent_id` or parent with an id)) set.\n        \"\"\"\n        parent_id = parent.id if parent else self.parent_id\n        if not (self.id or (self.name and parent_id)):\n            raise ValueError(\n                \"The folder must have an id or a \"\n                \"(name and (`parent_id` or parent with an id)) set.\"\n            )\n        self.parent_id = parent_id\n\n        if (\n            self.create_or_update\n            and not self._last_persistent_instance\n            and (\n                existing_folder_id := await get_id(\n                    entity=self, failure_strategy=None, synapse_client=synapse_client\n                )\n            )\n            and (existing_folder := await Folder(id=existing_folder_id).get_async())\n        ):\n            merge_dataclass_entities(source=existing_folder, destination=self)\n        trace.get_current_span().set_attributes(\n            {\n                \"synapse.name\": self.name or \"\",\n                \"synapse.id\": self.id or \"\",\n            }\n        )\n        if self.has_changed:\n            loop = asyncio.get_event_loop()\n            synapse_folder = Synapse_Folder(\n                id=self.id,\n                name=self.name,\n                parent=parent_id,\n                etag=self.etag,\n                description=self.description,\n            )\n            delete_none_keys(synapse_folder)\n            current_context = context.get_current()\n            entity = await loop.run_in_executor(\n                None,\n                lambda: run_and_attach_otel_context(\n                    lambda: Synapse.get_client(synapse_client=synapse_client).store(\n                        obj=synapse_folder,\n                        set_annotations=False,\n                        isRestricted=self.is_restricted,\n                        createOrUpdate=False,\n                    ),\n                    current_context,\n                ),\n            )\n\n            self.fill_from_dict(synapse_folder=entity, set_annotations=False)\n\n        await store_entity_components(\n            root_resource=self,\n            failure_strategy=failure_strategy,\n            synapse_client=synapse_client,\n        )\n        self._set_last_persistent_instance()\n        Synapse.get_client(synapse_client=synapse_client).logger.debug(\n            f\"Saved Folder {self.name}, id: {self.id}: parent: {self.parent_id}\"\n        )\n\n        return self\n\n    @otel_trace_method(\n        method_to_trace_name=lambda self, **kwargs: f\"Folder_Get: {self.id}\"\n    )\n    async def get_async(\n        self,\n        parent: Optional[Union[\"Folder\", \"Project\"]] = None,\n        *,\n        synapse_client: Optional[Synapse] = None,\n    ) -&gt; \"Folder\":\n        \"\"\"Get the folder metadata from Synapse. You are able to find a folder by\n        either the id or the name and parent_id.\n\n        Arguments:\n            parent: The parent folder or project this folder exists under.\n            synapse_client: If not passed in or None this will use the last client from\n                the `.login()` method.\n\n        Returns:\n            The folder object.\n\n        Raises:\n            ValueError: If the folder does not have an id or a\n                (name and (`parent_id` or parent with an id)) set.\n        \"\"\"\n        parent_id = parent.id if parent else self.parent_id\n        if not (self.id or (self.name and parent_id)):\n            raise ValueError(\n                \"The folder must have an id or a \"\n                \"(name and (`parent_id` or parent with an id)) set.\"\n            )\n        self.parent_id = parent_id\n\n        entity_id = await get_id(entity=self, synapse_client=synapse_client)\n\n        await get_from_entity_factory(\n            entity_to_update=self,\n            synapse_id_or_path=entity_id,\n        )\n\n        self._set_last_persistent_instance()\n        return self\n\n    @otel_trace_method(\n        method_to_trace_name=lambda self, **kwargs: f\"Folder_Delete: {self.id}\"\n    )\n    async def delete_async(self, *, synapse_client: Optional[Synapse] = None) -&gt; None:\n        \"\"\"Delete the folder from Synapse by its id.\n\n        Arguments:\n            synapse_client: If not passed in or None this will use the last client from\n                the `.login()` method.\n\n        Returns:\n            None\n\n        Raises:\n            ValueError: If the folder does not have an id set.\n        \"\"\"\n        if not self.id:\n            raise ValueError(\"The folder must have an id set.\")\n        loop = asyncio.get_event_loop()\n        current_context = context.get_current()\n        await loop.run_in_executor(\n            None,\n            lambda: run_and_attach_otel_context(\n                lambda: Synapse.get_client(synapse_client=synapse_client).delete(\n                    obj=self.id,\n                ),\n                current_context=current_context,\n            ),\n        )\n\n    @otel_trace_method(\n        method_to_trace_name=lambda self, **kwargs: f\"Folder_Copy: {self.id}\"\n    )\n    async def copy_async(\n        self,\n        parent_id: str,\n        copy_annotations: bool = True,\n        exclude_types: Optional[List[str]] = None,\n        file_update_existing: bool = False,\n        file_copy_activity: Union[str, None] = \"traceback\",\n        *,\n        synapse_client: Optional[Synapse] = None,\n    ) -&gt; \"Folder\":\n        \"\"\"\n        Copy the folder to another Synapse location. This will recursively copy all\n        Tables, Links, Files, and Folders within the folder.\n\n        Arguments:\n            parent_id: Synapse ID of a folder/project that the copied entity is\n                being copied to\n            copy_annotations: True to copy the annotations.\n            exclude_types: A list of entity types ['file', 'table', 'link'] which\n                determines which entity types to not copy. Defaults to an empty list.\n            file_update_existing: When the destination has a file that has the same name,\n                users can choose to update that file.\n            file_copy_activity: Has three options to set the activity of the copied file:\n\n                    - traceback: Creates a copy of the source files Activity.\n                    - existing: Link to the source file's original Activity (if it exists)\n                    - None: No activity is set\n            synapse_client: If not passed in or None this will use the last client from\n                the `.login()` method.\n\n        Returns:\n            The copied folder object.\n\n        Example: Using this function\n            Assuming you have a folder with the ID \"syn123\" and you want to copy it to a\n            project with the ID \"syn456\":\n\n                new_folder_instance = await Folder(id=\"syn123\").copy_async(parent_id=\"syn456\")\n\n            Copy the folder but do not persist annotations:\n\n                new_folder_instance = await Folder(id=\"syn123\").copy_async(parent_id=\"syn456\", copy_annotations=False)\n\n        Raises:\n            ValueError: If the folder does not have an ID and parent_id to copy.\n        \"\"\"\n        if not self.id or not parent_id:\n            raise ValueError(\"The folder must have an ID and parent_id to copy.\")\n\n        loop = asyncio.get_event_loop()\n\n        current_context = context.get_current()\n        syn = Synapse.get_client(synapse_client=synapse_client)\n        source_and_destination = await loop.run_in_executor(\n            None,\n            lambda: run_and_attach_otel_context(\n                lambda: copy(\n                    syn=syn,\n                    entity=self.id,\n                    destinationId=parent_id,\n                    excludeTypes=exclude_types or [],\n                    skipCopyAnnotations=not copy_annotations,\n                    updateExisting=file_update_existing,\n                    setProvenance=file_copy_activity,\n                ),\n                current_context,\n            ),\n        )\n\n        new_folder_id = source_and_destination.get(self.id, None)\n        if not new_folder_id:\n            raise SynapseError(\"Failed to copy folder.\")\n        folder_copy = await (\n            await Folder(id=new_folder_id).get_async()\n        ).sync_from_synapse_async(\n            download_file=False,\n            synapse_client=synapse_client,\n        )\n        Synapse.get_client(synapse_client=synapse_client).logger.debug(\n            f\"Copied from folder {self.id} to {parent_id} with new id of {folder_copy.id}\"\n        )\n        return folder_copy\n</code></pre>"},{"location":"reference/oop/models_async/#synapseclient.models.Folder-functions","title":"Functions","text":""},{"location":"reference/oop/models_async/#synapseclient.models.Folder.get_async","title":"<code>get_async(parent=None, *, synapse_client=None)</code>  <code>async</code>","text":"<p>Get the folder metadata from Synapse. You are able to find a folder by either the id or the name and parent_id.</p> PARAMETER DESCRIPTION <code>parent</code> <p>The parent folder or project this folder exists under.</p> <p> TYPE: <code>Optional[Union[Folder, Project]]</code> DEFAULT: <code>None</code> </p> <code>synapse_client</code> <p>If not passed in or None this will use the last client from the <code>.login()</code> method.</p> <p> TYPE: <code>Optional[Synapse]</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>Folder</code> <p>The folder object.</p> RAISES DESCRIPTION <code>ValueError</code> <p>If the folder does not have an id or a (name and (<code>parent_id</code> or parent with an id)) set.</p> Source code in <code>synapseclient/models/folder.py</code> <pre><code>@otel_trace_method(\n    method_to_trace_name=lambda self, **kwargs: f\"Folder_Get: {self.id}\"\n)\nasync def get_async(\n    self,\n    parent: Optional[Union[\"Folder\", \"Project\"]] = None,\n    *,\n    synapse_client: Optional[Synapse] = None,\n) -&gt; \"Folder\":\n    \"\"\"Get the folder metadata from Synapse. You are able to find a folder by\n    either the id or the name and parent_id.\n\n    Arguments:\n        parent: The parent folder or project this folder exists under.\n        synapse_client: If not passed in or None this will use the last client from\n            the `.login()` method.\n\n    Returns:\n        The folder object.\n\n    Raises:\n        ValueError: If the folder does not have an id or a\n            (name and (`parent_id` or parent with an id)) set.\n    \"\"\"\n    parent_id = parent.id if parent else self.parent_id\n    if not (self.id or (self.name and parent_id)):\n        raise ValueError(\n            \"The folder must have an id or a \"\n            \"(name and (`parent_id` or parent with an id)) set.\"\n        )\n    self.parent_id = parent_id\n\n    entity_id = await get_id(entity=self, synapse_client=synapse_client)\n\n    await get_from_entity_factory(\n        entity_to_update=self,\n        synapse_id_or_path=entity_id,\n    )\n\n    self._set_last_persistent_instance()\n    return self\n</code></pre>"},{"location":"reference/oop/models_async/#synapseclient.models.Folder.store_async","title":"<code>store_async(parent=None, failure_strategy=FailureStrategy.LOG_EXCEPTION, *, synapse_client=None)</code>  <code>async</code>","text":"<p>Store folders and files to synapse. If you have any files or folders attached to this folder they will be stored as well. You may attach files and folders to this folder by setting the <code>files</code> and <code>folders</code> attributes.</p> <p>By default the store operation will non-destructively update the folder if you have not already retrieved the folder from Synapse. If you have already retrieved the folder from Synapse then the store operation will be destructive and will overwrite the folder with the current state of this object. See the <code>create_or_update</code> attribute for more information.</p> PARAMETER DESCRIPTION <code>parent</code> <p>The parent folder or project to store the folder in.</p> <p> TYPE: <code>Optional[Union[Folder, Project]]</code> DEFAULT: <code>None</code> </p> <code>failure_strategy</code> <p>Determines how to handle failures when storing attached Files and Folders under this Folder and an exception occurs.</p> <p> TYPE: <code>FailureStrategy</code> DEFAULT: <code>LOG_EXCEPTION</code> </p> <code>synapse_client</code> <p>If not passed in or None this will use the last client from the <code>.login()</code> method.</p> <p> TYPE: <code>Optional[Synapse]</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>Folder</code> <p>The folder object.</p> RAISES DESCRIPTION <code>ValueError</code> <p>If the folder does not have an id or a (name and (<code>parent_id</code> or parent with an id)) set.</p> Source code in <code>synapseclient/models/folder.py</code> <pre><code>@otel_trace_method(\n    method_to_trace_name=lambda self, **kwargs: f\"Folder_Store: {self.name}\"\n)\nasync def store_async(\n    self,\n    parent: Optional[Union[\"Folder\", \"Project\"]] = None,\n    failure_strategy: FailureStrategy = FailureStrategy.LOG_EXCEPTION,\n    *,\n    synapse_client: Optional[Synapse] = None,\n) -&gt; \"Folder\":\n    \"\"\"Store folders and files to synapse. If you have any files or folders attached\n    to this folder they will be stored as well. You may attach files and folders\n    to this folder by setting the `files` and `folders` attributes.\n\n    By default the store operation will non-destructively update the folder if\n    you have not already retrieved the folder from Synapse. If you have already\n    retrieved the folder from Synapse then the store operation will be destructive\n    and will overwrite the folder with the current state of this object. See the\n    `create_or_update` attribute for more information.\n\n    Arguments:\n        parent: The parent folder or project to store the folder in.\n        failure_strategy: Determines how to handle failures when storing attached\n            Files and Folders under this Folder and an exception occurs.\n        synapse_client: If not passed in or None this will use the last client from\n            the `.login()` method.\n\n    Returns:\n        The folder object.\n\n    Raises:\n        ValueError: If the folder does not have an id or a\n            (name and (`parent_id` or parent with an id)) set.\n    \"\"\"\n    parent_id = parent.id if parent else self.parent_id\n    if not (self.id or (self.name and parent_id)):\n        raise ValueError(\n            \"The folder must have an id or a \"\n            \"(name and (`parent_id` or parent with an id)) set.\"\n        )\n    self.parent_id = parent_id\n\n    if (\n        self.create_or_update\n        and not self._last_persistent_instance\n        and (\n            existing_folder_id := await get_id(\n                entity=self, failure_strategy=None, synapse_client=synapse_client\n            )\n        )\n        and (existing_folder := await Folder(id=existing_folder_id).get_async())\n    ):\n        merge_dataclass_entities(source=existing_folder, destination=self)\n    trace.get_current_span().set_attributes(\n        {\n            \"synapse.name\": self.name or \"\",\n            \"synapse.id\": self.id or \"\",\n        }\n    )\n    if self.has_changed:\n        loop = asyncio.get_event_loop()\n        synapse_folder = Synapse_Folder(\n            id=self.id,\n            name=self.name,\n            parent=parent_id,\n            etag=self.etag,\n            description=self.description,\n        )\n        delete_none_keys(synapse_folder)\n        current_context = context.get_current()\n        entity = await loop.run_in_executor(\n            None,\n            lambda: run_and_attach_otel_context(\n                lambda: Synapse.get_client(synapse_client=synapse_client).store(\n                    obj=synapse_folder,\n                    set_annotations=False,\n                    isRestricted=self.is_restricted,\n                    createOrUpdate=False,\n                ),\n                current_context,\n            ),\n        )\n\n        self.fill_from_dict(synapse_folder=entity, set_annotations=False)\n\n    await store_entity_components(\n        root_resource=self,\n        failure_strategy=failure_strategy,\n        synapse_client=synapse_client,\n    )\n    self._set_last_persistent_instance()\n    Synapse.get_client(synapse_client=synapse_client).logger.debug(\n        f\"Saved Folder {self.name}, id: {self.id}: parent: {self.parent_id}\"\n    )\n\n    return self\n</code></pre>"},{"location":"reference/oop/models_async/#synapseclient.models.Folder.delete_async","title":"<code>delete_async(*, synapse_client=None)</code>  <code>async</code>","text":"<p>Delete the folder from Synapse by its id.</p> PARAMETER DESCRIPTION <code>synapse_client</code> <p>If not passed in or None this will use the last client from the <code>.login()</code> method.</p> <p> TYPE: <code>Optional[Synapse]</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>None</code> <p>None</p> RAISES DESCRIPTION <code>ValueError</code> <p>If the folder does not have an id set.</p> Source code in <code>synapseclient/models/folder.py</code> <pre><code>@otel_trace_method(\n    method_to_trace_name=lambda self, **kwargs: f\"Folder_Delete: {self.id}\"\n)\nasync def delete_async(self, *, synapse_client: Optional[Synapse] = None) -&gt; None:\n    \"\"\"Delete the folder from Synapse by its id.\n\n    Arguments:\n        synapse_client: If not passed in or None this will use the last client from\n            the `.login()` method.\n\n    Returns:\n        None\n\n    Raises:\n        ValueError: If the folder does not have an id set.\n    \"\"\"\n    if not self.id:\n        raise ValueError(\"The folder must have an id set.\")\n    loop = asyncio.get_event_loop()\n    current_context = context.get_current()\n    await loop.run_in_executor(\n        None,\n        lambda: run_and_attach_otel_context(\n            lambda: Synapse.get_client(synapse_client=synapse_client).delete(\n                obj=self.id,\n            ),\n            current_context=current_context,\n        ),\n    )\n</code></pre>"},{"location":"reference/oop/models_async/#synapseclient.models.Folder.copy_async","title":"<code>copy_async(parent_id, copy_annotations=True, exclude_types=None, file_update_existing=False, file_copy_activity='traceback', *, synapse_client=None)</code>  <code>async</code>","text":"<p>Copy the folder to another Synapse location. This will recursively copy all Tables, Links, Files, and Folders within the folder.</p> PARAMETER DESCRIPTION <code>parent_id</code> <p>Synapse ID of a folder/project that the copied entity is being copied to</p> <p> TYPE: <code>str</code> </p> <code>copy_annotations</code> <p>True to copy the annotations.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> <code>exclude_types</code> <p>A list of entity types ['file', 'table', 'link'] which determines which entity types to not copy. Defaults to an empty list.</p> <p> TYPE: <code>Optional[List[str]]</code> DEFAULT: <code>None</code> </p> <code>file_update_existing</code> <p>When the destination has a file that has the same name, users can choose to update that file.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>file_copy_activity</code> <p>Has three options to set the activity of the copied file:</p> <pre><code>- traceback: Creates a copy of the source files Activity.\n- existing: Link to the source file's original Activity (if it exists)\n- None: No activity is set\n</code></pre> <p> TYPE: <code>Union[str, None]</code> DEFAULT: <code>'traceback'</code> </p> <code>synapse_client</code> <p>If not passed in or None this will use the last client from the <code>.login()</code> method.</p> <p> TYPE: <code>Optional[Synapse]</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>Folder</code> <p>The copied folder object.</p> Using this function <p>Assuming you have a folder with the ID \"syn123\" and you want to copy it to a project with the ID \"syn456\":</p> <pre><code>new_folder_instance = await Folder(id=\"syn123\").copy_async(parent_id=\"syn456\")\n</code></pre> <p>Copy the folder but do not persist annotations:</p> <pre><code>new_folder_instance = await Folder(id=\"syn123\").copy_async(parent_id=\"syn456\", copy_annotations=False)\n</code></pre> RAISES DESCRIPTION <code>ValueError</code> <p>If the folder does not have an ID and parent_id to copy.</p> Source code in <code>synapseclient/models/folder.py</code> <pre><code>@otel_trace_method(\n    method_to_trace_name=lambda self, **kwargs: f\"Folder_Copy: {self.id}\"\n)\nasync def copy_async(\n    self,\n    parent_id: str,\n    copy_annotations: bool = True,\n    exclude_types: Optional[List[str]] = None,\n    file_update_existing: bool = False,\n    file_copy_activity: Union[str, None] = \"traceback\",\n    *,\n    synapse_client: Optional[Synapse] = None,\n) -&gt; \"Folder\":\n    \"\"\"\n    Copy the folder to another Synapse location. This will recursively copy all\n    Tables, Links, Files, and Folders within the folder.\n\n    Arguments:\n        parent_id: Synapse ID of a folder/project that the copied entity is\n            being copied to\n        copy_annotations: True to copy the annotations.\n        exclude_types: A list of entity types ['file', 'table', 'link'] which\n            determines which entity types to not copy. Defaults to an empty list.\n        file_update_existing: When the destination has a file that has the same name,\n            users can choose to update that file.\n        file_copy_activity: Has three options to set the activity of the copied file:\n\n                - traceback: Creates a copy of the source files Activity.\n                - existing: Link to the source file's original Activity (if it exists)\n                - None: No activity is set\n        synapse_client: If not passed in or None this will use the last client from\n            the `.login()` method.\n\n    Returns:\n        The copied folder object.\n\n    Example: Using this function\n        Assuming you have a folder with the ID \"syn123\" and you want to copy it to a\n        project with the ID \"syn456\":\n\n            new_folder_instance = await Folder(id=\"syn123\").copy_async(parent_id=\"syn456\")\n\n        Copy the folder but do not persist annotations:\n\n            new_folder_instance = await Folder(id=\"syn123\").copy_async(parent_id=\"syn456\", copy_annotations=False)\n\n    Raises:\n        ValueError: If the folder does not have an ID and parent_id to copy.\n    \"\"\"\n    if not self.id or not parent_id:\n        raise ValueError(\"The folder must have an ID and parent_id to copy.\")\n\n    loop = asyncio.get_event_loop()\n\n    current_context = context.get_current()\n    syn = Synapse.get_client(synapse_client=synapse_client)\n    source_and_destination = await loop.run_in_executor(\n        None,\n        lambda: run_and_attach_otel_context(\n            lambda: copy(\n                syn=syn,\n                entity=self.id,\n                destinationId=parent_id,\n                excludeTypes=exclude_types or [],\n                skipCopyAnnotations=not copy_annotations,\n                updateExisting=file_update_existing,\n                setProvenance=file_copy_activity,\n            ),\n            current_context,\n        ),\n    )\n\n    new_folder_id = source_and_destination.get(self.id, None)\n    if not new_folder_id:\n        raise SynapseError(\"Failed to copy folder.\")\n    folder_copy = await (\n        await Folder(id=new_folder_id).get_async()\n    ).sync_from_synapse_async(\n        download_file=False,\n        synapse_client=synapse_client,\n    )\n    Synapse.get_client(synapse_client=synapse_client).logger.debug(\n        f\"Copied from folder {self.id} to {parent_id} with new id of {folder_copy.id}\"\n    )\n    return folder_copy\n</code></pre>"},{"location":"reference/oop/models_async/#synapseclient.models.Folder.sync_from_synapse_async","title":"<code>sync_from_synapse_async(path=None, recursive=True, download_file=True, if_collision=COLLISION_OVERWRITE_LOCAL, failure_strategy=FailureStrategy.LOG_EXCEPTION, include_activity=True, follow_link=False, link_hops=1, *, synapse_client=None)</code>  <code>async</code>","text":"<p>Sync this container and all possible sub-folders from Synapse. By default this will download the files that are found and it will populate the <code>files</code> and <code>folders</code> attributes with the found files and folders. If you only want to retrieve the full tree of metadata about your container specify <code>download_file</code> as False.</p> <p>This works similar to synapseutils.syncFromSynapse, however, this does not currently support the writing of data to a manifest TSV file. This will be a future enhancement.</p> <p>Only Files and Folders are supported at this time to be synced from synapse.</p> PARAMETER DESCRIPTION <code>path</code> <p>An optional path where the file hierarchy will be reproduced. If not specified the files will by default be placed in the synapseCache.</p> <p> TYPE: <code>Optional[str]</code> DEFAULT: <code>None</code> </p> <code>recursive</code> <p>Whether or not to recursively get the entire hierarchy of the folder and sub-folders.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> <code>download_file</code> <p>Whether to download the files found or not.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> <code>if_collision</code> <p>Determines how to handle file collisions. May be</p> <ul> <li><code>overwrite.local</code></li> <li><code>keep.local</code></li> <li><code>keep.both</code></li> </ul> <p> TYPE: <code>str</code> DEFAULT: <code>COLLISION_OVERWRITE_LOCAL</code> </p> <code>failure_strategy</code> <p>Determines how to handle failures when retrieving children under this Folder and an exception occurs.</p> <p> TYPE: <code>FailureStrategy</code> DEFAULT: <code>LOG_EXCEPTION</code> </p> <code>include_activity</code> <p>Whether to include the activity of the files.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> <code>follow_link</code> <p>Whether to follow a link entity or not. Links can be used to point at other Synapse entities.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>link_hops</code> <p>The number of hops to follow the link. A number of 1 is used to prevent circular references. There is nothing in place to prevent infinite loops. Be careful if setting this above 1.</p> <p> TYPE: <code>int</code> DEFAULT: <code>1</code> </p> <code>synapse_client</code> <p>If not passed in or None this will use the last client from the <code>.login()</code> method.</p> <p> TYPE: <code>Optional[Synapse]</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>Self</code> <p>The object that was called on. This will be the same object that was called on to start the sync.</p> Using this function <p>Suppose I want to walk the immediate children of a folder without downloading the files:</p> <pre><code>from synapseclient import Synapse\nfrom synapseclient.models import Folder\n\nsyn = Synapse()\nsyn.login()\n\nmy_folder = Folder(id=\"syn12345\")\nawait my_folder.sync_from_synapse_async(download_file=False, recursive=False)\n\nfor folder in my_folder.folders:\n    print(folder.name)\n\nfor file in my_folder.files:\n    print(file.name)\n</code></pre> <p>Suppose I want to download the immediate children of a folder:</p> <pre><code>from synapseclient import Synapse\nfrom synapseclient.models import Folder\n\nsyn = Synapse()\nsyn.login()\n\nmy_folder = Folder(id=\"syn12345\")\nawait my_folder.sync_from_synapse_async(path=\"/path/to/folder\", recursive=False)\n\nfor folder in my_folder.folders:\n    print(folder.name)\n\nfor file in my_folder.files:\n    print(file.name)\n</code></pre> <p>Suppose I want to download the immediate all children of a Project and all sub-folders and files:</p> <pre><code>from synapseclient import Synapse\nfrom synapseclient.models import Project\n\nsyn = Synapse()\nsyn.login()\n\nmy_project = Project(id=\"syn12345\")\nawait my_project.sync_from_synapse_async(path=\"/path/to/folder\")\n</code></pre> RAISES DESCRIPTION <code>ValueError</code> <p>If the folder does not have an id set.</p> <p>A sequence diagram for this method is as follows:</p> <pre><code>sequenceDiagram\n    autonumber\n    participant project_or_folder\n    activate project_or_folder\n    project_or_folder-&gt;&gt;sync_from_synapse: Recursive search and download files\n    activate sync_from_synapse\n        opt Current instance not retrieved from Synapse\n            sync_from_synapse-&gt;&gt;project_or_folder: Call `.get()` method\n            project_or_folder--&gt;&gt;sync_from_synapse: .\n        end\n\n        loop For each return of the generator\n            sync_from_synapse-&gt;&gt;client: call `.getChildren()` method\n            client--&gt;&gt;sync_from_synapse: .\n            note over sync_from_synapse: Append to a running list\n        end\n\n        loop For each child\n            note over sync_from_synapse: Create all `pending_tasks` at current depth\n\n            alt Child is File\n                note over sync_from_synapse: Append `file.get()` method\n            else Child is Folder\n                note over sync_from_synapse: Append `folder.get()` method\n                alt Recursive is True\n                    note over sync_from_synapse: Append `folder.sync_from_synapse()` method\n                end\n            else Child is Link and hops &gt; 0\n                note over sync_from_synapse: Append task to follow link\n            end\n        end\n\n        loop For each task in pending_tasks\n            par `file.get()`\n                sync_from_synapse-&gt;&gt;File: Retrieve File metadata and Optionally download\n                File-&gt;&gt;client: `.get()`\n                client--&gt;&gt;File: .\n                File--&gt;&gt;sync_from_synapse: .\n            and `folder.get()`\n                sync_from_synapse-&gt;&gt;Folder: Retrieve Folder metadataa\n                Folder-&gt;&gt;client: `.get()`\n                client--&gt;&gt;Folder: .\n                Folder--&gt;&gt;sync_from_synapse: .\n            and `folder.sync_from_synapse_async()`\n                note over sync_from_synapse: This is a recursive call to `sync_from_synapse`\n                sync_from_synapse-&gt;&gt;sync_from_synapse: Recursive call to `.sync_from_synapse_async()`\n            and `_follow_link`\n                sync_from_synapse -&gt;&gt;client: call `get_entity_id_bundle2` function\n                client--&gt;sync_from_synapse: .\n                note over sync_from_synapse: Do nothing if not link\n                note over sync_from_synapse: call `_create_task_for_child` and execute\n            end\n        end\n\n    deactivate sync_from_synapse\n    deactivate project_or_folder</code></pre> Source code in <code>synapseclient/models/mixins/storable_container.py</code> <pre><code>@otel_trace_method(\n    method_to_trace_name=lambda self, **kwargs: f\"{self.__class__.__name__}_sync_from_synapse: {self.id}\"\n)\nasync def sync_from_synapse_async(\n    self: Self,\n    path: Optional[str] = None,\n    recursive: bool = True,\n    download_file: bool = True,\n    if_collision: str = COLLISION_OVERWRITE_LOCAL,\n    failure_strategy: FailureStrategy = FailureStrategy.LOG_EXCEPTION,\n    include_activity: bool = True,\n    follow_link: bool = False,\n    link_hops: int = 1,\n    *,\n    synapse_client: Optional[Synapse] = None,\n) -&gt; Self:\n    \"\"\"\n    Sync this container and all possible sub-folders from Synapse. By default this\n    will download the files that are found and it will populate the\n    `files` and `folders` attributes with the found files and folders. If you only\n    want to retrieve the full tree of metadata about your container specify\n    `download_file` as False.\n\n    This works similar to [synapseutils.syncFromSynapse][], however, this does not\n    currently support the writing of data to a manifest TSV file. This will be a\n    future enhancement.\n\n    Only Files and Folders are supported at this time to be synced from synapse.\n\n    Arguments:\n        path: An optional path where the file hierarchy will be reproduced. If not\n            specified the files will by default be placed in the synapseCache.\n        recursive: Whether or not to recursively get the entire hierarchy of the\n            folder and sub-folders.\n        download_file: Whether to download the files found or not.\n        if_collision: Determines how to handle file collisions. May be\n\n            - `overwrite.local`\n            - `keep.local`\n            - `keep.both`\n        failure_strategy: Determines how to handle failures when retrieving children\n            under this Folder and an exception occurs.\n        include_activity: Whether to include the activity of the files.\n        follow_link: Whether to follow a link entity or not. Links can be used to\n            point at other Synapse entities.\n        link_hops: The number of hops to follow the link. A number of 1 is used to\n            prevent circular references. There is nothing in place to prevent\n            infinite loops. Be careful if setting this above 1.\n        synapse_client: If not passed in or None this will use the last client from\n            the `.login()` method.\n\n    Returns:\n        The object that was called on. This will be the same object that was called on\n            to start the sync.\n\n    Example: Using this function\n        Suppose I want to walk the immediate children of a folder without downloading the files:\n\n            from synapseclient import Synapse\n            from synapseclient.models import Folder\n\n            syn = Synapse()\n            syn.login()\n\n            my_folder = Folder(id=\"syn12345\")\n            await my_folder.sync_from_synapse_async(download_file=False, recursive=False)\n\n            for folder in my_folder.folders:\n                print(folder.name)\n\n            for file in my_folder.files:\n                print(file.name)\n\n        Suppose I want to download the immediate children of a folder:\n\n            from synapseclient import Synapse\n            from synapseclient.models import Folder\n\n            syn = Synapse()\n            syn.login()\n\n            my_folder = Folder(id=\"syn12345\")\n            await my_folder.sync_from_synapse_async(path=\"/path/to/folder\", recursive=False)\n\n            for folder in my_folder.folders:\n                print(folder.name)\n\n            for file in my_folder.files:\n                print(file.name)\n\n\n        Suppose I want to download the immediate all children of a Project and all sub-folders and files:\n\n            from synapseclient import Synapse\n            from synapseclient.models import Project\n\n            syn = Synapse()\n            syn.login()\n\n            my_project = Project(id=\"syn12345\")\n            await my_project.sync_from_synapse_async(path=\"/path/to/folder\")\n\n\n    Raises:\n        ValueError: If the folder does not have an id set.\n\n\n    A sequence diagram for this method is as follows:\n\n    ```mermaid\n    sequenceDiagram\n        autonumber\n        participant project_or_folder\n        activate project_or_folder\n        project_or_folder-&gt;&gt;sync_from_synapse: Recursive search and download files\n        activate sync_from_synapse\n            opt Current instance not retrieved from Synapse\n                sync_from_synapse-&gt;&gt;project_or_folder: Call `.get()` method\n                project_or_folder--&gt;&gt;sync_from_synapse: .\n            end\n\n            loop For each return of the generator\n                sync_from_synapse-&gt;&gt;client: call `.getChildren()` method\n                client--&gt;&gt;sync_from_synapse: .\n                note over sync_from_synapse: Append to a running list\n            end\n\n            loop For each child\n                note over sync_from_synapse: Create all `pending_tasks` at current depth\n\n                alt Child is File\n                    note over sync_from_synapse: Append `file.get()` method\n                else Child is Folder\n                    note over sync_from_synapse: Append `folder.get()` method\n                    alt Recursive is True\n                        note over sync_from_synapse: Append `folder.sync_from_synapse()` method\n                    end\n                else Child is Link and hops &gt; 0\n                    note over sync_from_synapse: Append task to follow link\n                end\n            end\n\n            loop For each task in pending_tasks\n                par `file.get()`\n                    sync_from_synapse-&gt;&gt;File: Retrieve File metadata and Optionally download\n                    File-&gt;&gt;client: `.get()`\n                    client--&gt;&gt;File: .\n                    File--&gt;&gt;sync_from_synapse: .\n                and `folder.get()`\n                    sync_from_synapse-&gt;&gt;Folder: Retrieve Folder metadataa\n                    Folder-&gt;&gt;client: `.get()`\n                    client--&gt;&gt;Folder: .\n                    Folder--&gt;&gt;sync_from_synapse: .\n                and `folder.sync_from_synapse_async()`\n                    note over sync_from_synapse: This is a recursive call to `sync_from_synapse`\n                    sync_from_synapse-&gt;&gt;sync_from_synapse: Recursive call to `.sync_from_synapse_async()`\n                and `_follow_link`\n                    sync_from_synapse -&gt;&gt;client: call `get_entity_id_bundle2` function\n                    client--&gt;sync_from_synapse: .\n                    note over sync_from_synapse: Do nothing if not link\n                    note over sync_from_synapse: call `_create_task_for_child` and execute\n                end\n            end\n\n        deactivate sync_from_synapse\n        deactivate project_or_folder\n    ```\n\n    \"\"\"\n    if not self._last_persistent_instance:\n        await self.get_async(synapse_client=synapse_client)\n    Synapse.get_client(synapse_client=synapse_client).logger.info(\n        f\"Syncing {self.__class__.__name__} ({self.id}:{self.name}) from Synapse.\"\n    )\n    path = os.path.expanduser(path) if path else None\n\n    loop = asyncio.get_event_loop()\n    current_context = context.get_current()\n    children = await loop.run_in_executor(\n        None,\n        lambda: run_and_attach_otel_context(\n            lambda: self._retrieve_children(\n                follow_link=follow_link,\n                synapse_client=synapse_client,\n            ),\n            current_context,\n        ),\n    )\n\n    pending_tasks = []\n    self.folders = []\n    self.files = []\n\n    for child in children:\n        pending_tasks.extend(\n            self._create_task_for_child(\n                child=child,\n                recursive=recursive,\n                path=path,\n                download_file=download_file,\n                if_collision=if_collision,\n                failure_strategy=failure_strategy,\n                synapse_client=synapse_client,\n                include_activity=include_activity,\n                follow_link=follow_link,\n                link_hops=link_hops,\n            )\n        )\n\n    for task in asyncio.as_completed(pending_tasks):\n        result = await task\n        self._resolve_sync_from_synapse_result(\n            result=result,\n            failure_strategy=failure_strategy,\n            synapse_client=synapse_client,\n        )\n    return self\n</code></pre>"},{"location":"reference/oop/models_async/#synapseclient.models.Folder.get_permissions_async","title":"<code>get_permissions_async(*, synapse_client=None)</code>  <code>async</code>","text":"<p>Get the permissions that the caller has on an Entity.</p> PARAMETER DESCRIPTION <code>synapse_client</code> <p>If not passed in or None this will use the last client from the <code>.login()</code> method.</p> <p> TYPE: <code>Optional[Synapse]</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>Permissions</code> <p>A Permissions object</p> Using this function: <p>Getting permissions for a Synapse Entity</p> <pre><code>permissions = await File(id=\"syn123\").get_permissions_async()\n</code></pre> <p>Getting access types list from the Permissions object</p> <pre><code>permissions.access_types\n</code></pre> Source code in <code>synapseclient/models/mixins/access_control.py</code> <pre><code>async def get_permissions_async(\n    self,\n    *,\n    synapse_client: Optional[Synapse] = None,\n) -&gt; \"Permissions\":\n    \"\"\"\n    Get the [permissions][synapseclient.core.models.permission.Permissions]\n    that the caller has on an Entity.\n\n    Arguments:\n        synapse_client: If not passed in or None this will use the last client\n            from the `.login()` method.\n\n    Returns:\n        A Permissions object\n\n\n    Example: Using this function:\n        Getting permissions for a Synapse Entity\n\n            permissions = await File(id=\"syn123\").get_permissions_async()\n\n        Getting access types list from the Permissions object\n\n            permissions.access_types\n    \"\"\"\n    loop = asyncio.get_event_loop()\n    current_context = context.get_current()\n\n    return await loop.run_in_executor(\n        None,\n        lambda: run_and_attach_otel_context(\n            lambda: Synapse.get_client(\n                synapse_client=synapse_client\n            ).get_permissions(entity=self.id),\n            current_context,\n        ),\n    )\n</code></pre>"},{"location":"reference/oop/models_async/#synapseclient.models.Folder.get_acl_async","title":"<code>get_acl_async(principal_id=None, *, synapse_client=None)</code>  <code>async</code>","text":"<p>Get the ACL that a user or group has on an Entity.</p> PARAMETER DESCRIPTION <code>principal_id</code> <p>Identifier of a user or group (defaults to PUBLIC users)</p> <p> TYPE: <code>int</code> DEFAULT: <code>None</code> </p> <code>synapse_client</code> <p>If not passed in or None this will use the last client from the <code>.login()</code> method.</p> <p> TYPE: <code>Optional[Synapse]</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>List[str]</code> <p>An array containing some combination of ['READ', 'UPDATE', 'CREATE', 'DELETE', 'DOWNLOAD', 'MODERATE', 'CHANGE_PERMISSIONS', 'CHANGE_SETTINGS'] or an empty array</p> Source code in <code>synapseclient/models/mixins/access_control.py</code> <pre><code>async def get_acl_async(\n    self, principal_id: int = None, *, synapse_client: Optional[Synapse] = None\n) -&gt; List[str]:\n    \"\"\"\n    Get the [ACL][synapseclient.core.models.permission.Permissions.access_types]\n    that a user or group has on an Entity.\n\n    Arguments:\n        principal_id: Identifier of a user or group (defaults to PUBLIC users)\n        synapse_client: If not passed in or None this will use the last client\n            from the `.login()` method.\n\n    Returns:\n        An array containing some combination of\n            ['READ', 'UPDATE', 'CREATE', 'DELETE', 'DOWNLOAD', 'MODERATE',\n            'CHANGE_PERMISSIONS', 'CHANGE_SETTINGS']\n            or an empty array\n    \"\"\"\n    loop = asyncio.get_event_loop()\n    current_context = context.get_current()\n\n    return await loop.run_in_executor(\n        None,\n        lambda: run_and_attach_otel_context(\n            lambda: Synapse.get_client(synapse_client=synapse_client).get_acl(\n                entity=self.id, principal_id=principal_id\n            ),\n            current_context,\n        ),\n    )\n</code></pre>"},{"location":"reference/oop/models_async/#synapseclient.models.Folder.set_permissions_async","title":"<code>set_permissions_async(principal_id=None, access_type=None, modify_benefactor=False, warn_if_inherits=True, overwrite=True, *, synapse_client=None)</code>  <code>async</code>","text":"<p>Sets permission that a user or group has on an Entity. An Entity may have its own ACL or inherit its ACL from a benefactor.</p> PARAMETER DESCRIPTION <code>principal_id</code> <p>Identifier of a user or group. <code>273948</code> is for all registered Synapse users and <code>273949</code> is for public access. None implies public access.</p> <p> TYPE: <code>int</code> DEFAULT: <code>None</code> </p> <code>access_type</code> <p>Type of permission to be granted. One or more of CREATE, READ, DOWNLOAD, UPDATE, DELETE, CHANGE_PERMISSIONS.</p> <p>Defaults to ['READ', 'DOWNLOAD']</p> <p> TYPE: <code>List[str]</code> DEFAULT: <code>None</code> </p> <code>modify_benefactor</code> <p>Set as True when modifying a benefactor's ACL</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>warn_if_inherits</code> <p>Set as False, when creating a new ACL. Trying to modify the ACL of an Entity that inherits its ACL will result in a warning</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> <code>overwrite</code> <p>By default this function overwrites existing permissions for the specified user. Set this flag to False to add new permissions non-destructively.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> <code>synapse_client</code> <p>If not passed in or None this will use the last client from the <code>.login()</code> method.</p> <p> TYPE: <code>Optional[Synapse]</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>Dict[str, Union[str, list]]</code> <p>An Access Control List object</p> Setting permissions <p>Grant all registered users download access</p> <pre><code>await File(id=\"syn123\").set_permissions_async(principal_id=273948, access_type=['READ','DOWNLOAD'])\n</code></pre> <p>Grant the public view access</p> <pre><code>await File(id=\"syn123\").set_permissions_async(principal_id=273949, access_type=['READ'])\n</code></pre> Source code in <code>synapseclient/models/mixins/access_control.py</code> <pre><code>async def set_permissions_async(\n    self,\n    principal_id: int = None,\n    access_type: List[str] = None,\n    modify_benefactor: bool = False,\n    warn_if_inherits: bool = True,\n    overwrite: bool = True,\n    *,\n    synapse_client: Optional[Synapse] = None,\n) -&gt; Dict[str, Union[str, list]]:\n    \"\"\"\n    Sets permission that a user or group has on an Entity.\n    An Entity may have its own ACL or inherit its ACL from a benefactor.\n\n    Arguments:\n        principal_id: Identifier of a user or group. `273948` is for all\n            registered Synapse users and `273949` is for public access.\n            None implies public access.\n        access_type: Type of permission to be granted. One or more of CREATE,\n            READ, DOWNLOAD, UPDATE, DELETE, CHANGE_PERMISSIONS.\n\n            **Defaults to ['READ', 'DOWNLOAD']**\n        modify_benefactor: Set as True when modifying a benefactor's ACL\n        warn_if_inherits: Set as False, when creating a new ACL. Trying to modify\n            the ACL of an Entity that inherits its ACL will result in a warning\n        overwrite: By default this function overwrites existing permissions for\n            the specified user. Set this flag to False to add new permissions\n            non-destructively.\n        synapse_client: If not passed in or None this will use the last client\n            from the `.login()` method.\n\n    Returns:\n        An Access Control List object\n\n    Example: Setting permissions\n        Grant all registered users download access\n\n            await File(id=\"syn123\").set_permissions_async(principal_id=273948, access_type=['READ','DOWNLOAD'])\n\n        Grant the public view access\n\n            await File(id=\"syn123\").set_permissions_async(principal_id=273949, access_type=['READ'])\n    \"\"\"\n    if access_type is None:\n        access_type = [\"READ\", \"DOWNLOAD\"]\n    loop = asyncio.get_event_loop()\n    current_context = context.get_current()\n\n    return await loop.run_in_executor(\n        None,\n        lambda: run_and_attach_otel_context(\n            lambda: Synapse.get_client(\n                synapse_client=synapse_client\n            ).setPermissions(\n                entity=self.id,\n                principalId=principal_id,\n                accessType=access_type,\n                modify_benefactor=modify_benefactor,\n                warn_if_inherits=warn_if_inherits,\n                overwrite=overwrite,\n            ),\n            current_context,\n        ),\n    )\n</code></pre>"},{"location":"reference/oop/models_async/#synapseclient.models.File","title":"<code>synapseclient.models.File</code>  <code>dataclass</code>","text":"<p>               Bases: <code>FileSynchronousProtocol</code>, <code>AccessControllable</code></p> <p>A file within Synapse.</p> ATTRIBUTE DESCRIPTION <code>id</code> <p>The unique immutable ID for this file. A new ID will be generated for new Files. Once issued, this ID is guaranteed to never change or be re-issued.</p> <p> TYPE: <code>Optional[str]</code> </p> <code>name</code> <p>The name of this entity. Must be 256 characters or less. Names may only contain: letters, numbers, spaces, underscores, hyphens, periods, plus signs, apostrophes, and parentheses. If not specified, the name will be derived from the file name.</p> <p> TYPE: <code>Optional[str]</code> </p> <code>path</code> <p>The path to the file on disk.</p> <p> TYPE: <code>Optional[str]</code> </p> <code>description</code> <p>The description of this file. Must be 1000 characters or less.</p> <p> TYPE: <code>Optional[str]</code> </p> <code>parent_id</code> <p>The ID of the Entity that is the parent of this Entity. Setting this to a new value and storing it will move this File under the new parent.</p> <p> TYPE: <code>Optional[str]</code> </p> <code>version_label</code> <p>The version label for this entity. Updates to the entity will increment the version number.</p> <p> TYPE: <code>Optional[str]</code> </p> <code>version_comment</code> <p>The version comment for this entity</p> <p> TYPE: <code>Optional[str]</code> </p> <code>data_file_handle_id</code> <p>ID of the file associated with this entity. You may define an existing data_file_handle_id to use the existing data_file_handle_id. The creator of the file must also be the owner of the data_file_handle_id to have permission to store the file.</p> <p> TYPE: <code>Optional[str]</code> </p> <code>external_url</code> <p>The external URL of this file. If this is set AND <code>synapse_store</code> is False, only a reference to this URL and the file metadata will be stored in Synapse. The file itself will not be uploaded. If this attribute is set it will override the <code>path</code>.</p> <p> TYPE: <code>Optional[str]</code> </p> <code>activity</code> <p>The Activity model represents the main record of Provenance in Synapse. It is analygous to the Activity defined in the W3C Specification on Provenance. Activity cannot be removed during a store operation by setting it to None. You must use: synapseclient.models.Activity.delete_async or synapseclient.models.Activity.disassociate_from_entity_async.</p> <p> TYPE: <code>Optional[Activity]</code> </p> <code>annotations</code> <p>Additional metadata associated with the folder. The key is the name of your desired annotations. The value is an object containing a list of values (use empty list to represent no values for key) and the value type associated with all values in the list. To remove all annotations set this to an empty dict <code>{}</code> or None and store the entity.</p> <p> TYPE: <code>Optional[Dict[str, Union[List[str], List[bool], List[float], List[int], List[date], List[datetime]]]]</code> </p> ATTRIBUTE DESCRIPTION <code>content_type</code> <p>(New Upload Only) Used to manually specify Content-type header, for example 'application/png' or 'application/json; charset=UTF-8'. If not specified, the content type will be derived from the file extension.</p> <p>This can be specified only during the initial store of this file or any time there is a new file to upload. In order to change this after the File has been created use synapseclient.models.File.change_metadata.</p> <p> TYPE: <code>Optional[str]</code> </p> <code>content_size</code> <p>(New Upload Only) The size of the file in bytes. This can be specified only during the initial creation of the File. This is also only applicable to files not uploaded to Synapse. ie: <code>synapse_store</code> is False.</p> <p> TYPE: <code>Optional[int]</code> </p> ATTRIBUTE DESCRIPTION <code>content_md5</code> <p>(Store only) The MD5 of the file is known. If not supplied this will be computed in the client is possible. If supplied for a file entity already stored in Synapse it will be calculated again to check if a new upload needs to occur. This will not be filled in during a read for data. It is only used during a store operation. To retrieve the md5 of the file after read from synapse use the <code>.file_handle.content_md5</code> attribute.</p> <p> TYPE: <code>Optional[str]</code> </p> <code>create_or_update</code> <p>(Store only) Indicates whether the method should automatically perform an update if the <code>file</code> conflicts with an existing Synapse object.</p> <p> TYPE: <code>bool</code> </p> <code>force_version</code> <p>(Store only) Indicates whether the method should increment the version of the object if something within the entity has changed. For example updating the description or name. You may set this to False and an update to the entity will not increment the version.</p> <p>Updating the <code>version_label</code> attribute will also cause a version update regardless  of this flag.</p> <p>An update to the MD5 of the file will force a version update regardless of this  flag.</p> <p> TYPE: <code>bool</code> </p> <code>is_restricted</code> <p>(Store only) If set to true, an email will be sent to the Synapse access control team to start the process of adding terms-of-use or review board approval for this entity. You will be contacted with regards to the specific data being restricted and the requirements of access.</p> <p>This may be used only by an administrator of the specified file.</p> <p> TYPE: <code>bool</code> </p> <code>merge_existing_annotations</code> <p>(Store only) Works in conjunction with <code>create_or_update</code> in that this is only evaluated if <code>create_or_update</code> is True. If this entity exists in Synapse that has annotations that are not present in a store operation, these annotations will be added to the entity. If this is False any annotations that are not present within a store operation will be removed from this entity. This allows one to complete a destructive update of annotations on an entity.</p> <p> TYPE: <code>bool</code> </p> <code>associate_activity_to_new_version</code> <p>(Store only) Works in conjunction with <code>create_or_update</code> in that this is only evaluated if <code>create_or_update</code> is True. When true an activity already attached to the current version of this entity will be associated the new version during a store operation if the version was updated. This is useful if you are updating the entity and want to ensure that the activity is persisted onto the new version the entity.</p> <p> TYPE: <code>bool</code> </p> <code>synapse_store</code> <p>(Store only) Whether the File should be uploaded or if false: only the path should be stored when synapseclient.models.File.store is called.</p> <p> TYPE: <code>bool</code> </p> ATTRIBUTE DESCRIPTION <code>download_file</code> <p>(Get only) If True the file will be downloaded.</p> <p> TYPE: <code>bool</code> </p> <code>download_location</code> <p>(Get only) The location to download the file to.</p> <p> TYPE: <code>str</code> </p> <code>if_collision</code> <p>(Get only) Determines how to handle file collisions. Defaults to \"keep.both\". May be:</p> <ul> <li><code>overwrite.local</code></li> <li><code>keep.local</code></li> <li><code>keep.both</code></li> </ul> <p> TYPE: <code>str</code> </p> <code>synapse_container_limit</code> <p>(Get only) A Synanpse ID used to limit the search in Synapse if file is specified as a local file. That is, if the file is stored in multiple locations in Synapse only the ones in the specified folder/project will be returned.</p> <p> TYPE: <code>Optional[str]</code> </p> ATTRIBUTE DESCRIPTION <code>etag</code> <p>(Read Only) Synapse employs an Optimistic Concurrency Control (OCC) scheme to handle concurrent updates. Since the E-Tag changes every time an entity is updated it is used to detect when a client's current representation of an entity is out-of-date.</p> <p> TYPE: <code>Optional[str]</code> </p> <code>created_on</code> <p>(Read Only) The date this entity was created.</p> <p> TYPE: <code>Optional[str]</code> </p> <code>modified_on</code> <p>(Read Only) The date this entity was last modified.</p> <p> TYPE: <code>Optional[str]</code> </p> <code>created_by</code> <p>(Read Only) The ID of the user that created this entity.</p> <p> TYPE: <code>Optional[str]</code> </p> <code>modified_by</code> <p>(Read Only) The ID of the user that last modified this entity.</p> <p> TYPE: <code>Optional[str]</code> </p> <code>version_number</code> <p>(Read Only) The version number issued to this version on the object.</p> <p> TYPE: <code>Optional[int]</code> </p> <code>is_latest_version</code> <p>(Read Only) If this is the latest version of the object.</p> <p> TYPE: <code>Optional[bool]</code> </p> <code>file_handle</code> <p>(Read Only) The file handle associated with this entity.</p> <p> TYPE: <code>Optional[FileHandle]</code> </p> Source code in <code>synapseclient/models/file.py</code> <pre><code>@dataclass()\n@async_to_sync\nclass File(FileSynchronousProtocol, AccessControllable):\n    \"\"\"A file within Synapse.\n\n    Attributes:\n        id: The unique immutable ID for this file. A new ID will be generated for new\n            Files. Once issued, this ID is guaranteed to never change or be re-issued.\n        name: The name of this entity. Must be 256 characters or less. Names may only\n            contain: letters, numbers, spaces, underscores, hyphens, periods, plus\n            signs, apostrophes, and parentheses. If not specified, the name will be\n            derived from the file name.\n        path: The path to the file on disk.\n        description: The description of this file. Must be 1000 characters or less.\n        parent_id: The ID of the Entity that is the parent of this Entity. Setting this\n            to a new value and storing it will move this File under the new parent.\n        version_label: The version label for this entity. Updates to the entity will\n            increment the version number.\n        version_comment: The version comment for this entity\n        data_file_handle_id: ID of the file associated with this entity. You may define\n            an existing data_file_handle_id to use the existing data_file_handle_id. The\n            creator of the file must also be the owner of the data_file_handle_id to\n            have permission to store the file.\n        external_url: The external URL of this file. If this is set AND `synapse_store`\n            is False, only a reference to this URL and the file metadata will be stored\n            in Synapse. The file itself will not be uploaded. If this attribute is set\n            it will override the `path`.\n        activity: The Activity model represents the main record of Provenance in\n            Synapse. It is analygous to the Activity defined in the\n            [W3C Specification](https://www.w3.org/TR/prov-n/) on Provenance. Activity\n            cannot be removed during a store operation by setting it to None. You must\n            use: [synapseclient.models.Activity.delete_async][] or\n            [synapseclient.models.Activity.disassociate_from_entity_async][].\n        annotations: Additional metadata associated with the folder. The key is the name\n            of your desired annotations. The value is an object containing a list of\n            values (use empty list to represent no values for key) and the value type\n            associated with all values in the list. To remove all annotations set this\n            to an empty dict `{}` or None and store the entity.\n\n    Attributes:\n        content_type: (New Upload Only)\n            Used to manually specify Content-type header, for example\n            'application/png' or 'application/json; charset=UTF-8'. If not specified,\n            the content type will be derived from the file extension.\n\n\n            This can be specified only during the initial store of this file or any time\n            there is a new file to upload.\n            In order to change this after the File has been created use\n            [synapseclient.models.File.change_metadata][].\n        content_size: (New Upload Only)\n            The size of the file in bytes. This can be specified only during the initial\n            creation of the File. This is also only applicable to files not uploaded to\n            Synapse. ie: `synapse_store` is False.\n\n    Attributes:\n        content_md5: (Store only) The MD5 of the file is known. If not supplied this\n            will be computed in the client is possible. If supplied for a file entity\n            already stored in Synapse it will be calculated again to check if a new\n            upload needs to occur. This will not be filled in during a read for data. It\n            is only used during a store operation. To retrieve the md5 of the file after\n            read from synapse use the `.file_handle.content_md5` attribute.\n        create_or_update: (Store only)\n            Indicates whether the method should automatically perform an\n            update if the `file` conflicts with an existing Synapse object.\n        force_version: (Store only)\n            Indicates whether the method should increment the version of the object if\n            something within the entity has changed. For example updating the\n            description or name. You may set this to False and an update to the\n            entity will not increment the version.\n\n            Updating the `version_label` attribute will also cause a version update\n            regardless  of this flag.\n\n            An update to the MD5 of the file will force a version update regardless of\n            this  flag.\n        is_restricted: (Store only)\n            If set to true, an email will be sent to the Synapse access control\n            team to start the process of adding terms-of-use or review board approval\n            for this entity. You will be contacted with regards to the specific data\n            being restricted and the requirements of access.\n\n            This may be used only by an administrator of the specified file.\n        merge_existing_annotations: (Store only)\n            Works in conjunction with `create_or_update` in that this is only evaluated\n            if `create_or_update` is True. If this entity exists in Synapse that has\n            annotations that are not present in a store operation, these annotations\n            will be added to the entity. If this is False any annotations that are not\n            present within a store operation will be removed from this entity. This\n            allows one to complete a destructive update of annotations on an entity.\n        associate_activity_to_new_version: (Store only)\n            Works in conjunction with `create_or_update` in that this is only evaluated\n            if `create_or_update` is True. When true an activity already attached to the\n            current version of this entity will be associated the new version during a\n            store operation if the version was updated. This is useful if you are\n            updating the entity and want to ensure that the activity is persisted onto\n            the new version the entity.\n        synapse_store: (Store only)\n            Whether the File should be uploaded or if false: only the path should\n            be stored when [synapseclient.models.File.store][] is called.\n\n    Attributes:\n        download_file: (Get only) If True the file will be downloaded.\n        download_location: (Get only) The location to download the file to.\n        if_collision: (Get only)\n            Determines how to handle file collisions. Defaults to \"keep.both\". May be:\n\n            - `overwrite.local`\n            - `keep.local`\n            - `keep.both`\n        synapse_container_limit: (Get only)\n            A Synanpse ID used to limit the search in Synapse if\n            file is specified as a local file. That is, if the file is stored in\n            multiple locations in Synapse only the ones in the specified folder/project\n            will be returned.\n\n    Attributes:\n        etag: (Read Only) Synapse employs an Optimistic Concurrency Control (OCC) scheme\n            to handle concurrent updates. Since the E-Tag changes every time an entity\n            is updated it is used to detect when a client's current representation of an\n            entity is out-of-date.\n        created_on: (Read Only) The date this entity was created.\n        modified_on: (Read Only) The date this entity was last modified.\n        created_by: (Read Only) The ID of the user that created this entity.\n        modified_by: (Read Only) The ID of the user that last modified this entity.\n        version_number: (Read Only) The version number issued to this version on the\n            object.\n        is_latest_version: (Read Only) If this is the latest version of the object.\n        file_handle: (Read Only) The file handle associated with this entity.\n    \"\"\"\n\n    id: Optional[str] = None\n    \"\"\"The unique immutable ID for this file. A new ID will be generated for new Files.\n    Once issued, this ID is guaranteed to never change or be re-issued.\"\"\"\n\n    name: Optional[str] = None\n    \"\"\"\n    The name of this entity. Must be 256 characters or less.\n    Names may only contain: letters, numbers, spaces, underscores, hyphens, periods,\n    plus signs, apostrophes, and parentheses. If not specified, the name will be\n    derived from the file name.\n    \"\"\"\n\n    path: Optional[str] = field(default=None, compare=False)\n    \"\"\"The path to the file on disk.\"\"\"\n\n    description: Optional[str] = None\n    \"\"\"The description of this file. Must be 1000 characters or less.\"\"\"\n\n    parent_id: Optional[str] = None\n    \"\"\"The ID of the Entity that is the parent of this Entity. Setting this to a new\n    value and storing it will move this File under the new parent.\"\"\"\n\n    version_label: Optional[str] = None\n    \"\"\"The version label for this entity. Updates to the entity will increment the\n    version number.\"\"\"\n\n    version_comment: Optional[str] = None\n    \"\"\"The version comment for this entity.\"\"\"\n\n    data_file_handle_id: Optional[str] = None\n    \"\"\"\n    ID of the file handle associated with this entity. You may define an existing\n    data_file_handle_id to use the existing data_file_handle_id. The creator of the\n    file must also be the owner of the data_file_handle_id to have permission to\n    store the file.\n    \"\"\"\n\n    external_url: Optional[str] = field(default=None, compare=False)\n    \"\"\"\n    The external URL of this file. If this is set AND `synapse_store` is False, only\n    a reference to this URL and the file metadata will be stored in Synapse. The file\n    itself will not be uploaded. If this attribute is set it will override the `path`.\n    \"\"\"\n\n    activity: Optional[Activity] = field(default=None, compare=False)\n    \"\"\"The Activity model represents the main record of Provenance in Synapse.  It is\n    analygous to the Activity defined in the\n    [W3C Specification](https://www.w3.org/TR/prov-n/) on Provenance. Activity cannot\n    be removed during a store operation by setting it to None. You must use:\n    [synapseclient.models.Activity.delete_async][] or\n    [synapseclient.models.Activity.disassociate_from_entity_async][].\n    \"\"\"\n\n    annotations: Optional[\n        Dict[\n            str,\n            Union[\n                List[str],\n                List[bool],\n                List[float],\n                List[int],\n                List[date],\n                List[datetime],\n            ],\n        ]\n    ] = field(default_factory=dict, compare=False)\n    \"\"\"Additional metadata associated with the folder. The key is the name of your\n    desired annotations. The value is an object containing a list of values\n    (use empty list to represent no values for key) and the value type associated with\n    all values in the list. To remove all annotations set this to an empty dict `{}`.\"\"\"\n\n    content_type: Optional[str] = None\n    \"\"\"\n    (New Upload Only)\n    Used to manually specify Content-type header, for example 'application/png'\n    or 'application/json; charset=UTF-8'. If not specified, the content type will be\n    derived from the file extension.\n\n    This can be specified only during the initial store of this file. In order to change\n    this after the File has been created use\n    [synapseclient.models.File.change_metadata][].\n    \"\"\"\n\n    content_size: Optional[int] = None\n    \"\"\"\n    (New Upload Only)\n    The size of the file in bytes. This can be specified only during the initial\n    creation of the File. This is also only applicable to files not uploaded to Synapse.\n    ie: `synapse_store` is False.\n    \"\"\"\n\n    content_md5: Optional[str] = field(default=None, compare=False)\n    \"\"\"\n    (Store only)\n    The MD5 of the file is known. If not supplied this will be computed in the client\n    is possible. If supplied for a file entity already stored in Synapse it will be\n    calculated again to check if a new upload needs to occur. This will not be filled\n    in during a read for data. It is only used during a store operation. To retrieve\n    the md5 of the file after read from synapse use the `.file_handle.content_md5`\n    attribute.\n    \"\"\"\n\n    create_or_update: bool = field(default=True, repr=False, compare=False)\n    \"\"\"\n    (Store only)\n\n    Indicates whether the method should automatically perform an update if the file\n    conflicts with an existing Synapse object.\n    \"\"\"\n\n    force_version: bool = field(default=True, repr=False, compare=False)\n    \"\"\"\n    (Store only)\n\n    Indicates whether the method should increment the version of the object if something\n    within the entity has changed. For example updating the description or name.\n    You may set this to False and an update to the entity will not increment the\n    version.\n\n    Updating the `version_label` attribute will also cause a version update regardless\n    of this flag.\n\n    An update to the MD5 of the file will force a version update regardless of this\n    flag.\n    \"\"\"\n\n    is_restricted: bool = field(default=False, repr=False)\n    \"\"\"\n    (Store only)\n\n    If set to true, an email will be sent to the Synapse access control team to start\n    the process of adding terms-of-use or review board approval for this entity.\n    You will be contacted with regards to the specific data being restricted and the\n    requirements of access.\n\n    This may be used only by an administrator of the specified file.\n    \"\"\"\n\n    merge_existing_annotations: bool = field(default=True, repr=False, compare=False)\n    \"\"\"\n    (Store only)\n\n    Works in conjunction with `create_or_update` in that this is only evaluated if\n    `create_or_update` is True. If this entity exists in Synapse that has annotations\n    that are not present in a store operation, these annotations will be added to the\n    entity. If this is False any annotations that are not present within a store\n    operation will be removed from this entity. This allows one to complete a\n    destructive update of annotations on an entity.\n    \"\"\"\n\n    associate_activity_to_new_version: bool = field(\n        default=False, repr=False, compare=False\n    )\n    \"\"\"\n    (Store only)\n\n    Works in conjunction with `create_or_update` in that this is only evaluated if\n    `create_or_update` is True. When true an activity already attached to the current\n    version of this entity will be associated the new version during a store operation\n    if the version was updated. This is useful if you are updating the entity and want\n    to ensure that the activity is persisted onto the new version the entity.\n\n    When this is False the activity will not be associated to the new version of the\n    entity during a store operation.\n\n    Regardless of this setting, if you have an Activity object on the entity it will be\n    persisted onto the new version. This is only used when you don't have an Activity\n    object on the entity.\n    \"\"\"\n\n    _present_manifest_fields: List[str] = field(default=None, repr=False, compare=False)\n    \"\"\"Hidden attribute to pass along what columns were present in a manifest upload.\"\"\"\n\n    synapse_store: bool = field(default=True, repr=False)\n    \"\"\"\n    (Store only)\n\n    Whether the File should be uploaded or if false: only the path should be stored when\n    [synapseclient.models.File.store][] is called.\n    \"\"\"\n\n    download_file: bool = field(default=True, repr=False, compare=False)\n    \"\"\"\n    (Get only)\n\n    If True the file will be downloaded.\"\"\"\n\n    download_location: str = field(default=None, repr=False, compare=False)\n    \"\"\"\n    (Get only)\n\n    The location to download the file to.\"\"\"\n\n    if_collision: str = field(default=\"keep.both\", repr=False, compare=False)\n    \"\"\"\n    (Get only)\n\n    Determines how to handle file collisions. Defaults to \"keep.both\".\n            May be\n\n            - `overwrite.local`\n            - `keep.local`\n            - `keep.both`\n    \"\"\"\n\n    synapse_container_limit: Optional[str] = field(\n        default=None, repr=False, compare=False\n    )\n    \"\"\"A Synanpse ID used to limit the search in Synapse if file is specified as a local\n    file. That is, if the file is stored in multiple locations in Synapse only the\n    ones in the specified folder/project will be returned.\"\"\"\n\n    etag: Optional[str] = field(default=None, compare=False)\n    \"\"\"\n    (Read Only)\n    Synapse employs an Optimistic Concurrency Control (OCC) scheme to handle\n    concurrent updates. Since the E-Tag changes every time an entity is updated it is\n    used to detect when a client's current representation of an entity is out-of-date.\n    \"\"\"\n\n    created_on: Optional[str] = field(default=None, compare=False)\n    \"\"\"(Read Only) The date this entity was created.\"\"\"\n\n    modified_on: Optional[str] = field(default=None, compare=False)\n    \"\"\"(Read Only) The date this entity was last modified.\"\"\"\n\n    created_by: Optional[str] = field(default=None, compare=False)\n    \"\"\"(Read Only) The ID of the user that created this entity.\"\"\"\n\n    modified_by: Optional[str] = field(default=None, compare=False)\n    \"\"\"(Read Only) The ID of the user that last modified this entity.\"\"\"\n\n    version_number: Optional[int] = field(default=None, compare=False)\n    \"\"\"(Read Only) The version number issued to this version on the object.\"\"\"\n\n    is_latest_version: Optional[bool] = field(default=None, compare=False)\n    \"\"\"(Read Only) If this is the latest version of the object.\"\"\"\n\n    file_handle: Optional[FileHandle] = field(default=None, compare=False)\n    \"\"\"(Read Only) The file handle associated with this entity.\"\"\"\n\n    _last_persistent_instance: Optional[\"File\"] = field(\n        default=None, repr=False, compare=False\n    )\n    \"\"\"The last persistent instance of this object. This is used to determine if the\n    object has been changed and needs to be updated in Synapse.\"\"\"\n\n    @property\n    def has_changed(self) -&gt; bool:\n        \"\"\"Determines if the object has been changed and needs to be updated in Synapse.\"\"\"\n        return (\n            not self._last_persistent_instance or self._last_persistent_instance != self\n        )\n\n    def _set_last_persistent_instance(self) -&gt; None:\n        \"\"\"Stash the last time this object interacted with Synapse. This is used to\n        determine if the object has been changed and needs to be updated in Synapse.\"\"\"\n        del self._last_persistent_instance\n        self._last_persistent_instance = dataclasses.replace(self)\n        self._last_persistent_instance.activity = (\n            dataclasses.replace(self.activity) if self.activity else None\n        )\n        self._last_persistent_instance.annotations = (\n            deepcopy(self.annotations) if self.annotations else {}\n        )\n\n    def _fill_from_file_handle(self) -&gt; None:\n        \"\"\"Fill the file object from the file handle.\"\"\"\n        if self.file_handle:\n            self.data_file_handle_id = self.file_handle.id\n            self.content_type = self.file_handle.content_type\n            self.content_size = self.file_handle.content_size\n            self.external_url = self.file_handle.external_url\n\n    def fill_from_dict(\n        self,\n        synapse_file: Union[Synapse_File, Dict[str, Union[bool, str, int]]],\n        set_annotations: bool = True,\n    ) -&gt; \"File\":\n        \"\"\"\n        Converts a response from the REST API into this dataclass.\n\n        Arguments:\n            synapse_file: The response from the REST API.\n            set_annotations: Whether to set the annotations from the response.\n\n        Returns:\n            The File object.\n        \"\"\"\n        self.id = synapse_file.get(\"id\", None)\n        self.name = synapse_file.get(\"name\", None)\n        self.description = synapse_file.get(\"description\", None)\n        self.etag = synapse_file.get(\"etag\", None)\n        self.created_on = synapse_file.get(\"createdOn\", None)\n        self.modified_on = synapse_file.get(\"modifiedOn\", None)\n        self.created_by = synapse_file.get(\"createdBy\", None)\n        self.modified_by = synapse_file.get(\"modifiedBy\", None)\n        self.parent_id = synapse_file.get(\"parentId\", None)\n        self.version_number = synapse_file.get(\"versionNumber\", None)\n        self.version_label = synapse_file.get(\"versionLabel\", None)\n        self.version_comment = synapse_file.get(\"versionComment\", None)\n        self.is_latest_version = synapse_file.get(\"isLatestVersion\", False)\n        self.data_file_handle_id = synapse_file.get(\"dataFileHandleId\", None)\n        self.path = synapse_file.get(\"path\", self.path)\n        synapse_file_handle = synapse_file.get(\"_file_handle\", None)\n        if synapse_file_handle:\n            file_handle = self.file_handle or FileHandle()\n            self.file_handle = file_handle.fill_from_dict(\n                synapse_instance=synapse_file_handle\n            )\n            self._fill_from_file_handle()\n\n        if set_annotations:\n            self.annotations = Annotations.from_dict(\n                synapse_file.get(\"annotations\", {})\n            )\n        return self\n\n    def _cannot_store(self) -&gt; bool:\n        \"\"\"Determines based on some guard conditions if we are unable to continue with\n        a store operation.\"\"\"\n        return (\n            not (\n                self.id is not None\n                and (self.path is not None or self.data_file_handle_id is not None)\n            )\n            and not (self.path is not None and self.parent_id is not None)\n            and not (\n                self.parent_id is not None and self.data_file_handle_id is not None\n            )\n        )\n\n    async def _load_local_md5(self) -&gt; None:\n        \"\"\"Load the MD5 of the file if it's a local file and we have not already loaded\n        it.\"\"\"\n        if not self.content_md5 and self.path and os.path.isfile(self.path):\n            self.content_md5 = utils.md5_for_file_hex(filename=self.path)\n\n    async def _find_existing_file(\n        self, *, synapse_client: Optional[Synapse] = None\n    ) -&gt; Union[\"File\", None]:\n        \"\"\"Determines if the file already exists in Synapse. If it does it will return\n        the file object, otherwise it will return None. This is used to determine if the\n        file should be updated or created.\"\"\"\n\n        async def get_file(existing_id: str) -&gt; \"File\":\n            \"\"\"Small wrapper to retrieve a file instance without raising an error if it\n            does not exist.\n\n            Arguments:\n                existing_id: The ID of the file to retrieve.\n\n            Returns:\n                The file object if it exists, otherwise None.\n            \"\"\"\n            try:\n                file_copy = File(\n                    id=existing_id,\n                    download_file=False,\n                    version_number=self.version_number,\n                    synapse_container_limit=self.synapse_container_limit,\n                    parent_id=self.parent_id,\n                )\n                return await file_copy.get_async(\n                    synapse_client=synapse_client,\n                    include_activity=self.activity is not None\n                    or self.associate_activity_to_new_version,\n                )\n            except SynapseFileNotFoundError:\n                return None\n\n        if (\n            self.create_or_update\n            and not self._last_persistent_instance\n            and (\n                existing_file_id := await get_id(\n                    entity=self,\n                    failure_strategy=None,\n                    synapse_client=synapse_client,\n                )\n            )\n            and (existing_file := await get_file(existing_file_id))\n        ):\n            return existing_file\n        return None\n\n    def _determine_fields_to_ignore_in_merge(self) -&gt; List[str]:\n        \"\"\"This is used to determine what fields should not be merged when merging two\n        entities. This allows for a fine tuned destructive update of an entity.\n\n        This also has special handling during a manifest upload of files. If a manifest\n        is specifying fields we'll use those values rather than copying them from the\n        existing entity. This is to allow for a destructive update of an entity.\n\n        \"\"\"\n        fields_to_not_merge = []\n        if not self.merge_existing_annotations:\n            fields_to_not_merge.append(\"annotations\")\n\n        if not self.associate_activity_to_new_version:\n            fields_to_not_merge.append(\"activity\")\n\n        if self._present_manifest_fields:\n            if \"name\" in self._present_manifest_fields:\n                fields_to_not_merge.append(\"name\")\n\n            if \"contentType\" in self._present_manifest_fields:\n                fields_to_not_merge.append(\"content_type\")\n\n        return fields_to_not_merge\n\n    @otel_trace_method(\n        method_to_trace_name=lambda self, **kwargs: f\"File_Store: {self.path if self.path else self.id}\"\n    )\n    async def store_async(\n        self,\n        parent: Optional[Union[\"Folder\", \"Project\"]] = None,\n        *,\n        synapse_client: Optional[Synapse] = None,\n    ) -&gt; \"File\":\n        \"\"\"\n        Store the file in Synapse. With this method you may:\n\n        - Upload a file into Synapse\n        - Update the metadata of a file in Synapse\n        - Store a File object in Synapse without updating a file by setting\n            `synapse_store` to False.\n        - Change the name of a file in Synapse by setting the `name` attribute of the\n            File object. Also see the [synapseclient.models.File.change_metadata][]\n            method for changing the name of the downloaded file.\n        - Moving a file to a new parent by setting the `parent_id` attribute of the\n            File object.\n\n        If no Name is specified this will be derived from the file name. This is the\n        reccommended way to store a file in Synapse.\n\n        Please note:\n        The file, as it appears on disk, will be the file that is downloaded from\n        Synapse. The name of the actual File is different from the name of the File\n        Entity in Synapse. It is generally not reccommended to specify a different\n        name for the Entity and the file as it will cause confusion and potential\n        conflicts later on.\n\n        Arguments:\n            parent: The parent folder or project to store the file in. May also be\n                specified in the File object. If both are provided the parent passed\n                into `store` will take precedence.\n            synapse_client: If not passed in or None this will use the last client from\n                the `.login()` method.\n\n        Returns:\n            The file object.\n\n        Raises:\n            ValueError: If the file does not have an ID and a path, or a path and a\n                parent ID, or a data file handle ID and a parent ID.\n\n        Example: Using this function\n            File with the ID `syn123` at path `path/to/file.txt`:\n\n                file_instance = await File(id=\"syn123\", path=\"path/to/file.txt\").store_async()\n\n            File at the path `path/to/file.txt` and a parent folder with the ID `syn456`:\n\n                file_instance = await File(path=\"path/to/file.txt\", parent_id=\"syn456\").store_async()\n\n            File at the path `path/to/file.txt` and a parent folder with the ID `syn456`:\n\n                file_instance = await File(path=\"path/to/file.txt\").store_async(parent=Folder(id=\"syn456\"))\n\n            File with a parent and existing file handle (This allows multiple entities to reference the underlying file):\n\n                file_instance = await File(data_file_handle_id=\"123\", parent_id=\"syn456\").store_async()\n\n            Rename a file (Does not update the file on disk or the name of the downloaded file):\n\n                file_instance = await File(id=\"syn123\", download_file=False).get_async()\n                print(file_instance.name)  ## prints, e.g., \"my_file.txt\"\n                await file_instance.change_metadata_async(name=\"my_new_name_file.txt\")\n\n            Rename a file, and the name of the file as downloaded\n                (Does not update the file on disk). Is is reccommended that `name` and\n                `download_as` match to prevent confusion later on:\n\n                file_instance = await File(id=\"syn123\", download_file=False).get_async()\n                print(file_instance.name)  ## prints, e.g., \"my_file.txt\"\n                await file_instance.change_metadata_async(name=\"my_new_name_file.txt\", download_as=\"my_new_name_file.txt\")\n\n        \"\"\"\n        self.parent_id = parent.id if parent else self.parent_id\n        if self._cannot_store():\n            raise ValueError(\n                \"The file must have an (ID with a (path or `data_file_handle_id`)), or a \"\n                \"(path with a (`parent_id` or parent with an id)), or a \"\n                \"(data_file_handle_id with a (`parent_id` or parent with an id)) to store.\"\n            )\n        self.name = self.name or (guess_file_name(self.path) if self.path else None)\n        client = Synapse.get_client(synapse_client=synapse_client)\n\n        if existing_file := await self._find_existing_file(synapse_client=client):\n            merge_dataclass_entities(\n                source=existing_file,\n                destination=self,\n                fields_to_ignore=self._determine_fields_to_ignore_in_merge(),\n            )\n\n        if self.path:\n            self.path = os.path.expanduser(self.path)\n            async with client._get_parallel_file_transfer_semaphore(\n                asyncio_event_loop=asyncio.get_running_loop()\n            ):\n                await self._upload_file(synapse_client=client)\n        elif self.data_file_handle_id:\n            self.path = client.cache.get(file_handle_id=self.data_file_handle_id)\n\n        if self.has_changed:\n            synapse_file = Synapse_File(\n                id=self.id,\n                path=self.path,\n                description=self.description,\n                etag=self.etag,\n                name=self.name,\n                parent=parent.id if parent else self.parent_id,\n                contentType=self.content_type,\n                contentSize=self.content_size,\n                dataFileHandleId=self.data_file_handle_id,\n                synapseStore=self.synapse_store,\n                modifiedOn=self.modified_on,\n                versionLabel=self.version_label,\n                versionNumber=self.version_number,\n                versionComment=self.version_comment,\n            )\n            delete_none_keys(synapse_file)\n\n            entity = await store_entity(\n                resource=self, entity=synapse_file, synapse_client=client\n            )\n\n            self.fill_from_dict(synapse_file=entity, set_annotations=False)\n\n        re_read_required = await store_entity_components(\n            root_resource=self, synapse_client=client\n        )\n        if re_read_required:\n            before_download_file = self.download_file\n            self.download_file = False\n            await self.get_async(\n                synapse_client=client,\n            )\n            self.download_file = before_download_file\n\n        self._set_last_persistent_instance()\n\n        client.logger.debug(f\"Stored File {self.name}, id: {self.id}: {self.path}\")\n        # Clear the content_md5 so that it is recalculated if the file is updated\n        self.content_md5 = None\n        return self\n\n    @otel_trace_method(\n        method_to_trace_name=lambda self, **kwargs: f\"File_Change_Metadata: {self.id}\"\n    )\n    async def change_metadata_async(\n        self,\n        name: Optional[str] = None,\n        download_as: Optional[str] = None,\n        content_type: Optional[str] = None,\n        *,\n        synapse_client: Optional[Synapse] = None,\n    ) -&gt; \"File\":\n        \"\"\"\n        Change File Entity metadata for properties that are immutable after creation\n        through the store method.\n\n        Arguments:\n            name: Specify to change the filename of a file as seen on Synapse.\n            download_as: Specify filename to change the filename of a filehandle.\n            content_type: Specify content type to change the content type of a\n                filehandle.\n            synapse_client: If not passed in or None this will use the last client from\n                the `.login()` method.\n\n        Returns:\n            The file object.\n\n        Example: Using this function\n            Can be used to change the filename, the filename when the file is\n            downloaded, or the file content-type without downloading:\n\n                file_entity = await File(id=\"syn123\", download_file=False).get_async()\n                print(os.path.basename(file_entity.path))  ## prints, e.g., \"my_file.txt\"\n                file_entity = await file_entity.change_metadata_async(name=\"my_new_name_file.txt\", download_as=\"my_new_downloadAs_name_file.txt\", content_type=\"text/plain\")\n                print(os.path.basename(file_entity.path))  ## prints, \"my_new_downloadAs_name_file.txt\"\n                print(file_entity.name) ## prints, \"my_new_name_file.txt\"\n\n        Raises:\n            ValueError: If the file does not have an ID to change metadata.\n        \"\"\"\n        if not self.id:\n            raise ValueError(\"The file must have an ID to change metadata.\")\n        from synapseutils.copy_functions import changeFileMetaData\n\n        loop = asyncio.get_event_loop()\n\n        current_context = context.get_current()\n        syn = Synapse.get_client(synapse_client=synapse_client)\n        entity = await loop.run_in_executor(\n            None,\n            lambda: run_and_attach_otel_context(\n                lambda: changeFileMetaData(\n                    syn=syn,\n                    entity=self.id,\n                    name=name,\n                    downloadAs=download_as,\n                    contentType=content_type,\n                    forceVersion=self.force_version,\n                ),\n                current_context,\n            ),\n        )\n\n        self.fill_from_dict(synapse_file=entity, set_annotations=True)\n        self._set_last_persistent_instance()\n        Synapse.get_client(synapse_client=synapse_client).logger.debug(\n            f\"Change metadata for file {self.name}, id: {self.id}: {self.path}\"\n        )\n        return self\n\n    @otel_trace_method(\n        method_to_trace_name=lambda self, **kwargs: f\"File_Get: {self.id}, {self.path}\"\n    )\n    async def get_async(\n        self,\n        include_activity: bool = False,\n        *,\n        synapse_client: Optional[Synapse] = None,\n    ) -&gt; \"File\":\n        \"\"\"\n        Get the file from Synapse. You may retrieve a File entity by either:\n\n        - id\n        - path\n\n\n        If you specify both, the `id` will take precedence.\n\n\n        If you specify the `path` and the file is stored in multiple locations in\n        Synapse only the first one found will be returned. The other matching files\n        will be printed to the console.\n\n\n        You may also specify a `version_number` to get a specific version of the file.\n\n        Arguments:\n            include_activity: If True the activity will be included in the file\n                if it exists.\n            synapse_client: If not passed in or None this will use the last client from\n                the `.login()` method.\n\n        Returns:\n            The file object.\n\n        Raises:\n            ValueError: If the file does not have an ID or path to get.\n\n\n        Example: Using this function\n            Assuming you have a file with the ID \"syn123\":\n\n                file_instance = await File(id=\"syn123\").get_async()\n\n            Assuming you have a file at the path \"path/to/file.txt\":\n\n                file_instance = await File(path=\"path/to/file.txt\").get_async()\n        \"\"\"\n        if not self.id and not self.path:\n            raise ValueError(\"The file must have an ID or path to get.\")\n        syn = Synapse.get_client(synapse_client=synapse_client)\n\n        await self._load_local_md5()\n\n        await get_from_entity_factory(\n            entity_to_update=self,\n            synapse_id_or_path=self.id or self.path,\n            version=self.version_number,\n            if_collision=self.if_collision,\n            limit_search=self.synapse_container_limit or self.parent_id,\n            download_file=self.download_file,\n            download_location=self.download_location,\n            md5=self.content_md5,\n        )\n\n        if (\n            not self.path\n            and self.data_file_handle_id\n            and (cached_path := syn.cache.get(file_handle_id=self.data_file_handle_id))\n        ):\n            self.path = cached_path\n\n        if include_activity:\n            self.activity = await Activity.from_parent_async(\n                parent=self, synapse_client=synapse_client\n            )\n\n        self._set_last_persistent_instance()\n        Synapse.get_client(synapse_client=synapse_client).logger.debug(\n            f\"Got file {self.name}, id: {self.id}, path: {self.path}\"\n        )\n        return self\n\n    @classmethod\n    async def from_id_async(\n        cls,\n        synapse_id: str,\n        *,\n        synapse_client: Optional[Synapse] = None,\n    ) -&gt; \"File\":\n        \"\"\"Wrapper for [synapseclient.models.File.get][].\n\n        Arguments:\n            synapse_id: The ID of the file in Synapse.\n            synapse_client: If not passed in or None this will use the last client\n                from the `.login()` method.\n\n        Returns:\n            The file object.\n\n        Example: Using this function\n            Assuming you have a file with the ID \"syn123\":\n\n                file_instance = await File.from_id_async(synapse_id=\"syn123\")\n        \"\"\"\n        return await cls(id=synapse_id).get_async(\n            synapse_client=synapse_client,\n        )\n\n    @classmethod\n    async def from_path_async(\n        cls,\n        path: str,\n        *,\n        synapse_client: Optional[Synapse] = None,\n    ) -&gt; \"File\":\n        \"\"\"Get the file from Synapse. If the path of the file matches multiple files\n        within Synapse the first one found will be returned. The other matching\n        files will be printed to the console.\n\n\n        Wrapper for [synapseclient.models.File.get][].\n\n        Arguments:\n            path: The path to the file on disk.\n            synapse_client: If not passed in or None this will use the last client\n                from the `.login()` method.\n\n        Returns:\n            The file object.\n\n        Example: Using this function\n            Assuming you have a file at the path \"path/to/file.txt\":\n\n                file_instance = await File.from_path_async(path=\"path/to/file.txt\")\n        \"\"\"\n        return await cls(path=path).get_async(\n            synapse_client=synapse_client,\n        )\n\n    @otel_trace_method(\n        method_to_trace_name=lambda self, **kwargs: f\"File_Delete: {self.id}\"\n    )\n    async def delete_async(\n        self,\n        version_only: Optional[bool] = False,\n        *,\n        synapse_client: Optional[Synapse] = None,\n    ) -&gt; None:\n        \"\"\"\n        Delete the file from Synapse using the ID of the file.\n\n        Arguments:\n            version_only: If True only the version specified in the `version_number`\n                attribute of the file will be deleted. If False the entire file will\n                be deleted.\n            synapse_client: If not passed in or None this will use the last client from\n                the `.login()` method.\n\n        Returns:\n            None\n\n        Raises:\n            ValueError: If the file does not have an ID to delete.\n            ValueError: If the file does not have a version number to delete a version,\n                and `version_only` is True.\n\n        Example: Using this function\n            Assuming you have a file with the ID \"syn123\":\n\n                await File(id=\"syn123\").delete_async()\n        \"\"\"\n        if not self.id:\n            raise ValueError(\"The file must have an ID to delete.\")\n        if version_only and not self.version_number:\n            raise ValueError(\"The file must have a version number to delete a version.\")\n\n        loop = asyncio.get_event_loop()\n        current_context = context.get_current()\n        await loop.run_in_executor(\n            None,\n            lambda: run_and_attach_otel_context(\n                lambda: Synapse.get_client(synapse_client=synapse_client).delete(\n                    obj=self.id,\n                    version=self.version_number if version_only else None,\n                ),\n                current_context,\n            ),\n        )\n        Synapse.get_client(synapse_client=synapse_client).logger.debug(\n            f\"Deleted file {self.id}\"\n        )\n\n    @otel_trace_method(\n        method_to_trace_name=lambda self, **kwargs: f\"File_Copy: {self.id}\"\n    )\n    async def copy_async(\n        self,\n        parent_id: str,\n        update_existing: bool = False,\n        copy_annotations: bool = True,\n        copy_activity: Union[str, None] = \"traceback\",\n        *,\n        synapse_client: Optional[Synapse] = None,\n    ) -&gt; \"File\":\n        \"\"\"\n        Copy the file to another Synapse location. Defaults to the latest version of the\n        file, or the version_number specified in the instance.\n\n        Arguments:\n            parent_id: Synapse ID of a folder/project that the copied entity is being\n                copied to\n            update_existing: When the destination has a file that has the same name,\n                users can choose to update that file.\n            copy_annotations: True to copy the annotations.\n            copy_activity: Has three options to set the activity of the copied file:\n\n                    - traceback: Creates a copy of the source files Activity.\n                    - existing: Link to the source file's original Activity (if it exists)\n                    - None: No activity is set\n            synapse_client: If not passed in or None this will use the last client from\n                the `.login()` method.\n\n        Returns:\n            The copied file object.\n\n        Example: Using this function\n            Assuming you have a file with the ID \"syn123\" and you want to copy it to a folder with the ID \"syn456\":\n\n                new_file_instance = await File(id=\"syn123\").copy_async(parent_id=\"syn456\")\n\n            Copy the file but do not persist annotations or activity:\n\n                new_file_instance = await File(id=\"syn123\").copy_async(parent_id=\"syn456\", copy_annotations=False, copy_activity=None)\n\n        Raises:\n            ValueError: If the file does not have an ID and parent_id to copy.\n        \"\"\"\n        if not self.id or not parent_id:\n            raise ValueError(\"The file must have an ID and parent_id to copy.\")\n        from synapseutils.copy_functions import copy\n\n        loop = asyncio.get_event_loop()\n\n        current_context = context.get_current()\n        syn = Synapse.get_client(synapse_client=synapse_client)\n        source_and_destination = await loop.run_in_executor(\n            None,\n            lambda: run_and_attach_otel_context(\n                lambda: copy(\n                    syn=syn,\n                    version=self.version_number,\n                    entity=self.id,\n                    destinationId=parent_id,\n                    skipCopyAnnotations=not copy_annotations,\n                    updateExisting=update_existing,\n                    setProvenance=copy_activity,\n                ),\n                current_context,\n            ),\n        )\n\n        parent_id = source_and_destination.get(self.id, None)\n        if not parent_id:\n            raise SynapseError(\"Failed to copy file.\")\n        file_copy = await File(id=parent_id, download_file=False).get_async(\n            synapse_client=synapse_client\n        )\n        file_copy.download_file = True\n        Synapse.get_client(synapse_client=synapse_client).logger.debug(\n            f\"Copied from file {self.id} to {parent_id} with new id of {file_copy.id}\"\n        )\n        return file_copy\n\n    async def _needs_upload(self, syn: Synapse) -&gt; bool:\n        \"\"\"\n        Determines if a file needs to be uploaded to Synapse. The following conditions\n        apply:\n\n        - The file exists and is an ExternalFileHandle and the url has changed\n        - The file exists and is a local file and the MD5 has changed\n        - The file is not present in Synapse\n\n        If the file is already specifying a data_file_handle_id then it is assumed that\n        the file is already uploaded to Synapse. It does not need to be uploaded and\n        the only thing that will occur is the File metadata will be added to Synapse\n        outside of this upload process.\n\n        Arguments:\n            syn: If not passed in or None this will use the last client from\n                the `.login()` method.\n\n        Returns:\n            True if the file needs to be uploaded, otherwise False.\n        \"\"\"\n        needs_upload = False\n        # Check if the file should be uploaded\n        if self._last_persistent_instance is not None:\n            if (\n                self.file_handle\n                and self.file_handle.concrete_type\n                == \"org.sagebionetworks.repo.model.file.ExternalFileHandle\"\n            ):\n                # switching away from ExternalFileHandle or the url was updated\n                needs_upload = self.synapse_store or (\n                    self.file_handle.external_url != self.external_url\n                )\n            else:\n                # Check if we need to upload a new version of an existing\n                # file. If the file referred to by entity['path'] has been\n                # modified, we want to upload the new version.\n                # If synapeStore is false then we must upload a ExternalFileHandle\n                needs_upload = (\n                    not self.synapse_store\n                    or not self.file_handle\n                    or not (\n                        exists_in_cache := syn.cache.contains(\n                            self.file_handle.id, self.path\n                        )\n                    )\n                )\n\n                md5_stored_in_synapse = (\n                    self.file_handle.content_md5 if self.file_handle else None\n                )\n\n                # Check if we got an MD5 checksum from Synapse and compare it to the local file\n                if (\n                    self.synapse_store\n                    and needs_upload\n                    and os.path.isfile(self.path)\n                    and md5_stored_in_synapse\n                ):\n                    await self._load_local_md5()\n                    if md5_stored_in_synapse == (\n                        local_file_md5_hex := self.content_md5\n                    ):\n                        needs_upload = False\n\n                    # If we had a cache miss, but already uploaded to Synapse we\n                    # can add the file to the cache.\n                    if (\n                        not exists_in_cache\n                        and self.file_handle\n                        and self.file_handle.id\n                        and local_file_md5_hex\n                    ):\n                        syn.cache.add(\n                            file_handle_id=self.file_handle.id,\n                            path=self.path,\n                            md5=local_file_md5_hex,\n                        )\n        elif self.data_file_handle_id is not None:\n            needs_upload = False\n        else:\n            needs_upload = True\n        return needs_upload\n\n    async def _upload_file(\n        self,\n        *,\n        synapse_client: Optional[Synapse] = None,\n    ) -&gt; \"File\":\n        \"\"\"The upload process for a file. This will upload the file to Synapse if it\n        needs to be uploaded. If the file does not need to be uploaded the file\n        metadata will be added to Synapse outside of this upload process.\n\n        Arguments:\n            synapse_client: If not passed in or None this will use the last client from\n                the `.login()` method.\n\n        Returns:\n            The file object.\n        \"\"\"\n        syn = Synapse.get_client(synapse_client=synapse_client)\n\n        needs_upload = await self._needs_upload(syn=syn)\n\n        if needs_upload:\n            parent_id_for_upload = self.parent_id\n\n            if not parent_id_for_upload:\n                raise SynapseMalformedEntityError(\n                    \"Entities of type File must have a parentId.\"\n                )\n\n            updated_file_handle = await upload_file_handle(\n                syn=syn,\n                parent_entity_id=parent_id_for_upload,\n                path=(\n                    self.path\n                    if (self.synapse_store or self.external_url is None)\n                    else self.external_url\n                ),\n                synapse_store=self.synapse_store,\n                md5=self.content_md5,\n                file_size=self.content_size,\n                mimetype=self.content_type,\n            )\n\n            self.file_handle = FileHandle().fill_from_dict(updated_file_handle)\n            self._fill_from_file_handle()\n\n        return self\n\n    def _convert_into_legacy_file(self) -&gt; SynapseFile:\n        \"\"\"Convert the file object into a SynapseFile object.\"\"\"\n        return_data = SynapseFile(\n            id=self.id,\n            name=self.name,\n            description=self.description,\n            etag=self.etag,\n            createdOn=self.created_on,\n            modifiedOn=self.modified_on,\n            createdBy=self.created_by,\n            modifiedBy=self.modified_by,\n            parentId=self.parent_id,\n            versionNumber=self.version_number,\n            versionLabel=self.version_label,\n            versionComment=self.version_comment,\n            dataFileHandleId=self.data_file_handle_id,\n            path=self.path,\n            properties={\n                \"isLatestVersion\": self.is_latest_version,\n            },\n            _file_handle=(\n                self.file_handle._convert_into_legacy_file_handle()\n                if self.file_handle\n                else None\n            ),\n            annotations=self.annotations,\n        )\n        delete_none_keys(return_data)\n        return return_data\n</code></pre>"},{"location":"reference/oop/models_async/#synapseclient.models.File-functions","title":"Functions","text":""},{"location":"reference/oop/models_async/#synapseclient.models.File.get_async","title":"<code>get_async(include_activity=False, *, synapse_client=None)</code>  <code>async</code>","text":"<p>Get the file from Synapse. You may retrieve a File entity by either:</p> <ul> <li>id</li> <li>path</li> </ul> <p>If you specify both, the <code>id</code> will take precedence.</p> <p>If you specify the <code>path</code> and the file is stored in multiple locations in Synapse only the first one found will be returned. The other matching files will be printed to the console.</p> <p>You may also specify a <code>version_number</code> to get a specific version of the file.</p> PARAMETER DESCRIPTION <code>include_activity</code> <p>If True the activity will be included in the file if it exists.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>synapse_client</code> <p>If not passed in or None this will use the last client from the <code>.login()</code> method.</p> <p> TYPE: <code>Optional[Synapse]</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>File</code> <p>The file object.</p> RAISES DESCRIPTION <code>ValueError</code> <p>If the file does not have an ID or path to get.</p> Using this function <p>Assuming you have a file with the ID \"syn123\":</p> <pre><code>file_instance = await File(id=\"syn123\").get_async()\n</code></pre> <p>Assuming you have a file at the path \"path/to/file.txt\":</p> <pre><code>file_instance = await File(path=\"path/to/file.txt\").get_async()\n</code></pre> Source code in <code>synapseclient/models/file.py</code> <pre><code>@otel_trace_method(\n    method_to_trace_name=lambda self, **kwargs: f\"File_Get: {self.id}, {self.path}\"\n)\nasync def get_async(\n    self,\n    include_activity: bool = False,\n    *,\n    synapse_client: Optional[Synapse] = None,\n) -&gt; \"File\":\n    \"\"\"\n    Get the file from Synapse. You may retrieve a File entity by either:\n\n    - id\n    - path\n\n\n    If you specify both, the `id` will take precedence.\n\n\n    If you specify the `path` and the file is stored in multiple locations in\n    Synapse only the first one found will be returned. The other matching files\n    will be printed to the console.\n\n\n    You may also specify a `version_number` to get a specific version of the file.\n\n    Arguments:\n        include_activity: If True the activity will be included in the file\n            if it exists.\n        synapse_client: If not passed in or None this will use the last client from\n            the `.login()` method.\n\n    Returns:\n        The file object.\n\n    Raises:\n        ValueError: If the file does not have an ID or path to get.\n\n\n    Example: Using this function\n        Assuming you have a file with the ID \"syn123\":\n\n            file_instance = await File(id=\"syn123\").get_async()\n\n        Assuming you have a file at the path \"path/to/file.txt\":\n\n            file_instance = await File(path=\"path/to/file.txt\").get_async()\n    \"\"\"\n    if not self.id and not self.path:\n        raise ValueError(\"The file must have an ID or path to get.\")\n    syn = Synapse.get_client(synapse_client=synapse_client)\n\n    await self._load_local_md5()\n\n    await get_from_entity_factory(\n        entity_to_update=self,\n        synapse_id_or_path=self.id or self.path,\n        version=self.version_number,\n        if_collision=self.if_collision,\n        limit_search=self.synapse_container_limit or self.parent_id,\n        download_file=self.download_file,\n        download_location=self.download_location,\n        md5=self.content_md5,\n    )\n\n    if (\n        not self.path\n        and self.data_file_handle_id\n        and (cached_path := syn.cache.get(file_handle_id=self.data_file_handle_id))\n    ):\n        self.path = cached_path\n\n    if include_activity:\n        self.activity = await Activity.from_parent_async(\n            parent=self, synapse_client=synapse_client\n        )\n\n    self._set_last_persistent_instance()\n    Synapse.get_client(synapse_client=synapse_client).logger.debug(\n        f\"Got file {self.name}, id: {self.id}, path: {self.path}\"\n    )\n    return self\n</code></pre>"},{"location":"reference/oop/models_async/#synapseclient.models.File.store_async","title":"<code>store_async(parent=None, *, synapse_client=None)</code>  <code>async</code>","text":"<p>Store the file in Synapse. With this method you may:</p> <ul> <li>Upload a file into Synapse</li> <li>Update the metadata of a file in Synapse</li> <li>Store a File object in Synapse without updating a file by setting     <code>synapse_store</code> to False.</li> <li>Change the name of a file in Synapse by setting the <code>name</code> attribute of the     File object. Also see the synapseclient.models.File.change_metadata     method for changing the name of the downloaded file.</li> <li>Moving a file to a new parent by setting the <code>parent_id</code> attribute of the     File object.</li> </ul> <p>If no Name is specified this will be derived from the file name. This is the reccommended way to store a file in Synapse.</p> <p>Please note: The file, as it appears on disk, will be the file that is downloaded from Synapse. The name of the actual File is different from the name of the File Entity in Synapse. It is generally not reccommended to specify a different name for the Entity and the file as it will cause confusion and potential conflicts later on.</p> PARAMETER DESCRIPTION <code>parent</code> <p>The parent folder or project to store the file in. May also be specified in the File object. If both are provided the parent passed into <code>store</code> will take precedence.</p> <p> TYPE: <code>Optional[Union[Folder, Project]]</code> DEFAULT: <code>None</code> </p> <code>synapse_client</code> <p>If not passed in or None this will use the last client from the <code>.login()</code> method.</p> <p> TYPE: <code>Optional[Synapse]</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>File</code> <p>The file object.</p> RAISES DESCRIPTION <code>ValueError</code> <p>If the file does not have an ID and a path, or a path and a parent ID, or a data file handle ID and a parent ID.</p> Using this function <p>File with the ID <code>syn123</code> at path <code>path/to/file.txt</code>:</p> <pre><code>file_instance = await File(id=\"syn123\", path=\"path/to/file.txt\").store_async()\n</code></pre> <p>File at the path <code>path/to/file.txt</code> and a parent folder with the ID <code>syn456</code>:</p> <pre><code>file_instance = await File(path=\"path/to/file.txt\", parent_id=\"syn456\").store_async()\n</code></pre> <p>File at the path <code>path/to/file.txt</code> and a parent folder with the ID <code>syn456</code>:</p> <pre><code>file_instance = await File(path=\"path/to/file.txt\").store_async(parent=Folder(id=\"syn456\"))\n</code></pre> <p>File with a parent and existing file handle (This allows multiple entities to reference the underlying file):</p> <pre><code>file_instance = await File(data_file_handle_id=\"123\", parent_id=\"syn456\").store_async()\n</code></pre> <p>Rename a file (Does not update the file on disk or the name of the downloaded file):</p> <pre><code>file_instance = await File(id=\"syn123\", download_file=False).get_async()\nprint(file_instance.name)  ## prints, e.g., \"my_file.txt\"\nawait file_instance.change_metadata_async(name=\"my_new_name_file.txt\")\n</code></pre> <p>Rename a file, and the name of the file as downloaded     (Does not update the file on disk). Is is reccommended that <code>name</code> and     <code>download_as</code> match to prevent confusion later on:</p> <pre><code>file_instance = await File(id=\"syn123\", download_file=False).get_async()\nprint(file_instance.name)  ## prints, e.g., \"my_file.txt\"\nawait file_instance.change_metadata_async(name=\"my_new_name_file.txt\", download_as=\"my_new_name_file.txt\")\n</code></pre> Source code in <code>synapseclient/models/file.py</code> <pre><code>@otel_trace_method(\n    method_to_trace_name=lambda self, **kwargs: f\"File_Store: {self.path if self.path else self.id}\"\n)\nasync def store_async(\n    self,\n    parent: Optional[Union[\"Folder\", \"Project\"]] = None,\n    *,\n    synapse_client: Optional[Synapse] = None,\n) -&gt; \"File\":\n    \"\"\"\n    Store the file in Synapse. With this method you may:\n\n    - Upload a file into Synapse\n    - Update the metadata of a file in Synapse\n    - Store a File object in Synapse without updating a file by setting\n        `synapse_store` to False.\n    - Change the name of a file in Synapse by setting the `name` attribute of the\n        File object. Also see the [synapseclient.models.File.change_metadata][]\n        method for changing the name of the downloaded file.\n    - Moving a file to a new parent by setting the `parent_id` attribute of the\n        File object.\n\n    If no Name is specified this will be derived from the file name. This is the\n    reccommended way to store a file in Synapse.\n\n    Please note:\n    The file, as it appears on disk, will be the file that is downloaded from\n    Synapse. The name of the actual File is different from the name of the File\n    Entity in Synapse. It is generally not reccommended to specify a different\n    name for the Entity and the file as it will cause confusion and potential\n    conflicts later on.\n\n    Arguments:\n        parent: The parent folder or project to store the file in. May also be\n            specified in the File object. If both are provided the parent passed\n            into `store` will take precedence.\n        synapse_client: If not passed in or None this will use the last client from\n            the `.login()` method.\n\n    Returns:\n        The file object.\n\n    Raises:\n        ValueError: If the file does not have an ID and a path, or a path and a\n            parent ID, or a data file handle ID and a parent ID.\n\n    Example: Using this function\n        File with the ID `syn123` at path `path/to/file.txt`:\n\n            file_instance = await File(id=\"syn123\", path=\"path/to/file.txt\").store_async()\n\n        File at the path `path/to/file.txt` and a parent folder with the ID `syn456`:\n\n            file_instance = await File(path=\"path/to/file.txt\", parent_id=\"syn456\").store_async()\n\n        File at the path `path/to/file.txt` and a parent folder with the ID `syn456`:\n\n            file_instance = await File(path=\"path/to/file.txt\").store_async(parent=Folder(id=\"syn456\"))\n\n        File with a parent and existing file handle (This allows multiple entities to reference the underlying file):\n\n            file_instance = await File(data_file_handle_id=\"123\", parent_id=\"syn456\").store_async()\n\n        Rename a file (Does not update the file on disk or the name of the downloaded file):\n\n            file_instance = await File(id=\"syn123\", download_file=False).get_async()\n            print(file_instance.name)  ## prints, e.g., \"my_file.txt\"\n            await file_instance.change_metadata_async(name=\"my_new_name_file.txt\")\n\n        Rename a file, and the name of the file as downloaded\n            (Does not update the file on disk). Is is reccommended that `name` and\n            `download_as` match to prevent confusion later on:\n\n            file_instance = await File(id=\"syn123\", download_file=False).get_async()\n            print(file_instance.name)  ## prints, e.g., \"my_file.txt\"\n            await file_instance.change_metadata_async(name=\"my_new_name_file.txt\", download_as=\"my_new_name_file.txt\")\n\n    \"\"\"\n    self.parent_id = parent.id if parent else self.parent_id\n    if self._cannot_store():\n        raise ValueError(\n            \"The file must have an (ID with a (path or `data_file_handle_id`)), or a \"\n            \"(path with a (`parent_id` or parent with an id)), or a \"\n            \"(data_file_handle_id with a (`parent_id` or parent with an id)) to store.\"\n        )\n    self.name = self.name or (guess_file_name(self.path) if self.path else None)\n    client = Synapse.get_client(synapse_client=synapse_client)\n\n    if existing_file := await self._find_existing_file(synapse_client=client):\n        merge_dataclass_entities(\n            source=existing_file,\n            destination=self,\n            fields_to_ignore=self._determine_fields_to_ignore_in_merge(),\n        )\n\n    if self.path:\n        self.path = os.path.expanduser(self.path)\n        async with client._get_parallel_file_transfer_semaphore(\n            asyncio_event_loop=asyncio.get_running_loop()\n        ):\n            await self._upload_file(synapse_client=client)\n    elif self.data_file_handle_id:\n        self.path = client.cache.get(file_handle_id=self.data_file_handle_id)\n\n    if self.has_changed:\n        synapse_file = Synapse_File(\n            id=self.id,\n            path=self.path,\n            description=self.description,\n            etag=self.etag,\n            name=self.name,\n            parent=parent.id if parent else self.parent_id,\n            contentType=self.content_type,\n            contentSize=self.content_size,\n            dataFileHandleId=self.data_file_handle_id,\n            synapseStore=self.synapse_store,\n            modifiedOn=self.modified_on,\n            versionLabel=self.version_label,\n            versionNumber=self.version_number,\n            versionComment=self.version_comment,\n        )\n        delete_none_keys(synapse_file)\n\n        entity = await store_entity(\n            resource=self, entity=synapse_file, synapse_client=client\n        )\n\n        self.fill_from_dict(synapse_file=entity, set_annotations=False)\n\n    re_read_required = await store_entity_components(\n        root_resource=self, synapse_client=client\n    )\n    if re_read_required:\n        before_download_file = self.download_file\n        self.download_file = False\n        await self.get_async(\n            synapse_client=client,\n        )\n        self.download_file = before_download_file\n\n    self._set_last_persistent_instance()\n\n    client.logger.debug(f\"Stored File {self.name}, id: {self.id}: {self.path}\")\n    # Clear the content_md5 so that it is recalculated if the file is updated\n    self.content_md5 = None\n    return self\n</code></pre>"},{"location":"reference/oop/models_async/#synapseclient.models.File.copy_async","title":"<code>copy_async(parent_id, update_existing=False, copy_annotations=True, copy_activity='traceback', *, synapse_client=None)</code>  <code>async</code>","text":"<p>Copy the file to another Synapse location. Defaults to the latest version of the file, or the version_number specified in the instance.</p> PARAMETER DESCRIPTION <code>parent_id</code> <p>Synapse ID of a folder/project that the copied entity is being copied to</p> <p> TYPE: <code>str</code> </p> <code>update_existing</code> <p>When the destination has a file that has the same name, users can choose to update that file.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>copy_annotations</code> <p>True to copy the annotations.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> <code>copy_activity</code> <p>Has three options to set the activity of the copied file:</p> <pre><code>- traceback: Creates a copy of the source files Activity.\n- existing: Link to the source file's original Activity (if it exists)\n- None: No activity is set\n</code></pre> <p> TYPE: <code>Union[str, None]</code> DEFAULT: <code>'traceback'</code> </p> <code>synapse_client</code> <p>If not passed in or None this will use the last client from the <code>.login()</code> method.</p> <p> TYPE: <code>Optional[Synapse]</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>File</code> <p>The copied file object.</p> Using this function <p>Assuming you have a file with the ID \"syn123\" and you want to copy it to a folder with the ID \"syn456\":</p> <pre><code>new_file_instance = await File(id=\"syn123\").copy_async(parent_id=\"syn456\")\n</code></pre> <p>Copy the file but do not persist annotations or activity:</p> <pre><code>new_file_instance = await File(id=\"syn123\").copy_async(parent_id=\"syn456\", copy_annotations=False, copy_activity=None)\n</code></pre> RAISES DESCRIPTION <code>ValueError</code> <p>If the file does not have an ID and parent_id to copy.</p> Source code in <code>synapseclient/models/file.py</code> <pre><code>@otel_trace_method(\n    method_to_trace_name=lambda self, **kwargs: f\"File_Copy: {self.id}\"\n)\nasync def copy_async(\n    self,\n    parent_id: str,\n    update_existing: bool = False,\n    copy_annotations: bool = True,\n    copy_activity: Union[str, None] = \"traceback\",\n    *,\n    synapse_client: Optional[Synapse] = None,\n) -&gt; \"File\":\n    \"\"\"\n    Copy the file to another Synapse location. Defaults to the latest version of the\n    file, or the version_number specified in the instance.\n\n    Arguments:\n        parent_id: Synapse ID of a folder/project that the copied entity is being\n            copied to\n        update_existing: When the destination has a file that has the same name,\n            users can choose to update that file.\n        copy_annotations: True to copy the annotations.\n        copy_activity: Has three options to set the activity of the copied file:\n\n                - traceback: Creates a copy of the source files Activity.\n                - existing: Link to the source file's original Activity (if it exists)\n                - None: No activity is set\n        synapse_client: If not passed in or None this will use the last client from\n            the `.login()` method.\n\n    Returns:\n        The copied file object.\n\n    Example: Using this function\n        Assuming you have a file with the ID \"syn123\" and you want to copy it to a folder with the ID \"syn456\":\n\n            new_file_instance = await File(id=\"syn123\").copy_async(parent_id=\"syn456\")\n\n        Copy the file but do not persist annotations or activity:\n\n            new_file_instance = await File(id=\"syn123\").copy_async(parent_id=\"syn456\", copy_annotations=False, copy_activity=None)\n\n    Raises:\n        ValueError: If the file does not have an ID and parent_id to copy.\n    \"\"\"\n    if not self.id or not parent_id:\n        raise ValueError(\"The file must have an ID and parent_id to copy.\")\n    from synapseutils.copy_functions import copy\n\n    loop = asyncio.get_event_loop()\n\n    current_context = context.get_current()\n    syn = Synapse.get_client(synapse_client=synapse_client)\n    source_and_destination = await loop.run_in_executor(\n        None,\n        lambda: run_and_attach_otel_context(\n            lambda: copy(\n                syn=syn,\n                version=self.version_number,\n                entity=self.id,\n                destinationId=parent_id,\n                skipCopyAnnotations=not copy_annotations,\n                updateExisting=update_existing,\n                setProvenance=copy_activity,\n            ),\n            current_context,\n        ),\n    )\n\n    parent_id = source_and_destination.get(self.id, None)\n    if not parent_id:\n        raise SynapseError(\"Failed to copy file.\")\n    file_copy = await File(id=parent_id, download_file=False).get_async(\n        synapse_client=synapse_client\n    )\n    file_copy.download_file = True\n    Synapse.get_client(synapse_client=synapse_client).logger.debug(\n        f\"Copied from file {self.id} to {parent_id} with new id of {file_copy.id}\"\n    )\n    return file_copy\n</code></pre>"},{"location":"reference/oop/models_async/#synapseclient.models.File.delete_async","title":"<code>delete_async(version_only=False, *, synapse_client=None)</code>  <code>async</code>","text":"<p>Delete the file from Synapse using the ID of the file.</p> PARAMETER DESCRIPTION <code>version_only</code> <p>If True only the version specified in the <code>version_number</code> attribute of the file will be deleted. If False the entire file will be deleted.</p> <p> TYPE: <code>Optional[bool]</code> DEFAULT: <code>False</code> </p> <code>synapse_client</code> <p>If not passed in or None this will use the last client from the <code>.login()</code> method.</p> <p> TYPE: <code>Optional[Synapse]</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>None</code> <p>None</p> RAISES DESCRIPTION <code>ValueError</code> <p>If the file does not have an ID to delete.</p> <code>ValueError</code> <p>If the file does not have a version number to delete a version, and <code>version_only</code> is True.</p> Using this function <p>Assuming you have a file with the ID \"syn123\":</p> <pre><code>await File(id=\"syn123\").delete_async()\n</code></pre> Source code in <code>synapseclient/models/file.py</code> <pre><code>@otel_trace_method(\n    method_to_trace_name=lambda self, **kwargs: f\"File_Delete: {self.id}\"\n)\nasync def delete_async(\n    self,\n    version_only: Optional[bool] = False,\n    *,\n    synapse_client: Optional[Synapse] = None,\n) -&gt; None:\n    \"\"\"\n    Delete the file from Synapse using the ID of the file.\n\n    Arguments:\n        version_only: If True only the version specified in the `version_number`\n            attribute of the file will be deleted. If False the entire file will\n            be deleted.\n        synapse_client: If not passed in or None this will use the last client from\n            the `.login()` method.\n\n    Returns:\n        None\n\n    Raises:\n        ValueError: If the file does not have an ID to delete.\n        ValueError: If the file does not have a version number to delete a version,\n            and `version_only` is True.\n\n    Example: Using this function\n        Assuming you have a file with the ID \"syn123\":\n\n            await File(id=\"syn123\").delete_async()\n    \"\"\"\n    if not self.id:\n        raise ValueError(\"The file must have an ID to delete.\")\n    if version_only and not self.version_number:\n        raise ValueError(\"The file must have a version number to delete a version.\")\n\n    loop = asyncio.get_event_loop()\n    current_context = context.get_current()\n    await loop.run_in_executor(\n        None,\n        lambda: run_and_attach_otel_context(\n            lambda: Synapse.get_client(synapse_client=synapse_client).delete(\n                obj=self.id,\n                version=self.version_number if version_only else None,\n            ),\n            current_context,\n        ),\n    )\n    Synapse.get_client(synapse_client=synapse_client).logger.debug(\n        f\"Deleted file {self.id}\"\n    )\n</code></pre>"},{"location":"reference/oop/models_async/#synapseclient.models.File.from_id_async","title":"<code>from_id_async(synapse_id, *, synapse_client=None)</code>  <code>async</code> <code>classmethod</code>","text":"<p>Wrapper for synapseclient.models.File.get.</p> PARAMETER DESCRIPTION <code>synapse_id</code> <p>The ID of the file in Synapse.</p> <p> TYPE: <code>str</code> </p> <code>synapse_client</code> <p>If not passed in or None this will use the last client from the <code>.login()</code> method.</p> <p> TYPE: <code>Optional[Synapse]</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>File</code> <p>The file object.</p> Using this function <p>Assuming you have a file with the ID \"syn123\":</p> <pre><code>file_instance = await File.from_id_async(synapse_id=\"syn123\")\n</code></pre> Source code in <code>synapseclient/models/file.py</code> <pre><code>@classmethod\nasync def from_id_async(\n    cls,\n    synapse_id: str,\n    *,\n    synapse_client: Optional[Synapse] = None,\n) -&gt; \"File\":\n    \"\"\"Wrapper for [synapseclient.models.File.get][].\n\n    Arguments:\n        synapse_id: The ID of the file in Synapse.\n        synapse_client: If not passed in or None this will use the last client\n            from the `.login()` method.\n\n    Returns:\n        The file object.\n\n    Example: Using this function\n        Assuming you have a file with the ID \"syn123\":\n\n            file_instance = await File.from_id_async(synapse_id=\"syn123\")\n    \"\"\"\n    return await cls(id=synapse_id).get_async(\n        synapse_client=synapse_client,\n    )\n</code></pre>"},{"location":"reference/oop/models_async/#synapseclient.models.File.from_path_async","title":"<code>from_path_async(path, *, synapse_client=None)</code>  <code>async</code> <code>classmethod</code>","text":"<p>Get the file from Synapse. If the path of the file matches multiple files within Synapse the first one found will be returned. The other matching files will be printed to the console.</p> <p>Wrapper for synapseclient.models.File.get.</p> PARAMETER DESCRIPTION <code>path</code> <p>The path to the file on disk.</p> <p> TYPE: <code>str</code> </p> <code>synapse_client</code> <p>If not passed in or None this will use the last client from the <code>.login()</code> method.</p> <p> TYPE: <code>Optional[Synapse]</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>File</code> <p>The file object.</p> Using this function <p>Assuming you have a file at the path \"path/to/file.txt\":</p> <pre><code>file_instance = await File.from_path_async(path=\"path/to/file.txt\")\n</code></pre> Source code in <code>synapseclient/models/file.py</code> <pre><code>@classmethod\nasync def from_path_async(\n    cls,\n    path: str,\n    *,\n    synapse_client: Optional[Synapse] = None,\n) -&gt; \"File\":\n    \"\"\"Get the file from Synapse. If the path of the file matches multiple files\n    within Synapse the first one found will be returned. The other matching\n    files will be printed to the console.\n\n\n    Wrapper for [synapseclient.models.File.get][].\n\n    Arguments:\n        path: The path to the file on disk.\n        synapse_client: If not passed in or None this will use the last client\n            from the `.login()` method.\n\n    Returns:\n        The file object.\n\n    Example: Using this function\n        Assuming you have a file at the path \"path/to/file.txt\":\n\n            file_instance = await File.from_path_async(path=\"path/to/file.txt\")\n    \"\"\"\n    return await cls(path=path).get_async(\n        synapse_client=synapse_client,\n    )\n</code></pre>"},{"location":"reference/oop/models_async/#synapseclient.models.File.change_metadata_async","title":"<code>change_metadata_async(name=None, download_as=None, content_type=None, *, synapse_client=None)</code>  <code>async</code>","text":"<p>Change File Entity metadata for properties that are immutable after creation through the store method.</p> PARAMETER DESCRIPTION <code>name</code> <p>Specify to change the filename of a file as seen on Synapse.</p> <p> TYPE: <code>Optional[str]</code> DEFAULT: <code>None</code> </p> <code>download_as</code> <p>Specify filename to change the filename of a filehandle.</p> <p> TYPE: <code>Optional[str]</code> DEFAULT: <code>None</code> </p> <code>content_type</code> <p>Specify content type to change the content type of a filehandle.</p> <p> TYPE: <code>Optional[str]</code> DEFAULT: <code>None</code> </p> <code>synapse_client</code> <p>If not passed in or None this will use the last client from the <code>.login()</code> method.</p> <p> TYPE: <code>Optional[Synapse]</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>File</code> <p>The file object.</p> Using this function <p>Can be used to change the filename, the filename when the file is downloaded, or the file content-type without downloading:</p> <pre><code>file_entity = await File(id=\"syn123\", download_file=False).get_async()\nprint(os.path.basename(file_entity.path))  ## prints, e.g., \"my_file.txt\"\nfile_entity = await file_entity.change_metadata_async(name=\"my_new_name_file.txt\", download_as=\"my_new_downloadAs_name_file.txt\", content_type=\"text/plain\")\nprint(os.path.basename(file_entity.path))  ## prints, \"my_new_downloadAs_name_file.txt\"\nprint(file_entity.name) ## prints, \"my_new_name_file.txt\"\n</code></pre> RAISES DESCRIPTION <code>ValueError</code> <p>If the file does not have an ID to change metadata.</p> Source code in <code>synapseclient/models/file.py</code> <pre><code>@otel_trace_method(\n    method_to_trace_name=lambda self, **kwargs: f\"File_Change_Metadata: {self.id}\"\n)\nasync def change_metadata_async(\n    self,\n    name: Optional[str] = None,\n    download_as: Optional[str] = None,\n    content_type: Optional[str] = None,\n    *,\n    synapse_client: Optional[Synapse] = None,\n) -&gt; \"File\":\n    \"\"\"\n    Change File Entity metadata for properties that are immutable after creation\n    through the store method.\n\n    Arguments:\n        name: Specify to change the filename of a file as seen on Synapse.\n        download_as: Specify filename to change the filename of a filehandle.\n        content_type: Specify content type to change the content type of a\n            filehandle.\n        synapse_client: If not passed in or None this will use the last client from\n            the `.login()` method.\n\n    Returns:\n        The file object.\n\n    Example: Using this function\n        Can be used to change the filename, the filename when the file is\n        downloaded, or the file content-type without downloading:\n\n            file_entity = await File(id=\"syn123\", download_file=False).get_async()\n            print(os.path.basename(file_entity.path))  ## prints, e.g., \"my_file.txt\"\n            file_entity = await file_entity.change_metadata_async(name=\"my_new_name_file.txt\", download_as=\"my_new_downloadAs_name_file.txt\", content_type=\"text/plain\")\n            print(os.path.basename(file_entity.path))  ## prints, \"my_new_downloadAs_name_file.txt\"\n            print(file_entity.name) ## prints, \"my_new_name_file.txt\"\n\n    Raises:\n        ValueError: If the file does not have an ID to change metadata.\n    \"\"\"\n    if not self.id:\n        raise ValueError(\"The file must have an ID to change metadata.\")\n    from synapseutils.copy_functions import changeFileMetaData\n\n    loop = asyncio.get_event_loop()\n\n    current_context = context.get_current()\n    syn = Synapse.get_client(synapse_client=synapse_client)\n    entity = await loop.run_in_executor(\n        None,\n        lambda: run_and_attach_otel_context(\n            lambda: changeFileMetaData(\n                syn=syn,\n                entity=self.id,\n                name=name,\n                downloadAs=download_as,\n                contentType=content_type,\n                forceVersion=self.force_version,\n            ),\n            current_context,\n        ),\n    )\n\n    self.fill_from_dict(synapse_file=entity, set_annotations=True)\n    self._set_last_persistent_instance()\n    Synapse.get_client(synapse_client=synapse_client).logger.debug(\n        f\"Change metadata for file {self.name}, id: {self.id}: {self.path}\"\n    )\n    return self\n</code></pre>"},{"location":"reference/oop/models_async/#synapseclient.models.File.get_permissions_async","title":"<code>get_permissions_async(*, synapse_client=None)</code>  <code>async</code>","text":"<p>Get the permissions that the caller has on an Entity.</p> PARAMETER DESCRIPTION <code>synapse_client</code> <p>If not passed in or None this will use the last client from the <code>.login()</code> method.</p> <p> TYPE: <code>Optional[Synapse]</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>Permissions</code> <p>A Permissions object</p> Using this function: <p>Getting permissions for a Synapse Entity</p> <pre><code>permissions = await File(id=\"syn123\").get_permissions_async()\n</code></pre> <p>Getting access types list from the Permissions object</p> <pre><code>permissions.access_types\n</code></pre> Source code in <code>synapseclient/models/mixins/access_control.py</code> <pre><code>async def get_permissions_async(\n    self,\n    *,\n    synapse_client: Optional[Synapse] = None,\n) -&gt; \"Permissions\":\n    \"\"\"\n    Get the [permissions][synapseclient.core.models.permission.Permissions]\n    that the caller has on an Entity.\n\n    Arguments:\n        synapse_client: If not passed in or None this will use the last client\n            from the `.login()` method.\n\n    Returns:\n        A Permissions object\n\n\n    Example: Using this function:\n        Getting permissions for a Synapse Entity\n\n            permissions = await File(id=\"syn123\").get_permissions_async()\n\n        Getting access types list from the Permissions object\n\n            permissions.access_types\n    \"\"\"\n    loop = asyncio.get_event_loop()\n    current_context = context.get_current()\n\n    return await loop.run_in_executor(\n        None,\n        lambda: run_and_attach_otel_context(\n            lambda: Synapse.get_client(\n                synapse_client=synapse_client\n            ).get_permissions(entity=self.id),\n            current_context,\n        ),\n    )\n</code></pre>"},{"location":"reference/oop/models_async/#synapseclient.models.File.get_acl_async","title":"<code>get_acl_async(principal_id=None, *, synapse_client=None)</code>  <code>async</code>","text":"<p>Get the ACL that a user or group has on an Entity.</p> PARAMETER DESCRIPTION <code>principal_id</code> <p>Identifier of a user or group (defaults to PUBLIC users)</p> <p> TYPE: <code>int</code> DEFAULT: <code>None</code> </p> <code>synapse_client</code> <p>If not passed in or None this will use the last client from the <code>.login()</code> method.</p> <p> TYPE: <code>Optional[Synapse]</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>List[str]</code> <p>An array containing some combination of ['READ', 'UPDATE', 'CREATE', 'DELETE', 'DOWNLOAD', 'MODERATE', 'CHANGE_PERMISSIONS', 'CHANGE_SETTINGS'] or an empty array</p> Source code in <code>synapseclient/models/mixins/access_control.py</code> <pre><code>async def get_acl_async(\n    self, principal_id: int = None, *, synapse_client: Optional[Synapse] = None\n) -&gt; List[str]:\n    \"\"\"\n    Get the [ACL][synapseclient.core.models.permission.Permissions.access_types]\n    that a user or group has on an Entity.\n\n    Arguments:\n        principal_id: Identifier of a user or group (defaults to PUBLIC users)\n        synapse_client: If not passed in or None this will use the last client\n            from the `.login()` method.\n\n    Returns:\n        An array containing some combination of\n            ['READ', 'UPDATE', 'CREATE', 'DELETE', 'DOWNLOAD', 'MODERATE',\n            'CHANGE_PERMISSIONS', 'CHANGE_SETTINGS']\n            or an empty array\n    \"\"\"\n    loop = asyncio.get_event_loop()\n    current_context = context.get_current()\n\n    return await loop.run_in_executor(\n        None,\n        lambda: run_and_attach_otel_context(\n            lambda: Synapse.get_client(synapse_client=synapse_client).get_acl(\n                entity=self.id, principal_id=principal_id\n            ),\n            current_context,\n        ),\n    )\n</code></pre>"},{"location":"reference/oop/models_async/#synapseclient.models.File.set_permissions_async","title":"<code>set_permissions_async(principal_id=None, access_type=None, modify_benefactor=False, warn_if_inherits=True, overwrite=True, *, synapse_client=None)</code>  <code>async</code>","text":"<p>Sets permission that a user or group has on an Entity. An Entity may have its own ACL or inherit its ACL from a benefactor.</p> PARAMETER DESCRIPTION <code>principal_id</code> <p>Identifier of a user or group. <code>273948</code> is for all registered Synapse users and <code>273949</code> is for public access. None implies public access.</p> <p> TYPE: <code>int</code> DEFAULT: <code>None</code> </p> <code>access_type</code> <p>Type of permission to be granted. One or more of CREATE, READ, DOWNLOAD, UPDATE, DELETE, CHANGE_PERMISSIONS.</p> <p>Defaults to ['READ', 'DOWNLOAD']</p> <p> TYPE: <code>List[str]</code> DEFAULT: <code>None</code> </p> <code>modify_benefactor</code> <p>Set as True when modifying a benefactor's ACL</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>warn_if_inherits</code> <p>Set as False, when creating a new ACL. Trying to modify the ACL of an Entity that inherits its ACL will result in a warning</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> <code>overwrite</code> <p>By default this function overwrites existing permissions for the specified user. Set this flag to False to add new permissions non-destructively.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> <code>synapse_client</code> <p>If not passed in or None this will use the last client from the <code>.login()</code> method.</p> <p> TYPE: <code>Optional[Synapse]</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>Dict[str, Union[str, list]]</code> <p>An Access Control List object</p> Setting permissions <p>Grant all registered users download access</p> <pre><code>await File(id=\"syn123\").set_permissions_async(principal_id=273948, access_type=['READ','DOWNLOAD'])\n</code></pre> <p>Grant the public view access</p> <pre><code>await File(id=\"syn123\").set_permissions_async(principal_id=273949, access_type=['READ'])\n</code></pre> Source code in <code>synapseclient/models/mixins/access_control.py</code> <pre><code>async def set_permissions_async(\n    self,\n    principal_id: int = None,\n    access_type: List[str] = None,\n    modify_benefactor: bool = False,\n    warn_if_inherits: bool = True,\n    overwrite: bool = True,\n    *,\n    synapse_client: Optional[Synapse] = None,\n) -&gt; Dict[str, Union[str, list]]:\n    \"\"\"\n    Sets permission that a user or group has on an Entity.\n    An Entity may have its own ACL or inherit its ACL from a benefactor.\n\n    Arguments:\n        principal_id: Identifier of a user or group. `273948` is for all\n            registered Synapse users and `273949` is for public access.\n            None implies public access.\n        access_type: Type of permission to be granted. One or more of CREATE,\n            READ, DOWNLOAD, UPDATE, DELETE, CHANGE_PERMISSIONS.\n\n            **Defaults to ['READ', 'DOWNLOAD']**\n        modify_benefactor: Set as True when modifying a benefactor's ACL\n        warn_if_inherits: Set as False, when creating a new ACL. Trying to modify\n            the ACL of an Entity that inherits its ACL will result in a warning\n        overwrite: By default this function overwrites existing permissions for\n            the specified user. Set this flag to False to add new permissions\n            non-destructively.\n        synapse_client: If not passed in or None this will use the last client\n            from the `.login()` method.\n\n    Returns:\n        An Access Control List object\n\n    Example: Setting permissions\n        Grant all registered users download access\n\n            await File(id=\"syn123\").set_permissions_async(principal_id=273948, access_type=['READ','DOWNLOAD'])\n\n        Grant the public view access\n\n            await File(id=\"syn123\").set_permissions_async(principal_id=273949, access_type=['READ'])\n    \"\"\"\n    if access_type is None:\n        access_type = [\"READ\", \"DOWNLOAD\"]\n    loop = asyncio.get_event_loop()\n    current_context = context.get_current()\n\n    return await loop.run_in_executor(\n        None,\n        lambda: run_and_attach_otel_context(\n            lambda: Synapse.get_client(\n                synapse_client=synapse_client\n            ).setPermissions(\n                entity=self.id,\n                principalId=principal_id,\n                accessType=access_type,\n                modify_benefactor=modify_benefactor,\n                warn_if_inherits=warn_if_inherits,\n                overwrite=overwrite,\n            ),\n            current_context,\n        ),\n    )\n</code></pre>"},{"location":"reference/oop/models_async/#synapseclient.models.Table","title":"<code>synapseclient.models.Table</code>  <code>dataclass</code>","text":"<p>               Bases: <code>TableSynchronousProtocol</code>, <code>AccessControllable</code></p> <p>A Table represents the metadata of a table.</p> ATTRIBUTE DESCRIPTION <code>id</code> <p>The unique immutable ID for this table. A new ID will be generated for new Tables. Once issued, this ID is guaranteed to never change or be re-issued</p> <p> TYPE: <code>Optional[str]</code> </p> <code>name</code> <p>The name of this table. Must be 256 characters or less. Names may only contain: letters, numbers, spaces, underscores, hyphens, periods, plus signs, apostrophes, and parentheses</p> <p> TYPE: <code>Optional[str]</code> </p> <code>parent_id</code> <p>The ID of the Entity that is the parent of this table.</p> <p> TYPE: <code>Optional[str]</code> </p> <code>columns</code> <p>The columns of this table.</p> <p> TYPE: <code>Optional[List[Column]]</code> </p> <code>description</code> <p>The description of this entity. Must be 1000 characters or less.</p> <p> TYPE: <code>Optional[List[Column]]</code> </p> <code>etag</code> <p>Synapse employs an Optimistic Concurrency Control (OCC) scheme to handle concurrent updates. Since the E-Tag changes every time an entity is updated it is used to detect when a client's current representation of an entity is out-of-date.</p> <p> TYPE: <code>Optional[str]</code> </p> <code>created_on</code> <p>The date this table was created.</p> <p> TYPE: <code>Optional[str]</code> </p> <code>created_by</code> <p>The ID of the user that created this table.</p> <p> TYPE: <code>Optional[str]</code> </p> <code>modified_on</code> <p>The date this table was last modified. In YYYY-MM-DD-Thh:mm:ss.sssZ format</p> <p> TYPE: <code>Optional[str]</code> </p> <code>modified_by</code> <p>The ID of the user that last modified this table.</p> <p> TYPE: <code>Optional[str]</code> </p> <code>version_number</code> <p>The version number issued to this version on the object.</p> <p> TYPE: <code>Optional[int]</code> </p> <code>version_label</code> <p>The version label for this table</p> <p> TYPE: <code>Optional[str]</code> </p> <code>version_comment</code> <p>The version comment for this table</p> <p> TYPE: <code>Optional[str]</code> </p> <code>is_latest_version</code> <p>If this is the latest version of the object.</p> <p> TYPE: <code>Optional[bool]</code> </p> <code>is_search_enabled</code> <p>When creating or updating a table or view specifies if full text search should be enabled. Note that enabling full text search might slow down the indexing of the table or view.</p> <p> TYPE: <code>Optional[bool]</code> </p> <code>activity</code> <p>The Activity model represents the main record of Provenance in Synapse. It is analygous to the Activity defined in the W3C Specification on Provenance. Activity cannot be removed during a store operation by setting it to None. You must use: synapseclient.models.Activity.delete_async or synapseclient.models.Activity.disassociate_from_entity_async.</p> <p> TYPE: <code>Optional[Activity]</code> </p> <code>annotations</code> <p>Additional metadata associated with the table. The key is the name of your desired annotations. The value is an object containing a list of values (use empty list to represent no values for key) and the value type associated with all values in the list. To remove all annotations set this to an empty dict <code>{}</code> or None and store the entity.</p> <p> TYPE: <code>Optional[Dict[str, Union[List[str], List[bool], List[float], List[int], List[date], List[datetime]]]]</code> </p> Source code in <code>synapseclient/models/table.py</code> <pre><code>@dataclass()\n@async_to_sync\nclass Table(TableSynchronousProtocol, AccessControllable):\n    \"\"\"A Table represents the metadata of a table.\n\n    Attributes:\n        id: The unique immutable ID for this table. A new ID will be generated for new\n            Tables. Once issued, this ID is guaranteed to never change or be re-issued\n        name: The name of this table. Must be 256 characters or less. Names may only\n            contain: letters, numbers, spaces, underscores, hyphens, periods, plus\n            signs, apostrophes, and parentheses\n        parent_id: The ID of the Entity that is the parent of this table.\n        columns: The columns of this table.\n        description: The description of this entity. Must be 1000 characters or less.\n        etag: Synapse employs an Optimistic Concurrency Control (OCC) scheme to handle\n            concurrent updates. Since the E-Tag changes every time an entity is updated\n            it is used to detect when a client's current representation of an entity is\n            out-of-date.\n        created_on: The date this table was created.\n        created_by: The ID of the user that created this table.\n        modified_on: The date this table was last modified.\n            In YYYY-MM-DD-Thh:mm:ss.sssZ format\n        modified_by: The ID of the user that last modified this table.\n        version_number: The version number issued to this version on the object.\n        version_label: The version label for this table\n        version_comment: The version comment for this table\n        is_latest_version: If this is the latest version of the object.\n        is_search_enabled: When creating or updating a table or view specifies if full\n            text search should be enabled. Note that enabling full text search might\n            slow down the indexing of the table or view.\n        activity: The Activity model represents the main record of Provenance in\n            Synapse. It is analygous to the Activity defined in the\n            [W3C Specification](https://www.w3.org/TR/prov-n/) on Provenance. Activity\n            cannot be removed during a store operation by setting it to None. You must\n            use: [synapseclient.models.Activity.delete_async][] or\n            [synapseclient.models.Activity.disassociate_from_entity_async][].\n        annotations: Additional metadata associated with the table. The key is the name\n            of your desired annotations. The value is an object containing a list of\n            values (use empty list to represent no values for key) and the value type\n            associated with all values in the list. To remove all annotations set this\n            to an empty dict `{}` or None and store the entity.\n\n    \"\"\"\n\n    id: Optional[str] = None\n    \"\"\"The unique immutable ID for this table. A new ID will be generated for new\n    Tables. Once issued, this ID is guaranteed to never change or be re-issued\"\"\"\n\n    name: Optional[str] = None\n    \"\"\"The name of this table. Must be 256 characters or less. Names may only\n    contain: letters, numbers, spaces, underscores, hyphens, periods, plus signs,\n    apostrophes, and parentheses\"\"\"\n\n    parent_id: Optional[str] = None\n    \"\"\"The ID of the Entity that is the parent of this table.\"\"\"\n\n    columns: Optional[List[Column]] = None\n\n    # TODO: Description doesn't seem to be returned from the API. Look into why.\n    # description: Optional[str] = None\n    # \"\"\"The description of this entity. Must be 1000 characters or less.\"\"\"\n\n    etag: Optional[str] = None\n    \"\"\"\n    Synapse employs an Optimistic Concurrency Control (OCC) scheme to handle\n    concurrent updates. Since the E-Tag changes every time an entity is updated it is\n    used to detect when a client's current representation of an entity is out-of-date.\n    \"\"\"\n\n    created_on: Optional[str] = None\n    \"\"\"The date this table was created.\"\"\"\n\n    created_by: Optional[str] = None\n    \"\"\"The ID of the user that created this table.\"\"\"\n\n    modified_on: Optional[str] = None\n    \"\"\"The date this table was last modified. In YYYY-MM-DD-Thh:mm:ss.sssZ format\"\"\"\n\n    modified_by: Optional[str] = None\n    \"\"\"The ID of the user that last modified this table.\"\"\"\n\n    version_number: Optional[int] = None\n    \"\"\"The version number issued to this version on the object.\"\"\"\n\n    version_label: Optional[str] = None\n    \"\"\"The version label for this table\"\"\"\n\n    version_comment: Optional[str] = None\n    \"\"\"The version comment for this table\"\"\"\n\n    is_latest_version: Optional[bool] = None\n    \"\"\"If this is the latest version of the object.\"\"\"\n\n    is_search_enabled: Optional[bool] = None\n    \"\"\"When creating or updating a table or view specifies if full text search\n    should be enabled. Note that enabling full text search might slow down the\n    indexing of the table or view.\"\"\"\n\n    activity: Optional[Activity] = None\n    \"\"\"The Activity model represents the main record of Provenance in Synapse.  It is\n    analygous to the Activity defined in the\n    [W3C Specification](https://www.w3.org/TR/prov-n/) on Provenance. Activity cannot\n    be removed during a store operation by setting it to None. You must use:\n    [synapseclient.models.Activity.delete_async][] or\n    [synapseclient.models.Activity.disassociate_from_entity_async][].\n    \"\"\"\n\n    annotations: Optional[\n        Dict[\n            str,\n            Union[\n                List[str],\n                List[bool],\n                List[float],\n                List[int],\n                List[date],\n                List[datetime],\n            ],\n        ]\n    ] = field(default_factory=dict)\n    \"\"\"Additional metadata associated with the table. The key is the name of your\n    desired annotations. The value is an object containing a list of values\n    (use empty list to represent no values for key) and the value type associated with\n    all values in the list. To remove all annotations set this to an empty dict `{}`\n    or None and store the entity.\"\"\"\n\n    def fill_from_dict(\n        self, synapse_table: Synapse_Table, set_annotations: bool = True\n    ) -&gt; \"Table\":\n        \"\"\"Converts the data coming from the Synapse API into this datamodel.\n\n        :param synapse_table: The data coming from the Synapse API\n        \"\"\"\n        self.id = synapse_table.get(\"id\", None)\n        self.name = synapse_table.get(\"name\", None)\n        self.parent_id = synapse_table.get(\"parentId\", None)\n        # TODO: Description doesn't seem to be returned from the API. Look into why.\n        # self.description = synapse_table.description\n        self.etag = synapse_table.get(\"etag\", None)\n        self.created_on = synapse_table.get(\"createdOn\", None)\n        self.created_by = synapse_table.get(\"createdBy\", None)\n        self.modified_on = synapse_table.get(\"modifiedOn\", None)\n        self.modified_by = synapse_table.get(\"modifiedBy\", None)\n        self.version_number = synapse_table.get(\"versionNumber\", None)\n        self.version_label = synapse_table.get(\"versionLabel\", None)\n        self.version_comment = synapse_table.get(\"versionComment\", None)\n        self.is_latest_version = synapse_table.get(\"isLatestVersion\", None)\n        self.is_search_enabled = synapse_table.get(\"isSearchEnabled\", False)\n        self.columns = [\n            Column(id=columnId, name=None, column_type=None)\n            for columnId in synapse_table.get(\"columnIds\", [])\n        ]\n        if set_annotations:\n            self.annotations = Annotations.from_dict(\n                synapse_table.get(\"annotations\", {})\n            )\n        return self\n\n    @otel_trace_method(\n        method_to_trace_name=lambda _, **kwargs: f\"Store_rows_by_csv: {kwargs.get('csv_path', None)}\"\n    )\n    async def store_rows_from_csv_async(\n        self, csv_path: str, *, synapse_client: Optional[Synapse] = None\n    ) -&gt; str:\n        \"\"\"Takes in a path to a CSV and stores the rows to Synapse.\n\n        Arguments:\n            csv_path: The path to the CSV to store.\n            synapse_client: If not passed in or None this will use the last client\n                from the `.login()` method.\n\n        Returns:\n            The path to the CSV that was stored.\n        \"\"\"\n        synapse_table = Synapse_Table(schema=self.id, values=csv_path)\n        loop = asyncio.get_event_loop()\n        current_context = context.get_current()\n        entity = await loop.run_in_executor(\n            None,\n            lambda: run_and_attach_otel_context(\n                lambda: Synapse.get_client(synapse_client=synapse_client).store(\n                    obj=synapse_table\n                ),\n                current_context,\n            ),\n        )\n        print(entity)\n        # TODO: What should this return?\n        return csv_path\n\n    @otel_trace_method(\n        method_to_trace_name=lambda self, **kwargs: f\"Delete_rows: {self.name}\"\n    )\n    async def delete_rows_async(\n        self, rows: List[Row], *, synapse_client: Optional[Synapse] = None\n    ) -&gt; None:\n        \"\"\"Delete rows from a table.\n\n        Arguments:\n            rows: The rows to delete.\n            synapse_client: If not passed in or None this will use the last client\n                from the `.login()` method.\n\n        Returns:\n            None\n        \"\"\"\n        rows_to_delete = []\n        for row in rows:\n            rows_to_delete.append([row.row_id, row.version_number])\n        loop = asyncio.get_event_loop()\n        current_context = context.get_current()\n        await loop.run_in_executor(\n            None,\n            lambda: run_and_attach_otel_context(\n                lambda: delete_rows(\n                    syn=Synapse.get_client(synapse_client=synapse_client),\n                    table_id=self.id,\n                    row_id_vers_list=rows_to_delete,\n                ),\n                current_context,\n            ),\n        )\n\n    @otel_trace_method(\n        method_to_trace_name=lambda self, **kwargs: f\"Table_Schema_Store: {self.name}\"\n    )\n    async def store_schema_async(\n        self, *, synapse_client: Optional[Synapse] = None\n    ) -&gt; \"Table\":\n        \"\"\"Store non-row information about a table including the columns and annotations.\n\n        Arguments:\n            synapse_client: If not passed in or None this will use the last client\n                from the `.login()` method.\n\n        Returns:\n            The Table instance stored in synapse.\n        \"\"\"\n        tasks = []\n        if self.columns:\n            # TODO: When a table is retrieved via `.get()` we create Column objects but\n            # TODO: We only have the ID attribute. THis is causing this if check to eval\n            # TODO: To True, however, we aren't actually modifying the column.\n            # TODO: Perhaps we should have a `has_changed` boolean on all dataclasses\n            # TODO: That we can check to see if we need to store the data.\n            tasks.extend(\n                column.store_async(synapse_client=synapse_client)\n                for column in self.columns\n            )\n            try:\n                results = await asyncio.gather(*tasks, return_exceptions=True)\n\n                # TODO: Proper exception handling\n                for result in results:\n                    if isinstance(result, Column):\n                        print(f\"Stored {result.name}\")\n                    else:\n                        if isinstance(result, BaseException):\n                            raise result\n                        raise ValueError(f\"Unknown type: {type(result)}\", result)\n            except Exception as ex:\n                Synapse.get_client(synapse_client=synapse_client).logger.exception(ex)\n                print(\"I hit an exception\")\n\n        synapse_schema = Synapse_Schema(\n            name=self.name,\n            columns=self.columns,\n            parent=self.parent_id,\n        )\n        trace.get_current_span().set_attributes(\n            {\n                \"synapse.name\": self.name or \"\",\n                \"synapse.id\": self.id or \"\",\n            }\n        )\n        loop = asyncio.get_event_loop()\n        current_context = context.get_current()\n        entity = await loop.run_in_executor(\n            None,\n            lambda: run_and_attach_otel_context(\n                lambda: Synapse.get_client(synapse_client=synapse_client).store(\n                    obj=synapse_schema\n                ),\n                current_context,\n            ),\n        )\n\n        self.fill_from_dict(synapse_table=entity, set_annotations=False)\n\n        re_read_required = await store_entity_components(\n            root_resource=self, synapse_client=synapse_client\n        )\n        if re_read_required:\n            await self.get_async(\n                synapse_client=synapse_client,\n            )\n\n        return self\n\n    @otel_trace_method(\n        method_to_trace_name=lambda self, **kwargs: f\"Table_Get: {self.name}\"\n    )\n    async def get_async(self, *, synapse_client: Optional[Synapse] = None) -&gt; \"Table\":\n        \"\"\"Get the metadata about the table from synapse.\n\n        Arguments:\n            synapse_client: If not passed in or None this will use the last client\n                from the `.login()` method.\n\n        Returns:\n            The Table instance stored in synapse.\n        \"\"\"\n        # TODO: How do we want to support retriving the table? Do we want to support by name, and parent?\n        loop = asyncio.get_event_loop()\n        current_context = context.get_current()\n        entity = await loop.run_in_executor(\n            None,\n            lambda: run_and_attach_otel_context(\n                lambda: Synapse.get_client(synapse_client=synapse_client).get(\n                    entity=self.id\n                ),\n                current_context,\n            ),\n        )\n        self.fill_from_dict(synapse_table=entity, set_annotations=True)\n        return self\n\n    @otel_trace_method(\n        method_to_trace_name=lambda self, **kwargs: f\"Table_Delete: {self.name}\"\n    )\n    # TODO: Synapse allows immediate deletion of entities, but the Synapse Client does not\n    # TODO: Should we support immediate deletion?\n    async def delete_async(self, *, synapse_client: Optional[Synapse] = None) -&gt; None:\n        \"\"\"Delete the table from synapse.\n\n        Arguments:\n            synapse_client: If not passed in or None this will use the last client\n                from the `.login()` method.\n\n        Returns:\n            None\n        \"\"\"\n        loop = asyncio.get_event_loop()\n        current_context = context.get_current()\n        await loop.run_in_executor(\n            None,\n            lambda: run_and_attach_otel_context(\n                lambda: Synapse.get_client(synapse_client=synapse_client).delete(\n                    obj=self.id\n                ),\n                current_context,\n            ),\n        )\n\n    @classmethod\n    async def query_async(\n        cls,\n        query: str,\n        result_format: Union[CsvResultFormat, RowsetResultFormat] = CsvResultFormat(),\n        *,\n        synapse_client: Optional[Synapse] = None,\n    ) -&gt; Union[Synapse_CsvFileTable, Synaspe_TableQueryResult]:\n        \"\"\"Query for data on a table stored in Synapse.\n\n        Arguments:\n            query: The query to run.\n            result_format: The format of the results. Defaults to CsvResultFormat().\n            synapse_client: If not passed in or None this will use the last client\n                from the `.login()` method.\n\n        Returns:\n            The results of the query.\n        \"\"\"\n        loop = asyncio.get_event_loop()\n        current_context = context.get_current()\n\n        # TODO: Future Idea - We stream back a CSV, and let those reading this to handle the CSV however they want\n        results = await loop.run_in_executor(\n            None,\n            lambda: run_and_attach_otel_context(\n                lambda: Synapse.get_client(synapse_client=synapse_client).tableQuery(\n                    query=query,\n                    **result_format.to_dict(),\n                ),\n                current_context,\n            ),\n        )\n        print(results)\n        return results\n</code></pre>"},{"location":"reference/oop/models_async/#synapseclient.models.Table-functions","title":"Functions","text":""},{"location":"reference/oop/models_async/#synapseclient.models.Table.get_async","title":"<code>get_async(*, synapse_client=None)</code>  <code>async</code>","text":"<p>Get the metadata about the table from synapse.</p> PARAMETER DESCRIPTION <code>synapse_client</code> <p>If not passed in or None this will use the last client from the <code>.login()</code> method.</p> <p> TYPE: <code>Optional[Synapse]</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>Table</code> <p>The Table instance stored in synapse.</p> Source code in <code>synapseclient/models/table.py</code> <pre><code>@otel_trace_method(\n    method_to_trace_name=lambda self, **kwargs: f\"Table_Get: {self.name}\"\n)\nasync def get_async(self, *, synapse_client: Optional[Synapse] = None) -&gt; \"Table\":\n    \"\"\"Get the metadata about the table from synapse.\n\n    Arguments:\n        synapse_client: If not passed in or None this will use the last client\n            from the `.login()` method.\n\n    Returns:\n        The Table instance stored in synapse.\n    \"\"\"\n    # TODO: How do we want to support retriving the table? Do we want to support by name, and parent?\n    loop = asyncio.get_event_loop()\n    current_context = context.get_current()\n    entity = await loop.run_in_executor(\n        None,\n        lambda: run_and_attach_otel_context(\n            lambda: Synapse.get_client(synapse_client=synapse_client).get(\n                entity=self.id\n            ),\n            current_context,\n        ),\n    )\n    self.fill_from_dict(synapse_table=entity, set_annotations=True)\n    return self\n</code></pre>"},{"location":"reference/oop/models_async/#synapseclient.models.Table.store_schema_async","title":"<code>store_schema_async(*, synapse_client=None)</code>  <code>async</code>","text":"<p>Store non-row information about a table including the columns and annotations.</p> PARAMETER DESCRIPTION <code>synapse_client</code> <p>If not passed in or None this will use the last client from the <code>.login()</code> method.</p> <p> TYPE: <code>Optional[Synapse]</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>Table</code> <p>The Table instance stored in synapse.</p> Source code in <code>synapseclient/models/table.py</code> <pre><code>@otel_trace_method(\n    method_to_trace_name=lambda self, **kwargs: f\"Table_Schema_Store: {self.name}\"\n)\nasync def store_schema_async(\n    self, *, synapse_client: Optional[Synapse] = None\n) -&gt; \"Table\":\n    \"\"\"Store non-row information about a table including the columns and annotations.\n\n    Arguments:\n        synapse_client: If not passed in or None this will use the last client\n            from the `.login()` method.\n\n    Returns:\n        The Table instance stored in synapse.\n    \"\"\"\n    tasks = []\n    if self.columns:\n        # TODO: When a table is retrieved via `.get()` we create Column objects but\n        # TODO: We only have the ID attribute. THis is causing this if check to eval\n        # TODO: To True, however, we aren't actually modifying the column.\n        # TODO: Perhaps we should have a `has_changed` boolean on all dataclasses\n        # TODO: That we can check to see if we need to store the data.\n        tasks.extend(\n            column.store_async(synapse_client=synapse_client)\n            for column in self.columns\n        )\n        try:\n            results = await asyncio.gather(*tasks, return_exceptions=True)\n\n            # TODO: Proper exception handling\n            for result in results:\n                if isinstance(result, Column):\n                    print(f\"Stored {result.name}\")\n                else:\n                    if isinstance(result, BaseException):\n                        raise result\n                    raise ValueError(f\"Unknown type: {type(result)}\", result)\n        except Exception as ex:\n            Synapse.get_client(synapse_client=synapse_client).logger.exception(ex)\n            print(\"I hit an exception\")\n\n    synapse_schema = Synapse_Schema(\n        name=self.name,\n        columns=self.columns,\n        parent=self.parent_id,\n    )\n    trace.get_current_span().set_attributes(\n        {\n            \"synapse.name\": self.name or \"\",\n            \"synapse.id\": self.id or \"\",\n        }\n    )\n    loop = asyncio.get_event_loop()\n    current_context = context.get_current()\n    entity = await loop.run_in_executor(\n        None,\n        lambda: run_and_attach_otel_context(\n            lambda: Synapse.get_client(synapse_client=synapse_client).store(\n                obj=synapse_schema\n            ),\n            current_context,\n        ),\n    )\n\n    self.fill_from_dict(synapse_table=entity, set_annotations=False)\n\n    re_read_required = await store_entity_components(\n        root_resource=self, synapse_client=synapse_client\n    )\n    if re_read_required:\n        await self.get_async(\n            synapse_client=synapse_client,\n        )\n\n    return self\n</code></pre>"},{"location":"reference/oop/models_async/#synapseclient.models.Table.store_rows_from_csv_async","title":"<code>store_rows_from_csv_async(csv_path, *, synapse_client=None)</code>  <code>async</code>","text":"<p>Takes in a path to a CSV and stores the rows to Synapse.</p> PARAMETER DESCRIPTION <code>csv_path</code> <p>The path to the CSV to store.</p> <p> TYPE: <code>str</code> </p> <code>synapse_client</code> <p>If not passed in or None this will use the last client from the <code>.login()</code> method.</p> <p> TYPE: <code>Optional[Synapse]</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>str</code> <p>The path to the CSV that was stored.</p> Source code in <code>synapseclient/models/table.py</code> <pre><code>@otel_trace_method(\n    method_to_trace_name=lambda _, **kwargs: f\"Store_rows_by_csv: {kwargs.get('csv_path', None)}\"\n)\nasync def store_rows_from_csv_async(\n    self, csv_path: str, *, synapse_client: Optional[Synapse] = None\n) -&gt; str:\n    \"\"\"Takes in a path to a CSV and stores the rows to Synapse.\n\n    Arguments:\n        csv_path: The path to the CSV to store.\n        synapse_client: If not passed in or None this will use the last client\n            from the `.login()` method.\n\n    Returns:\n        The path to the CSV that was stored.\n    \"\"\"\n    synapse_table = Synapse_Table(schema=self.id, values=csv_path)\n    loop = asyncio.get_event_loop()\n    current_context = context.get_current()\n    entity = await loop.run_in_executor(\n        None,\n        lambda: run_and_attach_otel_context(\n            lambda: Synapse.get_client(synapse_client=synapse_client).store(\n                obj=synapse_table\n            ),\n            current_context,\n        ),\n    )\n    print(entity)\n    # TODO: What should this return?\n    return csv_path\n</code></pre>"},{"location":"reference/oop/models_async/#synapseclient.models.Table.delete_rows_async","title":"<code>delete_rows_async(rows, *, synapse_client=None)</code>  <code>async</code>","text":"<p>Delete rows from a table.</p> PARAMETER DESCRIPTION <code>rows</code> <p>The rows to delete.</p> <p> TYPE: <code>List[Row]</code> </p> <code>synapse_client</code> <p>If not passed in or None this will use the last client from the <code>.login()</code> method.</p> <p> TYPE: <code>Optional[Synapse]</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>None</code> <p>None</p> Source code in <code>synapseclient/models/table.py</code> <pre><code>@otel_trace_method(\n    method_to_trace_name=lambda self, **kwargs: f\"Delete_rows: {self.name}\"\n)\nasync def delete_rows_async(\n    self, rows: List[Row], *, synapse_client: Optional[Synapse] = None\n) -&gt; None:\n    \"\"\"Delete rows from a table.\n\n    Arguments:\n        rows: The rows to delete.\n        synapse_client: If not passed in or None this will use the last client\n            from the `.login()` method.\n\n    Returns:\n        None\n    \"\"\"\n    rows_to_delete = []\n    for row in rows:\n        rows_to_delete.append([row.row_id, row.version_number])\n    loop = asyncio.get_event_loop()\n    current_context = context.get_current()\n    await loop.run_in_executor(\n        None,\n        lambda: run_and_attach_otel_context(\n            lambda: delete_rows(\n                syn=Synapse.get_client(synapse_client=synapse_client),\n                table_id=self.id,\n                row_id_vers_list=rows_to_delete,\n            ),\n            current_context,\n        ),\n    )\n</code></pre>"},{"location":"reference/oop/models_async/#synapseclient.models.Table.query_async","title":"<code>query_async(query, result_format=CsvResultFormat(), *, synapse_client=None)</code>  <code>async</code> <code>classmethod</code>","text":"<p>Query for data on a table stored in Synapse.</p> PARAMETER DESCRIPTION <code>query</code> <p>The query to run.</p> <p> TYPE: <code>str</code> </p> <code>result_format</code> <p>The format of the results. Defaults to CsvResultFormat().</p> <p> TYPE: <code>Union[CsvResultFormat, RowsetResultFormat]</code> DEFAULT: <code>CsvResultFormat()</code> </p> <code>synapse_client</code> <p>If not passed in or None this will use the last client from the <code>.login()</code> method.</p> <p> TYPE: <code>Optional[Synapse]</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>Union[CsvFileTable, TableQueryResult]</code> <p>The results of the query.</p> Source code in <code>synapseclient/models/table.py</code> <pre><code>@classmethod\nasync def query_async(\n    cls,\n    query: str,\n    result_format: Union[CsvResultFormat, RowsetResultFormat] = CsvResultFormat(),\n    *,\n    synapse_client: Optional[Synapse] = None,\n) -&gt; Union[Synapse_CsvFileTable, Synaspe_TableQueryResult]:\n    \"\"\"Query for data on a table stored in Synapse.\n\n    Arguments:\n        query: The query to run.\n        result_format: The format of the results. Defaults to CsvResultFormat().\n        synapse_client: If not passed in or None this will use the last client\n            from the `.login()` method.\n\n    Returns:\n        The results of the query.\n    \"\"\"\n    loop = asyncio.get_event_loop()\n    current_context = context.get_current()\n\n    # TODO: Future Idea - We stream back a CSV, and let those reading this to handle the CSV however they want\n    results = await loop.run_in_executor(\n        None,\n        lambda: run_and_attach_otel_context(\n            lambda: Synapse.get_client(synapse_client=synapse_client).tableQuery(\n                query=query,\n                **result_format.to_dict(),\n            ),\n            current_context,\n        ),\n    )\n    print(results)\n    return results\n</code></pre>"},{"location":"reference/oop/models_async/#synapseclient.models.Table.delete_async","title":"<code>delete_async(*, synapse_client=None)</code>  <code>async</code>","text":"<p>Delete the table from synapse.</p> PARAMETER DESCRIPTION <code>synapse_client</code> <p>If not passed in or None this will use the last client from the <code>.login()</code> method.</p> <p> TYPE: <code>Optional[Synapse]</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>None</code> <p>None</p> Source code in <code>synapseclient/models/table.py</code> <pre><code>@otel_trace_method(\n    method_to_trace_name=lambda self, **kwargs: f\"Table_Delete: {self.name}\"\n)\n# TODO: Synapse allows immediate deletion of entities, but the Synapse Client does not\n# TODO: Should we support immediate deletion?\nasync def delete_async(self, *, synapse_client: Optional[Synapse] = None) -&gt; None:\n    \"\"\"Delete the table from synapse.\n\n    Arguments:\n        synapse_client: If not passed in or None this will use the last client\n            from the `.login()` method.\n\n    Returns:\n        None\n    \"\"\"\n    loop = asyncio.get_event_loop()\n    current_context = context.get_current()\n    await loop.run_in_executor(\n        None,\n        lambda: run_and_attach_otel_context(\n            lambda: Synapse.get_client(synapse_client=synapse_client).delete(\n                obj=self.id\n            ),\n            current_context,\n        ),\n    )\n</code></pre>"},{"location":"reference/oop/models_async/#synapseclient.models.Table.get_permissions_async","title":"<code>get_permissions_async(*, synapse_client=None)</code>  <code>async</code>","text":"<p>Get the permissions that the caller has on an Entity.</p> PARAMETER DESCRIPTION <code>synapse_client</code> <p>If not passed in or None this will use the last client from the <code>.login()</code> method.</p> <p> TYPE: <code>Optional[Synapse]</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>Permissions</code> <p>A Permissions object</p> Using this function: <p>Getting permissions for a Synapse Entity</p> <pre><code>permissions = await File(id=\"syn123\").get_permissions_async()\n</code></pre> <p>Getting access types list from the Permissions object</p> <pre><code>permissions.access_types\n</code></pre> Source code in <code>synapseclient/models/mixins/access_control.py</code> <pre><code>async def get_permissions_async(\n    self,\n    *,\n    synapse_client: Optional[Synapse] = None,\n) -&gt; \"Permissions\":\n    \"\"\"\n    Get the [permissions][synapseclient.core.models.permission.Permissions]\n    that the caller has on an Entity.\n\n    Arguments:\n        synapse_client: If not passed in or None this will use the last client\n            from the `.login()` method.\n\n    Returns:\n        A Permissions object\n\n\n    Example: Using this function:\n        Getting permissions for a Synapse Entity\n\n            permissions = await File(id=\"syn123\").get_permissions_async()\n\n        Getting access types list from the Permissions object\n\n            permissions.access_types\n    \"\"\"\n    loop = asyncio.get_event_loop()\n    current_context = context.get_current()\n\n    return await loop.run_in_executor(\n        None,\n        lambda: run_and_attach_otel_context(\n            lambda: Synapse.get_client(\n                synapse_client=synapse_client\n            ).get_permissions(entity=self.id),\n            current_context,\n        ),\n    )\n</code></pre>"},{"location":"reference/oop/models_async/#synapseclient.models.Table.get_acl_async","title":"<code>get_acl_async(principal_id=None, *, synapse_client=None)</code>  <code>async</code>","text":"<p>Get the ACL that a user or group has on an Entity.</p> PARAMETER DESCRIPTION <code>principal_id</code> <p>Identifier of a user or group (defaults to PUBLIC users)</p> <p> TYPE: <code>int</code> DEFAULT: <code>None</code> </p> <code>synapse_client</code> <p>If not passed in or None this will use the last client from the <code>.login()</code> method.</p> <p> TYPE: <code>Optional[Synapse]</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>List[str]</code> <p>An array containing some combination of ['READ', 'UPDATE', 'CREATE', 'DELETE', 'DOWNLOAD', 'MODERATE', 'CHANGE_PERMISSIONS', 'CHANGE_SETTINGS'] or an empty array</p> Source code in <code>synapseclient/models/mixins/access_control.py</code> <pre><code>async def get_acl_async(\n    self, principal_id: int = None, *, synapse_client: Optional[Synapse] = None\n) -&gt; List[str]:\n    \"\"\"\n    Get the [ACL][synapseclient.core.models.permission.Permissions.access_types]\n    that a user or group has on an Entity.\n\n    Arguments:\n        principal_id: Identifier of a user or group (defaults to PUBLIC users)\n        synapse_client: If not passed in or None this will use the last client\n            from the `.login()` method.\n\n    Returns:\n        An array containing some combination of\n            ['READ', 'UPDATE', 'CREATE', 'DELETE', 'DOWNLOAD', 'MODERATE',\n            'CHANGE_PERMISSIONS', 'CHANGE_SETTINGS']\n            or an empty array\n    \"\"\"\n    loop = asyncio.get_event_loop()\n    current_context = context.get_current()\n\n    return await loop.run_in_executor(\n        None,\n        lambda: run_and_attach_otel_context(\n            lambda: Synapse.get_client(synapse_client=synapse_client).get_acl(\n                entity=self.id, principal_id=principal_id\n            ),\n            current_context,\n        ),\n    )\n</code></pre>"},{"location":"reference/oop/models_async/#synapseclient.models.Table.set_permissions_async","title":"<code>set_permissions_async(principal_id=None, access_type=None, modify_benefactor=False, warn_if_inherits=True, overwrite=True, *, synapse_client=None)</code>  <code>async</code>","text":"<p>Sets permission that a user or group has on an Entity. An Entity may have its own ACL or inherit its ACL from a benefactor.</p> PARAMETER DESCRIPTION <code>principal_id</code> <p>Identifier of a user or group. <code>273948</code> is for all registered Synapse users and <code>273949</code> is for public access. None implies public access.</p> <p> TYPE: <code>int</code> DEFAULT: <code>None</code> </p> <code>access_type</code> <p>Type of permission to be granted. One or more of CREATE, READ, DOWNLOAD, UPDATE, DELETE, CHANGE_PERMISSIONS.</p> <p>Defaults to ['READ', 'DOWNLOAD']</p> <p> TYPE: <code>List[str]</code> DEFAULT: <code>None</code> </p> <code>modify_benefactor</code> <p>Set as True when modifying a benefactor's ACL</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>warn_if_inherits</code> <p>Set as False, when creating a new ACL. Trying to modify the ACL of an Entity that inherits its ACL will result in a warning</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> <code>overwrite</code> <p>By default this function overwrites existing permissions for the specified user. Set this flag to False to add new permissions non-destructively.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> <code>synapse_client</code> <p>If not passed in or None this will use the last client from the <code>.login()</code> method.</p> <p> TYPE: <code>Optional[Synapse]</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>Dict[str, Union[str, list]]</code> <p>An Access Control List object</p> Setting permissions <p>Grant all registered users download access</p> <pre><code>await File(id=\"syn123\").set_permissions_async(principal_id=273948, access_type=['READ','DOWNLOAD'])\n</code></pre> <p>Grant the public view access</p> <pre><code>await File(id=\"syn123\").set_permissions_async(principal_id=273949, access_type=['READ'])\n</code></pre> Source code in <code>synapseclient/models/mixins/access_control.py</code> <pre><code>async def set_permissions_async(\n    self,\n    principal_id: int = None,\n    access_type: List[str] = None,\n    modify_benefactor: bool = False,\n    warn_if_inherits: bool = True,\n    overwrite: bool = True,\n    *,\n    synapse_client: Optional[Synapse] = None,\n) -&gt; Dict[str, Union[str, list]]:\n    \"\"\"\n    Sets permission that a user or group has on an Entity.\n    An Entity may have its own ACL or inherit its ACL from a benefactor.\n\n    Arguments:\n        principal_id: Identifier of a user or group. `273948` is for all\n            registered Synapse users and `273949` is for public access.\n            None implies public access.\n        access_type: Type of permission to be granted. One or more of CREATE,\n            READ, DOWNLOAD, UPDATE, DELETE, CHANGE_PERMISSIONS.\n\n            **Defaults to ['READ', 'DOWNLOAD']**\n        modify_benefactor: Set as True when modifying a benefactor's ACL\n        warn_if_inherits: Set as False, when creating a new ACL. Trying to modify\n            the ACL of an Entity that inherits its ACL will result in a warning\n        overwrite: By default this function overwrites existing permissions for\n            the specified user. Set this flag to False to add new permissions\n            non-destructively.\n        synapse_client: If not passed in or None this will use the last client\n            from the `.login()` method.\n\n    Returns:\n        An Access Control List object\n\n    Example: Setting permissions\n        Grant all registered users download access\n\n            await File(id=\"syn123\").set_permissions_async(principal_id=273948, access_type=['READ','DOWNLOAD'])\n\n        Grant the public view access\n\n            await File(id=\"syn123\").set_permissions_async(principal_id=273949, access_type=['READ'])\n    \"\"\"\n    if access_type is None:\n        access_type = [\"READ\", \"DOWNLOAD\"]\n    loop = asyncio.get_event_loop()\n    current_context = context.get_current()\n\n    return await loop.run_in_executor(\n        None,\n        lambda: run_and_attach_otel_context(\n            lambda: Synapse.get_client(\n                synapse_client=synapse_client\n            ).setPermissions(\n                entity=self.id,\n                principalId=principal_id,\n                accessType=access_type,\n                modify_benefactor=modify_benefactor,\n                warn_if_inherits=warn_if_inherits,\n                overwrite=overwrite,\n            ),\n            current_context,\n        ),\n    )\n</code></pre>"},{"location":"reference/oop/models_async/#synapseclient.models.Activity","title":"<code>synapseclient.models.Activity</code>  <code>dataclass</code>","text":"<p>               Bases: <code>ActivitySynchronousProtocol</code></p> <p>An activity is a Synapse object that helps to keep track of what objects were used in an analysis step, as well as what objects were generated. Thus, all relationships between Synapse objects and an activity are governed by dependencies. That is, an activity needs to know what it <code>used</code>, and outputs need to know what activity they were <code>generatedBy</code>.</p> ATTRIBUTE DESCRIPTION <code>id</code> <p>The unique immutable ID for this actvity.</p> <p> TYPE: <code>Optional[str]</code> </p> <code>name</code> <p>A name for this Activity.</p> <p> TYPE: <code>Optional[str]</code> </p> <code>description</code> <p>A description for this Activity.</p> <p> TYPE: <code>Optional[str]</code> </p> <code>etag</code> <p>Synapse employs an Optimistic Concurrency Control (OCC) scheme to handle concurrent updates. Since the E-Tag changes every time an entity is updated it is used to detect when a client's current representation of an entity is out-of-date.</p> <p> TYPE: <code>Optional[str]</code> </p> <code>created_on</code> <p>The date this object was created.</p> <p> TYPE: <code>Optional[str]</code> </p> <code>modified_on</code> <p>The date this object was last modified.</p> <p> TYPE: <code>Optional[str]</code> </p> <code>created_by</code> <p>The user that created this object.</p> <p> TYPE: <code>Optional[str]</code> </p> <code>modified_by</code> <p>The user that last modified this object.</p> <p> TYPE: <code>Optional[str]</code> </p> <code>used</code> <p>The entities or URLs used by this Activity.</p> <p> TYPE: <code>List[Union[UsedEntity, UsedURL]]</code> </p> <code>executed</code> <p>The entities or URLs executed by this Activity.</p> <p> TYPE: <code>List[Union[UsedEntity, UsedURL]]</code> </p> Source code in <code>synapseclient/models/activity.py</code> <pre><code>@dataclass\n@async_to_sync\nclass Activity(ActivitySynchronousProtocol):\n    \"\"\"\n    An activity is a Synapse object that helps to keep track of what objects were used\n    in an analysis step, as well as what objects were generated. Thus, all relationships\n    between Synapse objects and an activity are governed by dependencies. That is, an\n    activity needs to know what it `used`, and outputs need to know what activity\n    they were `generatedBy`.\n\n    Attributes:\n        id: The unique immutable ID for this actvity.\n        name: A name for this Activity.\n        description: A description for this Activity.\n        etag: Synapse employs an Optimistic Concurrency Control (OCC) scheme to handle\n            concurrent updates. Since the E-Tag changes every time an entity is updated\n            it is used to detect when a client's current representation of an entity is\n            out-of-date.\n        created_on: The date this object was created.\n        modified_on: The date this object was last modified.\n        created_by: The user that created this object.\n        modified_by: The user that last modified this object.\n        used: The entities or URLs used by this Activity.\n        executed: The entities or URLs executed by this Activity.\n    \"\"\"\n\n    id: Optional[str] = None\n    \"\"\"The unique immutable ID for this actvity.\"\"\"\n\n    name: Optional[str] = None\n    \"\"\"A name for this Activity.\"\"\"\n\n    description: Optional[str] = None\n    \"\"\"A description for this Activity.\"\"\"\n\n    etag: Optional[str] = None\n    \"\"\"\n    Synapse employs an Optimistic Concurrency Control (OCC) scheme to handle\n    concurrent updates. Since the E-Tag changes every time an entity is updated it is\n    used to detect when a client's current representation of an entity is out-of-date.\n    \"\"\"\n\n    created_on: Optional[str] = None\n    \"\"\"The date this object was created.\"\"\"\n\n    modified_on: Optional[str] = None\n    \"\"\"The date this object was last modified.\"\"\"\n\n    created_by: Optional[str] = None\n    \"\"\"The user that created this object.\"\"\"\n\n    modified_by: Optional[str] = None\n    \"\"\"The user that last modified this object.\"\"\"\n\n    used: List[Union[UsedEntity, UsedURL]] = field(default_factory=list)\n    \"\"\"The entities used by this Activity.\"\"\"\n\n    executed: List[Union[UsedEntity, UsedURL]] = field(default_factory=list)\n    \"\"\"The entities executed by this Activity.\"\"\"\n\n    def fill_from_dict(\n        self, synapse_activity: Union[Synapse_Activity, Dict]\n    ) -&gt; \"Activity\":\n        \"\"\"\n        Converts a response from the REST API into this dataclass.\n\n        Arguments:\n            synapse_activity: The response from the REST API.\n\n        Returns:\n            The Activity object.\n        \"\"\"\n        if not synapse_activity:\n            synapse_activity = {}\n        self.id = synapse_activity.get(\"id\", None)\n        self.name = synapse_activity.get(\"name\", None)\n        self.description = synapse_activity.get(\"description\", None)\n        self.etag = synapse_activity.get(\"etag\", None)\n        self.created_on = synapse_activity.get(\"createdOn\", None)\n        self.modified_on = synapse_activity.get(\"modifiedOn\", None)\n        self.created_by = synapse_activity.get(\"createdBy\", None)\n        self.modified_by = synapse_activity.get(\"modifiedBy\", None)\n        self.executed = []\n        self.used = []\n        for used in synapse_activity.get(\"used\", []):\n            concrete_type = used.get(\"concreteType\", None)\n            if USED_URL == concrete_type:\n                used_url = UsedURL(\n                    name=used.get(\"name\", None),\n                    url=used.get(\"url\", None),\n                )\n\n                if used.get(\"wasExecuted\", False):\n                    self.executed.append(used_url)\n                else:\n                    self.used.append(used_url)\n            elif USED_ENTITY == concrete_type:\n                reference = used.get(\"reference\", {})\n                used_entity = UsedEntity(\n                    target_id=reference.get(\"targetId\", None),\n                    target_version_number=reference.get(\"targetVersionNumber\", None),\n                )\n\n                if used.get(\"wasExecuted\", False):\n                    self.executed.append(used_entity)\n                else:\n                    self.used.append(used_entity)\n\n        return self\n\n    def _create_used_and_executed_synapse_activities(\n        self,\n    ) -&gt; UsedAndExecutedSynapseActivities:\n        \"\"\"\n        Helper function to create the used and executed activities for the\n        Synapse Activity.\n\n        Returns:\n            A tuple of the used and executed activities.\n        \"\"\"\n        synapse_activity_used = []\n        synapse_activity_executed = []\n\n        for used in self.used:\n            if isinstance(used, UsedEntity):\n                synapse_activity_used.append(\n                    {\n                        \"reference\": {\n                            \"targetId\": used.target_id,\n                            \"targetVersionNumber\": used.target_version_number,\n                        }\n                    }\n                )\n            elif isinstance(used, UsedURL):\n                synapse_activity_used.append(\n                    {\n                        \"name\": used.name,\n                        \"url\": used.url,\n                    }\n                )\n\n        for executed in self.executed:\n            if isinstance(executed, UsedEntity):\n                synapse_activity_executed.append(\n                    {\n                        \"reference\": {\n                            \"targetId\": executed.target_id,\n                            \"targetVersionNumber\": executed.target_version_number,\n                        },\n                        \"wasExecuted\": True,\n                    }\n                )\n            elif isinstance(executed, UsedURL):\n                synapse_activity_executed.append(\n                    {\"name\": executed.name, \"url\": executed.url, \"wasExecuted\": True}\n                )\n        return UsedAndExecutedSynapseActivities(\n            used=synapse_activity_used, executed=synapse_activity_executed\n        )\n\n    @otel_trace_method(\n        method_to_trace_name=lambda self, **kwargs: f\"Activity_store: {self.name}\"\n    )\n    async def store_async(\n        self,\n        parent: Optional[Union[\"Table\", \"File\"]] = None,\n        *,\n        synapse_client: Optional[Synapse] = None,\n    ) -&gt; \"Activity\":\n        \"\"\"\n        Store the Activity in Synapse.\n\n        Arguments:\n            parent: The parent entity to associate this activity with.\n            synapse_client: If not passed in or None this will use the last client\n                from the `.login()` method.\n\n        Returns:\n            The activity object.\n\n        Raises:\n            ValueError: Raised if both of the following are true:\n\n                - If the parent does not have an ID.\n                - If the Activity does not have an ID and ETag.\n        \"\"\"\n        # TODO: Input validation: SYNPY-1400\n        used_and_executed_activities = (\n            self._create_used_and_executed_synapse_activities()\n        )\n\n        synapse_activity = Synapse_Activity(\n            name=self.name,\n            description=self.description,\n            used=used_and_executed_activities.used,\n            executed=used_and_executed_activities.executed,\n        )\n\n        loop = asyncio.get_event_loop()\n        current_context = context.get_current()\n        if self.id:\n            # Despite init in `Synapse_Activity` not accepting an ID/ETAG the\n            # `updateActivity` method expects that it exists on the dict\n            # and `setProvenance` accepts it as well.\n            synapse_activity[\"id\"] = self.id\n            synapse_activity[\"etag\"] = self.etag\n        if parent:\n            saved_activity = await loop.run_in_executor(\n                None,\n                lambda: run_and_attach_otel_context(\n                    lambda: Synapse.get_client(\n                        synapse_client=synapse_client\n                    ).setProvenance(\n                        entity=parent.id,\n                        activity=synapse_activity,\n                    ),\n                    current_context,\n                ),\n            )\n        else:\n            saved_activity = await loop.run_in_executor(\n                None,\n                lambda: run_and_attach_otel_context(\n                    lambda: Synapse.get_client(\n                        synapse_client=synapse_client\n                    ).updateActivity(\n                        activity=synapse_activity,\n                    ),\n                    current_context,\n                ),\n            )\n        self.fill_from_dict(synapse_activity=saved_activity)\n        Synapse.get_client(synapse_client=synapse_client).logger.debug(\n            f\"Stored activity {self.id}\"\n        )\n\n        return self\n\n    @classmethod\n    async def from_parent_async(\n        cls,\n        parent: Union[\"Table\", \"File\"],\n        *,\n        synapse_client: Optional[Synapse] = None,\n    ) -&gt; Union[\"Activity\", None]:\n        \"\"\"\n        Get the Activity from Synapse based on the parent entity.\n\n        Arguments:\n            parent: The parent entity this activity is associated with. The parent may\n                also have a version_number. Gets the most recent version if version is\n                omitted.\n            synapse_client: If not passed in or None this will use the last client\n                from the `.login()` method.\n\n        Returns:\n            The activity object or None if it does not exist.\n\n        Raises:\n            ValueError: If the parent does not have an ID.\n        \"\"\"\n        # TODO: Input validation: SYNPY-1400\n        with tracer.start_as_current_span(name=f\"Activity_get: Parent_ID: {parent.id}\"):\n            loop = asyncio.get_event_loop()\n            current_context = context.get_current()\n            try:\n                synapse_activity = await loop.run_in_executor(\n                    None,\n                    lambda: run_and_attach_otel_context(\n                        lambda: Synapse.get_client(\n                            synapse_client=synapse_client\n                        ).getProvenance(\n                            entity=parent.id,\n                            version=parent.version_number,\n                        ),\n                        current_context,\n                    ),\n                )\n            except SynapseHTTPError as ex:\n                if ex.response.status_code == 404:\n                    return None\n                else:\n                    raise ex\n            if synapse_activity:\n                return cls().fill_from_dict(synapse_activity=synapse_activity)\n            else:\n                return None\n\n    @classmethod\n    async def delete_async(\n        cls,\n        parent: Union[\"Table\", \"File\"],\n        *,\n        synapse_client: Optional[Synapse] = None,\n    ) -&gt; None:\n        \"\"\"\n        Delete the Activity from Synapse. The Activity must be disassociated from\n        all entities before it can be deleted. The first step of this delete call\n        is to disassociate the Activity from the parent entity. If you have other\n        entities that are associated with this Activity you must disassociate them\n        by calling this method on them as well. You'll receive an error for all entities\n        until the last one which will delete the Activity.\n\n        Arguments:\n            parent: The parent entity this activity is associated with.\n            synapse_client: If not passed in or None this will use the last client\n                from the `.login()` method.\n\n        Raises:\n            ValueError: If the parent does not have an ID.\n        \"\"\"\n        # TODO: Input validation: SYNPY-1400\n        with tracer.start_as_current_span(\n            name=f\"Activity_delete: Parent_ID: {parent.id}\"\n        ):\n            loop = asyncio.get_event_loop()\n            current_context = context.get_current()\n            await loop.run_in_executor(\n                None,\n                lambda: run_and_attach_otel_context(\n                    lambda: Synapse.get_client(\n                        synapse_client=synapse_client\n                    ).deleteProvenance(\n                        entity=parent.id,\n                    ),\n                    current_context,\n                ),\n            )\n            parent.activity = None\n\n    @classmethod\n    async def disassociate_from_entity_async(\n        cls,\n        parent: Union[\"Table\", \"File\"],\n        *,\n        synapse_client: Optional[Synapse] = None,\n    ) -&gt; None:\n        \"\"\"\n        Disassociate the Activity from the parent entity. This is the first step in\n        deleting the Activity. If you have other entities that are associated with this\n        Activity you must disassociate them by calling this method on them as well.\n\n        Arguments:\n            parent: The parent entity this activity is associated with.\n            synapse_client: If not passed in or None this will use the last client\n                from the `.login()` method.\n\n        Raises:\n            ValueError: If the parent does not have an ID.\n        \"\"\"\n        # TODO: Input validation: SYNPY-1400\n        with tracer.start_as_current_span(\n            name=f\"Activity_disassociate: Parent_ID: {parent.id}\"\n        ):\n            await delete_entity_generated_by(\n                entity_id=parent.id, synapse_client=synapse_client\n            )\n            parent.activity = None\n</code></pre>"},{"location":"reference/oop/models_async/#synapseclient.models.Activity-functions","title":"Functions","text":""},{"location":"reference/oop/models_async/#synapseclient.models.Activity.from_parent_async","title":"<code>from_parent_async(parent, *, synapse_client=None)</code>  <code>async</code> <code>classmethod</code>","text":"<p>Get the Activity from Synapse based on the parent entity.</p> PARAMETER DESCRIPTION <code>parent</code> <p>The parent entity this activity is associated with. The parent may also have a version_number. Gets the most recent version if version is omitted.</p> <p> TYPE: <code>Union[Table, File]</code> </p> <code>synapse_client</code> <p>If not passed in or None this will use the last client from the <code>.login()</code> method.</p> <p> TYPE: <code>Optional[Synapse]</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>Union[Activity, None]</code> <p>The activity object or None if it does not exist.</p> RAISES DESCRIPTION <code>ValueError</code> <p>If the parent does not have an ID.</p> Source code in <code>synapseclient/models/activity.py</code> <pre><code>@classmethod\nasync def from_parent_async(\n    cls,\n    parent: Union[\"Table\", \"File\"],\n    *,\n    synapse_client: Optional[Synapse] = None,\n) -&gt; Union[\"Activity\", None]:\n    \"\"\"\n    Get the Activity from Synapse based on the parent entity.\n\n    Arguments:\n        parent: The parent entity this activity is associated with. The parent may\n            also have a version_number. Gets the most recent version if version is\n            omitted.\n        synapse_client: If not passed in or None this will use the last client\n            from the `.login()` method.\n\n    Returns:\n        The activity object or None if it does not exist.\n\n    Raises:\n        ValueError: If the parent does not have an ID.\n    \"\"\"\n    # TODO: Input validation: SYNPY-1400\n    with tracer.start_as_current_span(name=f\"Activity_get: Parent_ID: {parent.id}\"):\n        loop = asyncio.get_event_loop()\n        current_context = context.get_current()\n        try:\n            synapse_activity = await loop.run_in_executor(\n                None,\n                lambda: run_and_attach_otel_context(\n                    lambda: Synapse.get_client(\n                        synapse_client=synapse_client\n                    ).getProvenance(\n                        entity=parent.id,\n                        version=parent.version_number,\n                    ),\n                    current_context,\n                ),\n            )\n        except SynapseHTTPError as ex:\n            if ex.response.status_code == 404:\n                return None\n            else:\n                raise ex\n        if synapse_activity:\n            return cls().fill_from_dict(synapse_activity=synapse_activity)\n        else:\n            return None\n</code></pre>"},{"location":"reference/oop/models_async/#synapseclient.models.Activity.store_async","title":"<code>store_async(parent=None, *, synapse_client=None)</code>  <code>async</code>","text":"<p>Store the Activity in Synapse.</p> PARAMETER DESCRIPTION <code>parent</code> <p>The parent entity to associate this activity with.</p> <p> TYPE: <code>Optional[Union[Table, File]]</code> DEFAULT: <code>None</code> </p> <code>synapse_client</code> <p>If not passed in or None this will use the last client from the <code>.login()</code> method.</p> <p> TYPE: <code>Optional[Synapse]</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>Activity</code> <p>The activity object.</p> RAISES DESCRIPTION <code>ValueError</code> <p>Raised if both of the following are true:</p> <ul> <li>If the parent does not have an ID.</li> <li>If the Activity does not have an ID and ETag.</li> </ul> Source code in <code>synapseclient/models/activity.py</code> <pre><code>@otel_trace_method(\n    method_to_trace_name=lambda self, **kwargs: f\"Activity_store: {self.name}\"\n)\nasync def store_async(\n    self,\n    parent: Optional[Union[\"Table\", \"File\"]] = None,\n    *,\n    synapse_client: Optional[Synapse] = None,\n) -&gt; \"Activity\":\n    \"\"\"\n    Store the Activity in Synapse.\n\n    Arguments:\n        parent: The parent entity to associate this activity with.\n        synapse_client: If not passed in or None this will use the last client\n            from the `.login()` method.\n\n    Returns:\n        The activity object.\n\n    Raises:\n        ValueError: Raised if both of the following are true:\n\n            - If the parent does not have an ID.\n            - If the Activity does not have an ID and ETag.\n    \"\"\"\n    # TODO: Input validation: SYNPY-1400\n    used_and_executed_activities = (\n        self._create_used_and_executed_synapse_activities()\n    )\n\n    synapse_activity = Synapse_Activity(\n        name=self.name,\n        description=self.description,\n        used=used_and_executed_activities.used,\n        executed=used_and_executed_activities.executed,\n    )\n\n    loop = asyncio.get_event_loop()\n    current_context = context.get_current()\n    if self.id:\n        # Despite init in `Synapse_Activity` not accepting an ID/ETAG the\n        # `updateActivity` method expects that it exists on the dict\n        # and `setProvenance` accepts it as well.\n        synapse_activity[\"id\"] = self.id\n        synapse_activity[\"etag\"] = self.etag\n    if parent:\n        saved_activity = await loop.run_in_executor(\n            None,\n            lambda: run_and_attach_otel_context(\n                lambda: Synapse.get_client(\n                    synapse_client=synapse_client\n                ).setProvenance(\n                    entity=parent.id,\n                    activity=synapse_activity,\n                ),\n                current_context,\n            ),\n        )\n    else:\n        saved_activity = await loop.run_in_executor(\n            None,\n            lambda: run_and_attach_otel_context(\n                lambda: Synapse.get_client(\n                    synapse_client=synapse_client\n                ).updateActivity(\n                    activity=synapse_activity,\n                ),\n                current_context,\n            ),\n        )\n    self.fill_from_dict(synapse_activity=saved_activity)\n    Synapse.get_client(synapse_client=synapse_client).logger.debug(\n        f\"Stored activity {self.id}\"\n    )\n\n    return self\n</code></pre>"},{"location":"reference/oop/models_async/#synapseclient.models.Activity.delete_async","title":"<code>delete_async(parent, *, synapse_client=None)</code>  <code>async</code> <code>classmethod</code>","text":"<p>Delete the Activity from Synapse. The Activity must be disassociated from all entities before it can be deleted. The first step of this delete call is to disassociate the Activity from the parent entity. If you have other entities that are associated with this Activity you must disassociate them by calling this method on them as well. You'll receive an error for all entities until the last one which will delete the Activity.</p> PARAMETER DESCRIPTION <code>parent</code> <p>The parent entity this activity is associated with.</p> <p> TYPE: <code>Union[Table, File]</code> </p> <code>synapse_client</code> <p>If not passed in or None this will use the last client from the <code>.login()</code> method.</p> <p> TYPE: <code>Optional[Synapse]</code> DEFAULT: <code>None</code> </p> RAISES DESCRIPTION <code>ValueError</code> <p>If the parent does not have an ID.</p> Source code in <code>synapseclient/models/activity.py</code> <pre><code>@classmethod\nasync def delete_async(\n    cls,\n    parent: Union[\"Table\", \"File\"],\n    *,\n    synapse_client: Optional[Synapse] = None,\n) -&gt; None:\n    \"\"\"\n    Delete the Activity from Synapse. The Activity must be disassociated from\n    all entities before it can be deleted. The first step of this delete call\n    is to disassociate the Activity from the parent entity. If you have other\n    entities that are associated with this Activity you must disassociate them\n    by calling this method on them as well. You'll receive an error for all entities\n    until the last one which will delete the Activity.\n\n    Arguments:\n        parent: The parent entity this activity is associated with.\n        synapse_client: If not passed in or None this will use the last client\n            from the `.login()` method.\n\n    Raises:\n        ValueError: If the parent does not have an ID.\n    \"\"\"\n    # TODO: Input validation: SYNPY-1400\n    with tracer.start_as_current_span(\n        name=f\"Activity_delete: Parent_ID: {parent.id}\"\n    ):\n        loop = asyncio.get_event_loop()\n        current_context = context.get_current()\n        await loop.run_in_executor(\n            None,\n            lambda: run_and_attach_otel_context(\n                lambda: Synapse.get_client(\n                    synapse_client=synapse_client\n                ).deleteProvenance(\n                    entity=parent.id,\n                ),\n                current_context,\n            ),\n        )\n        parent.activity = None\n</code></pre>"},{"location":"reference/oop/models_async/#synapseclient.models.Team","title":"<code>synapseclient.models.Team</code>  <code>dataclass</code>","text":"<p>               Bases: <code>TeamSynchronousProtocol</code></p> <p>Represents a Synapse Team. User definable fields are:</p> ATTRIBUTE DESCRIPTION <code>id</code> <p>The ID of the team</p> <p> TYPE: <code>Optional[int]</code> </p> <code>name</code> <p>The name of the team</p> <p> TYPE: <code>Optional[str]</code> </p> <code>description</code> <p>A short description of the team</p> <p> TYPE: <code>Optional[str]</code> </p> <code>icon</code> <p>A file handle ID for the icon image of the team</p> <p> TYPE: <code>Optional[str]</code> </p> <code>can_public_join</code> <p>True if members can join without an invitation or approval</p> <p> TYPE: <code>Optional[bool]</code> </p> <code>can_request_membership</code> <p>True if users can create a membership request to join</p> <p> TYPE: <code>Optional[bool]</code> </p> <code>etag</code> <p>Synapse employs an Optimistic Concurrency Control (OCC) scheme to handle concurrent updates Since the E-Tag changes every time an entity is updated it is used to detect when a client's current representation of an entity is out-of-date.</p> <p> TYPE: <code>Optional[str]</code> </p> <code>created_on</code> <p>The date this team was created</p> <p> TYPE: <code>Optional[str]</code> </p> <code>modified_on</code> <p>The date this team was last modified</p> <p> TYPE: <code>Optional[str]</code> </p> <code>created_by</code> <p>The ID of the user that created this team</p> <p> TYPE: <code>Optional[str]</code> </p> <code>modified_by</code> <p>The ID of the user that last modified this team</p> <p> TYPE: <code>Optional[str]</code> </p> Source code in <code>synapseclient/models/team.py</code> <pre><code>@dataclass\n@async_to_sync\nclass Team(TeamSynchronousProtocol):\n    \"\"\"\n    Represents a [Synapse Team](https://rest-docs.synapse.org/rest/org/sagebionetworks/repo/model/Team.html).\n    User definable fields are:\n\n    Attributes:\n        id: The ID of the team\n        name: The name of the team\n        description: A short description of the team\n        icon: A file handle ID for the icon image of the team\n        can_public_join: True if members can join without an invitation or approval\n        can_request_membership: True if users can create a membership request to join\n        etag: Synapse employs an Optimistic Concurrency Control (OCC) scheme to handle\n            concurrent updates Since the E-Tag changes every time an entity is updated\n            it is used to detect when a client's current representation of an entity\n            is out-of-date.\n        created_on: The date this team was created\n        modified_on: The date this team was last modified\n        created_by: The ID of the user that created this team\n        modified_by: The ID of the user that last modified this team\n    \"\"\"\n\n    id: Optional[int] = None\n    \"\"\"The ID of the team\"\"\"\n\n    name: Optional[str] = None\n    \"\"\"The name of the team\"\"\"\n\n    description: Optional[str] = None\n    \"\"\"A short description of the team\"\"\"\n\n    icon: Optional[str] = None\n    \"\"\"A file handle ID for the icon image of the team\"\"\"\n\n    can_public_join: Optional[bool] = False\n    \"\"\"True if members can join without an invitation or approval\"\"\"\n\n    can_request_membership: Optional[bool] = True\n    \"\"\"True if users can create a membership request to join\"\"\"\n\n    etag: Optional[str] = None\n    \"\"\"\n    Synapse employs an Optimistic Concurrency Control (OCC) scheme to handle\n    concurrent updates Since the E-Tag changes every time an entity is updated it is\n    used to detect when a client's current representation of an entity is out-of-date.\n    \"\"\"\n\n    created_on: Optional[str] = None\n    \"\"\"The date this team was created\"\"\"\n\n    modified_on: Optional[str] = None\n    \"\"\"The date this team was last modified\"\"\"\n\n    created_by: Optional[str] = None\n    \"\"\"The ID of the user that created this team\"\"\"\n\n    modified_by: Optional[str] = None\n    \"\"\"The ID of the user that last modified this team\"\"\"\n\n    def fill_from_dict(\n        self, synapse_team: Union[Synapse_Team, Dict[str, str]]\n    ) -&gt; \"Team\":\n        \"\"\"\n        Converts a response from the REST API into this dataclass.\n\n        Arguments:\n            synapse_team: The response from the REST API.\n\n        Returns:\n            The Team object.\n        \"\"\"\n        self.id = (\n            int(synapse_team.get(\"id\", None)) if synapse_team.get(\"id\", None) else None\n        )\n        self.name = synapse_team.get(\"name\", None)\n        self.description = synapse_team.get(\"description\", None)\n        self.icon = synapse_team.get(\"icon\", None)\n        self.can_public_join = synapse_team.get(\"canPublicJoin\", False)\n        self.can_request_membership = synapse_team.get(\"canRequestMembership\", True)\n        self.etag = synapse_team.get(\"etag\", None)\n        self.created_on = synapse_team.get(\"createdOn\", None)\n        self.modified_on = synapse_team.get(\"modifiedOn\", None)\n        self.created_by = synapse_team.get(\"createdBy\", None)\n        self.modified_by = synapse_team.get(\"modifiedBy\", None)\n        return self\n\n    @otel_trace_method(\n        method_to_trace_name=lambda self, **kwargs: f\"Team_Create: {self.name}\"\n    )\n    async def create_async(self, *, synapse_client: Optional[Synapse] = None) -&gt; \"Team\":\n        \"\"\"Creates a new team on Synapse.\n\n        Arguments:\n            synapse_client: If not passed in or None this will use the last client\n                from the `.login()` method.\n\n        Returns:\n            Team: The Team object.\n        \"\"\"\n        loop = asyncio.get_event_loop()\n        current_context = context.get_current()\n        trace.get_current_span().set_attributes(\n            {\n                \"synapse.name\": self.name or \"\",\n                \"synapse.id\": self.id or \"\",\n            }\n        )\n        team = await loop.run_in_executor(\n            None,\n            lambda: run_and_attach_otel_context(\n                lambda: Synapse.get_client(synapse_client=synapse_client).create_team(\n                    name=self.name,\n                    description=self.description,\n                    icon=self.icon,\n                    can_public_join=self.can_public_join,\n                    can_request_membership=self.can_request_membership,\n                ),\n                current_context,\n            ),\n        )\n        self.fill_from_dict(synapse_team=team)\n        return self\n\n    @otel_trace_method(\n        method_to_trace_name=lambda self, **kwargs: f\"Team_Delete: {self.id}\"\n    )\n    async def delete_async(self, *, synapse_client: Optional[Synapse] = None) -&gt; None:\n        \"\"\"Deletes a team from Synapse.\n\n        Arguments:\n            synapse_client: If not passed in or None this will use the last client\n                from the `.login()` method.\n\n        Returns:\n            None\n        \"\"\"\n        loop = asyncio.get_event_loop()\n        current_context = context.get_current()\n        await loop.run_in_executor(\n            None,\n            lambda: run_and_attach_otel_context(\n                lambda: Synapse.get_client(synapse_client=synapse_client).delete_team(\n                    id=self.id,\n                ),\n                current_context,\n            ),\n        )\n\n    @otel_trace_method(\n        method_to_trace_name=lambda self, **kwargs: f\"Team_Get: {self.id if self.id else self.name}\"\n    )\n    async def get_async(self, *, synapse_client: Optional[Synapse] = None) -&gt; \"Team\":\n        \"\"\"\n        Gets a Team from Synapse by ID or Name. If both are added to the Team instance\n        it will use the ID.\n\n        Arguments:\n            synapse_client: If not passed in or None this will use the last client\n                from the `.login()` method.\n\n        Raises:\n            ValueError: If the Team object has neither an id nor a name.\n\n        Returns:\n            Team: The Team object.\n        \"\"\"\n        if self.id:\n            loop = asyncio.get_event_loop()\n            current_context = context.get_current()\n            api_team = await loop.run_in_executor(\n                None,\n                lambda: run_and_attach_otel_context(\n                    lambda: Synapse.get_client(synapse_client=synapse_client).getTeam(\n                        id=self.id,\n                    ),\n                    current_context,\n                ),\n            )\n            return self.fill_from_dict(api_team)\n        elif self.name:\n            loop = asyncio.get_event_loop()\n            current_context = context.get_current()\n            api_team = await loop.run_in_executor(\n                None,\n                lambda: run_and_attach_otel_context(\n                    lambda: Synapse.get_client(synapse_client=synapse_client).getTeam(\n                        id=self.name,\n                    ),\n                    current_context,\n                ),\n            )\n            return self.fill_from_dict(api_team)\n        raise ValueError(\"Team must have either an id or a name\")\n\n    @classmethod\n    @otel_trace_method(\n        method_to_trace_name=lambda cls, id, **kwargs: f\"Team_From_Id: {id}\"\n    )\n    async def from_id_async(\n        cls, id: int, *, synapse_client: Optional[Synapse] = None\n    ) -&gt; \"Team\":\n        \"\"\"Gets Team object using its integer id.\n\n        Arguments:\n            id: The id of the team.\n            synapse_client: If not passed in or None this will use the last client\n                from the `.login()` method.\n\n        Returns:\n            Team: The Team object.\n        \"\"\"\n\n        return await cls(id=id).get_async(synapse_client=synapse_client)\n\n    @classmethod\n    @otel_trace_method(\n        method_to_trace_name=lambda cls, name, **kwargs: f\"Team_From_Name: {name}\"\n    )\n    async def from_name_async(\n        cls, name: str, *, synapse_client: Optional[Synapse] = None\n    ) -&gt; \"Team\":\n        \"\"\"Gets Team object using its string name.\n\n        *** You will be unable to retrieve a team by name immediately after its\n        creation because the fragment service is eventually consistent. If you need to\n        retrieve a team immediately following creation you should use the\n        [from_id][synapseclient.models.Team.from_id] method. ***\n\n        Arguments:\n            name: The name of the team.\n            synapse_client: If not passed in or None this will use the last client\n                from the `.login()` method.\n\n        Returns:\n            Team: The Team object.\n        \"\"\"\n        return await cls(name=name).get_async(synapse_client=synapse_client)\n\n    @otel_trace_method(\n        method_to_trace_name=lambda self, **kwargs: f\"Team_Members: {self.name}\"\n    )\n    async def members_async(\n        self, *, synapse_client: Optional[Synapse] = None\n    ) -&gt; List[TeamMember]:\n        \"\"\"\n        Gets the TeamMembers associated with a team given the ID field on the\n        Team instance.\n\n        Arguments:\n            synapse_client: If not passed in or None this will use the last client\n                from the `.login()` method.\n\n        Returns:\n            List[TeamMember]: A List of TeamMember objects.\n        \"\"\"\n        loop = asyncio.get_event_loop()\n        current_context = context.get_current()\n        team_members = await loop.run_in_executor(\n            None,\n            lambda: run_and_attach_otel_context(\n                lambda: Synapse.get_client(\n                    synapse_client=synapse_client\n                ).getTeamMembers(team=self),\n                current_context,\n            ),\n        )\n        team_member_list = [\n            TeamMember().fill_from_dict(synapse_team_member=member)\n            for member in team_members\n        ]\n        return team_member_list\n\n    @otel_trace_method(\n        method_to_trace_name=lambda self, **kwargs: f\"Team_Invite: {self.name}\"\n    )\n    async def invite_async(\n        self,\n        user: str,\n        message: str,\n        force: bool = True,\n        *,\n        synapse_client: Optional[Synapse] = None,\n    ) -&gt; Dict[str, str]:\n        \"\"\"Invites a user to a team given the ID field on the Team instance.\n\n        Arguments:\n            user: The username of the user to invite.\n            message: The message to send.\n            synapse_client: If not passed in or None this will use the last client\n                from the `.login()` method.\n\n        Returns:\n            dict: The invite response.\n        \"\"\"\n        loop = asyncio.get_event_loop()\n        current_context = context.get_current()\n        invite = await loop.run_in_executor(\n            None,\n            lambda: run_and_attach_otel_context(\n                lambda: Synapse.get_client(\n                    synapse_client=synapse_client\n                ).invite_to_team(\n                    team=self,\n                    user=user,\n                    message=message,\n                    force=force,\n                ),\n                current_context,\n            ),\n        )\n        return invite\n\n    @otel_trace_method(\n        method_to_trace_name=lambda self, **kwargs: f\"Team_Open_Invitations: {self.name}\"\n    )\n    async def open_invitations_async(\n        self, *, synapse_client: Optional[Synapse] = None\n    ) -&gt; List[Dict[str, str]]:\n        \"\"\"Gets all open invitations for a team given the ID field on the Team instance.\n\n        Arguments:\n            synapse_client: If not passed in or None this will use the last client\n                from the `.login()` method.\n\n        Returns:\n            List[dict]: A list of invitations.\n        \"\"\"\n        loop = asyncio.get_event_loop()\n        current_context = context.get_current()\n        invitations = await loop.run_in_executor(\n            None,\n            lambda: run_and_attach_otel_context(\n                lambda: Synapse.get_client(\n                    synapse_client=synapse_client\n                ).get_team_open_invitations(\n                    team=self,\n                ),\n                current_context,\n            ),\n        )\n        return list(invitations)\n</code></pre>"},{"location":"reference/oop/models_async/#synapseclient.models.Team-functions","title":"Functions","text":""},{"location":"reference/oop/models_async/#synapseclient.models.Team.create_async","title":"<code>create_async(*, synapse_client=None)</code>  <code>async</code>","text":"<p>Creates a new team on Synapse.</p> PARAMETER DESCRIPTION <code>synapse_client</code> <p>If not passed in or None this will use the last client from the <code>.login()</code> method.</p> <p> TYPE: <code>Optional[Synapse]</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>Team</code> <p>The Team object.</p> <p> TYPE: <code>Team</code> </p> Source code in <code>synapseclient/models/team.py</code> <pre><code>@otel_trace_method(\n    method_to_trace_name=lambda self, **kwargs: f\"Team_Create: {self.name}\"\n)\nasync def create_async(self, *, synapse_client: Optional[Synapse] = None) -&gt; \"Team\":\n    \"\"\"Creates a new team on Synapse.\n\n    Arguments:\n        synapse_client: If not passed in or None this will use the last client\n            from the `.login()` method.\n\n    Returns:\n        Team: The Team object.\n    \"\"\"\n    loop = asyncio.get_event_loop()\n    current_context = context.get_current()\n    trace.get_current_span().set_attributes(\n        {\n            \"synapse.name\": self.name or \"\",\n            \"synapse.id\": self.id or \"\",\n        }\n    )\n    team = await loop.run_in_executor(\n        None,\n        lambda: run_and_attach_otel_context(\n            lambda: Synapse.get_client(synapse_client=synapse_client).create_team(\n                name=self.name,\n                description=self.description,\n                icon=self.icon,\n                can_public_join=self.can_public_join,\n                can_request_membership=self.can_request_membership,\n            ),\n            current_context,\n        ),\n    )\n    self.fill_from_dict(synapse_team=team)\n    return self\n</code></pre>"},{"location":"reference/oop/models_async/#synapseclient.models.Team.delete_async","title":"<code>delete_async(*, synapse_client=None)</code>  <code>async</code>","text":"<p>Deletes a team from Synapse.</p> PARAMETER DESCRIPTION <code>synapse_client</code> <p>If not passed in or None this will use the last client from the <code>.login()</code> method.</p> <p> TYPE: <code>Optional[Synapse]</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>None</code> <p>None</p> Source code in <code>synapseclient/models/team.py</code> <pre><code>@otel_trace_method(\n    method_to_trace_name=lambda self, **kwargs: f\"Team_Delete: {self.id}\"\n)\nasync def delete_async(self, *, synapse_client: Optional[Synapse] = None) -&gt; None:\n    \"\"\"Deletes a team from Synapse.\n\n    Arguments:\n        synapse_client: If not passed in or None this will use the last client\n            from the `.login()` method.\n\n    Returns:\n        None\n    \"\"\"\n    loop = asyncio.get_event_loop()\n    current_context = context.get_current()\n    await loop.run_in_executor(\n        None,\n        lambda: run_and_attach_otel_context(\n            lambda: Synapse.get_client(synapse_client=synapse_client).delete_team(\n                id=self.id,\n            ),\n            current_context,\n        ),\n    )\n</code></pre>"},{"location":"reference/oop/models_async/#synapseclient.models.Team.from_id_async","title":"<code>from_id_async(id, *, synapse_client=None)</code>  <code>async</code> <code>classmethod</code>","text":"<p>Gets Team object using its integer id.</p> PARAMETER DESCRIPTION <code>id</code> <p>The id of the team.</p> <p> TYPE: <code>int</code> </p> <code>synapse_client</code> <p>If not passed in or None this will use the last client from the <code>.login()</code> method.</p> <p> TYPE: <code>Optional[Synapse]</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>Team</code> <p>The Team object.</p> <p> TYPE: <code>Team</code> </p> Source code in <code>synapseclient/models/team.py</code> <pre><code>@classmethod\n@otel_trace_method(\n    method_to_trace_name=lambda cls, id, **kwargs: f\"Team_From_Id: {id}\"\n)\nasync def from_id_async(\n    cls, id: int, *, synapse_client: Optional[Synapse] = None\n) -&gt; \"Team\":\n    \"\"\"Gets Team object using its integer id.\n\n    Arguments:\n        id: The id of the team.\n        synapse_client: If not passed in or None this will use the last client\n            from the `.login()` method.\n\n    Returns:\n        Team: The Team object.\n    \"\"\"\n\n    return await cls(id=id).get_async(synapse_client=synapse_client)\n</code></pre>"},{"location":"reference/oop/models_async/#synapseclient.models.Team.from_name_async","title":"<code>from_name_async(name, *, synapse_client=None)</code>  <code>async</code> <code>classmethod</code>","text":"<p>Gets Team object using its string name.</p> <p>*** You will be unable to retrieve a team by name immediately after its creation because the fragment service is eventually consistent. If you need to retrieve a team immediately following creation you should use the from_id method. ***</p> PARAMETER DESCRIPTION <code>name</code> <p>The name of the team.</p> <p> TYPE: <code>str</code> </p> <code>synapse_client</code> <p>If not passed in or None this will use the last client from the <code>.login()</code> method.</p> <p> TYPE: <code>Optional[Synapse]</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>Team</code> <p>The Team object.</p> <p> TYPE: <code>Team</code> </p> Source code in <code>synapseclient/models/team.py</code> <pre><code>@classmethod\n@otel_trace_method(\n    method_to_trace_name=lambda cls, name, **kwargs: f\"Team_From_Name: {name}\"\n)\nasync def from_name_async(\n    cls, name: str, *, synapse_client: Optional[Synapse] = None\n) -&gt; \"Team\":\n    \"\"\"Gets Team object using its string name.\n\n    *** You will be unable to retrieve a team by name immediately after its\n    creation because the fragment service is eventually consistent. If you need to\n    retrieve a team immediately following creation you should use the\n    [from_id][synapseclient.models.Team.from_id] method. ***\n\n    Arguments:\n        name: The name of the team.\n        synapse_client: If not passed in or None this will use the last client\n            from the `.login()` method.\n\n    Returns:\n        Team: The Team object.\n    \"\"\"\n    return await cls(name=name).get_async(synapse_client=synapse_client)\n</code></pre>"},{"location":"reference/oop/models_async/#synapseclient.models.Team.members_async","title":"<code>members_async(*, synapse_client=None)</code>  <code>async</code>","text":"<p>Gets the TeamMembers associated with a team given the ID field on the Team instance.</p> PARAMETER DESCRIPTION <code>synapse_client</code> <p>If not passed in or None this will use the last client from the <code>.login()</code> method.</p> <p> TYPE: <code>Optional[Synapse]</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>List[TeamMember]</code> <p>List[TeamMember]: A List of TeamMember objects.</p> Source code in <code>synapseclient/models/team.py</code> <pre><code>@otel_trace_method(\n    method_to_trace_name=lambda self, **kwargs: f\"Team_Members: {self.name}\"\n)\nasync def members_async(\n    self, *, synapse_client: Optional[Synapse] = None\n) -&gt; List[TeamMember]:\n    \"\"\"\n    Gets the TeamMembers associated with a team given the ID field on the\n    Team instance.\n\n    Arguments:\n        synapse_client: If not passed in or None this will use the last client\n            from the `.login()` method.\n\n    Returns:\n        List[TeamMember]: A List of TeamMember objects.\n    \"\"\"\n    loop = asyncio.get_event_loop()\n    current_context = context.get_current()\n    team_members = await loop.run_in_executor(\n        None,\n        lambda: run_and_attach_otel_context(\n            lambda: Synapse.get_client(\n                synapse_client=synapse_client\n            ).getTeamMembers(team=self),\n            current_context,\n        ),\n    )\n    team_member_list = [\n        TeamMember().fill_from_dict(synapse_team_member=member)\n        for member in team_members\n    ]\n    return team_member_list\n</code></pre>"},{"location":"reference/oop/models_async/#synapseclient.models.Team.invite_async","title":"<code>invite_async(user, message, force=True, *, synapse_client=None)</code>  <code>async</code>","text":"<p>Invites a user to a team given the ID field on the Team instance.</p> PARAMETER DESCRIPTION <code>user</code> <p>The username of the user to invite.</p> <p> TYPE: <code>str</code> </p> <code>message</code> <p>The message to send.</p> <p> TYPE: <code>str</code> </p> <code>synapse_client</code> <p>If not passed in or None this will use the last client from the <code>.login()</code> method.</p> <p> TYPE: <code>Optional[Synapse]</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>dict</code> <p>The invite response.</p> <p> TYPE: <code>Dict[str, str]</code> </p> Source code in <code>synapseclient/models/team.py</code> <pre><code>@otel_trace_method(\n    method_to_trace_name=lambda self, **kwargs: f\"Team_Invite: {self.name}\"\n)\nasync def invite_async(\n    self,\n    user: str,\n    message: str,\n    force: bool = True,\n    *,\n    synapse_client: Optional[Synapse] = None,\n) -&gt; Dict[str, str]:\n    \"\"\"Invites a user to a team given the ID field on the Team instance.\n\n    Arguments:\n        user: The username of the user to invite.\n        message: The message to send.\n        synapse_client: If not passed in or None this will use the last client\n            from the `.login()` method.\n\n    Returns:\n        dict: The invite response.\n    \"\"\"\n    loop = asyncio.get_event_loop()\n    current_context = context.get_current()\n    invite = await loop.run_in_executor(\n        None,\n        lambda: run_and_attach_otel_context(\n            lambda: Synapse.get_client(\n                synapse_client=synapse_client\n            ).invite_to_team(\n                team=self,\n                user=user,\n                message=message,\n                force=force,\n            ),\n            current_context,\n        ),\n    )\n    return invite\n</code></pre>"},{"location":"reference/oop/models_async/#synapseclient.models.Team.open_invitations_async","title":"<code>open_invitations_async(*, synapse_client=None)</code>  <code>async</code>","text":"<p>Gets all open invitations for a team given the ID field on the Team instance.</p> PARAMETER DESCRIPTION <code>synapse_client</code> <p>If not passed in or None this will use the last client from the <code>.login()</code> method.</p> <p> TYPE: <code>Optional[Synapse]</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>List[Dict[str, str]]</code> <p>List[dict]: A list of invitations.</p> Source code in <code>synapseclient/models/team.py</code> <pre><code>@otel_trace_method(\n    method_to_trace_name=lambda self, **kwargs: f\"Team_Open_Invitations: {self.name}\"\n)\nasync def open_invitations_async(\n    self, *, synapse_client: Optional[Synapse] = None\n) -&gt; List[Dict[str, str]]:\n    \"\"\"Gets all open invitations for a team given the ID field on the Team instance.\n\n    Arguments:\n        synapse_client: If not passed in or None this will use the last client\n            from the `.login()` method.\n\n    Returns:\n        List[dict]: A list of invitations.\n    \"\"\"\n    loop = asyncio.get_event_loop()\n    current_context = context.get_current()\n    invitations = await loop.run_in_executor(\n        None,\n        lambda: run_and_attach_otel_context(\n            lambda: Synapse.get_client(\n                synapse_client=synapse_client\n            ).get_team_open_invitations(\n                team=self,\n            ),\n            current_context,\n        ),\n    )\n    return list(invitations)\n</code></pre>"},{"location":"reference/oop/models_async/#synapseclient.models.UserProfile","title":"<code>synapseclient.models.UserProfile</code>  <code>dataclass</code>","text":"<p>               Bases: <code>UserProfileSynchronousProtocol</code></p> <p>UserProfile represents a user's profile in the system.</p> ATTRIBUTE DESCRIPTION <code>id</code> <p>A foreign key to the ID of the 'principal' object for the user.</p> <p> TYPE: <code>Optional[int]</code> </p> <code>etag</code> <p>Synapse employs an Optimistic Concurrency Control (OCC) scheme to handle concurrent updates. Since the E-Tag changes every time an entity is updated it is used to detect when a client's currentrepresentation of an entity is out-of-date.</p> <p> TYPE: <code>Optional[str]</code> </p> <code>first_name</code> <p>This person's given name (forename)</p> <p> TYPE: <code>Optional[str]</code> </p> <code>last_name</code> <p>This person's family name (surname)</p> <p> TYPE: <code>Optional[str]</code> </p> <code>emails</code> <p>The list of user email addresses registered to this user.</p> <p> TYPE: <code>List[str]</code> </p> <code>open_ids</code> <p>The list of OpenIds bound to this user's account.</p> <p> TYPE: <code>List[str]</code> </p> <code>username</code> <p>A name chosen by the user that uniquely identifies them.</p> <p> TYPE: <code>Optional[str]</code> </p> <code>display_name</code> <p>This field is deprecated and will always be null.</p> <p> TYPE: <code>Optional[str]</code> </p> <code>r_studio_url</code> <p>URL for RStudio server assigned to the user.</p> <p> TYPE: <code>Optional[str]</code> </p> <code>summary</code> <p>A summary description about this person.</p> <p> TYPE: <code>Optional[str]</code> </p> <code>position</code> <p>This person's current position title.</p> <p> TYPE: <code>Optional[str]</code> </p> <code>location</code> <p>This person's location.</p> <p> TYPE: <code>Optional[str]</code> </p> <code>industry</code> <p>The industry/discipline that this person is associated with.</p> <p> TYPE: <code>Optional[str]</code> </p> <code>company</code> <p>This person's current affiliation.</p> <p> TYPE: <code>Optional[str]</code> </p> <code>profile_picure_file_handle_id</code> <p>The File Handle id of the user's profile picture.</p> <p> TYPE: <code>Optional[str]</code> </p> <code>url</code> <p>A link to more information about this person.</p> <p> TYPE: <code>Optional[str]</code> </p> <code>team_name</code> <p>This person's default team name.</p> <p> TYPE: <code>Optional[str]</code> </p> <code>notification_settings</code> <p>Contains a user's notification settings.</p> <p> TYPE: <code>Optional[str]</code> </p> <code>preferences</code> <p>User preferences</p> <p> TYPE: <code>Optional[List[UserPreference]]</code> </p> <code>created_on</code> <p>The date this profile was created.</p> <p> TYPE: <code>Optional[str]</code> </p> Source code in <code>synapseclient/models/user.py</code> <pre><code>@dataclass()\n@async_to_sync\nclass UserProfile(UserProfileSynchronousProtocol):\n    \"\"\"\n    UserProfile represents a user's profile in the system.\n\n    Attributes:\n        id: A foreign key to the ID of the 'principal' object for the user.\n        etag: Synapse employs an Optimistic Concurrency Control (OCC) scheme to handle\n            concurrent updates. Since the E-Tag changes every time an entity is updated\n            it is used to detect when a client's currentrepresentation of an entity is\n            out-of-date.\n        first_name: This person's given name (forename)\n        last_name: This person's family name (surname)\n        emails: The list of user email addresses registered to this user.\n        open_ids: The list of OpenIds bound to this user's account.\n        username: A name chosen by the user that uniquely identifies them.\n        display_name: This field is deprecated and will always be null.\n        r_studio_url: URL for RStudio server assigned to the user.\n        summary: A summary description about this person.\n        position: This person's current position title.\n        location: This person's location.\n        industry: The industry/discipline that this person is associated with.\n        company: This person's current affiliation.\n        profile_picure_file_handle_id: The File Handle id of the user's profile picture.\n        url: A link to more information about this person.\n        team_name: This person's default team name.\n        notification_settings: Contains a user's notification settings.\n        preferences: User preferences\n        created_on: The date this profile was created.\n    \"\"\"\n\n    id: Optional[int] = None\n    \"\"\"A foreign key to the ID of the 'principal' object for the user.\"\"\"\n\n    username: Optional[str] = None\n    \"\"\"A name chosen by the user that uniquely identifies them.\"\"\"\n\n    etag: Optional[str] = None\n    \"\"\"\n    Synapse employs an Optimistic Concurrency Control (OCC) scheme to handle\n    concurrent updates. Since the E-Tag changes every time an entity is updated it is\n    used to detect when a client's current representation of an entity is out-of-date.\n    \"\"\"\n\n    first_name: Optional[str] = None\n    \"\"\"This person's given name (forename)\"\"\"\n\n    last_name: Optional[str] = None\n    \"\"\"This person's family name (surname)\"\"\"\n\n    emails: List[str] = field(default_factory=list)\n    \"\"\"The list of user email addresses registered to this user.\"\"\"\n\n    open_ids: List[str] = field(default_factory=list)\n    \"\"\"The list of OpenIds bound to this user's account.\"\"\"\n\n    r_studio_url: Optional[str] = None\n    \"\"\"URL for RStudio server assigned to the user\"\"\"\n\n    summary: Optional[str] = None\n    \"\"\"A summary description about this person\"\"\"\n\n    position: Optional[str] = None\n    \"\"\"This person's current position title\"\"\"\n\n    location: Optional[str] = None\n    \"\"\"This person's location\"\"\"\n\n    industry: Optional[str] = None\n    \"\"\"The industry/discipline that this person is associated with\"\"\"\n\n    company: Optional[str] = None\n    \"\"\"This person's current affiliation\"\"\"\n\n    profile_picure_file_handle_id: Optional[str] = None\n    \"\"\"The File Handle id of the user's profile picture\"\"\"\n\n    url: Optional[str] = None\n    \"\"\"A link to more information about this person\"\"\"\n\n    team_name: Optional[str] = None\n    \"\"\"This person's default team name\"\"\"\n\n    send_email_notifications: Optional[bool] = True\n    \"\"\"Should the user receive email notifications? Default true.\"\"\"\n\n    mark_emailed_messages_as_read: Optional[bool] = False\n    \"\"\"Should messages that are emailed to the user be marked as\n    READ in Synapse? Default false.\"\"\"\n\n    preferences: Optional[List[UserPreference]] = field(default_factory=list)\n    \"\"\"User preferences\"\"\"\n\n    created_on: Optional[str] = None\n    \"\"\"The date this profile was created.\"\"\"\n\n    def fill_from_dict(\n        self, synapse_user_profile: Union[Synapse_UserProfile, Dict]\n    ) -&gt; \"UserProfile\":\n        \"\"\"Fills the UserProfile object from a dictionary.\n\n        Arguments:\n            synapse_user_profile: The dictionary to fill the UserProfile object from.\n                Typically filled from a\n                [Synapse UserProfile](https://rest-docs.synapse.org/rest/org/sagebionetworks/repo/model/UserProfile.html) object.\n        \"\"\"\n        self.id = (\n            int(synapse_user_profile.get(\"ownerId\", None))\n            if synapse_user_profile.get(\"ownerId\", None)\n            else None\n        )\n        self.etag = synapse_user_profile.get(\"etag\", None)\n        self.first_name = synapse_user_profile.get(\"firstName\", None)\n        self.last_name = synapse_user_profile.get(\"lastName\", None)\n        self.emails = synapse_user_profile.get(\"emails\", [])\n        self.open_ids = synapse_user_profile.get(\"openIds\", [])\n        self.username = synapse_user_profile.get(\"userName\", None)\n        self.r_studio_url = synapse_user_profile.get(\"rStudioUrl\", None)\n        self.summary = synapse_user_profile.get(\"summary\", None)\n        self.position = synapse_user_profile.get(\"position\", None)\n        self.location = synapse_user_profile.get(\"location\", None)\n        self.industry = synapse_user_profile.get(\"industry\", None)\n        self.company = synapse_user_profile.get(\"company\", None)\n        self.profile_picure_file_handle_id = synapse_user_profile.get(\n            \"profilePicureFileHandleId\", None\n        )\n        self.url = synapse_user_profile.get(\"url\", None)\n        self.team_name = synapse_user_profile.get(\"teamName\", None)\n        notification_settings = synapse_user_profile.get(\"notificationSettings\", {})\n        self.send_email_notifications = notification_settings.get(\n            \"sendEmailNotifications\", True\n        )\n        self.mark_emailed_messages_as_read = notification_settings.get(\n            \"markEmailedMessagesAsRead\", False\n        )\n        synapse_preferences_list = synapse_user_profile.get(\"preferences\", [])\n        preferences = []\n        for preference in synapse_preferences_list:\n            preferences.append(\n                UserPreference(\n                    name=preference.get(\"name\", None),\n                    value=preference.get(\"value\", None),\n                )\n            )\n        self.preferences = preferences\n        self.created_on = synapse_user_profile.get(\"createdOn\", None)\n\n        return self\n\n    @otel_trace_method(\n        method_to_trace_name=lambda self, **kwargs: f\"Profile_Get: Username: {self.username}, id: {self.id}\"\n    )\n    async def get_async(\n        self,\n        *,\n        synapse_client: Optional[Synapse] = None,\n    ) -&gt; \"UserProfile\":\n        \"\"\"\n        Gets a UserProfile object using its id or username in that order. If an id\n        and username is not specified this will retrieve the current user's profile.\n\n        Arguments:\n            synapse_client: If not passed in or None this will use the last client\n                from the `.login()` method.\n\n        Returns:\n            The UserProfile object.\n\n        \"\"\"\n        loop = asyncio.get_event_loop()\n\n        current_context = context.get_current()\n        if self.id:\n            synapse_user_profile = await loop.run_in_executor(\n                None,\n                lambda: run_and_attach_otel_context(\n                    lambda: Synapse.get_client(\n                        synapse_client=synapse_client\n                    ).get_user_profile_by_id(id=self.id),\n                    current_context,\n                ),\n            )\n        elif self.username:\n            synapse_user_profile = await loop.run_in_executor(\n                None,\n                lambda: run_and_attach_otel_context(\n                    lambda: Synapse.get_client(\n                        synapse_client=synapse_client\n                    ).get_user_profile_by_username(username=self.username),\n                    current_context,\n                ),\n            )\n        else:\n            synapse_user_profile = await loop.run_in_executor(\n                None,\n                lambda: run_and_attach_otel_context(\n                    lambda: Synapse.get_client(\n                        synapse_client=synapse_client\n                    ).get_user_profile_by_username(),\n                    current_context,\n                ),\n            )\n\n        self.fill_from_dict(synapse_user_profile=synapse_user_profile)\n        return self\n\n    @classmethod\n    @otel_trace_method(\n        method_to_trace_name=lambda cls, user_id, **kwargs: f\"Profile_From_Id: {user_id}\"\n    )\n    async def from_id_async(\n        cls, user_id: int, *, synapse_client: Optional[Synapse] = None\n    ) -&gt; \"UserProfile\":\n        \"\"\"Gets UserProfile object using its integer id. Wrapper for the\n        [get][synapseclient.models.UserProfile.get] method.\n\n        Arguments:\n            user_id: The id of the user.\n            synapse_client: If not passed in or None this will use the last client\n                from the `.login()` method.\n\n        Returns:\n            The UserProfile object.\n        \"\"\"\n\n        return await cls(id=user_id).get_async(synapse_client=synapse_client)\n\n    @classmethod\n    @otel_trace_method(\n        method_to_trace_name=lambda cls, username, **kwargs: f\"Profile_From_Username: {username}\"\n    )\n    async def from_username_async(\n        cls, username: str, *, synapse_client: Optional[Synapse] = None\n    ) -&gt; \"UserProfile\":\n        \"\"\"\n        Gets UserProfile object using its string name. Wrapper for the\n        [get][synapseclient.models.UserProfile.get] method.\n\n        Arguments:\n            username: A name chosen by the user that uniquely identifies them.\n            synapse_client: If not passed in or None this will use the last client\n                from the `.login()` method.\n\n        Returns:\n            The UserProfile object.\n        \"\"\"\n        return await cls(username=username).get_async(synapse_client=synapse_client)\n\n    @otel_trace_method(\n        method_to_trace_name=lambda self, **kwargs: f\"Profile_is_certified: Username: {self.username}, id: {self.id}\"\n    )\n    async def is_certified_async(\n        self,\n        *,\n        synapse_client: Optional[Synapse] = None,\n    ) -&gt; \"bool\":\n        \"\"\"\n        Determine whether a user is certified.\n\n        Arguments:\n            synapse_client: If not passed in or None this will use the last client\n                from the `.login()` method.\n\n        Returns:\n            True if the user is certified, False otherwise.\n\n        Raises:\n            ValueError: If id nor username is specified.\n        \"\"\"\n        loop = asyncio.get_event_loop()\n\n        current_context = context.get_current()\n        if self.id or self.username:\n            is_certified = await loop.run_in_executor(\n                None,\n                lambda: run_and_attach_otel_context(\n                    lambda: Synapse.get_client(\n                        synapse_client=synapse_client\n                    ).is_certified(user=self.id or self.username),\n                    current_context,\n                ),\n            )\n        else:\n            raise ValueError(\"Must specify either id or username\")\n\n        return is_certified\n</code></pre>"},{"location":"reference/oop/models_async/#synapseclient.models.UserProfile-functions","title":"Functions","text":""},{"location":"reference/oop/models_async/#synapseclient.models.UserProfile.get_async","title":"<code>get_async(*, synapse_client=None)</code>  <code>async</code>","text":"<p>Gets a UserProfile object using its id or username in that order. If an id and username is not specified this will retrieve the current user's profile.</p> PARAMETER DESCRIPTION <code>synapse_client</code> <p>If not passed in or None this will use the last client from the <code>.login()</code> method.</p> <p> TYPE: <code>Optional[Synapse]</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>UserProfile</code> <p>The UserProfile object.</p> Source code in <code>synapseclient/models/user.py</code> <pre><code>@otel_trace_method(\n    method_to_trace_name=lambda self, **kwargs: f\"Profile_Get: Username: {self.username}, id: {self.id}\"\n)\nasync def get_async(\n    self,\n    *,\n    synapse_client: Optional[Synapse] = None,\n) -&gt; \"UserProfile\":\n    \"\"\"\n    Gets a UserProfile object using its id or username in that order. If an id\n    and username is not specified this will retrieve the current user's profile.\n\n    Arguments:\n        synapse_client: If not passed in or None this will use the last client\n            from the `.login()` method.\n\n    Returns:\n        The UserProfile object.\n\n    \"\"\"\n    loop = asyncio.get_event_loop()\n\n    current_context = context.get_current()\n    if self.id:\n        synapse_user_profile = await loop.run_in_executor(\n            None,\n            lambda: run_and_attach_otel_context(\n                lambda: Synapse.get_client(\n                    synapse_client=synapse_client\n                ).get_user_profile_by_id(id=self.id),\n                current_context,\n            ),\n        )\n    elif self.username:\n        synapse_user_profile = await loop.run_in_executor(\n            None,\n            lambda: run_and_attach_otel_context(\n                lambda: Synapse.get_client(\n                    synapse_client=synapse_client\n                ).get_user_profile_by_username(username=self.username),\n                current_context,\n            ),\n        )\n    else:\n        synapse_user_profile = await loop.run_in_executor(\n            None,\n            lambda: run_and_attach_otel_context(\n                lambda: Synapse.get_client(\n                    synapse_client=synapse_client\n                ).get_user_profile_by_username(),\n                current_context,\n            ),\n        )\n\n    self.fill_from_dict(synapse_user_profile=synapse_user_profile)\n    return self\n</code></pre>"},{"location":"reference/oop/models_async/#synapseclient.models.UserProfile.from_id_async","title":"<code>from_id_async(user_id, *, synapse_client=None)</code>  <code>async</code> <code>classmethod</code>","text":"<p>Gets UserProfile object using its integer id. Wrapper for the get method.</p> PARAMETER DESCRIPTION <code>user_id</code> <p>The id of the user.</p> <p> TYPE: <code>int</code> </p> <code>synapse_client</code> <p>If not passed in or None this will use the last client from the <code>.login()</code> method.</p> <p> TYPE: <code>Optional[Synapse]</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>UserProfile</code> <p>The UserProfile object.</p> Source code in <code>synapseclient/models/user.py</code> <pre><code>@classmethod\n@otel_trace_method(\n    method_to_trace_name=lambda cls, user_id, **kwargs: f\"Profile_From_Id: {user_id}\"\n)\nasync def from_id_async(\n    cls, user_id: int, *, synapse_client: Optional[Synapse] = None\n) -&gt; \"UserProfile\":\n    \"\"\"Gets UserProfile object using its integer id. Wrapper for the\n    [get][synapseclient.models.UserProfile.get] method.\n\n    Arguments:\n        user_id: The id of the user.\n        synapse_client: If not passed in or None this will use the last client\n            from the `.login()` method.\n\n    Returns:\n        The UserProfile object.\n    \"\"\"\n\n    return await cls(id=user_id).get_async(synapse_client=synapse_client)\n</code></pre>"},{"location":"reference/oop/models_async/#synapseclient.models.UserProfile.from_username_async","title":"<code>from_username_async(username, *, synapse_client=None)</code>  <code>async</code> <code>classmethod</code>","text":"<p>Gets UserProfile object using its string name. Wrapper for the get method.</p> PARAMETER DESCRIPTION <code>username</code> <p>A name chosen by the user that uniquely identifies them.</p> <p> TYPE: <code>str</code> </p> <code>synapse_client</code> <p>If not passed in or None this will use the last client from the <code>.login()</code> method.</p> <p> TYPE: <code>Optional[Synapse]</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>UserProfile</code> <p>The UserProfile object.</p> Source code in <code>synapseclient/models/user.py</code> <pre><code>@classmethod\n@otel_trace_method(\n    method_to_trace_name=lambda cls, username, **kwargs: f\"Profile_From_Username: {username}\"\n)\nasync def from_username_async(\n    cls, username: str, *, synapse_client: Optional[Synapse] = None\n) -&gt; \"UserProfile\":\n    \"\"\"\n    Gets UserProfile object using its string name. Wrapper for the\n    [get][synapseclient.models.UserProfile.get] method.\n\n    Arguments:\n        username: A name chosen by the user that uniquely identifies them.\n        synapse_client: If not passed in or None this will use the last client\n            from the `.login()` method.\n\n    Returns:\n        The UserProfile object.\n    \"\"\"\n    return await cls(username=username).get_async(synapse_client=synapse_client)\n</code></pre>"},{"location":"reference/oop/models_async/#synapseclient.models.UserProfile.is_certified_async","title":"<code>is_certified_async(*, synapse_client=None)</code>  <code>async</code>","text":"<p>Determine whether a user is certified.</p> PARAMETER DESCRIPTION <code>synapse_client</code> <p>If not passed in or None this will use the last client from the <code>.login()</code> method.</p> <p> TYPE: <code>Optional[Synapse]</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>bool</code> <p>True if the user is certified, False otherwise.</p> RAISES DESCRIPTION <code>ValueError</code> <p>If id nor username is specified.</p> Source code in <code>synapseclient/models/user.py</code> <pre><code>@otel_trace_method(\n    method_to_trace_name=lambda self, **kwargs: f\"Profile_is_certified: Username: {self.username}, id: {self.id}\"\n)\nasync def is_certified_async(\n    self,\n    *,\n    synapse_client: Optional[Synapse] = None,\n) -&gt; \"bool\":\n    \"\"\"\n    Determine whether a user is certified.\n\n    Arguments:\n        synapse_client: If not passed in or None this will use the last client\n            from the `.login()` method.\n\n    Returns:\n        True if the user is certified, False otherwise.\n\n    Raises:\n        ValueError: If id nor username is specified.\n    \"\"\"\n    loop = asyncio.get_event_loop()\n\n    current_context = context.get_current()\n    if self.id or self.username:\n        is_certified = await loop.run_in_executor(\n            None,\n            lambda: run_and_attach_otel_context(\n                lambda: Synapse.get_client(\n                    synapse_client=synapse_client\n                ).is_certified(user=self.id or self.username),\n                current_context,\n            ),\n        )\n    else:\n        raise ValueError(\"Must specify either id or username\")\n\n    return is_certified\n</code></pre>"},{"location":"reference/oop/models_async/#synapseclient.models.Annotations","title":"<code>synapseclient.models.Annotations</code>  <code>dataclass</code>","text":"<p>               Bases: <code>AnnotationsSynchronousProtocol</code></p> <p>Annotations that can be applied to a number of Synapse resources to provide additional information.</p> ATTRIBUTE DESCRIPTION <code>annotations</code> <p>Additional metadata associated with the object. The key is the name of your desired annotations. The value is an object containing a list of string values (use empty list to represent no values for key) and the value type associated with all values in the list.</p> <p> TYPE: <code>Union[Dict[str, Union[List[str], List[bool], List[float], List[int], List[date], List[datetime]]], None]</code> </p> <code>id</code> <p>ID of the object to which this annotation belongs. Not required if being used as a member variable on another class.</p> <p> TYPE: <code>Optional[str]</code> </p> <code>etag</code> <p>Etag of the object to which this annotation belongs. This field must match the current etag on the object. Not required if being used as a member variable on another class.</p> <p> TYPE: <code>Optional[str]</code> </p> Source code in <code>synapseclient/models/annotations.py</code> <pre><code>@dataclass()\n@async_to_sync\nclass Annotations(AnnotationsSynchronousProtocol):\n    \"\"\"Annotations that can be applied to a number of Synapse resources to provide\n    additional information.\n\n    Attributes:\n        annotations: Additional metadata associated with the object. The key is the name\n            of your desired annotations. The value is an object containing a list of\n            string values (use empty list to represent no values for key) and the value\n            type associated with all values in the list.\n        id: ID of the object to which this annotation belongs. Not required if being\n            used as a member variable on another class.\n        etag: Etag of the object to which this annotation belongs. This field must match\n            the current etag on the object. Not required if being used as a member\n            variable on another class.\n    \"\"\"\n\n    annotations: Union[\n        Dict[\n            str,\n            Union[\n                List[str],\n                List[bool],\n                List[float],\n                List[int],\n                List[date],\n                List[datetime],\n            ],\n        ],\n        None,\n    ] = field(default_factory=dict)\n    \"\"\"Additional metadata associated with the object. The key is the name of your\n    desired annotations. The value is an object containing a list of string values\n    (use empty list to represent no values for key) and the value type associated with\n    all values in the list.\n    \"\"\"\n\n    id: Optional[str] = None\n    \"\"\"ID of the object to which this annotation belongs. Not required if being used as\n    a member variable on another class.\"\"\"\n\n    etag: Optional[str] = None\n    \"\"\" Etag of the object to which this annotation belongs. To update an AnnotationV2,\n    this field must match the current etag on the object. Not required if being used as\n    a member variable on another class.\"\"\"\n\n    async def store_async(\n        self,\n        *,\n        synapse_client: Optional[Synapse] = None,\n    ) -&gt; \"Annotations\":\n        \"\"\"Storing annotations to synapse.\n\n        Arguments:\n            synapse_client: If not passed in or None this will use the last client\n                from the `.login()` method.\n\n        Returns:\n            The stored annotations.\n\n        Raises:\n            ValueError: If the id or etag are not set.\n        \"\"\"\n        if self.id is None or self.etag is None:\n            raise ValueError(\"id and etag are required to store annotations.\")\n\n        result = await set_annotations_async(\n            annotations=self,\n            synapse_client=synapse_client,\n        )\n        self.annotations = Annotations.from_dict(result)\n        self.etag = result[\"etag\"]\n        Synapse.get_client(synapse_client=synapse_client).logger.debug(\n            f\"Annotations stored for {self.id}\"\n        )\n        return self\n\n    @classmethod\n    def from_dict(\n        cls, synapse_annotations: dict\n    ) -&gt; Union[\n        Dict[\n            str,\n            Union[\n                List[str],\n                List[bool],\n                List[float],\n                List[int],\n                List[date],\n                List[datetime],\n            ],\n        ],\n        None,\n    ]:\n        \"\"\"Convert the annotations from the format the synapse rest API works in -\n        to the format used by this class.\n\n        Arguments:\n            synapse_annotations: The annotations from the synapse rest API.\n\n        Returns:\n            The annotations in python class format or None.\n        \"\"\"\n        if synapse_annotations is None:\n            return None\n        annotations = {}\n        dict_to_convert = (\n            synapse_annotations[\"annotations\"]\n            if \"annotations\" in synapse_annotations\n            else synapse_annotations\n        )\n        for key in dict_to_convert:\n            if isinstance(dict_to_convert[key], dict):\n                conversion_func = ANNO_TYPE_TO_FUNC[dict_to_convert[key][\"type\"]]\n                annotations[key] = [\n                    conversion_func(v) for v in dict_to_convert[key][\"value\"]\n                ]\n            else:\n                annotations[key] = dict_to_convert[key]\n\n        return annotations\n</code></pre>"},{"location":"reference/oop/models_async/#synapseclient.models.Annotations-functions","title":"Functions","text":""},{"location":"reference/oop/models_async/#synapseclient.models.Annotations.store_async","title":"<code>store_async(*, synapse_client=None)</code>  <code>async</code>","text":"<p>Storing annotations to synapse.</p> PARAMETER DESCRIPTION <code>synapse_client</code> <p>If not passed in or None this will use the last client from the <code>.login()</code> method.</p> <p> TYPE: <code>Optional[Synapse]</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>Annotations</code> <p>The stored annotations.</p> RAISES DESCRIPTION <code>ValueError</code> <p>If the id or etag are not set.</p> Source code in <code>synapseclient/models/annotations.py</code> <pre><code>async def store_async(\n    self,\n    *,\n    synapse_client: Optional[Synapse] = None,\n) -&gt; \"Annotations\":\n    \"\"\"Storing annotations to synapse.\n\n    Arguments:\n        synapse_client: If not passed in or None this will use the last client\n            from the `.login()` method.\n\n    Returns:\n        The stored annotations.\n\n    Raises:\n        ValueError: If the id or etag are not set.\n    \"\"\"\n    if self.id is None or self.etag is None:\n        raise ValueError(\"id and etag are required to store annotations.\")\n\n    result = await set_annotations_async(\n        annotations=self,\n        synapse_client=synapse_client,\n    )\n    self.annotations = Annotations.from_dict(result)\n    self.etag = result[\"etag\"]\n    Synapse.get_client(synapse_client=synapse_client).logger.debug(\n        f\"Annotations stored for {self.id}\"\n    )\n    return self\n</code></pre>"},{"location":"tutorials/authentication/","title":"Authentication","text":"<p>There are multiple ways one can login to Synapse. We recommend users to choose the method that fits their workflow.</p>"},{"location":"tutorials/authentication/#prerequisites","title":"Prerequisites","text":"<ul> <li>Create a Personal Access Token (aka: Synapse Auth Token) token obtained from synapse.org under your Settings.<ul> <li>Note that a token must minimally have the view scope to be used with the Synapse Python Client.</li> <li>Include Download and Modify permissions if you are using the Synapse Python Client to follow any subsequent tutorials.</li> </ul> </li> <li>Once a personal access token has been created it can be used for any of the options below.</li> </ul>"},{"location":"tutorials/authentication/#one-time-login","title":"One Time Login","text":""},{"location":"tutorials/authentication/#python","title":"Python","text":"<p>Use the synapseclient.login function</p> <pre><code>import synapseclient\nsyn = synapseclient.login(authToken=\"authtoken\")\n</code></pre>"},{"location":"tutorials/authentication/#command-line-client","title":"Command Line Client","text":"<p>Use the <code>synapse login</code> command</p> synapse login -p $MY_SYNAPSE_TOKENWelcome, First Last!Logged in as: username (1234567)"},{"location":"tutorials/authentication/#use-synapseconfig","title":"Use <code>.synapseConfig</code>","text":"<p>For writing code using the Synapse Python client that is easy to share with others, please do not include your credentials in the code. Instead, please use the <code>~/.synapseConfig</code> file to manage your credentials.</p> <p>When installing the Synapse Python client, the <code>~/.synapseConfig</code> is added to your home directory.</p>"},{"location":"tutorials/authentication/#automatically-modifying-the-synapseconfig-file-with-the-command-line-client","title":"Automatically modifying the <code>~/.synapseConfig</code> file with the Command line Client","text":"<p>You may modify the <code>~/.synapseConfig</code> file by utilizing the command line client command and following the interactive prompts:</p> synapse configSynapse username (Optional):Auth token: $MY_SYNAPSE_TOKEN"},{"location":"tutorials/authentication/#manually-modifying-the-synapseconfig-file","title":"Manually modifying the <code>~/.synapseConfig</code> file","text":"<p>The following describes how to add your credentials to the <code>~/.synapseConfig</code> file without the use of the <code>synapse config</code> command.</p> <p>Open the <code>~/.synapseConfig</code> file and find the following section:</p> <pre><code>#[authentication]\n#username = &lt;username&gt;\n#authtoken = &lt;authtoken&gt;\n</code></pre> <p>To enable this section, uncomment it. You don't need to specify your username when using authtoken as a pair, but if you do, it will be used to verify your identity. A personal access token generated from your synapse.org Settings can be used as your .synapseConfig authtoken. <pre><code>[authentication]\nauthtoken = &lt;authtoken&gt;\n</code></pre></p> <p>Now, you can login without specifying any arguments:</p> <pre><code>import synapseclient\nsyn = synapseclient.login()\n</code></pre>"},{"location":"tutorials/authentication/#use-environment-variable","title":"Use Environment Variable","text":"<p>Setting the <code>SYNAPSE_AUTH_TOKEN</code> environment variable will allow you to login to Synapse with a Personal Access Token</p> <p>The environment variable will take priority over credentials in the user's <code>.synapseConfig</code> file.</p> <p>In your shell, you can pass an environment variable to Python inline by defining it before the command:</p> <pre><code>SYNAPSE_AUTH_TOKEN='&lt;my_personal_access_token&gt;' python3\n</code></pre> <p>Alternatively you may export it first, then start: Python</p> <pre><code>export SYNAPSE_AUTH_TOKEN='&lt;my_personal_access_token&gt;'\npython3\n</code></pre> <p>Once you are inside Python, you may simply login without passing any arguments:</p> <pre><code>import synapseclient\nsyn = synapseclient.login()\n</code></pre> <p>To use the environment variable with the command line client, simply substitute <code>python</code> for the <code>synapse</code> command</p> <pre><code>SYNAPSE_AUTH_TOKEN='&lt;my_personal_access_token&gt;' synapse get syn123\nSYNAPSE_AUTH_TOKEN='&lt;my_personal_access_token&gt;' synapse store --parentid syn123 ~/foobar.txt\n</code></pre> <p>Or alternatively, for multiple commands:</p> <pre><code>export SYNAPSE_AUTH_TOKEN='&lt;my_personal_access_token&gt;'\nsynapse get syn123\nsynapse store --parentid syn123 ~/foobar.txt\n</code></pre>"},{"location":"tutorials/authentication/#for-more-information-see","title":"For more information, see:","text":"<ul> <li>synapseclient.Synapse</li> <li>synapseclient.Synapse.login</li> <li>synapseclient.Synapse.logout</li> <li>synapse config</li> </ul>"},{"location":"tutorials/command_line_client/","title":"Command Line Client","text":"<p>The Synapse Python Client can be used from the command line via the <code>synapse</code> command.</p> <p>Note: The command line client is installed along with Installation of the Synapse Python client.</p>"},{"location":"tutorials/command_line_client/#usage","title":"Usage","text":"<p>For help, type:</p> <pre><code>synapse -h\n</code></pre> <p>For help on specific commands, type:</p> <pre><code>synapse [command] -h\n</code></pre> <p>Test your login credentials with an auth token environment variable:</p> synapse login -p $MY_SYNAPSE_TOKENWelcome, First Last!Logged in as: username (1234567) <p>The usage is as follows:</p> <pre><code>synapse [-h] [--version] [-u SYNAPSEUSER] [-p SYNAPSE_AUTH_TOKEN] [-c CONFIGPATH] [--debug] [--silent] [-s]\n        [--otel {console,otlp}]\n        {get,manifest,sync,store,add,mv,cp,get-download-list,associate,delete,query,submit,show,cat,list,config,set-provenance,get-provenance,set-annotations,get-annotations,create,store-table,onweb,login,test-encoding,get-sts-token,migrate}\n        ...\n</code></pre>"},{"location":"tutorials/command_line_client/#options","title":"Options","text":"Name Type Description Default <code>--version</code> Flag Show program\u2019s version number and exit <code>-u, --username</code> Option Username used to connect to Synapse <code>-p, --password</code> Option Auth Token used to connect to Synapse <code>-c, --configPath</code> Option Path to configuration file used to connect to Synapse \u201c~/.synapseConfig\u201d <code>--debug</code> Flag Set to debug mode, additional output and error messages are printed to the console False <code>--silent</code> Flag Set to silent mode, console output is suppressed False <code>-s, --skip-checks</code> Flag Suppress checking for version upgrade messages and endpoint redirection False <code>--otel</code> Option Enable the usage of OpenTelemetry for tracing. Possible choices: console, otlp"},{"location":"tutorials/command_line_client/#subcommands","title":"Subcommands","text":"<ul> <li>get: downloads a file from Synapse</li> <li>manifest: Generate manifest for uploading directory tree to Synapse.</li> <li>sync: Synchronize files described in a manifest to Synapse</li> <li>store: uploads and adds a file to Synapse</li> <li>add: uploads and adds a file to Synapse</li> <li>mv: Moves a file/folder in Synapse</li> <li>cp: Copies specific versions of synapse content such as files, folders and projects by recursively copying all sub-content</li> <li>get-download-list: Download files from the Synapse download cart</li> <li>associate: Associate local files with the files stored in Synapse so that calls to \u201csynapse get\u201d and \u201csynapse show\u201d don\u2019t re-download the files but use the already existing file.</li> <li>delete: removes a dataset from Synapse</li> <li>query: Performs SQL like queries on Synapse</li> <li>submit: submit an entity or a file for evaluation</li> <li>show: show metadata for an entity</li> <li>cat: prints a dataset from Synapse</li> <li>list: List Synapse entities contained by the given Project or Folder. Note: May not be supported in future versions of the client.</li> <li>config: Create or modify a Synapse configuration file</li> <li>set-provenance: create provenance records</li> <li>get-provenance: show provenance records</li> <li>set-annotations: create annotations records</li> <li>get-annotations: show annotations records</li> <li>create: Creates folders or projects on Synapse</li> <li>store-table: Creates a Synapse Table given a csv</li> <li>onweb: opens Synapse website for Entity</li> <li>login: Verify credentials can be used to login to Synapse.         This does not need to be used prior to executing other commands.</li> <li>test-encoding: test character encoding to help diagnose problems</li> <li>get-sts-token: Get an STS token for access to AWS S3 storage underlying Synapse</li> <li>migrate: Migrate Synapse entities to a different storage location</li> </ul>"},{"location":"tutorials/command_line_client/#get","title":"<code>get</code>","text":"<pre><code>synapse get [-h] [-q queryString] [-v VERSION] [-r] [--followLink] [--limitSearch projId] [--downloadLocation path]\n            [--multiThreaded] [--manifest {all,root,suppress}]\n            [local path]\n</code></pre> Name Type Description Default <code>local path</code> Positional Synapse ID of form syn123 of desired data object. <code>-q, --query</code> Named Optional query parameter, will fetch all of the entities returned by a query. <code>-v, --version</code> Named Synapse version number of entity to retrieve. Most recent version <code>-r, --recursive</code> Named Fetches content in Synapse recursively contained in the parentId specified by id. False <code>--followLink</code> Named Determines whether the link returns the target Entity. False <code>--limitSearch</code> Named Synapse ID of a container such as project or folder to limit search for files if using a path. <code>--downloadLocation</code> Named Directory to download file to. \u201c./\u201d <code>--multiThreaded</code> Named Download file using a multiple threaded implementation. True <code>--manifest</code> Named Determines whether creating manifest file automatically. \u201call\u201d"},{"location":"tutorials/command_line_client/#manifest","title":"<code>manifest</code>","text":"<p>Generate manifest for uploading directory tree to Synapse.</p> <pre><code>synapse manifest [-h] --parent-id syn123 [--manifest-file OUTPUT] PATH\n</code></pre> Name Type Description Default <code>PATH</code> Positional A path to a file or folder whose manifest will be generated. <code>--parent-id</code> Named Synapse ID of project or folder where to upload data. <code>--manifest-file</code> Named A TSV output file path where the generated manifest is stored. stdout"},{"location":"tutorials/command_line_client/#sync","title":"<code>sync</code>","text":"<p>Synchronize files described in a manifest to Synapse.</p> <pre><code>synapse sync [-h] [--dryRun] [--sendMessages] [--retries INT] FILE\n</code></pre> Name Type Description Default <code>FILE</code> Positional A tsv file with file locations and metadata to be pushed to Synapse. See synapseutils.sync.syncToSynapse for details on the format of a manifest. <code>--dryRun</code> Named Perform validation without uploading. False <code>--sendMessages</code> Named Send notifications via Synapse messaging (email) at specific intervals, on errors and on completion. False <code>--retries</code> Named Number of retries for failed uploads. 4"},{"location":"tutorials/command_line_client/#store","title":"<code>store</code>","text":"<p>Uploads and adds a file to Synapse.</p> <pre><code>synapse store [-h] (--parentid syn123 | --id syn123 | --type TYPE) [--name NAME]\n              [--description DESCRIPTION | --descriptionFile DESCRIPTION_FILE_PATH] [--used [target [target ...]]]\n              [--executed [target [target ...]]] [--limitSearch projId] [--noForceVersion] [--annotations ANNOTATIONS]\n              [--replace]\n              [FILE]\n</code></pre> Name Type Description Default <code>FILE</code> Positional File to be added to synapse. <code>--parentid, --parentId</code> Named Synapse ID of project or folder where to upload data (must be specified if \u2013id is not used). <code>--id</code> Named Optional Id of entity in Synapse to be updated. <code>--type</code> Named Type of object, such as \u201cFile\u201d, \u201cFolder\u201d, or \u201cProject\u201d, to create in Synapse. \u201cFile\u201d <code>--name</code> Named Name of data object in Synapse. <code>--description</code> Named Description of data object in Synapse. <code>--descriptionFile</code> Named Path to a markdown file containing description of project/folder. <code>--used</code> Named Synapse ID, a url, or a local file path (of a file previously uploaded to Synapse) from which the specified entity is derived. <code>--executed</code> Named Synapse ID, a url, or a local file path (of a file previously uploaded to Synapse) that was executed to generate the specified entity. <code>--limitSearch</code> Named Synapse ID of a container such as project or folder to limit search for provenance files. <code>--noForceVersion</code> Named Do not force a new version to be created if the contents of the file have not changed. False <code>--annotations</code> Named Annotations to add as a JSON formatted string, should evaluate to a dictionary (key/value pairs). Example: \u2018{\u201cfoo\u201d: 1, \u201cbar\u201d:\u201dquux\u201d}\u2019 <code>--replace</code> Named Replace all existing annotations with the given annotations. False"},{"location":"tutorials/command_line_client/#add","title":"<code>add</code>","text":"<p>Uploads and adds a file to Synapse.</p> <pre><code>synapse add [-h] (--parentid syn123 | --id syn123 | --type TYPE) [--name NAME]\n            [--description DESCRIPTION | --descriptionFile DESCRIPTION_FILE_PATH] [--used [target [target ...]]]\n            [--executed [target [target ...]]] [--limitSearch projId] [--noForceVersion] [--annotations ANNOTATIONS] [--replace]\n            [FILE]\n</code></pre> Name Type Description Default <code>FILE</code> Positional File to be added to synapse. <code>--parentid, --parentId</code> Named Synapse ID of project or folder where to upload data (must be specified if \u2013id is not used). <code>--id</code> Named Optional Id of entity in Synapse to be updated. <code>--type</code> Named Type of object, such as \u201cFile\u201d, \u201cFolder\u201d, or \u201cProject\u201d, to create in Synapse. \u201cFile\u201d <code>--name</code> Named Name of data object in Synapse. <code>--description</code> Named Description of data object in Synapse. <code>--descriptionFile</code> Named Path to a markdown file containing description of project/folder. <code>--used</code> Named Synapse ID, a url, or a local file path (of a file previously uploaded to Synapse) from which the specified entity is derived. <code>--executed</code> Named Synapse ID, a url, or a local file path (of a file previously uploaded to Synapse) that was executed to generate the specified entity. <code>--limitSearch</code> Named Synapse ID of a container such as project or folder to limit search for provenance files. <code>--noForceVersion</code> Named Do not force a new version to be created if the contents of the file have not changed. False <code>--annotations</code> Named Annotations to add as a JSON formatted string, should evaluate to a dictionary (key/value pairs). Example: \u2018{\u201cfoo\u201d: 1, \u201cbar\u201d:\u201dquux\u201d}\u2019 <code>--replace</code> Named Replace all existing annotations with the given annotations. False"},{"location":"tutorials/command_line_client/#mv","title":"<code>mv</code>","text":"<p>Moves a file/folder in Synapse.</p> <pre><code>synapse mv [-h] --id syn123 --parentid syn123\n</code></pre> Name Type Description <code>--id</code> Named Id of entity in Synapse to be moved. <code>--parentid, --parentId</code> Named Synapse ID of project or folder where file/folder will be moved."},{"location":"tutorials/command_line_client/#cp","title":"<code>cp</code>","text":"<p>Copies specific versions of synapse content such as files, folders and projects by recursively copying all sub-content.</p> <pre><code>synapse cp [-h] --destinationId syn123 [--version 1] [--setProvenance traceback] [--updateExisting] [--skipCopyAnnotations]\n           [--excludeTypes [file table [file table ...]]] [--skipCopyWiki]\n           syn123\n</code></pre> Name Type Description Default <code>syn123</code> Positional Id of entity in Synapse to be copied. <code>--destinationId</code> Named Synapse ID of project or folder where file will be copied to. <code>--version, -v</code> Named Synapse version number of File or Link to retrieve. This parameter cannot be used when copying Projects or Folders. Defaults to most recent version. Most recent version <code>--setProvenance</code> Named Has three values to set the provenance of the copied entity-traceback: Sets to the source entityexisting: Sets to source entity\u2019s original provenance (if it exists)None/none: No provenance is set \"traceback\" <code>--updateExisting</code> Named Will update the file if there is already a file that is named the same in the destination False <code>--skipCopyAnnotations</code> Named Do not copy the annotations False <code>--excludeTypes</code> Named Accepts a list of entity types (file, table, link) which determines which entity types to not copy. [] <code>--skipCopyWiki</code> Named Do not copy the wiki pages False"},{"location":"tutorials/command_line_client/#get-download-list","title":"<code>get-download-list</code>","text":"<p>Download files from the Synapse download cart.</p> <pre><code>synapse get-download-list [-h] [--downloadLocation path]\n</code></pre> Name Type Description Default <code>--downloadLocation</code> Named Directory to download file to. \"./\""},{"location":"tutorials/command_line_client/#associate","title":"<code>associate</code>","text":"<p>Associate local files with the files stored in Synapse so that calls to \u201csynapse get\u201d and \u201csynapse show\u201d don\u2019t re-download the files but use the already existing file.</p> <pre><code>synapse associate [-h] [--limitSearch projId] [-r] path\n</code></pre> Name Type Description Default <code>path</code> Positional Local file path. <code>--limitSearch</code> Named Synapse ID of a container such as project or folder to limit search to. <code>-r</code> Named Perform recursive association with all local files in a folder. False"},{"location":"tutorials/command_line_client/#delete","title":"<code>delete</code>","text":"<p>Removes a dataset from Synapse.</p> <pre><code>synapse delete [-h] [--version VERSION] syn123\n</code></pre> Name Type Description <code>syn123</code> Positional Synapse ID of form syn123 of desired data object. <code>--version</code> Named Version number to delete of given entity."},{"location":"tutorials/command_line_client/#query","title":"<code>query</code>","text":"<p>Performs SQL like queries on Synapse.</p> <pre><code>synapse query [-h] [string [string ...]]\n</code></pre> Name Type Description <code>string</code> Positional A query string. Note that when using the command line query strings must be passed intact as a single string. In most shells this can mean wrapping the query in quotes as appropriate and escaping any quotes that may appear within the query string itself. Example: <code>synapse query \"select \\\"column has spaces\\\" from syn123\"</code>. See Table Examples for more information."},{"location":"tutorials/command_line_client/#submit","title":"<code>submit</code>","text":"<p>Submit an entity or a file for evaluation.</p> <pre><code>synapse submit [-h] [--evaluationID EVALUATIONID] [--evaluationName EVALUATIONNAME] [--entity ENTITY] [--file FILE]\n               [--parentId PARENTID] [--name NAME] [--teamName TEAMNAME] [--submitterAlias ALIAS] [--used [target [target ...]]]\n               [--executed [target [target ...]]] [--limitSearch projId]\n</code></pre> Name Type Description <code>--evaluationID, --evaluationId, --evalID</code> Named Evaluation ID where the entity/file will be submitted. <code>--evaluationName, --evalN</code> Named Evaluation Name where the entity/file will be submitted. <code>--entity, --eid, --entityId, --id</code> Named Synapse ID of the entity to be submitted. <code>--file, -f</code> Named File to be submitted to the challenge. <code>--parentId, --parentid, --parent</code> Named Synapse ID of project or folder where to upload data. <code>--name</code> Named Name of the submission. <code>--teamName, --team</code> Named Submit on behalf of a registered team. <code>--submitterAlias, --alias</code> Named A nickname, possibly for display in leaderboards. <code>--used</code> Named Synapse ID, a url, or a local file path (of a file previously uploaded to Synapse) from which the specified entity is derived. <code>--executed</code> Named Synapse ID, a url, or a local file path (of a file previously uploaded to Synapse) that was executed to generate the specified entity. <code>--limitSearch</code> Named Synapse ID of a container such as project or folder to limit search for provenance files."},{"location":"tutorials/command_line_client/#show","title":"<code>show</code>","text":"<p>Show metadata for an entity.</p> <pre><code>synapse show [-h] [--limitSearch projId] syn123\n</code></pre> Name Type Description <code>syn123</code> Positional Synapse ID of form syn123 of desired synapse object. <code>--limitSearch</code> Named Synapse ID of a container such as project or folder to limit search for provenance files."},{"location":"tutorials/command_line_client/#cat","title":"<code>cat</code>","text":"<p>Prints a dataset from Synapse.</p> <pre><code>synapse cat [-h] [-v VERSION] syn123\n</code></pre> Name Type Description Default <code>syn123</code> Positional Synapse ID of form syn123 of desired data object. <code>-v, --version</code> Named Synapse version number of entity to display. Most recent version"},{"location":"tutorials/command_line_client/#list","title":"<code>list</code>","text":"<p>List Synapse entities contained by the given Project or Folder. Note: May not be supported in future versions of the client.</p> <pre><code>synapse list [-h] [-r] [-l] [-m] syn123\n</code></pre> Name Type Description Default <code>syn123</code> Positional Synapse ID of a project or folder. <code>-r, --recursive</code> Named Recursively list contents of the subtree descending from the given Synapse ID. False <code>-l, --long</code> Named List synapse entities in long format. False <code>-m, --modified</code> Named List modified by and modified date. False"},{"location":"tutorials/command_line_client/#config","title":"<code>config</code>","text":"<p>Create or modify a Synapse configuration file.</p> <pre><code>synapse config [-h]\n</code></pre> Name Type Description <code>-h</code> Named Show the help message and exit."},{"location":"tutorials/command_line_client/#set-provenance","title":"<code>set-provenance</code>","text":"<p>Create provenance records.</p> <pre><code>synapse set-provenance [-h] --id syn123 [--name NAME] [--description DESCRIPTION] [-o [OUTPUT_FILE]]\n                       [--used [target [target ...]]] [--executed [target [target ...]]] [--limitSearch projId]\n</code></pre> Name Type Description <code>--id</code> Named Synapse ID of entity whose provenance we are accessing. <code>--name</code> Named Name of the activity that generated the entity. <code>--description</code> Named Description of the activity that generated the entity. <code>-o, --output</code> Named Output the provenance record in JSON format. <code>--used</code> Named Synapse ID, a url, or a local file path (of a file previously uploaded to Synapse) from which the specified entity is derived. <code>--executed</code> Named Synapse ID, a url, or a local file path (of a file previously uploaded to Synapse) that was executed to generate the specified entity. <code>--limitSearch</code> Named Synapse ID of a container such as project or folder to limit search for provenance files."},{"location":"tutorials/command_line_client/#get-provenance","title":"<code>get-provenance</code>","text":"<p>Show provenance records.</p> <pre><code>synapse get-provenance [-h] --id syn123 [--version version] [-o [OUTPUT_FILE]]\n</code></pre> Name Type Description <code>--id</code> Named Synapse ID of entity whose provenance we are accessing. <code>--version</code> Named Version of Synapse entity whose provenance we are accessing. <code>-o, --output</code> Named Output the provenance record in JSON format."},{"location":"tutorials/command_line_client/#set-annotations","title":"<code>set-annotations</code>","text":"<p>Create annotations records.</p> <pre><code>synapse set-annotations [-h] --id syn123 --annotations ANNOTATIONS [-r]\n</code></pre> Name Type Description Default <code>--id</code> Named Synapse ID of entity whose annotations we are accessing. <code>--annotations</code> Named Annotations to add as a JSON formatted string, should evaluate to a dictionary (key/value pairs). Example: \u2018{\u201cfoo\u201d: 1, \u201cbar\u201d:\u201dquux\u201d}\u2019. <code>-r, --replace</code> Named Replace all existing annotations with the given annotations. False"},{"location":"tutorials/command_line_client/#get-annotations","title":"<code>get-annotations</code>","text":"<p>Show annotations records.</p> <pre><code>synapse get-annotations [-h] --id syn123 [-o [OUTPUT_FILE]]\n</code></pre> Name Type Description <code>--id</code> Named Synapse ID of entity whose annotations we are accessing. <code>-o, --output</code> Named Output the annotations record in JSON format."},{"location":"tutorials/command_line_client/#create","title":"<code>create</code>","text":"<p>Creates folders or projects on Synapse.</p> <pre><code>synapse create [-h] [--parentid syn123] --name NAME [--description DESCRIPTION | --descriptionFile DESCRIPTION_FILE_PATH] type\n</code></pre> Name Type Description <code>type</code> Positional Type of object to create in synapse one of {Project, Folder}. <code>--parentid, --parentId</code> Named Synapse ID of project or folder where to place folder [not used with project]. <code>--name</code> Named Name of folder/project. <code>--description</code> Named Description of project/folder. <code>--descriptionFile</code> Named Path to a markdown file containing description of project/folder."},{"location":"tutorials/command_line_client/#store-table","title":"<code>store-table</code>","text":"<p>Creates a Synapse Table given a csv.</p> <pre><code>synapse store-table [-h] --name NAME [--parentid syn123] [--csv foo.csv]\n</code></pre> Name Type Description <code>--name</code> Named Name of Table. <code>--parentid, --parentId</code> Named Synapse ID of project. <code>--csv</code> Named Path to csv."},{"location":"tutorials/command_line_client/#onweb","title":"<code>onweb</code>","text":"<p>Opens Synapse website for Entity.</p> <pre><code>synapse onweb [-h] id\n</code></pre> Name Type Description <code>id</code> Positional Synapse id."},{"location":"tutorials/command_line_client/#login","title":"<code>login</code>","text":"<p>Verify credentials can be used to login to Synapse. This does not need to be used prior to executing other commands.</p> <pre><code>synapse login [-h] [-u SYNAPSEUSER] [-p SYNAPSE_AUTH_TOKEN]\n</code></pre> Name Type Description Default <code>-u, --username</code> Named Username used to connect to Synapse. <code>-p, --password</code> Named Synapse Auth Token (aka: Personal Access Token) used to connect to Synapse"},{"location":"tutorials/command_line_client/#test-encoding","title":"<code>test-encoding</code>","text":"<p>Test character encoding to help diagnose problems.</p> <pre><code>synapse test-encoding [-h]\n</code></pre> Name Type Description <code>-h</code> Named Show the help message and exit."},{"location":"tutorials/command_line_client/#get-sts-token","title":"<code>get-sts-token</code>","text":"<p>Get an STS token for access to AWS S3 storage underlying Synapse.</p> <pre><code>synapse get-sts-token [-h] [-o {json,boto,shell,bash,cmd,powershell}] id {read_write,read_only}\n</code></pre> Name Type Description Default <code>id</code> Positional Synapse id. <code>permission</code> Positional Possible choices: read_write, read_only. <code>-o, --output</code> Named Possible choices: json, boto, shell, bash, cmd, powershell. \"shell\""},{"location":"tutorials/command_line_client/#migrate","title":"<code>migrate</code>","text":"<p>Migrate Synapse entities to a different storage location.</p> <pre><code>synapse migrate [-h] [--source_storage_location_ids [SOURCE_STORAGE_LOCATION_IDS [SOURCE_STORAGE_LOCATION_IDS ...]]]\n                [--file_version_strategy FILE_VERSION_STRATEGY] [--include_table_files] [--continue_on_error]\n                [--csv_log_path CSV_LOG_PATH] [--dryRun] [--force]\n                id dest_storage_location_id db_path\n</code></pre> Name Type Description Default <code>id</code> Positional Synapse id. <code>dest_storage_location_id</code> Positional Destination Synapse storage location id. <code>db_path</code> Positional Local system path where a record keeping file can be stored. <code>--source_storage_location_ids</code> Named Source Synapse storage location ids. If specified only files in these storage locations will be migrated. <code>--file_version_strategy</code> Named One of \u2018new\u2019, \u2018latest\u2019, \u2018all\u2019, \u2018skip\u2019. New creates a new version of each entity, latest migrates the most recent version, all migrates all versions, skip avoids migrating file entities (use when exclusively targeting table attached files. \"new\" <code>--include_table_files</code> Named Include table attached files when migrating. False <code>--continue_on_error</code> Named Whether to continue processing other entities if migration of one fails. False <code>--csv_log_path</code> Named Path where to log a csv documenting the changes from the migration. <code>--dryRun</code> Named Dry run, files will be indexed by not migrated. False <code>--force</code> Named Bypass interactive prompt confirming migration. False"},{"location":"tutorials/configuration/","title":"Configuration","text":"<p>The Synapse Python client can be configured either programmatically or by using a configuration file.</p> <p>The default configuration file does not need to be modified for most use-cases.</p> <p>When installing the Synapse Python client, the <code>.synapseConfig</code> is added to your home directory. This configuration file is used to store a number of configuration options, including your Synapse authtoken, cache, and multi-threading settings.</p> <p>A full example <code>.synapseConfig</code> can be found in the github repository.</p>"},{"location":"tutorials/configuration/#synapseconfig-sections","title":"<code>.synapseConfig</code> sections","text":""},{"location":"tutorials/configuration/#authentication","title":"<code>[authentication]</code>","text":"<p>See details on this section in the authentication document.</p>"},{"location":"tutorials/configuration/#cache","title":"<code>[cache]</code>","text":"<p>Your downloaded files are cached to avoid repeat downloads of the same file. Change 'location' to use a different folder on your computer as the cache location</p>"},{"location":"tutorials/configuration/#endpoints","title":"<code>[endpoints]</code>","text":"<p>Configuring these will cause the Python client to use these as Synapse service endpoints instead of the default prod endpoints.</p>"},{"location":"tutorials/configuration/#transfer","title":"<code>[transfer]</code>","text":"<p>Settings to configure how Synapse uploads/downloads data.</p> <p>You may also set the <code>max_threads</code> programmatically via:</p> <pre><code>import synapseclient\nsyn = synapseclient.login()\nsyn.max_threads = 10\n</code></pre>"},{"location":"tutorials/file_versioning/","title":"File Upload","text":"<p>Files in Synapse are versionable. Please see Versioning for more information about how versions in Files works.</p>"},{"location":"tutorials/file_versioning/#uploading-a-new-version","title":"Uploading a New Version","text":"<p>Uploading a new version follows the same steps as uploading a file for the first time - use the same file name and store it in the same location (e.g., the same parentId). It is recommended to add a comment to the new version in order to easily track differences at a glance. The example file <code>raw_data.txt</code> will now have a version of 2 and a comment describing the change.</p> <p>Explicit example:</p> <pre><code>import synapseclient\n\n# fetch the file in Synapse\nfile_to_update = syn.get('syn2222', downloadFile=False)\n\n# save the local path to the new version of the file\nfile_to_update.path = '/path/to/new/version/of/raw_data.txt'\n\n# add a version comment\nfile_to_update.versionComment = 'Added 5 random normally distributed numbers.'\n\n# store the new file\nupdated_file = syn.store(file_to_update)\n</code></pre> <p>Implicit example:</p> <pre><code># Assuming that there is a file created with:\nsyn.store(File('path/to/old/raw_data.txt', parentId='syn123456'))\n\n# To create a new version of that file, make sure you store it with the exact same name\nnew_file = syn.store(File('path/to/new_version/raw_data.txt',  parentId='syn123456'))\n</code></pre>"},{"location":"tutorials/file_versioning/#updating-annotations-or-provenance-without-changing-versions","title":"Updating Annotations or Provenance without Changing Versions","text":"<p>Any change to a File will automatically update its version. If this isn\u2019t the desired behavior, such as minor changes to the metadata, you can set <code>forceVersion=False</code> with the Python client. For command line, the commands <code>set-annotations</code> and <code>set-provenance</code> will update the metadata without creating a new version. Adding/updating annotations and provenance in the web client will also not cause a version change.</p> <p>Important: Because Provenance is tracked by version, set <code>forceVersion=False</code> for minor changes to avoid breaking Provenance.</p> <p>Setting annotations without changing version:</p> <pre><code># Get file from Synapse, set download=False since we are only updating annotations\nfile = syn.get('syn56789', download=False)\n\n# Add annotations\nfile.annotations = {\"fileType\":\"bam\", \"assay\":\"RNA-seq\"}\n\n# Store the file without creating a new version\nfile = syn.store(file, forceVersion=False)\n</code></pre>"},{"location":"tutorials/file_versioning/#setting-provenance-without-changing-version","title":"Setting Provenance without Changing Version","text":"<p>To set Provenance without changing the file version:</p> <pre><code># Get file from Synapse, set download=False since we are only updating provenance\nfile = syn.get('syn56789', download=False)\n\n# Add provenance\nfile = syn.setProvenance(file, activity = Activity(used = '/path/to/example_code'))\n\n# Store the file without creating a new version\nfile = syn.store(file, forceVersion=False)\n</code></pre>"},{"location":"tutorials/file_versioning/#downloading-a-specific-version","title":"Downloading a Specific Version","text":"<p>By default, the File downloaded will always be the most recent version. However, a specific version can be downloaded by passing the version parameter:</p> <pre><code>entity = syn.get(\"syn3260973\", version=1)\n</code></pre>"},{"location":"tutorials/home/","title":"Getting Started","text":"<p>Welcome!</p> <p>In this module you'll find everything you need to get you and your team sharing, organizing, and discussing your scientific research.</p>"},{"location":"tutorials/home/#what-do-you-need-to-get-started","title":"What do you need to get started?","text":"<p>First off, to browse Synapse and access its most basic level of functionality, you will need to register for a Synapse account. In doing so, you will be agreeing to the Synapse Code of Conduct and Synapse Terms and Conditions of Use.</p> <p>If you\u2019re simply looking to view a public wiki page, or browse our public project or file catalog, you can do so without registering for a Synapse account.</p> <p>To perform other functions within Synapse, such as exploring, downloading, uploading, and organizing data, there are additional steps to take:</p>"},{"location":"tutorials/home/#exploring-and-downloading-data","title":"Exploring and downloading data","text":"<p>As a registered user, you can view and download any data that is publicly available.</p> <p>However, some data is considered controlled access and requires additional protections for who can access it and how it can be used. This data will be clearly labelled with its specific conditions for use. Occasionally, access to controlled data requires additional steps, like having your analysis plan approved by an ethics board or IRB. Controlled access data can not be shared. Anyone wishing to gain access to said data must individually agree to the conditions for use.</p>"},{"location":"tutorials/home/#uploading-organizing-and-curating-data","title":"Uploading, organizing, and curating data","text":"<p>To work with data of your own or your team\u2019s, you must become a certified user. To become certified, you must pass a certification quiz,  which will ask you about information that can be found throughout this documentation site.</p>"},{"location":"tutorials/home/#accessing-mhealth-data","title":"Accessing mHealth data","text":"<p>To access mHealth data, you must become a validated user.</p>"},{"location":"tutorials/home/#debugging-in-the-client","title":"Debugging in the client","text":"<p>Erorrs happen, and when they do it is useful to turn on debug level logging within the Synapse client. In order to turn on debug level logging see:</p> <ul> <li>Debug flag for the programmatic interface</li> <li>Debug flag for the command line interface</li> </ul>"},{"location":"tutorials/installation/","title":"Installation","text":"<p>By following the instructions below, you are installing the <code>synapseclient</code>, <code>synapseutils</code> and the command line client.</p>"},{"location":"tutorials/installation/#pypi","title":"PyPI","text":"<p>The synapseclient package is available from PyPI. It can be installed or upgraded with pip. Due to the nature of Python, we highly recommend you set up your python environment with conda or pyenv and create virtual environments to control your Python dependencies for your work.</p> <ul> <li>conda: Please follow instructions here to manage environments:</li> </ul> <pre><code>conda create -n synapseclient python=3.9\nconda activate synapseclient\n\n# Here are a few ways to install the client. Choose the one that fits your use-case\n# sudo may optionally be needed depending on your setup\n\npip install --upgrade synapseclient\npip install --upgrade \"synapseclient[pandas]\"\npip install --upgrade \"synapseclient[pandas, pysftp, boto3]\"\n</code></pre> <ul> <li>pyenv: Use virtualenv to manage your python environment:</li> </ul> <pre><code>pyenv install -v 3.9.13\npyenv global 3.9.13\npython -m venv env\nsource env/bin/activate\n\n# Here are a few ways to install the client. Choose the one that fits your use-case\n# sudo may optionally be needed depending on your setup\n\npython -m pip install --upgrade synapseclient\npython -m pip install --upgrade \"synapseclient[pandas]\"\npython -m pip install --upgrade \"synapseclient[pandas, pysftp, boto3]\"\n\npython3 -m pip3 install --upgrade synapseclient\npython3 -m pip3 install --upgrade \"synapseclient[pandas]\"\npython3 -m pip3 install --upgrade \"synapseclient[pandas, pysftp, boto3]\"\n</code></pre> <p>The dependencies on pandas, pysftp, and boto3 are optional. The Synapse <code>synapseclient.table</code> feature integrates with Pandas. Support for sftp is required for users of SFTP file storage. Both require native libraries to be compiled or installed separately from prebuilt binaries.</p>"},{"location":"tutorials/installation/#local","title":"Local","text":"<p>Source code and development versions are available on Github. Installing from source:</p> <pre><code>git clone https://github.com/Sage-Bionetworks/synapsePythonClient.git\ncd synapsePythonClient\n</code></pre> <p>You can stay on the master branch to get the latest stable release or check out the develop branch or a tagged revision:</p> <pre><code>git checkout &lt;branch or tag&gt;\n</code></pre> <p>Next, either install the package in the site-packages directory <code>pip install .</code> or <code>pip install -e .</code> to make the installation follow the head without having to reinstall:</p> <pre><code>pip install .\n</code></pre>"},{"location":"tutorials/python_client/","title":"Working with the Python client","text":"<p>Welcome to the Synapse Python client! In the following tutorials you'll create a new project and learn about things you can do with that project.</p> <p>These examples are themed around a biomedical researcher working with Alzheimer's Disease wanting to share their findings with their colleagues, and the world.</p>"},{"location":"tutorials/python_client/#prerequisites","title":"Prerequisites","text":"<p>To get started with these tutorials make sure that you have completed the Installation and Authentication setup.</p>"},{"location":"tutorials/python_client/#end-goal","title":"End goal","text":"<p>By the end of these tutorials you'll have:</p> <ul> <li>A Project created in Synapse</li> <li>Folders and Files added to your project</li> <li>Annotations added to your Project, Folders, and Files</li> <li>A File with multiple Versions</li> <li>A File that has an Activity/Provenance added to it</li> <li>A File View created for your Project</li> <li>A Table created for your Project</li> <li>Create, Read, Update, Delete operations for your table</li> <li>A Dataset created for your project</li> <li>A File with updated sharing settings</li> <li>A Wiki for your Project</li> <li>A Team created with one or more members</li> <li>Methods to upload data in bulk</li> <li>Methods to download data in bulk</li> <li>Methods to move files and folders</li> <li>Methods to migrate data to other storage locations</li> </ul>"},{"location":"tutorials/python_client/#current-python-client-documentation-being-split-into-individual-tutorials","title":"Current python client documentation being split into individual tutorials","text":""},{"location":"tutorials/python_client/#authentication","title":"Authentication","text":"<p>Most operations in Synapse require you to be logged in. Please follow instructions in authentication to configure your client:</p> <pre><code>import synapseclient\nsyn = synapseclient.Synapse()\nsyn.login()\n# If you aren't logged in, this following command will\n# show that you are an \"anonymous\" user.\nsyn.getUserProfile()\n</code></pre>"},{"location":"tutorials/python_client/#accessing-data","title":"Accessing Data","text":"<p>Synapse identifiers are used to refer to projects and data which are represented by <code>synapseclient.entity</code> objects. For example, the entity syn1899498 represents a tab-delimited file containing a 100 by 4 matrix. Getting the entity retrieves an object that holds metadata describing the matrix, and also downloads the file to a local cache:</p> <pre><code>import synapseclient\n# This is a shortcut to login\nsyn = synapseclient.login()\nentity = syn.get('syn1899498')\n</code></pre> <p>View the entity's metadata in the Python console:</p> <pre><code>print(entity)\n</code></pre> <p>This is one simple way to read in a small matrix:</p> <pre><code>rows = []\nwith open(entity.path) as f:\n    header = f.readline().split('\\t')\n    for line in f:\n        row = [float(x) for x in line.split('\\t')]\n        rows.append(row)\n</code></pre> <p>View the entity in the browser:</p> <pre><code>syn.onweb('syn1899498')\n</code></pre> <ul> <li>synapseclient.entity.Entity</li> <li>synapseclient.Synapse.get</li> <li>synapseclient.Synapse.onweb</li> </ul>"},{"location":"tutorials/python_client/#managing-data-in-a-project","title":"Managing Data in a Project","text":"<p>You can create your own projects and upload your own data sets. Synapse stores entities in a hierarchical or tree structure. Projects are at the top level and must be uniquely named:</p> <pre><code>import synapseclient\nfrom synapseclient import Project, Folder, File\n\nsyn = synapseclient.login()\n# Project names must be globally unique\nproject = Project('My uniquely named project')\nproject = syn.store(project)\n</code></pre> <p>Creating a folder:</p> <pre><code>data_folder = Folder('Data', parent=project)\ndata_folder = syn.store(data_folder)\n</code></pre> <p>Adding files to the project. You will get an error if you try to store an empty file in Synapse. Here we create temporary files, but you can specify your own file path:</p> <pre><code>import tempfile\n\ntemp = tempfile.NamedTemporaryFile(prefix='your_file', suffix='.txt')\nwith open(temp.name, \"w\") as temp_f:\n    temp_f.write(\"Example text\")\nfilepath = temp.name\ntest_entity = File(filepath, description='Fancy new data', parent=data_folder)\ntest_entity = syn.store(test_entity)\nprint(test_entity)\n</code></pre> <p>You may notice that there is \"downloadAs\" name and \"entity name\". By default, the client will use the file's name as the entity name, but you can configure the file to display a different name on Synapse:</p> <pre><code>test_second_entity = File(filepath, name=\"second file\", parent=data_folder)\ntest_second_entity = syn.store(test_second_entity)\nprint(test_second_entity)\n</code></pre> <p>In addition to simple data storage, Synapse entities can be annotated with key/value metadata, described in markdown documents (Wiki), and linked together in provenance graphs to create a reproducible record of a data analysis pipeline.</p> <p>See also:</p> <ul> <li>synapseclient.entity.Entity</li> <li>synapseclient.entity.Project</li> <li>synapseclient.entity.Folder</li> <li>synapseclient.entity.File</li> <li>synapseclient.Synapse.store</li> </ul>"},{"location":"tutorials/python_client/#annotating-synapse-entities","title":"Annotating Synapse Entities","text":"<p>Annotations are arbitrary metadata attached to Synapse entities. There are different ways to creating annotations. Using the entity created from the previous step in the tutorial, for example:</p> <pre><code># First method\ntest_ent = syn.get(test_entity.id)\ntest_ent.foo = \"foo\"\ntest_ent.bar = \"bar\"\nsyn.store(test_ent)\n\n# Second method\ntest_ent = syn.get(test_entity.id)\nannotations = {\"foo\": \"foo\", \"bar\": \"bar\"}\ntest_ent.annotations = annotations\nsyn.store(test_ent)\n</code></pre> <p>See:</p> <ul> <li>synapseclient.annotations</li> </ul>"},{"location":"tutorials/python_client/#versioning","title":"Versioning","text":"<p>Synapse supports versioning of many entity types. This tutorial will focus on File versions. Using the project/folder created earlier in this tutorial</p> <p>Uploading a new version. Synapse leverages the entity name to version entities:</p> <pre><code>import tempfile\n\ntemp = tempfile.NamedTemporaryFile(prefix='second', suffix='.txt')\nwith open(temp.name, \"w\") as temp_f:\n    temp_f.write(\"First text\")\n\nversion_entity = File(temp.name, parent=data_folder)\nversion_entity = syn.store(version_entity)\nprint(version_entity.versionNumber)\n\nwith open(temp.name, \"w\") as temp_f:\n    temp_f.write(\"Second text\")\nversion_entity = File(temp.name, parent=data_folder)\nversion_entity = syn.store(version_entity)\nprint(version_entity.versionNumber)\n</code></pre> <p>Downloading a specific version. By default, Synapse downloads the latest version unless a version is specified: <pre><code>version_1 = syn.get(version_entity, version=1)\n</code></pre></p>"},{"location":"tutorials/python_client/#provenance","title":"Provenance","text":"<p>Synapse provides tools for tracking 'provenance', or the transformation of raw data into processed results, by linking derived data objects to source data and the code used to perform the transformation:</p> <pre><code># pass the provenance to the store function\nprovenance_ent = syn.store(\n    version_entity,\n    used=[version_1.id],\n    executed=[\"https://github.com/Sage-Bionetworks/synapsePythonClient/tree/v2.7.2\"]\n)\n</code></pre> <p>See:</p> <ul> <li>synapseclient.activity.Activity</li> </ul>"},{"location":"tutorials/python_client/#file-views","title":"File Views","text":"<p>Views display rows and columns of information, and they can be shared and queried with SQL. Views are queries of other data already in Synapse. They allow you to see groups of files, tables, projects, or submissions and any associated annotations about those items.</p> <p>Annotations are an essential component to building a view. Annotations are labels that you apply to your data, stored as key-value pairs in Synapse.</p> <p>We will create a file view from the project above:</p> <pre><code>import synapseclient\nsyn = synapseclient.login()\n# Here we are using project.id from the earlier sections from this tutorial\nproject_id = project.id\nfileview = EntityViewSchema(\n    name='MyTable',\n    parent=project_id,\n    scopes=[project_id]\n)\nfileview_ent = syn.store(fileview)\n</code></pre> <p>You can now query it to see all the files within the project. Note: it is highly recommended to install <code>pandas</code>:</p> <pre><code>query = syn.tableQuery(f\"select * from {fileview_ent.id}\")\nquery_results = query.asDataFrame()\nprint(query_results)\n</code></pre> <p>See:</p> <ul> <li>synapseclient.table.EntityViewSchema</li> <li>Using Entity Views</li> </ul>"},{"location":"tutorials/python_client/#more-information","title":"More Information","text":"<p>For more information see the Synapse Getting Started.</p>"},{"location":"tutorials/reticulate/","title":"Using synapseclient with R through reticulate","text":"<p>This article describes using the Python synapseclient with R through the reticulate package, which provides an interface between R and Python libraries.</p> <p>While the separate synapser R package exists and can be installed directly in an R environment without the need for reticulate, it is not currently compatible with an R environment that already includes reticulate. In such cases using the Python synapseclient is an alternative.</p>"},{"location":"tutorials/reticulate/#installation","title":"Installation","text":""},{"location":"tutorials/reticulate/#installing-reticulate","title":"Installing reticulate","text":"<p>This article assumes that reticulate is installed and available in your R environment. If not it can be installed as follows:</p> <pre><code>install.packages(\"reticulate\")\n</code></pre>"},{"location":"tutorials/reticulate/#installing-synapseclient","title":"Installing synapseclient","text":"<p>The Python synapseclient can be installed either directly into the Python installation you intend to use with reticulate or from within R using the reticulate library.</p> <p>synapseclient has the same requirements and dependencies when installed for use with reticulate as it does in other usage. In particular note that synapseclient requires a Python version of 3.6 or greater.</p>"},{"location":"tutorials/reticulate/#installing-into-python","title":"Installing into Python","text":"<p>The Python synapseclient is available on the PyPi package repository and can be installed through Python tools that interface with the repository, such as pip. To install synapseclient for use with reticulate directly into a Python environment, first ensure that the current Python interpreter is the one you intend to use with reticulate. This may be a particular installation of Python, or a loaded virtual environment. See reticulate's Python version configuration documentation for more information on how reticulate can be configured to use particular Python environments.</p> <p>For help installing a reticulate compatible Python, see the reticulate version of the SynapseShinyApp.</p> <p>Once you have ensured you are interacting with your intended Python interpreter, follow the standard synapseclient installation instructions to install synapseclient.</p>"},{"location":"tutorials/reticulate/#installing-from-rreticulate","title":"Installing from R/Reticulate","text":"<p>To install synapseclient from within R, first ensure that the reticulate library is loaded.</p> <pre><code>library(reticulate)\n</code></pre> <p>Once loaded, ensure that reticulate will use the Python installation you intend. You may need to provide reticulate a hint or otherwise point it at the proper Python installation.</p> <p>Next install the synapseclient using reticulate's py_install command, e.g.</p> <pre><code>py_install(\"synapseclient\")\n</code></pre> <p>You may also want to install some of synapseclient's optional dependencies, such as Pandas for table support.</p> <pre><code>py_install(\"pandas\")\n</code></pre> <p>See synapseclient's installation instructions for more information on optional dependencies.</p>"},{"location":"tutorials/reticulate/#usage","title":"Usage","text":"<p>Once synapseclient is installed it can be used once it is imported through R's import command:</p> <pre><code>synapseclient &lt;- import(\"synapseclient\")\n</code></pre> <p>If you are using synapseclient with reticulate when writing an R package, you will want to wrap the import in an onLoad and use the delay_load option, .e.g.</p> <pre><code>synapseclient  &lt;- NULL\n\n.onLoad &lt;- function(libname, pkgname) {\n  synapseclient &lt;&lt;- reticulate::import(\"synapseclient\", delay_load = TRUE)\n}\n</code></pre> <p>This will allow users of your package to configure their reticulate usage properly regardless of when they load your package. More information on this technique can be found here.</p> <p>If you are familiar with the synapser R package, many of the commands will be similar, but unlike in synapser where package functions and classes are made available in the global namespace through the search path, when using synapseclient through reticulate, classes are accessed through the imported synapseclient module and functionality is provided through an instantiated Synapse instance.</p> <p>For example classes that were globally available are now available through the imported synapseclient module.</p> <pre><code># File from synapser\nsynapseclient$File\n\n# Table from synapser\nsynapseclient$Table\n</code></pre> <p>And various syn functions are now methods on the Synapse object:</p> <pre><code># using synapseclient with reticulate we must instantiate a Synapse instance\nsyn &lt;- synapseclient$Synapse()\n\n# synLogin from synapser\nsyn$login()\n\n# synGet from synapser\nsyn$get(identifier)\n\n# synStore from syanpser\nsyn$store(entity)\n</code></pre> <p>Each synapse object has its own state, such as configuration and login credentials.</p>"},{"location":"tutorials/reticulate/#credentials","title":"Credentials","text":"<p>synapseclient accessed through reticulate supports the same authentication options as it does when accessed directly from Python, for example:</p> <pre><code>syn &lt;- synapseclient$synapse()\n\n# one time login\nsyn$login('&lt;username', '&lt;authToken&gt;')\n</code></pre> <p>See Managing Synapse Credentials for complete documentation on how synapseclient handles credentials and authentication.</p>"},{"location":"tutorials/reticulate/#accessing-data","title":"Accessing Data","text":"<p>The following illustrates some examples of storing and retrieving data in Synapse using synapseclient through reticulate.</p> <p>See here for more details on available data access APIs.</p> <p>Create a project with a unique name</p> <pre><code># use hex_digits to generate random string and use it to name a project\nhex_digits &lt;- c(as.character(0:9), letters[1:6])\nprojectName &lt;- sprintf(\"My unique project %s\", paste0(sample(hex_digits, 32, replace = TRUE), collapse = \"\"))\n\nproject &lt;- synapseclient$Project(projectName)\nproject &lt;- syn$store(project)\n</code></pre> <p>Create, store, and retrieve a file</p> <pre><code>filePath &lt;- tempfile()\nconnection &lt;- file(filePath)\nwriteChar(\"a \\t b \\t c \\n d \\t e \\t f \\n\", connection, eos = NULL)\nclose(connection)\n\nfile &lt;- synapseclient$File(path = filePath, parent = project)\nfile &lt;- syn$store(file)\nsynId &lt;- file$properties$id\n\n# download the file using its identifier to specific path\nfileEntity &lt;- syn$get(synId, downloadLocation=\"/path/to/folder\")\n\n# view the file meta data in the console\nprint(fileEntity)\n\n# view the file on the web\nsyn$onweb(synId)\n</code></pre> <p>Create folder and add files to the folder:</p> <pre><code>dataFolder &lt;- synapseclient$Folder(\"Data\", parent = project)\ndataFolder &lt;- syn$store(dataFolder)\n\nfilePath &lt;- tempfile()\nconnection &lt;- file(filePath)\nwriteChar(\"this is the content of the file\", connection, eos = NULL)\nclose(connection)\nfile &lt;- synapseclient$File(path = filePath, parent = dataFolder)\nfile &lt;- syn$store(file)\n</code></pre>"},{"location":"tutorials/reticulate/#annotating-synapse-entities","title":"Annotating Synapse Entities","text":"<p>This illustrates adding annotations to a Synapse entity.</p> <pre><code># first retrieve the existing annotations object\nannotations &lt;- syn$get_annotations(project)\n\nannotations$foo &lt;- \"bar\"\nannotations$fooList &lt;- list(\"bar\", \"baz\")\n\nsyn$set_annotations(annotations)\n</code></pre> <p>See here for more information on annotations.</p>"},{"location":"tutorials/reticulate/#activityprovenance","title":"Activity/Provenance","text":"<p>This example illustrates creating an entity with associated provenance.</p> <p>See here for more information on Activity/Provenance related APIs.</p> <pre><code>act &lt;- synapseclient$Activity(\n  name = \"clustering\",\n  description = \"whizzy clustering\",\n  used = c(\"syn1234\", \"syn1235\"),\n  executed = \"syn4567\")\n</code></pre> <pre><code>filePath &lt;- tempfile()\nconnection &lt;- file(filePath)\nwriteChar(\"some test\", connection, eos = NULL)\nclose(connection)\n\nfile = synapseclient$File(filePath, name=\"provenance_file.txt\", parent=project)\nfile &lt;- syn$store(file, activity = act)\n</code></pre>"},{"location":"tutorials/reticulate/#tables","title":"Tables","text":"<p>These examples illustrate manipulating Synapse Tables. Note that you must have installed the Pandas dependency into the Python environment as described above in order to use this feature.</p> <p>See here for more information on tables.</p> <p>The following illustrates building a table from an R data frame. The schema will be generated from the data types of the values within the data frame.</p> <pre><code># start with an R data frame\ngenes &lt;- data.frame(\n  Name = c(\"foo\", \"arg\", \"zap\", \"bah\", \"bnk\", \"xyz\"),\n  Chromosome = c(1, 2, 2, 1, 1, 1),\n  Start = c(12345, 20001, 30033, 40444, 51234, 61234),\n  End = c(126000, 20200, 30999, 41444, 54567, 68686),\n  Strand = c(\"+\", \"+\", \"-\", \"-\", \"+\", \"+\"),\n  TranscriptionFactor = c(F, F, F, F, T, F))\n\n# build a Synapse table from the data frame.\n# a schema is automatically generated\n# note that reticulate will automatically convert from an R data frame to Pandas\ntable &lt;- synapseclient$build_table(\"My Favorite Genes\", project, genes)\n\ntable &lt;- syn$store(table)\n</code></pre> <p>Alternately the schema can be specified. At this time when using date values it is necessary to use a date string formatted in \"YYYY-MM-dd HH:mm:ss.mmm\" format or integer unix epoch millisecond value and explicitly specify the type in the schema due to how dates are translated to the Python client.</p> <pre><code>prez_birthdays &lt;- data.frame(\n  Name = c(\"George Washington\", \"Thomas Jefferson\", \"Abraham Lincoln\"),\n  Time = c(\"1732-02-22 11:23:11.024\", \"1743-04-13 00:00:00.000\", \"1809-02-12 01:02:03.456\"))\n\ncols &lt;- list(\n    synapseclient$Column(name = \"Name\", columnType = \"STRING\", maximumSize = 20),\n    synapseclient$Column(name = \"Time\", columnType = \"DATE\"))\n\nschema &lt;- synapseclient$Schema(name = \"President Birthdays\", columns = cols, parent = project)\ntable &lt;- synapseclient$Table(schema, prez_birthdays)\n\n# store the table in Synapse\ntable &lt;- syn$store(table)\n</code></pre> <p>We can query a table as in the following:</p> <pre><code>tableId &lt;- table$tableId\n\nresults &lt;- syn$tableQuery(sprintf(\"select * from %s where Name='George Washington'\", tableId))\nresults$asDataFrame()\n</code></pre>"},{"location":"tutorials/reticulate/#wikis","title":"Wikis","text":"<p>This example illustrates creating a wiki.</p> <p>See here for more information on wiki APIs.</p> <pre><code>content &lt;- \"\n# My Wiki Page\nHere is a description of my **fantastic** project!\n\"\n\n# attachment\nfilePath &lt;- tempfile()\nconnection &lt;- file(filePath)\nwriteChar(\"this is the content of the file\", connection, eos = NULL)\nclose(connection)\nwiki &lt;- synapseclient$Wiki(\n            owner = project,\n            title = \"My Wiki Page\",\n            markdown = content,\n            attachments = list(filePath)\n)\nwiki &lt;- syn$store(wiki)\n</code></pre> <p>An existing wiki can be updated as follows.</p> <pre><code>wiki &lt;- syn$getWiki(project)\nwiki$markdown &lt;- \"\n# My Wiki Page\nHere is a description of my **fantastic** project! Let's\n*emphasize* the important stuff.\n\"\nwiki &lt;- syn$store(wiki)\n</code></pre>"},{"location":"tutorials/reticulate/#evaluations","title":"Evaluations","text":"<p>An Evaluation is a Synapse construct useful for building processing pipelines and for scoring predictive modeling and data analysis challenges.</p> <p>See here for more information on Evaluations.</p> <p>Creating an Evaluation:</p> <pre><code>eval &lt;- synapseclient$Evaluation(\n  name = sprintf(\"My unique evaluation created on %s\", format(Sys.time(), \"%a %b %d %H%M%OS4 %Y\")),\n  description = \"testing\",\n  contentSource = project,\n  submissionReceiptMessage = \"Thank you for your submission!\",\n  submissionInstructionsMessage = \"This evaluation only accepts files.\")\n\neval &lt;- syn$store(eval)\n\neval &lt;- syn$getEvaluation(eval$id)\n</code></pre> <p>Submitting a file to an existing Evaluation:</p> <pre><code># first create a file to submit\nfilePath &lt;- tempfile()\nconnection &lt;- file(filePath)\nwriteChar(\"this is my first submission\", connection, eos = NULL)\nclose(connection)\nfile &lt;- synapseclient$File(path = filePath, parent = project)\nfile &lt;- syn$store(file)\n# submit the created file\nsubmission &lt;- syn$submit(eval, file)\n</code></pre> <p>List submissions:</p> <pre><code>submissions &lt;- syn$getSubmissionBundles(eval)\n\n# submissions are returned as a generator\nlist(iterate(submissions))\n</code></pre> <p>Retrieving submission by id:</p> <pre><code>submission &lt;- syn$getSubmission(submission$id)\n</code></pre> <p>Retrieving the submission status:</p> <pre><code>submissionStatus &lt;- syn$getSubmissionStatus(submission)\nsubmissionStatus\n</code></pre> <p>Query an evaluation:</p> <pre><code>queryString &lt;- sprintf(\"query=select * from evaluation_%s LIMIT %s OFFSET %s'\", eval$id, 10, 0)\nsyn$restGET(paste(\"/evaluation/submission/query?\", URLencode(queryString), sep = \"\"))\n</code></pre>"},{"location":"tutorials/reticulate/#sharing-access-to-content","title":"Sharing Access to Content","text":"<p>The following illustrates sharing access to a Synapse Entity.</p> <p>See here for more information on Access Control including all available permissions.</p> <pre><code># get permissions on an entity\n# to get permissions for a user/group pass a principalId identifier,\n# otherwise the assumed permission will apply to the public\n\n# make the project publicly accessible\nacl &lt;- syn$setPermissions(project, accessType = list(\"READ\"))\n\nperms = syn$getPermissions(project)\n</code></pre>"},{"location":"tutorials/reticulate/#views","title":"Views","text":"<p>A view is a view of all entities (File, Folder, Project, Table, Docker Repository, View) within one or more Projects or Folders. Views can: The following examples illustrate some view operations.</p> <p>See here for more information on Views. A view is implemented as a Table, see here for more information on Tables.</p> <p>First create some files we can use in a view:</p> <pre><code>filePath1 &lt;- tempfile()\nconnection &lt;- file(filePath1)\nwriteChar(\"this is the content of the first file\", connection, eos = NULL)\nclose(connection)\nfile1 &lt;- synapseclient$File(path = filePath1, parent = project)\nfile1 &lt;- syn$store(file1)\nfilePath2 &lt;- tempfile()\nconnection2 &lt;- file(filePath2)\nwriteChar(\"this is the content of the second file\", connection, eos = NULL)\nclose(connection2)\nfile2 &lt;- synapseclient$File(path = filePath2, parent = project)\nfile2 &lt;- syn$store(file2)\n\n# add some annotations\nfileAnnotations1 &lt;- syn$get_annotations(file1)\nfileAnnotations2 &lt;- syn$get_annotations(file2)\n\nfileAnnotations1$contributor &lt;- \"Sage\"\nfileAnnotations1$class &lt;- \"V\"\nsyn$set_annotations(fileAnnotations1)\n\nfileAnnotations2$contributor = \"UW\"\nfileAnnotations2$rank = \"X\"\nsyn$set_annotations(fileAnnotations2)\n</code></pre> <p>Now create a view:</p> <pre><code>columns = c(\n  synapseclient$Column(name = \"contributor\", columnType = \"STRING\"),\n  synapseclient$Column(name = \"class\", columnType = \"STRING\"),\n  synapseclient$Column(name = \"rank\", columnType = \"STRING\")\n)\n\nview &lt;- synapseclient$EntityViewSchema(\n    name = \"my first file view\",\n    columns = columns,\n    parent = project,\n    scopes = project,\n    includeEntityTypes = c(synapseclient$EntityViewType$FILE, synapseclient$EntityViewType$FOLDER),\n    addDefaultViewColumns = TRUE\n)\n\nview &lt;- syn$store(view)\n</code></pre> <p>We can now see content of our view (note that views are not created synchronously it may take a few seconds for the view table to be queryable).</p> <pre><code>queryResults &lt;- syn$tableQuery(sprintf(\"select * from %s\", view$properties$id))\ndata &lt;- queryResults$asDataFrame()\ndata\n</code></pre> <p>We can update annotations using a view as follows:</p> <pre><code>data[\"class\"] &lt;- c(\"V\", \"VI\")\nsyn$store(synapseclient$Table(view$properties$id, data))\n\n# the change in annotations is reflected in get_annotations():\nsyn$get_annotations(file2$properties$id)\n</code></pre>"},{"location":"tutorials/reticulate/#update-views-content","title":"Update View's Content","text":"<pre><code># A view can contain different types of entity. To change the types of entity that will show up in a view:\nview &lt;- syn$get(view$properties$id)\nview$set_entity_types(list(synapseclient$EntityViewType$FILE))\n</code></pre>"},{"location":"tutorials/reticulate/#using-with-a-shiny-app","title":"Using with a Shiny App","text":"<p>Reticulate and the Python synapseclient can be used to workaround an issue that exists when using synapser with a Shiny App. Since synapser shares a Synapse client instance within the R process, multiple users of a synapser integrated Shiny App may end up sharing a login if precautions aren't taken. When using reticulate with synapseclient, session scoped Synapse client objects can be created that avoid this issue.</p> <p>See SynapseShinyApp for a sample application and a discussion of the issue, and the reticulate branch for an alternative implementation using reticulate with synapseclient.</p>"},{"location":"tutorials/tables/","title":"Tables","text":"<p>Tables can be built up by adding sets of rows that follow a user-defined schema and queried using a SQL-like syntax.</p>"},{"location":"tutorials/tables/#creating-a-table-and-loading-it-with-data","title":"Creating a table and loading it with data","text":""},{"location":"tutorials/tables/#initial-setup","title":"Initial setup:","text":"<pre><code>import synapseclient\nfrom synapseclient import Project, File, Folder\nfrom synapseclient import Schema, Column, Table, Row, RowSet, as_table_columns, build_table\n\nsyn = synapseclient.Synapse()\nsyn.login()\n\nproject = syn.get('syn123')\n</code></pre>"},{"location":"tutorials/tables/#example-data","title":"Example data","text":"<p>First, let's load some data. Let's say we had a file, genes.csv:</p> <pre><code>Name,Chromosome,Start,End,Strand,TranscriptionFactor\nfoo,1,12345,12600,+,False\narg,2,20001,20200,+,False\nzap,2,30033,30999,-,False\nbah,1,40444,41444,-,False\nbnk,1,51234,54567,+,True\nxyz,1,61234,68686,+,False\n</code></pre>"},{"location":"tutorials/tables/#creating-a-table-with-columns","title":"Creating a table with columns","text":"<pre><code>table = build_table('My Favorite Genes', project, \"/path/to/genes.csv\")\nsyn.store(table)\n</code></pre> <p>build_table will set the Table Schema which defines the columns of the table. To create a table with a custom Schema, first create the Schema:</p> <pre><code>cols = [\n    Column(name='Name', columnType='STRING', maximumSize=20),\n    Column(name='Chromosome', columnType='STRING', maximumSize=20),\n    Column(name='Start', columnType='INTEGER'),\n    Column(name='End', columnType='INTEGER'),\n    Column(name='Strand', columnType='STRING', enumValues=['+', '-'], maximumSize=1),\n    Column(name='TranscriptionFactor', columnType='BOOLEAN')]\n\nschema = Schema(name='My Favorite Genes', columns=cols, parent=project)\n</code></pre>"},{"location":"tutorials/tables/#storing-the-table-in-synapse","title":"Storing the table in Synapse","text":"<pre><code>table = Table(schema, \"/path/to/genes.csv\")\ntable = syn.store(table)\n</code></pre> <p>The <code>Table</code> function takes two arguments, a schema object and data in some form, which can be:</p> <ul> <li>a path to a CSV file</li> <li>a Pandas DataFrame</li> <li>a <code>RowSet</code> object</li> <li>a list of lists where each of the inner lists is a row</li> </ul>"},{"location":"tutorials/tables/#querying-for-data","title":"Querying for data","text":"<p>With a bit of luck, we now have a table populated with data. Let's try to query:</p> <pre><code>results = syn.tableQuery(\"select * from %s where Chromosome='1' and Start &lt; 41000 and End &gt; 20000\"\n                         % table.schema.id)\nfor row in results:\n    print(row)\n</code></pre>"},{"location":"tutorials/tables/#using-pandas-to-accomplish-setup-and-querying","title":"Using Pandas to accomplish setup and querying","text":"<p>Pandas is a popular library for working with tabular data. If you have Pandas installed, the goal is that Synapse Tables will play nice with it.</p> <p>Create a Synapse Table from a DataFrame:</p> <pre><code>import pandas as pd\n\ndf = pd.read_csv(\"/path/to/genes.csv\", index_col=False)\ntable = build_table('My Favorite Genes', project, df)\ntable = syn.store(table)\n</code></pre> <p><code>build_table</code> uses pandas DataFrame dtype to set the Table <code>Schema</code>. To create a table with a custom <code>Schema</code>, first create the <code>Schema</code>:</p> <pre><code>schema = Schema(name='My Favorite Genes', columns=as_table_columns(df), parent=project)\ntable = syn.store(Table(schema, df))\n</code></pre> <p>Get query results as a DataFrame:</p> <pre><code>results = syn.tableQuery(\"select * from %s where Chromosome='2'\" % table.schema.id)\ndf = results.asDataFrame()\n</code></pre>"},{"location":"tutorials/tables/#changing-data","title":"Changing Data","text":"<p>Once the schema is settled, changes come in two flavors: appending new rows and updating existing ones.</p> <p>Appending new rows is fairly straightforward. To continue the previous example, we might add some new genes from another file:</p> <pre><code>table = syn.store(Table(table.schema.id, \"/path/to/more_genes.csv\"))\n</code></pre> <p>To quickly add a few rows, use a list of row data:</p> <pre><code>new_rows = [[\"Qux1\", \"4\", 201001, 202001, \"+\", False],\n            [\"Qux2\", \"4\", 203001, 204001, \"+\", False]]\ntable = syn.store(Table(schema, new_rows))\n</code></pre> <p>Updating rows requires an etag, which identifies the most recent change set plus row IDs and version numbers for each row to be modified. We get those by querying before updating. Minimizing changesets to contain only rows that actually change will make processing faster.</p> <p>For example, let's update the names of some of our favorite genes:</p> <pre><code>results = syn.tableQuery(\"select * from %s where Chromosome='1'\" % table.schema.id)\ndf = results.asDataFrame()\ndf['Name'] = ['rzing', 'zing1', 'zing2', 'zing3']\n</code></pre> <p>Note that we're propagating the etag from the query results. Without it, we'd get an error saying something about an \"Invalid etag\":</p> <pre><code>table = syn.store(Table(schema, df, etag=results.etag))\n</code></pre> <p>The etag is used by the server to prevent concurrent users from making conflicting changes, a technique called optimistic concurrency. In case of a conflict, your update may be rejected. You then have to do another query and try your update again.</p>"},{"location":"tutorials/tables/#changing-table-structure","title":"Changing Table Structure","text":"<p>Adding columns can be done using the methods <code>Schema.addColumn</code> or <code>addColumns</code> on the <code>Schema</code> object:</p> <pre><code>schema = syn.get(\"syn000000\")\nbday_column = syn.store(Column(name='birthday', columnType='DATE'))\nschema.addColumn(bday_column)\nschema = syn.store(schema)\n</code></pre> <p>Renaming or otherwise modifying a column involves removing the column and adding a new column:</p> <pre><code>cols = syn.getTableColumns(schema)\nfor col in cols:\n    if col.name == \"birthday\":\n        schema.removeColumn(col)\nbday_column2 = syn.store(Column(name='birthday2', columnType='DATE'))\nschema.addColumn(bday_column2)\nschema = syn.store(schema)\n</code></pre>"},{"location":"tutorials/tables/#table-attached-files","title":"Table attached files","text":"<p>Synapse tables support a special column type called 'File' which contain a file handle, an identifier of a file stored in Synapse. Here's an example of how to upload files into Synapse, associate them with a table and read them back later:</p> <pre><code># your synapse project\nimport tempfile\nproject = syn.get(...)\n\n# Create temporary files to store\ntemp = tempfile.NamedTemporaryFile()\nwith open(temp.name, \"w+\") as temp_d:\n    temp_d.write(\"this is a test\")\n\ntemp2 = tempfile.NamedTemporaryFile()\nwith open(temp2.name, \"w+\") as temp_d:\n    temp_d.write(\"this is a test 2\")\n\n# store the table's schema\ncols = [\n    Column(name='artist', columnType='STRING', maximumSize=50),\n    Column(name='album', columnType='STRING', maximumSize=50),\n    Column(name='year', columnType='INTEGER'),\n    Column(name='catalog', columnType='STRING', maximumSize=50),\n    Column(name='cover', columnType='FILEHANDLEID')]\nschema = syn.store(Schema(name='Jazz Albums', columns=cols, parent=project))\n\n# the actual data\ndata = [[\"John Coltrane\",  \"Blue Train\",   1957, \"BLP 1577\", temp.name],\n        [\"Sonny Rollins\",  \"Vol. 2\",       1957, \"BLP 1558\", temp.name],\n        [\"Sonny Rollins\",  \"Newk's Time\",  1958, \"BLP 4001\", temp2.name],\n        [\"Kenny Burrel\",   \"Kenny Burrel\", 1956, \"BLP 1543\", temp2.name]]\n\n# upload album covers\nfor row in data:\n    file_handle = syn.uploadFileHandle(row[4], parent=project)\n    row[4] = file_handle['id']\n\n# store the table data\nrow_reference_set = syn.store(RowSet(schema=schema, rows=[Row(r) for r in data]))\n\n# Later, we'll want to query the table and download our album covers\nresults = syn.tableQuery(f\"select artist, album, cover from {schema.id} where artist = 'Sonny Rollins'\")\ntest_files = syn.downloadTableColumns(results, ['cover'])\n</code></pre>"},{"location":"tutorials/tables/#deleting-rows","title":"Deleting rows","text":"<p>Query for the rows you want to delete and call syn.delete on the results:</p> <pre><code>results = syn.tableQuery(\"select * from %s where Chromosome='2'\" % table.schema.id)\na = syn.delete(results)\n</code></pre>"},{"location":"tutorials/tables/#deleting-the-whole-table","title":"Deleting the whole table","text":"<p>Deleting the schema deletes the whole table and all rows:</p> <pre><code>syn.delete(schema)\n</code></pre>"},{"location":"tutorials/tables/#queries","title":"Queries","text":"<p>The query language is quite similar to SQL select statements, except that joins are not supported. The documentation for the Synapse API has lots of query examples.</p> <p>See:</p> <ul> <li>synapseclient.table</li> <li>synapseclient.table.Schema</li> <li>synapseclient.table.Column</li> <li>synapseclient.Synapse.getColumns</li> <li>synapseclient.Synapse.getTableColumns</li> </ul>"},{"location":"tutorials/python/activity/","title":"Activity/Provenance","text":"<p>See the current available tutorial</p> <p></p> <p>Provenance is a concept describing the origin of something. In Synapse, it is used to describe the connections between the workflow steps used to create a particular file or set of results. Data analysis often involves multiple steps to go from a raw data file to a finished analysis. Synapse\u2019s provenance tools allow users to keep track of each step involved in an analysis and share those steps with other users.</p> <p>The model Synapse uses for provenance is based on the W3C provenance spec where items are derived from an activity which has components that were used and components that were executed. Think of the used items as input files and executed items as software or code. Both used and executed items can reside in Synapse or in URLs such as a link to a GitHub commit or a link to a specific version of a software tool.</p> <p>Dive into Activity/Provenance further here</p>"},{"location":"tutorials/python/activity/#tutorial-purpose","title":"Tutorial Purpose","text":"<p>In this tutorial you will:</p> <ol> <li>Add a new Activity to your File</li> <li>Add a new Activity to a specific version of your File</li> <li>Print stored activities on your File</li> <li>Delete an activity</li> </ol>"},{"location":"tutorials/python/activity/#prerequisites","title":"Prerequisites","text":"<ul> <li>In order to follow this tutorial you will need to have a Project created with at least one File with multiple Versions.</li> </ul>"},{"location":"tutorials/python/annotation/","title":"Annotations","text":"<p>Annotations help users search for and find data, and they are a powerful tool used to systematically group and/or describe things in Synapse.</p> <p>Annotations are stored as key-value pairs in Synapse, where the key defines a particular aspect of your data, for example (<code>species</code>, <code>assay</code>, <code>fileFormat</code>) and the value defines a variable that belongs to that category (<code>mouse</code>, <code>RNAseq</code>, <code>.bam</code>). You can use annotations to add additional information about a project, file, folder, table, or view.</p> <p>Annotations can be based on an existing ontology or controlled vocabulary, or can be created as needed and modified later as your metadata evolves.</p> <p>Note: You may optionally follow the Uploading data in bulk tutorial instead. The bulk tutorial may fit your needs better as it limits the amount of code that you are required to write and maintain.</p>"},{"location":"tutorials/python/annotation/#tutorial-purpose","title":"Tutorial Purpose","text":"<p>In this tutorial you will:</p> <ol> <li>Add several annotations to stored files</li> <li>Upload 2 new files and set the annotations at the same time</li> </ol>"},{"location":"tutorials/python/annotation/#prerequisites","title":"Prerequisites","text":"<ul> <li>Make sure that you have completed the File tutorial or have at least 1 file in your Synapse project.</li> </ul>"},{"location":"tutorials/python/annotation/#1-add-several-annotations-to-stored-files","title":"1. Add several annotations to stored files","text":""},{"location":"tutorials/python/annotation/#first-lets-retrieve-all-of-the-synapse-ids-we-are-going-to-use","title":"First let's retrieve all of the Synapse IDs we are going to use","text":"<pre><code># Step 1: Add several annotations to stored files\nimport os\n\nimport synapseclient\nfrom synapseclient import File\n\nsyn = synapseclient.login()\n\n# Retrieve the project ID\nmy_project_id = syn.findEntityId(\n    name=\"My uniquely named project about Alzheimer's Disease\"\n)\n\n# Retrieve the folders I want to annotate files in\nbatch_1_folder_id = syn.findEntityId(\n    name=\"single_cell_RNAseq_batch_1\", parent=my_project_id\n)\n</code></pre>"},{"location":"tutorials/python/annotation/#next-lets-define-the-annotations-i-want-to-set","title":"Next let's define the annotations I want to set","text":"<pre><code># Define the annotations I want to set\nannotation_values = {\n    \"species\": \"Homo sapiens\",\n    \"dataType\": \"geneExpression\",\n    \"assay\": \"SCRNA-seq\",\n    \"fileFormat\": \"fastq\",\n</code></pre>"},{"location":"tutorials/python/annotation/#finally-well-loop-over-all-of-the-files-and-set-their-annotations","title":"Finally we'll loop over all of the files and set their annotations","text":"<pre><code># Loop over all of the files and set their annotations\nfor file_batch_1 in syn.getChildren(parent=batch_1_folder_id, includeTypes=[\"file\"]):\n    # Grab and print the existing annotations this File may already have\n    existing_annotations_for_file = syn.get_annotations(entity=file_batch_1)\n\n    print(\n        f\"Got the annotations for File: {file_batch_1['name']}, ID: {file_batch_1['id']}, Annotations: {existing_annotations_for_file}\"\n    )\n\n    # Merge the new annotations with anything existing\n    existing_annotations_for_file.update(annotation_values)\n\n    existing_annotations_for_file = syn.set_annotations(\n        annotations=existing_annotations_for_file\n    )\n\n    print(\n        f\"Set the annotations for File: {file_batch_1['name']}, ID: {file_batch_1['id']}, Annotations: {existing_annotations_for_file}\"\n</code></pre> You'll see that each file now has a number of annotations: <pre><code>Batch 1 Folder ID: syn53205629\nGot the annotations for File: SRR12345678_R1.fastq.gz, ID: syn53205687, Annotations: {}\nSet the annotations for File: SRR12345678_R1.fastq.gz, ID: syn53205687, Annotations: {'assay': ['SCRNA-seq'], 'species': ['Homo sapiens'], 'dataType': ['geneExpression'], 'fileFormat': ['fastq']}\nGot the annotations for File: SRR12345678_R2.fastq.gz, ID: syn53205688, Annotations: {}\nSet the annotations for File: SRR12345678_R2.fastq.gz, ID: syn53205688, Annotations: {'assay': ['SCRNA-seq'], 'species': ['Homo sapiens'], 'dataType': ['geneExpression'], 'fileFormat': ['fastq']}\n</code></pre>"},{"location":"tutorials/python/annotation/#2-upload-2-new-files-and-set-the-annotations-at-the-same-time","title":"2. Upload 2 new files and set the annotations at the same time","text":"<p>Assuming we have a few new files we want to upload we'll follow a similar pattern defined in the File tutorial, except now we'll specify the <code>annotations</code> attribute before uploading the file to Synapse.</p> <p>In order for the following script to work please replace the files with ones that already exist on your local machine.</p> <pre><code># Step 2: Upload 2 new files and set the annotations at the same time\n# In order for the following script to work please replace the files with ones that\n# already exist on your local machine.\nbatch_1_scrnaseq_new_file_1 = File(\n    path=os.path.expanduser(\n        \"~/my_ad_project/single_cell_RNAseq_batch_1/SRR92345678_R1.fastq.gz\"\n    ),\n    parent=batch_1_folder_id,\n    annotations=annotation_values,\n)\nbatch_1_scrnaseq_new_file_2 = File(\n    path=os.path.expanduser(\n        \"~/my_ad_project/single_cell_RNAseq_batch_1/SRR92345678_R2.fastq.gz\"\n    ),\n    parent=batch_1_folder_id,\n    annotations=annotation_values,\n)\nbatch_1_scrnaseq_new_file_1 = syn.store(obj=batch_1_scrnaseq_new_file_1)\nbatch_1_scrnaseq_new_file_2 = syn.store(obj=batch_1_scrnaseq_new_file_2)\n\nprint(\n    f\"Stored file: {batch_1_scrnaseq_new_file_1['name']}, ID: {batch_1_scrnaseq_new_file_1['id']}, Annotations: {batch_1_scrnaseq_new_file_1['annotations']}\"\n)\nprint(\n    f\"Stored file: {batch_1_scrnaseq_new_file_2['name']}, ID: {batch_1_scrnaseq_new_file_2['id']}, Annotations: {batch_1_scrnaseq_new_file_2['annotations']}\"\n</code></pre> You'll notice the output looks like: <pre><code>Stored file: SRR92345678_R1.fastq.gz, ID: syn53206218, Annotations: {\n  \"assay\": [\n    \"SCRNA-seq\"\n  ],\n  \"dataType\": [\n    \"geneExpression\"\n  ],\n  \"fileFormat\": [\n    \"fastq\"\n  ],\n  \"species\": [\n    \"Homo sapiens\"\n  ]\n}\nStored file: SRR92345678_R2.fastq.gz, ID: syn53206219, Annotations: {\n  \"assay\": [\n    \"SCRNA-seq\"\n  ],\n  \"dataType\": [\n    \"geneExpression\"\n  ],\n  \"fileFormat\": [\n    \"fastq\"\n  ],\n  \"species\": [\n    \"Homo sapiens\"\n  ]\n}\n</code></pre>"},{"location":"tutorials/python/annotation/#results","title":"Results","text":"<p>Now that you have annotated your files you'll be able to inspect this on the individual files in the synapse web UI. It should look similar to:</p> <p></p>"},{"location":"tutorials/python/annotation/#source-code-for-this-tutorial","title":"Source code for this tutorial","text":"Click to show me <pre><code>\"\"\"\nHere is where you'll find the code for the Annotation tutorial.\n\"\"\"\n\n# Step 1: Add several annotations to stored files\nimport os\n\nimport synapseclient\nfrom synapseclient import File\n\nsyn = synapseclient.login()\n\n# Retrieve the project ID\nmy_project_id = syn.findEntityId(\n    name=\"My uniquely named project about Alzheimer's Disease\"\n)\n\n# Retrieve the folders I want to annotate files in\nbatch_1_folder_id = syn.findEntityId(\n    name=\"single_cell_RNAseq_batch_1\", parent=my_project_id\n)\n\nprint(f\"Batch 1 Folder ID: {batch_1_folder_id}\")\n\n\n# Define the annotations I want to set\nannotation_values = {\n    \"species\": \"Homo sapiens\",\n    \"dataType\": \"geneExpression\",\n    \"assay\": \"SCRNA-seq\",\n    \"fileFormat\": \"fastq\",\n}\n\n# Loop over all of the files and set their annotations\nfor file_batch_1 in syn.getChildren(parent=batch_1_folder_id, includeTypes=[\"file\"]):\n    # Grab and print the existing annotations this File may already have\n    existing_annotations_for_file = syn.get_annotations(entity=file_batch_1)\n\n    print(\n        f\"Got the annotations for File: {file_batch_1['name']}, ID: {file_batch_1['id']}, Annotations: {existing_annotations_for_file}\"\n    )\n\n    # Merge the new annotations with anything existing\n    existing_annotations_for_file.update(annotation_values)\n\n    existing_annotations_for_file = syn.set_annotations(\n        annotations=existing_annotations_for_file\n    )\n\n    print(\n        f\"Set the annotations for File: {file_batch_1['name']}, ID: {file_batch_1['id']}, Annotations: {existing_annotations_for_file}\"\n    )\n\n# Step 2: Upload 2 new files and set the annotations at the same time\n# In order for the following script to work please replace the files with ones that\n# already exist on your local machine.\nbatch_1_scrnaseq_new_file_1 = File(\n    path=os.path.expanduser(\n        \"~/my_ad_project/single_cell_RNAseq_batch_1/SRR92345678_R1.fastq.gz\"\n    ),\n    parent=batch_1_folder_id,\n    annotations=annotation_values,\n)\nbatch_1_scrnaseq_new_file_2 = File(\n    path=os.path.expanduser(\n        \"~/my_ad_project/single_cell_RNAseq_batch_1/SRR92345678_R2.fastq.gz\"\n    ),\n    parent=batch_1_folder_id,\n    annotations=annotation_values,\n)\nbatch_1_scrnaseq_new_file_1 = syn.store(obj=batch_1_scrnaseq_new_file_1)\nbatch_1_scrnaseq_new_file_2 = syn.store(obj=batch_1_scrnaseq_new_file_2)\n\nprint(\n    f\"Stored file: {batch_1_scrnaseq_new_file_1['name']}, ID: {batch_1_scrnaseq_new_file_1['id']}, Annotations: {batch_1_scrnaseq_new_file_1['annotations']}\"\n)\nprint(\n    f\"Stored file: {batch_1_scrnaseq_new_file_2['name']}, ID: {batch_1_scrnaseq_new_file_2['id']}, Annotations: {batch_1_scrnaseq_new_file_2['annotations']}\"\n)\n</code></pre>"},{"location":"tutorials/python/annotation/#references-used-in-this-tutorial","title":"References used in this tutorial","text":"<ul> <li>Annotations</li> <li>File</li> <li>syn.login</li> <li>syn.findEntityId</li> <li>syn.getChildren</li> <li>syn.get_annotations</li> <li>syn.set_annotations</li> <li>syn.store</li> </ul>"},{"location":"tutorials/python/dataset/","title":"Datasets in Synapse","text":""},{"location":"tutorials/python/download_data_in_bulk/","title":"Downloading data in bulk","text":"<p>Contained within this tutorial is an experimental interface for working with the Synapse Python Client. These interfaces are subject to change at any time. Use at your own risk.</p> <p>This tutorial will follow a Flattened Data Layout. With a project that has this example layout: <pre><code>.\n\u251c\u2500\u2500 biospecimen_experiment_1\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 fileA.txt\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 fileB.txt\n\u251c\u2500\u2500 biospecimen_experiment_2\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 fileC.txt\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 fileD.txt\n\u251c\u2500\u2500 single_cell_RNAseq_batch_1\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 SRR12345678_R1.fastq.gz\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 SRR12345678_R2.fastq.gz\n\u2514\u2500\u2500 single_cell_RNAseq_batch_2\n    \u251c\u2500\u2500 SRR12345678_R1.fastq.gz\n    \u2514\u2500\u2500 SRR12345678_R2.fastq.gz\n</code></pre></p>"},{"location":"tutorials/python/download_data_in_bulk/#tutorial-purpose","title":"Tutorial Purpose","text":"<p>In this tutorial you will:</p> <ol> <li>Download all files/folder from a project</li> <li>Download all files/folders for a specific folder within the project</li> <li>Loop over all files/folders on the project/folder object instances</li> </ol>"},{"location":"tutorials/python/download_data_in_bulk/#prerequisites","title":"Prerequisites","text":"<ul> <li>Make sure that you have completed the following tutorials:<ul> <li>Folder</li> <li>File</li> </ul> </li> <li>This tutorial is setup to download the data to <code>~/my_ad_project</code>, make sure that this or another desired directory exists.</li> </ul>"},{"location":"tutorials/python/download_data_in_bulk/#1-download-all-filesfolder-from-a-project","title":"1. Download all files/folder from a project","text":""},{"location":"tutorials/python/download_data_in_bulk/#first-lets-set-up-some-constants-well-use-in-this-script","title":"First let's set up some constants we'll use in this script","text":"<pre><code>import os\n\nimport synapseclient\nfrom synapseclient.models import Folder, Project\n\nsyn = synapseclient.Synapse()\nsyn.login()\n\n# Create some constants to store the paths to the data\nDIRECTORY_TO_SYNC_PROJECT_TO = os.path.expanduser(os.path.join(\"~\", \"my_ad_project\"))\nFOLDER_NAME_TO_SYNC = \"biospecimen_experiment_1\"\nDIRECTORY_TO_SYNC_FOLDER_TO = os.path.join(\n    DIRECTORY_TO_SYNC_PROJECT_TO, FOLDER_NAME_TO_SYNC\n)\n\n# Step 1: Create an instance of the container I want to sync the data from and sync\n</code></pre>"},{"location":"tutorials/python/download_data_in_bulk/#next-well-create-an-instance-of-the-project-we-are-going-to-sync","title":"Next we'll create an instance of the Project we are going to sync","text":"<pre><code># We'll set the `if_collision` to `keep.local` so that we don't overwrite any files\n</code></pre>"},{"location":"tutorials/python/download_data_in_bulk/#finally-well-sync-the-project-from-synapse-to-your-local-machine","title":"Finally we'll sync the project from synapse to your local machine","text":"<pre><code># Print out the contents of the directory where the data was synced to\n# Explore the directory to see the contents have been recursively synced.\nprint(os.listdir(DIRECTORY_TO_SYNC_PROJECT_TO))\n\n# Step 2: The same as step 1, but for a single folder\n</code></pre> While syncing your project you'll see results like: <pre><code>Syncing Project (syn53185532:My uniquely named project about Alzheimer's Disease) from Synapse.\nSyncing Folder (syn53205630:experiment_notes) from Synapse.\nSyncing Folder (syn53205632:notes_2022) from Synapse.\nSyncing Folder (syn53205629:single_cell_RNAseq_batch_1) from Synapse.\nSyncing Folder (syn53205656:single_cell_RNAseq_batch_2) from Synapse.\nSyncing Folder (syn53205631:notes_2023) from Synapse.\nDownloading  [####################]100.00%   4.0bytes/4.0bytes (1.8kB/s) fileA.txt Done...\nDownloading  [####################]100.00%   3.0bytes/3.0bytes (1.1kB/s) SRR92345678_R1.fastq.gz Done...\nDownloading  [####################]100.00%   4.0bytes/4.0bytes (1.7kB/s) SRR12345678_R1.fastq.gz Done...\nDownloading  [####################]100.00%   4.0bytes/4.0bytes (1.9kB/s) fileC.txt Done...\nDownloading  [####################]100.00%   4.0bytes/4.0bytes (2.7kB/s) fileB.txt Done...\nDownloading  [####################]100.00%   4.0bytes/4.0bytes (2.7kB/s) SRR12345678_R2.fastq.gz Done...\nDownloading  [####################]100.00%   4.0bytes/4.0bytes (2.6kB/s) SRR12345678_R2.fastq.gz Done...\nDownloading  [####################]100.00%   4.0bytes/4.0bytes (1.8kB/s) SRR12345678_R1.fastq.gz Done...\nDownloading  [####################]100.00%   3.0bytes/3.0bytes (1.5kB/s) SRR92345678_R2.fastq.gz Done...\nDownloading  [####################]100.00%   4.0bytes/4.0bytes (1.6kB/s) fileD.txt Done...\n['single_cell_RNAseq_batch_2', 'single_cell_RNAseq_batch_1', 'experiment_notes']\n</code></pre>"},{"location":"tutorials/python/download_data_in_bulk/#2-download-all-filesfolders-for-a-specific-folder-within-the-project","title":"2. Download all files/folders for a specific folder within the project","text":"<p>Following the same set of steps let's sync a specific folder</p> <pre><code>folder.sync_from_synapse(path=DIRECTORY_TO_SYNC_FOLDER_TO, if_collision=\"keep.local\")\n\nprint(os.listdir(os.path.expanduser(DIRECTORY_TO_SYNC_FOLDER_TO)))\n\n# Step 3: Loop over all files/folders on the project/folder object instances\n</code></pre> While syncing your folder you'll see results like: <pre><code>Syncing Folder (syn53205630:experiment_notes) from Synapse.\nSyncing Folder (syn53205632:notes_2022) from Synapse.\nSyncing Folder (syn53205631:notes_2023) from Synapse.\n['notes_2022', 'notes_2023']\n</code></pre> <p>You'll notice that no files are downloaded. This is because the client will see that you already have the content within this folder and will not attempt to download the content again. If you were to use an <code>if_collision</code> of <code>\"overwrite.local\"</code> you would see that when the content on your machine does not match Synapse the file will be overwritten.</p>"},{"location":"tutorials/python/download_data_in_bulk/#3-loop-over-all-filesfolders-on-the-projectfolder-object-instances","title":"3. Loop over all files/folders on the project/folder object instances","text":"<p>Using <code>sync_from_synapse</code> will load into memory the state of all Folders and Files retrieved from Synapse. This will allow you to loop over the contents of your container.</p> <pre><code>for file_in_root_folder in folder_at_root.files:\n        print(f\"File in {folder_at_root.name}: {file_in_root_folder.name}\")\n\n    for folder_in_folder in folder_at_root.folders:\n        print(f\"Folder in {folder_at_root.name}: {folder_in_folder.name}\")\n        for file_in_folder in folder_in_folder.files:\n            print(f\"File in {folder_in_folder.name}: {file_in_folder.name}\")\n</code></pre> The result of traversing some of your project structure should look like: <pre><code>Folder at root: experiment_notes\nFolder in experiment_notes: notes_2022\nFile in notes_2022: fileA.txt\nFile in notes_2022: fileB.txt\nFolder in experiment_notes: notes_2023\nFile in notes_2023: fileC.txt\nFile in notes_2023: fileD.txt\nFolder at root: single_cell_RNAseq_batch_1\nFile in single_cell_RNAseq_batch_1: SRR12345678_R1.fastq.gz\nFile in single_cell_RNAseq_batch_1: SRR12345678_R2.fastq.gz\nFile in single_cell_RNAseq_batch_1: SRR92345678_R1.fastq.gz\nFile in single_cell_RNAseq_batch_1: SRR92345678_R2.fastq.gz\nFolder at root: single_cell_RNAseq_batch_2\nFile in single_cell_RNAseq_batch_2: SRR12345678_R1.fastq.gz\nFile in single_cell_RNAseq_batch_2: SRR12345678_R2.fastq.gz\n</code></pre>"},{"location":"tutorials/python/download_data_in_bulk/#source-code-for-this-tutorial","title":"Source code for this tutorial","text":"Click to show me <pre><code>\"\"\"\nHere is where you'll find the code for the downloading data in bulk tutorial.\n\"\"\"\n\nimport os\n\nimport synapseclient\nfrom synapseclient.models import Folder, Project\n\nsyn = synapseclient.Synapse()\nsyn.login()\n\n# Create some constants to store the paths to the data\nDIRECTORY_TO_SYNC_PROJECT_TO = os.path.expanduser(os.path.join(\"~\", \"my_ad_project\"))\nFOLDER_NAME_TO_SYNC = \"biospecimen_experiment_1\"\nDIRECTORY_TO_SYNC_FOLDER_TO = os.path.join(\n    DIRECTORY_TO_SYNC_PROJECT_TO, FOLDER_NAME_TO_SYNC\n)\n\n# Step 1: Create an instance of the container I want to sync the data from and sync\nproject = Project(name=\"My uniquely named project about Alzheimer's Disease\")\n\n# We'll set the `if_collision` to `keep.local` so that we don't overwrite any files\nproject.sync_from_synapse(path=DIRECTORY_TO_SYNC_PROJECT_TO, if_collision=\"keep.local\")\n\n# Print out the contents of the directory where the data was synced to\n# Explore the directory to see the contents have been recursively synced.\nprint(os.listdir(DIRECTORY_TO_SYNC_PROJECT_TO))\n\n# Step 2: The same as step 1, but for a single folder\nfolder = Folder(name=FOLDER_NAME_TO_SYNC, parent_id=project.id)\n\nfolder.sync_from_synapse(path=DIRECTORY_TO_SYNC_FOLDER_TO, if_collision=\"keep.local\")\n\nprint(os.listdir(os.path.expanduser(DIRECTORY_TO_SYNC_FOLDER_TO)))\n\n# Step 3: Loop over all files/folders on the project/folder object instances\nfor folder_at_root in project.folders:\n    print(f\"Folder at root: {folder_at_root.name}\")\n\n    for file_in_root_folder in folder_at_root.files:\n        print(f\"File in {folder_at_root.name}: {file_in_root_folder.name}\")\n\n    for folder_in_folder in folder_at_root.folders:\n        print(f\"Folder in {folder_at_root.name}: {folder_in_folder.name}\")\n        for file_in_folder in folder_in_folder.files:\n            print(f\"File in {folder_in_folder.name}: {file_in_folder.name}\")\n</code></pre>"},{"location":"tutorials/python/file/","title":"Files in Synapse","text":"<p>Synapse files can be created by uploading content from your local computer or linking to digital files on the web.</p> <p>Files in Synapse always have a \u201cparent\u201d, which could be a project or a folder. You can organize collections of files into folders and sub-folders, just as you would on your local computer.</p> <p>Read more</p> <p>Note: You may optionally follow the Uploading data in bulk tutorial instead. The bulk tutorial may fit your needs better as it limits the amount of code that you are required to write and maintain.</p> <p>This tutorial will follow a Flattened Data Layout. With this example layout: <pre><code>.\n\u251c\u2500\u2500 biospecimen_experiment_1\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 fileA.txt\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 fileB.txt\n\u251c\u2500\u2500 biospecimen_experiment_2\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 fileC.txt\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 fileD.txt\n\u251c\u2500\u2500 single_cell_RNAseq_batch_1\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 SRR12345678_R1.fastq.gz\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 SRR12345678_R2.fastq.gz\n\u2514\u2500\u2500 single_cell_RNAseq_batch_2\n    \u251c\u2500\u2500 SRR12345678_R1.fastq.gz\n    \u2514\u2500\u2500 SRR12345678_R2.fastq.gz\n</code></pre></p>"},{"location":"tutorials/python/file/#tutorial-purpose","title":"Tutorial Purpose","text":"<p>In this tutorial you will:</p> <ol> <li>Upload several files to Synapse</li> <li>Print stored attributes about your files</li> <li>List all Folders and Files within my project</li> </ol>"},{"location":"tutorials/python/file/#prerequisites","title":"Prerequisites","text":"<ul> <li>Make sure that you have completed the Folder tutorial.</li> <li>The tutorial assumes you have a number of files ready to upload. If you do not, create test or dummy files. You may also use these dummy files used during the creation of these tutorials. These are text files with example file extensions that a researcher may be using.</li> </ul>"},{"location":"tutorials/python/file/#1-upload-several-files-to-synapse","title":"1. Upload several files to Synapse","text":""},{"location":"tutorials/python/file/#first-lets-retrieve-all-of-the-synapse-ids-we-are-going-to-use","title":"First let's retrieve all of the Synapse IDs we are going to use","text":"<pre><code># Step 1: Upload several files to Synapse\nimport os\n\nimport synapseclient\nimport synapseutils\nfrom synapseclient import File\n\nsyn = synapseclient.login()\n\n# Retrieve the project ID\nmy_project_id = syn.findEntityId(\n    name=\"My uniquely named project about Alzheimer's Disease\"\n)\n\n# Retrieve the IDs of the folders I want to upload to\nbatch_1_folder = syn.findEntityId(\n    parent=my_project_id, name=\"single_cell_RNAseq_batch_1\"\n)\nbatch_2_folder = syn.findEntityId(\n    parent=my_project_id, name=\"single_cell_RNAseq_batch_2\"\n)\nbiospecimen_experiment_1_folder = syn.findEntityId(\n    parent=my_project_id, name=\"biospecimen_experiment_1\"\n)\nbiospecimen_experiment_2_folder = syn.findEntityId(\n    parent=my_project_id, name=\"biospecimen_experiment_2\"\n</code></pre>"},{"location":"tutorials/python/file/#next-lets-create-all-of-the-file-objects-to-upload-content","title":"Next let's create all of the File objects to upload content","text":"<pre><code># Create a File object for each file I want to upload\nbiospecimen_experiment_1_a_2022 = File(\n    path=os.path.expanduser(\"~/my_ad_project/biospecimen_experiment_1/fileA.txt\"),\n    parent=biospecimen_experiment_1_folder,\n)\nbiospecimen_experiment_1_b_2022 = File(\n    path=os.path.expanduser(\"~/my_ad_project/biospecimen_experiment_1/fileB.txt\"),\n    parent=biospecimen_experiment_1_folder,\n)\n\nbiospecimen_experiment_2_c_2023 = File(\n    path=os.path.expanduser(\"~/my_ad_project/biospecimen_experiment_2/fileC.txt\"),\n    parent=biospecimen_experiment_2_folder,\n)\nbiospecimen_experiment_2_d_2023 = File(\n    path=os.path.expanduser(\"~/my_ad_project/biospecimen_experiment_2/fileD.txt\"),\n    parent=biospecimen_experiment_2_folder,\n)\n\nbatch_1_scrnaseq_file_1 = File(\n    path=os.path.expanduser(\n        \"~/my_ad_project/single_cell_RNAseq_batch_1/SRR12345678_R1.fastq.gz\"\n    ),\n    parent=batch_1_folder,\n)\nbatch_1_scrnaseq_file_2 = File(\n    path=os.path.expanduser(\n        \"~/my_ad_project/single_cell_RNAseq_batch_1/SRR12345678_R2.fastq.gz\"\n    ),\n    parent=batch_1_folder,\n)\n\nbatch_2_scrnaseq_file_1 = File(\n    path=os.path.expanduser(\n        \"~/my_ad_project/single_cell_RNAseq_batch_2/SRR12345678_R1.fastq.gz\"\n    ),\n    parent=batch_2_folder,\n)\nbatch_2_scrnaseq_file_2 = File(\n    path=os.path.expanduser(\n        \"~/my_ad_project/single_cell_RNAseq_batch_2/SRR12345678_R2.fastq.gz\"\n    ),\n    parent=batch_2_folder,\n</code></pre>"},{"location":"tutorials/python/file/#finally-well-store-the-files-in-synapse","title":"Finally we'll store the files in Synapse","text":"<pre><code># Upload each file to Synapse\nbiospecimen_experiment_1_a_2022 = syn.store(obj=biospecimen_experiment_1_a_2022)\nbiospecimen_experiment_1_b_2022 = syn.store(obj=biospecimen_experiment_1_b_2022)\nbiospecimen_experiment_2_c_2023 = syn.store(obj=biospecimen_experiment_2_c_2023)\nbiospecimen_experiment_2_d_2023 = syn.store(obj=biospecimen_experiment_2_d_2023)\nbatch_1_scrnaseq_file_1 = syn.store(obj=batch_1_scrnaseq_file_1)\nbatch_1_scrnaseq_file_2 = syn.store(obj=batch_1_scrnaseq_file_2)\nbatch_2_scrnaseq_file_1 = syn.store(obj=batch_2_scrnaseq_file_1)\n</code></pre> Each file being uploaded has an upload progress bar: <pre><code>##################################################\n Uploading file to Synapse storage\n##################################################\n\nUploading [####################]100.00%   2.0bytes/2.0bytes (1.8bytes/s) SRR12345678_R1.fastq.gz Done...\n</code></pre>"},{"location":"tutorials/python/file/#2-print-stored-attributes-about-your-files","title":"2. Print stored attributes about your files","text":"<pre><code># Step 2: Print stored attributes about your file\nbatch_1_scrnaseq_file_1_id = batch_1_scrnaseq_file_1.id\nprint(f\"My file ID is: {batch_1_scrnaseq_file_1_id}\")\n\nprint(f\"The parent ID of my file is: {batch_1_scrnaseq_file_1.parentId}\")\n\nprint(f\"I created my file on: {batch_1_scrnaseq_file_1.createdOn}\")\n\nprint(\n    f\"The ID of the user that created my file is: {batch_1_scrnaseq_file_1.createdBy}\"\n)\n</code></pre> You'll notice the output looks like: <pre><code>My file ID is: syn53205687\nThe parent ID of my file is: syn53205629\nI created my file on: 2023-12-28T21:55:17.971Z\nThe ID of the user that created my file is: 3481671\nMy file was last modified on: 2023-12-28T21:55:17.971Z\n</code></pre>"},{"location":"tutorials/python/file/#3-list-all-folders-and-files-within-my-project","title":"3. List all Folders and Files within my project","text":"<p>Now that your project has a number of Folders and Files let's explore how we can traverse the content stored within the Project.</p> <pre><code># Step 3: List all Folders and Files within my project\nfor directory_path, directory_names, file_name in synapseutils.walk(\n    syn=syn, synId=my_project_id, includeTypes=[\"file\"]\n):\n    for directory_name in directory_names:\n        print(\n            f\"Directory ({directory_name[1]}): {directory_path[0]}/{directory_name[0]}\"\n        )\n\n    for file in file_name:\n</code></pre> The result of walking your project structure should look something like: <pre><code>Directory (syn60109540): My uniquely named project about Alzheimer's Disease/biospecimen_experiment_1\nDirectory (syn60109543): My uniquely named project about Alzheimer's Disease/biospecimen_experiment_2\nDirectory (syn60109534): My uniquely named project about Alzheimer's Disease/single_cell_RNAseq_batch_1\nDirectory (syn60109537): My uniquely named project about Alzheimer's Disease/single_cell_RNAseq_batch_2\nFile (syn60115444): My uniquely named project about Alzheimer's Disease/biospecimen_experiment_1/fileA.txt\nFile (syn60115457): My uniquely named project about Alzheimer's Disease/biospecimen_experiment_1/fileB.txt\nFile (syn60115472): My uniquely named project about Alzheimer's Disease/biospecimen_experiment_2/fileC.txt\nFile (syn60115485): My uniquely named project about Alzheimer's Disease/biospecimen_experiment_2/fileD.txt\nFile (syn60115498): My uniquely named project about Alzheimer's Disease/single_cell_RNAseq_batch_1/SRR12345678_R1.fastq.gz\nFile (syn60115513): My uniquely named project about Alzheimer's Disease/single_cell_RNAseq_batch_1/SRR12345678_R2.fastq.gz\nFile (syn60115526): My uniquely named project about Alzheimer's Disease/single_cell_RNAseq_batch_2/SRR12345678_R1.fastq.gz\nFile (syn60115539): My uniquely named project about Alzheimer's Disease/single_cell_RNAseq_batch_2/SRR12345678_R2.fastq.gz\n</code></pre>"},{"location":"tutorials/python/file/#results","title":"Results","text":"<p>Now that you have created your files you'll be able to inspect this on the Files tab of your project in the synapse web UI. It should look similar to:</p> <p></p>"},{"location":"tutorials/python/file/#source-code-for-this-tutorial","title":"Source code for this tutorial","text":"Click to show me <pre><code>\"\"\"\nHere is where you'll find the code for the File tutorial.\n\"\"\"\n\n# Step 1: Upload several files to Synapse\nimport os\n\nimport synapseclient\nimport synapseutils\nfrom synapseclient import File\n\nsyn = synapseclient.login()\n\n# Retrieve the project ID\nmy_project_id = syn.findEntityId(\n    name=\"My uniquely named project about Alzheimer's Disease\"\n)\n\n# Retrieve the IDs of the folders I want to upload to\nbatch_1_folder = syn.findEntityId(\n    parent=my_project_id, name=\"single_cell_RNAseq_batch_1\"\n)\nbatch_2_folder = syn.findEntityId(\n    parent=my_project_id, name=\"single_cell_RNAseq_batch_2\"\n)\nbiospecimen_experiment_1_folder = syn.findEntityId(\n    parent=my_project_id, name=\"biospecimen_experiment_1\"\n)\nbiospecimen_experiment_2_folder = syn.findEntityId(\n    parent=my_project_id, name=\"biospecimen_experiment_2\"\n)\n\n# Create a File object for each file I want to upload\nbiospecimen_experiment_1_a_2022 = File(\n    path=os.path.expanduser(\"~/my_ad_project/biospecimen_experiment_1/fileA.txt\"),\n    parent=biospecimen_experiment_1_folder,\n)\nbiospecimen_experiment_1_b_2022 = File(\n    path=os.path.expanduser(\"~/my_ad_project/biospecimen_experiment_1/fileB.txt\"),\n    parent=biospecimen_experiment_1_folder,\n)\n\nbiospecimen_experiment_2_c_2023 = File(\n    path=os.path.expanduser(\"~/my_ad_project/biospecimen_experiment_2/fileC.txt\"),\n    parent=biospecimen_experiment_2_folder,\n)\nbiospecimen_experiment_2_d_2023 = File(\n    path=os.path.expanduser(\"~/my_ad_project/biospecimen_experiment_2/fileD.txt\"),\n    parent=biospecimen_experiment_2_folder,\n)\n\nbatch_1_scrnaseq_file_1 = File(\n    path=os.path.expanduser(\n        \"~/my_ad_project/single_cell_RNAseq_batch_1/SRR12345678_R1.fastq.gz\"\n    ),\n    parent=batch_1_folder,\n)\nbatch_1_scrnaseq_file_2 = File(\n    path=os.path.expanduser(\n        \"~/my_ad_project/single_cell_RNAseq_batch_1/SRR12345678_R2.fastq.gz\"\n    ),\n    parent=batch_1_folder,\n)\n\nbatch_2_scrnaseq_file_1 = File(\n    path=os.path.expanduser(\n        \"~/my_ad_project/single_cell_RNAseq_batch_2/SRR12345678_R1.fastq.gz\"\n    ),\n    parent=batch_2_folder,\n)\nbatch_2_scrnaseq_file_2 = File(\n    path=os.path.expanduser(\n        \"~/my_ad_project/single_cell_RNAseq_batch_2/SRR12345678_R2.fastq.gz\"\n    ),\n    parent=batch_2_folder,\n)\n\n# Upload each file to Synapse\nbiospecimen_experiment_1_a_2022 = syn.store(obj=biospecimen_experiment_1_a_2022)\nbiospecimen_experiment_1_b_2022 = syn.store(obj=biospecimen_experiment_1_b_2022)\nbiospecimen_experiment_2_c_2023 = syn.store(obj=biospecimen_experiment_2_c_2023)\nbiospecimen_experiment_2_d_2023 = syn.store(obj=biospecimen_experiment_2_d_2023)\nbatch_1_scrnaseq_file_1 = syn.store(obj=batch_1_scrnaseq_file_1)\nbatch_1_scrnaseq_file_2 = syn.store(obj=batch_1_scrnaseq_file_2)\nbatch_2_scrnaseq_file_1 = syn.store(obj=batch_2_scrnaseq_file_1)\nbatch_2_scrnaseq_file_2 = syn.store(obj=batch_2_scrnaseq_file_2)\n\n# Step 2: Print stored attributes about your file\nbatch_1_scrnaseq_file_1_id = batch_1_scrnaseq_file_1.id\nprint(f\"My file ID is: {batch_1_scrnaseq_file_1_id}\")\n\nprint(f\"The parent ID of my file is: {batch_1_scrnaseq_file_1.parentId}\")\n\nprint(f\"I created my file on: {batch_1_scrnaseq_file_1.createdOn}\")\n\nprint(\n    f\"The ID of the user that created my file is: {batch_1_scrnaseq_file_1.createdBy}\"\n)\n\nprint(f\"My file was last modified on: {batch_1_scrnaseq_file_1.modifiedOn}\")\n\n# Step 3: List all Folders and Files within my project\nfor directory_path, directory_names, file_name in synapseutils.walk(\n    syn=syn, synId=my_project_id, includeTypes=[\"file\"]\n):\n    for directory_name in directory_names:\n        print(\n            f\"Directory ({directory_name[1]}): {directory_path[0]}/{directory_name[0]}\"\n        )\n\n    for file in file_name:\n        print(f\"File ({file[1]}): {directory_path[0]}/{file[0]}\")\n</code></pre>"},{"location":"tutorials/python/file/#references-used-in-this-tutorial","title":"References used in this tutorial","text":"<ul> <li>File</li> <li>syn.login</li> <li>syn.findEntityId</li> <li>syn.store</li> <li>synapseutils.walk</li> </ul>"},{"location":"tutorials/python/file_view/","title":"File Views","text":"<p>See the current available tutorial</p> <p></p>"},{"location":"tutorials/python/folder/","title":"Folders in Synapse","text":"<p>Similar to Projects, Folders are \u201ccontainers\u201d that offer an additional way to organize your data. Instead of uploading a bunch of single files into your project, you can create folders to separate your data in a systematic way.</p> <p>Folders in Synapse always have a \u201cparent\u201d, which could be a project or a folder. You can organize collections of folders and sub-folders, just as you would on your local computer.</p> <p>Read more about Folders</p> <p>Note: You may optionally follow the Uploading data in bulk tutorial instead. The bulk tutorial may fit your needs better as it limits the amount of code that you are required to write and maintain.</p> <p>This tutorial will follow a mix of Flattened Data Layout and Hierarchy Data Layout. It is recommended to use one or the other, but not both. Both are used in this tutorial to demonstrate the flexibility of storing folders within folders on Synapse. With this example layout: <pre><code>.\n\u251c\u2500\u2500 experiment_notes\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 notes_2022\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 fileA.txt\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 fileB.txt\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 notes_2023\n\u2502\u00a0\u00a0     \u251c\u2500\u2500 fileC.txt\n\u2502\u00a0\u00a0     \u2514\u2500\u2500 fileD.txt\n\u251c\u2500\u2500 biospecimen_experiment_1\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 fileA.txt\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 fileB.txt\n\u251c\u2500\u2500 biospecimen_experiment_2\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 fileC.txt\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 fileD.txt\n\u251c\u2500\u2500 single_cell_RNAseq_batch_1\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 SRR12345678_R1.fastq.gz\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 SRR12345678_R2.fastq.gz\n\u2514\u2500\u2500 single_cell_RNAseq_batch_2\n    \u251c\u2500\u2500 SRR12345678_R1.fastq.gz\n    \u2514\u2500\u2500 SRR12345678_R2.fastq.gz\n</code></pre></p>"},{"location":"tutorials/python/folder/#tutorial-purpose","title":"Tutorial Purpose","text":"<p>In this tutorial you will:</p> <ol> <li>Create 4 new folders</li> <li>Print stored attributes about your folder</li> <li>Create 2 sub-folders</li> </ol>"},{"location":"tutorials/python/folder/#prerequisites","title":"Prerequisites","text":"<ul> <li>Make sure that you have completed the Project tutorial.</li> </ul>"},{"location":"tutorials/python/folder/#1-create-a-new-folder","title":"1. Create a new folder","text":"<pre><code># Step 1: Create a new folder\nimport synapseclient\nfrom synapseclient import Folder\n\nsyn = synapseclient.login()\n\n# Retrieve the project ID\nmy_project_id = syn.findEntityId(\n    name=\"My uniquely named project about Alzheimer's Disease\"\n)\n\n# Create a Folder object and store it\nmy_scrnaseq_batch_1_folder = Folder(\n    name=\"single_cell_RNAseq_batch_1\", parent=my_project_id\n)\nmy_scrnaseq_batch_1_folder = syn.store(obj=my_scrnaseq_batch_1_folder)\n\nmy_scrnaseq_batch_2_folder = Folder(\n    name=\"single_cell_RNAseq_batch_2\", parent=my_project_id\n)\nmy_scrnaseq_batch_2_folder = syn.store(obj=my_scrnaseq_batch_2_folder)\n\nbiospecimen_experiment_1_folder = Folder(\n    name=\"biospecimen_experiment_1\", parent=my_project_id\n)\nbiospecimen_experiment_1_folder = syn.store(obj=biospecimen_experiment_1_folder)\n\nbiospecimen_experiment_2_folder = Folder(\n    name=\"biospecimen_experiment_2\", parent=my_project_id\n)\nbiospecimen_experiment_2_folder = syn.store(obj=biospecimen_experiment_2_folder)\n</code></pre>"},{"location":"tutorials/python/folder/#2-print-stored-attributes-about-your-folder","title":"2. Print stored attributes about your folder","text":"<pre><code>biospecimen_experiment_2_folder = syn.store(obj=biospecimen_experiment_2_folder)\n\n# Step 2: Print stored attributes about your folder\nmy_scrnaseq_batch_1_folder_id = my_scrnaseq_batch_1_folder.id\nprint(f\"My folder ID is: {my_scrnaseq_batch_1_folder_id}\")\n\nprint(f\"The parent ID of my folder is: {my_scrnaseq_batch_1_folder.parentId}\")\n\nprint(f\"I created my folder on: {my_scrnaseq_batch_1_folder.createdOn}\")\n\nprint(\n    f\"The ID of the user that created my folder is: {my_scrnaseq_batch_1_folder.createdBy}\"\n)\n\nprint(f\"My folder was last modified on: {my_scrnaseq_batch_1_folder.modifiedOn}\")\n</code></pre> You'll notice the output looks like: <pre><code>My folder ID is: syn53205629\nThe parent ID of my folder is: syn53185532\nI created my folder on: 2023-12-28T20:52:50.193Z\nThe ID of the user that created my folder is: 3481671\nMy folder was last modified on: 2023-12-28T20:52:50.193Z\n</code></pre>"},{"location":"tutorials/python/folder/#3-create-2-sub-folders","title":"3. Create 2 sub-folders","text":"<pre><code>hierarchical_root_folder = Folder(name=\"experiment_notes\", parent=my_project_id)\nhierarchical_root_folder = syn.store(obj=hierarchical_root_folder)\n\nfolder_notes_2023 = Folder(name=\"notes_2023\", parent=hierarchical_root_folder.id)\nfolder_notes_2023 = syn.store(obj=folder_notes_2023)\n\nfolder_notes_2022 = Folder(name=\"notes_2022\", parent=hierarchical_root_folder.id)\nfolder_notes_2022 = syn.store(obj=folder_notes_2022)\n</code></pre>"},{"location":"tutorials/python/folder/#results","title":"Results","text":"<p>Now that you have created your folders you'll be able to inspect this on the Files tab of your project in the synapse web UI. It should look similar to:</p> <p></p>"},{"location":"tutorials/python/folder/#source-code-for-this-tutorial","title":"Source code for this tutorial","text":"Click to show me <pre><code>\"\"\"\nHere is where you'll find the code for the Folder tutorial.\n\"\"\"\n\n# Step 1: Create a new folder\nimport synapseclient\nfrom synapseclient import Folder\n\nsyn = synapseclient.login()\n\n# Retrieve the project ID\nmy_project_id = syn.findEntityId(\n    name=\"My uniquely named project about Alzheimer's Disease\"\n)\n\n# Create a Folder object and store it\nmy_scrnaseq_batch_1_folder = Folder(\n    name=\"single_cell_RNAseq_batch_1\", parent=my_project_id\n)\nmy_scrnaseq_batch_1_folder = syn.store(obj=my_scrnaseq_batch_1_folder)\n\nmy_scrnaseq_batch_2_folder = Folder(\n    name=\"single_cell_RNAseq_batch_2\", parent=my_project_id\n)\nmy_scrnaseq_batch_2_folder = syn.store(obj=my_scrnaseq_batch_2_folder)\n\nbiospecimen_experiment_1_folder = Folder(\n    name=\"biospecimen_experiment_1\", parent=my_project_id\n)\nbiospecimen_experiment_1_folder = syn.store(obj=biospecimen_experiment_1_folder)\n\nbiospecimen_experiment_2_folder = Folder(\n    name=\"biospecimen_experiment_2\", parent=my_project_id\n)\nbiospecimen_experiment_2_folder = syn.store(obj=biospecimen_experiment_2_folder)\n\n# Step 2: Print stored attributes about your folder\nmy_scrnaseq_batch_1_folder_id = my_scrnaseq_batch_1_folder.id\nprint(f\"My folder ID is: {my_scrnaseq_batch_1_folder_id}\")\n\nprint(f\"The parent ID of my folder is: {my_scrnaseq_batch_1_folder.parentId}\")\n\nprint(f\"I created my folder on: {my_scrnaseq_batch_1_folder.createdOn}\")\n\nprint(\n    f\"The ID of the user that created my folder is: {my_scrnaseq_batch_1_folder.createdBy}\"\n)\n\nprint(f\"My folder was last modified on: {my_scrnaseq_batch_1_folder.modifiedOn}\")\n\n# Step 3: Create 2 sub-folders\nhierarchical_root_folder = Folder(name=\"experiment_notes\", parent=my_project_id)\nhierarchical_root_folder = syn.store(obj=hierarchical_root_folder)\n\nfolder_notes_2023 = Folder(name=\"notes_2023\", parent=hierarchical_root_folder.id)\nfolder_notes_2023 = syn.store(obj=folder_notes_2023)\n\nfolder_notes_2022 = Folder(name=\"notes_2022\", parent=hierarchical_root_folder.id)\nfolder_notes_2022 = syn.store(obj=folder_notes_2022)\n</code></pre>"},{"location":"tutorials/python/folder/#references-used-in-this-tutorial","title":"References used in this tutorial","text":"<ul> <li>Folder</li> <li>syn.login</li> <li>syn.findEntityId</li> <li>syn.store</li> </ul>"},{"location":"tutorials/python/migrate_data_to_other_storage_locations/","title":"Migrating data to other store locations","text":""},{"location":"tutorials/python/move_files_and_folders/","title":"Moving files and folders","text":""},{"location":"tutorials/python/project/","title":"Projects in Synapse","text":"<p>Projects\u00a0in Synapse are \u201ccontainers\u201d that group relevant content and people together. All data must be uploaded into a project. Projects can be private so only you can see the contents, they can be shared with your collaborators, or they can be made public so anyone on the web can view your research.</p> <p>Read more about Projects</p> <p>Recommendations for Structuring Your Synapse Project</p>"},{"location":"tutorials/python/project/#tutorial-purpose","title":"Tutorial Purpose","text":"<p>In this tutorial you will:</p> <ol> <li>Create a new project</li> <li>Print stored attributes about your project</li> <li>Get an existing project</li> </ol>"},{"location":"tutorials/python/project/#prerequisites","title":"Prerequisites","text":"<ul> <li>Make sure that you have completed the Installation and Authentication setup.</li> </ul>"},{"location":"tutorials/python/project/#1-create-a-new-project","title":"1. Create a new project","text":"<pre><code>import synapseclient\nfrom synapseclient import Project\n\nsyn = synapseclient.login()\n\n# Project names must be globally unique\nproject = Project(name=\"My uniquely named project about Alzheimer's Disease\")\nproject = syn.store(obj=project)\n</code></pre> <p>Now that you have created your project you are able to inspect the project in the synapse web UI.</p>"},{"location":"tutorials/python/project/#2-print-stored-attributes-about-your-project","title":"2. Print stored attributes about your project","text":"<pre><code>my_synapse_project_id = project.id\nprint(f\"My project ID is: {my_synapse_project_id}\")\n\nproject_creation_date = project.createdOn\nprint(f\"I created my project on: {project.createdOn}\")\n\nuser_id_who_created_project = project.createdBy\nprint(f\"The ID of the user that created my project is: {user_id_who_created_project}\")\n\nproject_modified_on_date = project.modifiedOn\nprint(f\"My project was last modified on: {project_modified_on_date}\")\n</code></pre> You'll notice the output looks like: <pre><code>My project ID is: syn12345678\nI created my project on: 2000-01-01T12:00:00.001Z\nThe ID of the user that created my project is: 1234567\nMy project was last modified on: 2000-01-01T12:00:00.001Z\n</code></pre> <p>Find all of the available attributes about your project in the API Reference section of the documentation.</p>"},{"location":"tutorials/python/project/#3-get-an-existing-project","title":"3. Get an existing project","text":"<p>Each Project only needs to be created once. Since you've already created it you can access it again by retrieving the synapse ID of the project and retrieving the existing project object. <pre><code>my_project_id = syn.findEntityId(\n    name=\"My uniquely named project about Alzheimer's Disease\"\n)\nmy_project_object = syn.get(entity=my_project_id)\nprint(f\"I just got my project: {my_project_object.name}, id: {my_project_id}\")\n</code></pre></p> The result will look like: <pre><code>I just got my project: My uniquely named project about Alzheimer's Disease, id: syn12345678\n</code></pre>"},{"location":"tutorials/python/project/#source-code-for-this-tutorial","title":"Source code for this tutorial","text":"Click to show me <pre><code>\"\"\"\nHere is where you'll find the code for the Project tutorial.\n\"\"\"\n\n# Step 1: Create a new project\nimport synapseclient\nfrom synapseclient import Project\n\nsyn = synapseclient.login()\n\n# Project names must be globally unique\nproject = Project(name=\"My uniquely named project about Alzheimer's Disease\")\nproject = syn.store(obj=project)\n\n# Step 2: Print stored attributes about your project\nprint(f\"My project ID is: {project.id}\")\n\nprint(f\"I created my project on: {project.createdOn}\")\n\nprint(f\"The ID of the user that created my project is: {project.createdBy}\")\n\nprint(f\"My project was last modified on: {project.modifiedOn}\")\n\n# Step 3: Get an existing project\nmy_project_id = syn.findEntityId(\n    name=\"My uniquely named project about Alzheimer's Disease\"\n)\nmy_project_object = syn.get(entity=my_project_id)\nprint(f\"I just got my project: {my_project_object.name}, id: {my_project_id}\")\n</code></pre>"},{"location":"tutorials/python/project/#references-used-in-this-tutorial","title":"References used in this tutorial","text":"<ul> <li>Project</li> <li>syn.login</li> <li>syn.store</li> <li>syn.get</li> <li>syn.findEntityId</li> </ul>"},{"location":"tutorials/python/sharing_settings/","title":"Sharing Settings","text":""},{"location":"tutorials/python/table/","title":"Tables","text":""},{"location":"tutorials/python/table_crud/","title":"Using a Table (Create, Read, Update, Delete)","text":""},{"location":"tutorials/python/team/","title":"Teams","text":"<p> Teams allow you to easily manage groups of users to control access to projects, communicate with colleagues, and participate in challenges.</p> <p>In this tutorial you will:</p> <ul> <li>Create and manage a team</li> <li>Invite users to join a team</li> <li>Resend/Cancel an invitation to join a team</li> <li>Remove users from a team</li> </ul>"},{"location":"tutorials/python/upload_data_in_bulk/","title":"Uploading data in bulk","text":"<p>This tutorial will follow a Flattened Data Layout. With a project that has this example layout: <pre><code>.\n\u251c\u2500\u2500 biospecimen_experiment_1\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 fileA.txt\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 fileB.txt\n\u251c\u2500\u2500 biospecimen_experiment_2\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 fileC.txt\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 fileD.txt\n\u251c\u2500\u2500 single_cell_RNAseq_batch_1\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 SRR12345678_R1.fastq.gz\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 SRR12345678_R2.fastq.gz\n\u2514\u2500\u2500 single_cell_RNAseq_batch_2\n    \u251c\u2500\u2500 SRR12345678_R1.fastq.gz\n    \u2514\u2500\u2500 SRR12345678_R2.fastq.gz\n</code></pre></p>"},{"location":"tutorials/python/upload_data_in_bulk/#tutorial-purpose","title":"Tutorial Purpose","text":"<p>In this tutorial you will:</p> <ol> <li>Find the synapse ID of your project</li> <li>Create a manifest TSV file to upload data in bulk</li> <li>Upload all of the files for our project</li> <li>Add an annotation to all of our files</li> <li>Add a provenance/activity record to one of our files</li> </ol>"},{"location":"tutorials/python/upload_data_in_bulk/#prerequisites","title":"Prerequisites","text":"<ul> <li>Make sure that you have completed the following tutorials:<ul> <li>Project</li> </ul> </li> <li>This tutorial is setup to upload the data from <code>~/my_ad_project</code>, make sure that this or another desired directory exists.</li> <li>Pandas is used in this tutorial. Refer to our installation guide to install it. Feel free to skip this portion of the tutorial if you do not wish to use Pandas. You may also use external tools to open and manipulate Tab Separated Value (TSV) files.</li> </ul>"},{"location":"tutorials/python/upload_data_in_bulk/#1-find-the-synapse-id-of-your-project","title":"1. Find the synapse ID of your project","text":"<p>First let's set up some constants we'll use in this script, and find the ID of our project <pre><code>import os\n\nimport synapseclient\nimport synapseutils\n\nsyn = synapseclient.Synapse()\nsyn.login()\n\n# Create some constants to store the paths to the data\nDIRECTORY_FOR_MY_PROJECT = os.path.expanduser(os.path.join(\"~\", \"my_ad_project\"))\nPATH_TO_MANIFEST_FILE = os.path.expanduser(os.path.join(\"~\", \"manifest-for-upload.tsv\"))\n\n# Step 1: Let's find the synapse ID of our project:\nmy_project_id = syn.findEntityId(\n    name=\"My uniquely named project about Alzheimer's Disease\"\n</code></pre></p>"},{"location":"tutorials/python/upload_data_in_bulk/#2-create-a-manifest-tsv-file-to-upload-data-in-bulk","title":"2. Create a manifest TSV file to upload data in bulk","text":"<p>Let's \"walk\" our directory on disk to create a manifest file for upload <pre><code># Step 2: Create a manifest TSV file to upload data in bulk\n# Note: When this command is run it will re-create your directory structure within\n# Synapse. Be aware of this before running this command.\n# If folders with the exact names already exists in Synapse, those folders will be used.\nsynapseutils.generate_sync_manifest(\n    syn=syn,\n    directory_path=DIRECTORY_FOR_MY_PROJECT,\n    parent_id=my_project_id,\n    manifest_path=PATH_TO_MANIFEST_FILE,\n</code></pre></p> After this has been run if you inspect the TSV file created you'll see it will look similar to this: <pre><code>path    parent\n/home/user_name/my_ad_project/single_cell_RNAseq_batch_2/SRR12345678_R2.fastq.gz  syn60109537\n/home/user_name/my_ad_project/single_cell_RNAseq_batch_2/SRR12345678_R1.fastq.gz  syn60109537\n/home/user_name/my_ad_project/biospecimen_experiment_2/fileD.txt  syn60109543\n/home/user_name/my_ad_project/biospecimen_experiment_2/fileC.txt  syn60109543\n/home/user_name/my_ad_project/single_cell_RNAseq_batch_1/SRR12345678_R2.fastq.gz  syn60109534\n/home/user_name/my_ad_project/single_cell_RNAseq_batch_1/SRR12345678_R1.fastq.gz  syn60109534\n/home/user_name/my_ad_project/biospecimen_experiment_1/fileA.txt  syn60109540\n/home/user_name/my_ad_project/biospecimen_experiment_1/fileB.txt  syn60109540\n</code></pre>"},{"location":"tutorials/python/upload_data_in_bulk/#3-upload-the-data-in-bulk","title":"3. Upload the data in bulk","text":"<pre><code># Step 3: After generating the manifest file, we can upload the data in bulk\nsynapseutils.syncToSynapse(\n    syn=syn, manifestFile=PATH_TO_MANIFEST_FILE, sendMessages=False\n</code></pre> While this is running you'll see output in your console similar to: <pre><code>Validation and upload of: /home/user_name/manifest-for-upload.tsv\nValidating columns of manifest.....OK\nValidating that all paths exist...........OK\nValidating that all files are unique...OK\nValidating that all the files are not empty...OK\nValidating file names...\nOK\nValidating provenance...OK\nValidating that parents exist and are containers...OK\nWe are about to upload 8 files with a total size of 8.\nUploading 8 files: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 8.00/8.00 [00:01&lt;00:00, 6.09B/s]\n</code></pre>"},{"location":"tutorials/python/upload_data_in_bulk/#4-add-an-annotation-to-our-manifest-file","title":"4. Add an annotation to our manifest file","text":"<p>At this point in the tutorial we will start to use pandas to manipulate a TSV file. If you are not comfortable with pandas you may use any tool that can open and manipulate TSV such as excel or google sheets.</p> <pre><code># Step 4: Let's add an annotation to our manifest file\n# Pandas is a powerful data manipulation library in Python, although it is not required\n# for this tutorial, it is used here to demonstrate how you can manipulate the manifest\n# file before uploading it to Synapse.\nimport pandas as pd\n\n# Read TSV file into a pandas DataFrame\ndf = pd.read_csv(PATH_TO_MANIFEST_FILE, sep=\"\\t\")\n\n# Add a new column to the DataFrame\ndf[\"species\"] = \"Homo sapiens\"\n\n# Write the DataFrame back to the manifest file\ndf.to_csv(PATH_TO_MANIFEST_FILE, sep=\"\\t\", index=False)\n\nsynapseutils.syncToSynapse(\n    syn=syn,\n    manifestFile=PATH_TO_MANIFEST_FILE,\n    sendMessages=False,\n</code></pre> <p>Now that you have uploaded and annotated your files you'll be able to inspect your data on the Files tab of your project in the synapse web UI. Each file will have a single annotation that you added in the previous step. In more advanced workflows you'll likely need to build a more complex manifest file, but this should give you a good starting point.</p>"},{"location":"tutorials/python/upload_data_in_bulk/#5-create-an-activityprovenance","title":"5. Create an Activity/Provenance","text":"<p>Let's create an Activity/Provenance record for one of our files. In otherwords, we will record the steps taken to generate the file.</p> <p>In this code we are finding a row in our TSV file and pointing to the file path of another file within our manifest. By doing this we are creating a relationship between the two files. This is a simple example of how you can create a provenance record in Synapse. Additionally we'll link off to a sample URL that describes a process that we may have executed to generate the file.</p> <pre><code># Step 5: Let's create an Activity/Provenance\n# First let's find the row in the TSV we want to update. This code finds the row number\n# that we would like to update.\nrow_index = df[\n    df[\"path\"] == f\"{DIRECTORY_FOR_MY_PROJECT}/biospecimen_experiment_1/fileA.txt\"\n].index\n\n\n# After finding the row we want to update let's go ahead and add a relationship to\n# another file in our manifest. This allows us to say \"We used 'this' file in some way\".\ndf.loc[\n    row_index, \"used\"\n] = f\"{DIRECTORY_FOR_MY_PROJECT}/single_cell_RNAseq_batch_1/SRR12345678_R1.fastq.gz\"\n\n# Let's also link to the pipeline that we ran in order to produce these results. In a\n# real scenario you may want to link to a specific run of the tool where the results\n# were produced.\ndf.loc[row_index, \"executed\"] = \"https://nf-co.re/rnaseq/3.14.0\"\n\n# Let's also add a description for this Activity/Provenance\ndf.loc[\n    row_index, \"activityDescription\"\n] = \"Experiment results created as a result of the linked data while running the pipeline.\"\n\n# Write the DataFrame back to the manifest file\ndf.to_csv(PATH_TO_MANIFEST_FILE, sep=\"\\t\", index=False)\n\nsynapseutils.syncToSynapse(\n    syn=syn,\n    manifestFile=PATH_TO_MANIFEST_FILE,\n    sendMessages=False,\n</code></pre> <p>After running this code we may again inspect the synapse web UI. In this screenshot i've navigated to the Files tab and selected the file that we added a Provenance record to.</p> <p></p> <p></p>"},{"location":"tutorials/python/upload_data_in_bulk/#source-code-for-this-tutorial","title":"Source code for this tutorial","text":"Click to show me <pre><code>\"\"\"\nHere is where you'll find the code for the uploading data in bulk tutorial.\n\"\"\"\n\nimport os\n\nimport synapseclient\nimport synapseutils\n\nsyn = synapseclient.Synapse()\nsyn.login()\n\n# Create some constants to store the paths to the data\nDIRECTORY_FOR_MY_PROJECT = os.path.expanduser(os.path.join(\"~\", \"my_ad_project\"))\nPATH_TO_MANIFEST_FILE = os.path.expanduser(os.path.join(\"~\", \"manifest-for-upload.tsv\"))\n\n# Step 1: Let's find the synapse ID of our project:\nmy_project_id = syn.findEntityId(\n    name=\"My uniquely named project about Alzheimer's Disease\"\n)\n\n# Step 2: Create a manifest TSV file to upload data in bulk\n# Note: When this command is run it will re-create your directory structure within\n# Synapse. Be aware of this before running this command.\n# If folders with the exact names already exists in Synapse, those folders will be used.\nsynapseutils.generate_sync_manifest(\n    syn=syn,\n    directory_path=DIRECTORY_FOR_MY_PROJECT,\n    parent_id=my_project_id,\n    manifest_path=PATH_TO_MANIFEST_FILE,\n)\n\n# Step 3: After generating the manifest file, we can upload the data in bulk\nsynapseutils.syncToSynapse(\n    syn=syn, manifestFile=PATH_TO_MANIFEST_FILE, sendMessages=False\n)\n\n# Step 4: Let's add an annotation to our manifest file\n# Pandas is a powerful data manipulation library in Python, although it is not required\n# for this tutorial, it is used here to demonstrate how you can manipulate the manifest\n# file before uploading it to Synapse.\nimport pandas as pd\n\n# Read TSV file into a pandas DataFrame\ndf = pd.read_csv(PATH_TO_MANIFEST_FILE, sep=\"\\t\")\n\n# Add a new column to the DataFrame\ndf[\"species\"] = \"Homo sapiens\"\n\n# Write the DataFrame back to the manifest file\ndf.to_csv(PATH_TO_MANIFEST_FILE, sep=\"\\t\", index=False)\n\nsynapseutils.syncToSynapse(\n    syn=syn,\n    manifestFile=PATH_TO_MANIFEST_FILE,\n    sendMessages=False,\n)\n\n# Step 5: Let's create an Activity/Provenance\n# First let's find the row in the TSV we want to update. This code finds the row number\n# that we would like to update.\nrow_index = df[\n    df[\"path\"] == f\"{DIRECTORY_FOR_MY_PROJECT}/biospecimen_experiment_1/fileA.txt\"\n].index\n\n\n# After finding the row we want to update let's go ahead and add a relationship to\n# another file in our manifest. This allows us to say \"We used 'this' file in some way\".\ndf.loc[\n    row_index, \"used\"\n] = f\"{DIRECTORY_FOR_MY_PROJECT}/single_cell_RNAseq_batch_1/SRR12345678_R1.fastq.gz\"\n\n# Let's also link to the pipeline that we ran in order to produce these results. In a\n# real scenario you may want to link to a specific run of the tool where the results\n# were produced.\ndf.loc[row_index, \"executed\"] = \"https://nf-co.re/rnaseq/3.14.0\"\n\n# Let's also add a description for this Activity/Provenance\ndf.loc[\n    row_index, \"activityDescription\"\n] = \"Experiment results created as a result of the linked data while running the pipeline.\"\n\n# Write the DataFrame back to the manifest file\ndf.to_csv(PATH_TO_MANIFEST_FILE, sep=\"\\t\", index=False)\n\nsynapseutils.syncToSynapse(\n    syn=syn,\n    manifestFile=PATH_TO_MANIFEST_FILE,\n    sendMessages=False,\n)\n</code></pre>"},{"location":"tutorials/python/upload_data_in_bulk/#references-used-in-this-tutorial","title":"References used in this tutorial","text":"<ul> <li>syn.login</li> <li>syn.findEntityId</li> <li>synapseutils.generate_sync_manifest</li> <li>synapseutils.syncToSynapse</li> <li>Activity/Provenance</li> </ul>"},{"location":"tutorials/python/versions/","title":"Versions","text":"<p>See the current available tutorial</p> <p></p>"},{"location":"tutorials/python/wiki/","title":"Wikis on Projects","text":""}]}